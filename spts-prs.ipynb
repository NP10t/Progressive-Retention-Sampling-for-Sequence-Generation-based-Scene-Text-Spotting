{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!git clone https://github.com/shannanyinxiang/SPTS.git","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-10T13:31:21.957162Z","iopub.execute_input":"2024-07-10T13:31:21.957694Z","iopub.status.idle":"2024-07-10T13:31:23.741186Z","shell.execute_reply.started":"2024-07-10T13:31:21.957661Z","shell.execute_reply":"2024-07-10T13:31:23.740042Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!conda init bash\n!conda create -n spts python=3.7 -y","metadata":{"execution":{"iopub.status.busy":"2024-07-10T13:31:23.744241Z","iopub.execute_input":"2024-07-10T13:31:23.744624Z","iopub.status.idle":"2024-07-10T13:32:36.915161Z","shell.execute_reply.started":"2024-07-10T13:31:23.744588Z","shell.execute_reply":"2024-07-10T13:32:36.914053Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!conda env list","metadata":{"execution":{"iopub.status.busy":"2024-07-10T13:32:36.916708Z","iopub.execute_input":"2024-07-10T13:32:36.917403Z","iopub.status.idle":"2024-07-10T13:32:38.387605Z","shell.execute_reply.started":"2024-07-10T13:32:36.917363Z","shell.execute_reply":"2024-07-10T13:32:38.386719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!source /opt/conda/bin/activate spts","metadata":{"execution":{"iopub.status.busy":"2024-07-10T13:32:38.389042Z","iopub.execute_input":"2024-07-10T13:32:38.389443Z","iopub.status.idle":"2024-07-10T13:32:39.565450Z","shell.execute_reply.started":"2024-07-10T13:32:38.389406Z","shell.execute_reply":"2024-07-10T13:32:39.564250Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!conda install ipykernel -y","metadata":{"execution":{"iopub.status.busy":"2024-07-10T13:32:39.568191Z","iopub.execute_input":"2024-07-10T13:32:39.568499Z","iopub.status.idle":"2024-07-10T13:34:12.880810Z","shell.execute_reply.started":"2024-07-10T13:32:39.568469Z","shell.execute_reply":"2024-07-10T13:34:12.879618Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install gdown\nimport gdown\nimport os","metadata":{"execution":{"iopub.status.busy":"2024-07-10T13:34:12.882298Z","iopub.execute_input":"2024-07-10T13:34:12.882591Z","iopub.status.idle":"2024-07-10T13:34:27.382304Z","shell.execute_reply.started":"2024-07-10T13:34:12.882562Z","shell.execute_reply":"2024-07-10T13:34:27.381462Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd SPTS","metadata":{"execution":{"iopub.status.busy":"2024-07-10T13:34:27.383478Z","iopub.execute_input":"2024-07-10T13:34:27.383906Z","iopub.status.idle":"2024-07-10T13:34:27.390729Z","shell.execute_reply.started":"2024-07-10T13:34:27.383876Z","shell.execute_reply":"2024-07-10T13:34:27.389692Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(os.getcwd())","metadata":{"execution":{"iopub.status.busy":"2024-07-10T13:34:27.392039Z","iopub.execute_input":"2024-07-10T13:34:27.392596Z","iopub.status.idle":"2024-07-10T13:34:27.402411Z","shell.execute_reply.started":"2024-07-10T13:34:27.392570Z","shell.execute_reply":"2024-07-10T13:34:27.401629Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"env_path = \"/opt/conda/envs/spts\"\nPYTHON = os.path.join(env_path, \"bin\", \"python\")\n# PYTHON = \"/kaggle/working/SPTS\"","metadata":{"execution":{"iopub.status.busy":"2024-07-10T13:34:27.403880Z","iopub.execute_input":"2024-07-10T13:34:27.404188Z","iopub.status.idle":"2024-07-10T13:34:27.414505Z","shell.execute_reply.started":"2024-07-10T13:34:27.404152Z","shell.execute_reply":"2024-07-10T13:34:27.413488Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!{PYTHON} -m pip install torch==1.8.1 torchvision==0.9.1 torchaudio==0.8.1\n# !conda install pytorch==1.8.1 torchvision==0.9.1 torchaudio==0.8.1 -c pytorch","metadata":{"execution":{"iopub.status.busy":"2024-07-10T13:34:27.415777Z","iopub.execute_input":"2024-07-10T13:34:27.416231Z","iopub.status.idle":"2024-07-10T13:35:16.491480Z","shell.execute_reply.started":"2024-07-10T13:34:27.416196Z","shell.execute_reply":"2024-07-10T13:35:16.490492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"requirements = open(\"requirements.txt\", \"w\")\nrequirements.write('''bezier\nopencv-python\nPillow==8.2.0\npycocotools\ntqdm\neditdistance\nshapely''')\nrequirements.close()\n!{PYTHON} -m pip install -r requirements.txt","metadata":{"execution":{"iopub.status.busy":"2024-07-10T13:35:16.492914Z","iopub.execute_input":"2024-07-10T13:35:16.493248Z","iopub.status.idle":"2024-07-10T13:35:29.126822Z","shell.execute_reply.started":"2024-07-10T13:35:16.493217Z","shell.execute_reply":"2024-07-10T13:35:29.125901Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"url = 'https://drive.google.com/uc?id=1HuhbtL_pp-Qj2T7dLzKPgv7ypTQjgxRM'\ngdown.download(url, 'ic15.pth', quiet=False)","metadata":{"execution":{"iopub.status.busy":"2024-07-10T13:35:29.128200Z","iopub.execute_input":"2024-07-10T13:35:29.128514Z","iopub.status.idle":"2024-07-10T13:35:29.134791Z","shell.execute_reply.started":"2024-07-10T13:35:29.128484Z","shell.execute_reply":"2024-07-10T13:35:29.133941Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# url = 'https://drive.google.com/uc?id=12XFwSlZvNQ-_I16bSWgbnmD7-jMqR-CW'\n# gdown.download(url, 'ke2ne5.pth', quiet=False)","metadata":{"execution":{"iopub.status.busy":"2024-07-10T13:35:29.135836Z","iopub.execute_input":"2024-07-10T13:35:29.136112Z","iopub.status.idle":"2024-07-10T13:35:39.847010Z","shell.execute_reply.started":"2024-07-10T13:35:29.136089Z","shell.execute_reply":"2024-07-10T13:35:39.846192Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mkdir data","metadata":{"execution":{"iopub.status.busy":"2024-07-10T13:35:39.851784Z","iopub.execute_input":"2024-07-10T13:35:39.852084Z","iopub.status.idle":"2024-07-10T13:35:40.855264Z","shell.execute_reply.started":"2024-07-10T13:35:39.852059Z","shell.execute_reply":"2024-07-10T13:35:40.853961Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# %cd data\n# %mkdir totaltext_val\n# %cd ..","metadata":{"execution":{"iopub.status.busy":"2024-07-10T13:35:40.856753Z","iopub.execute_input":"2024-07-10T13:35:40.857061Z","iopub.status.idle":"2024-07-10T13:35:40.861394Z","shell.execute_reply.started":"2024-07-10T13:35:40.857031Z","shell.execute_reply":"2024-07-10T13:35:40.860338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !ls ./data/icdar2015","metadata":{"execution":{"iopub.status.busy":"2024-07-10T13:35:40.862572Z","iopub.execute_input":"2024-07-10T13:35:40.862828Z","iopub.status.idle":"2024-07-10T13:35:40.871380Z","shell.execute_reply.started":"2024-07-10T13:35:40.862805Z","shell.execute_reply":"2024-07-10T13:35:40.870439Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd data\n!gdown 1THhzo_WH1RY5DlGdBfjRA_dwu9tAmQUE\n!unzip icdar2015.zip\n%cd ..","metadata":{"execution":{"iopub.status.busy":"2024-07-10T13:35:40.872663Z","iopub.execute_input":"2024-07-10T13:35:40.873089Z","iopub.status.idle":"2024-07-10T13:35:48.659343Z","shell.execute_reply.started":"2024-07-10T13:35:40.873059Z","shell.execute_reply":"2024-07-10T13:35:48.658109Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !{PYTHON} main.py --eval --data_root ./data/ --val_dataset ic15_val --output_folder ./ --resume ./ic15.pth --tfm_pre_norm --visualize","metadata":{"execution":{"iopub.status.busy":"2024-07-10T13:35:48.660977Z","iopub.execute_input":"2024-07-10T13:35:48.661394Z","iopub.status.idle":"2024-07-10T13:35:48.666320Z","shell.execute_reply.started":"2024-07-10T13:35:48.661340Z","shell.execute_reply":"2024-07-10T13:35:48.665378Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !ls ./results/ep349/vis","metadata":{"execution":{"iopub.status.busy":"2024-07-10T13:35:48.667638Z","iopub.execute_input":"2024-07-10T13:35:48.668000Z","iopub.status.idle":"2024-07-10T13:35:48.875557Z","shell.execute_reply.started":"2024-07-10T13:35:48.667967Z","shell.execute_reply":"2024-07-10T13:35:48.874651Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import matplotlib.pyplot as plt\n# import matplotlib.image as mpimg","metadata":{"execution":{"iopub.status.busy":"2024-07-10T13:35:48.876726Z","iopub.execute_input":"2024-07-10T13:35:48.877064Z","iopub.status.idle":"2024-07-10T13:35:48.887770Z","shell.execute_reply.started":"2024-07-10T13:35:48.877023Z","shell.execute_reply":"2024-07-10T13:35:48.886975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# image_path = \"./results/ep349/vis/img_9.jpg\"\n\n# img = mpimg.imread(image_path)\n\n# fig = plt.figure(figsize=(10, 10))\n\n# print(f\"Image shape: {img.shape}\")\n\n# plt.imshow(img)\n# plt.axis('off')\n\n# plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-07-10T13:35:48.888913Z","iopub.execute_input":"2024-07-10T13:35:48.889265Z","iopub.status.idle":"2024-07-10T13:35:48.897860Z","shell.execute_reply.started":"2024-07-10T13:35:48.889235Z","shell.execute_reply":"2024-07-10T13:35:48.897055Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lr_scheduler = open('./optim/lr_scheduler.py', 'w')\nlr_scheduler.write('''import warnings\nfrom torch.optim.lr_scheduler import _LRScheduler\n\nclass LinearDecayLR(_LRScheduler):\n    def __init__(self, optimizer, args, last_epoch=-1, verbose=False):\n        if args.finetune:\n            self.lrs = [args.lr] * (args.epochs + 1)\n        else:\n            warmup_lr = [args.warmup_min_lr + ((args.lr - args.warmup_min_lr) * i / args.warmup_epochs) for i in range(args.warmup_epochs)]\n            decay_lr = [max(i * args.lr / args.epochs, args.min_lr) for i in range(args.epochs - args.warmup_epochs)]\n            decay_lr.reverse()\n            self.lrs = warmup_lr + decay_lr + decay_lr[-1:]\n        \n        self.lr_backbone_ratio = args.lr_backbone_ratio\n        \n        for param_group in optimizer.param_groups:\n            param_group['initial_lr'] = 0.00001\n        \n        \n        super(LinearDecayLR, self).__init__(optimizer, last_epoch, verbose)\n    \n    def get_lr(self):\n        if not self._get_lr_called_within_step:\n            warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n                        \"please use `get_last_lr()`.\", UserWarning) \n\n        lr = self.lrs[self.last_epoch]\n        return [lr, lr * self.lr_backbone_ratio]\n''')\nlr_scheduler.close()","metadata":{"execution":{"iopub.status.busy":"2024-07-10T13:35:48.898875Z","iopub.execute_input":"2024-07-10T13:35:48.899193Z","iopub.status.idle":"2024-07-10T13:35:48.909297Z","shell.execute_reply.started":"2024-07-10T13:35:48.899163Z","shell.execute_reply":"2024-07-10T13:35:48.908584Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tfm = open('model/transformer.py', 'w')\ntfm.write('''import copy\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nfrom typing import Optional\nfrom torch import nn, Tensor\n\ndef convert_hs_to_indices(hs, vocab_embed):\n    # Lấy output của lớp cuối cùng và chuyển đổi kích thước\n    hs_last_layer = hs[-1]  # shape: (163, 2, 256)\n    hs_reshaped = hs_last_layer.transpose(0, 1)  # shape: (2, 163, 256)\n    \n    # Áp dụng vocab_embed\n    logits = vocab_embed(hs_reshaped)  # shape: (2, 163, vocab_size)\n    \n    # Tìm chỉ số có xác suất cao nhất\n    _, indices = torch.max(logits, dim=-1)  # shape: (2, 163)\n    \n    return indices\n    \ndef mixer(previous_input, predicted_indices, sos_index, eos_index, pad_index, max_len, k):\n    batch_size, seq_len = predicted_indices.shape\n    \n    sample_mask = torch.ones(seq_len, device=predicted_indices.device, dtype=torch.bool)\n    sample_mask[0] = False\n    \n    # Thêm SOS token\n    # next_input = torch.full((batch_size, 1), sos_index, device=predicted_indices.device)\n    # formatted = torch.cat([formatted, predicted_indices], dim=1)\n    # formatted = formatted[:, :max_len]\n    \n    next_input = torch.ones((batch_size, seq_len), device=predicted_indices.device, dtype=torch.long)\n    \n    #for b in range(batch_size):\n    i = 0\n    while(i + 10 < seq_len):\n        sample_mask[i+1:i + 2 + k*4 + 1] = False\n        i += 27\n        \n    # print(sample_mask)\n    \n    for i in range(seq_len):\n        if sample_mask[i] == False:\n            # print(i, previous_input[:, i].shape)\n            next_input[:, i] = previous_input[:, i]\n        else:\n            next_input[:, i] = predicted_indices[:, i-1]\n        # if i == 0 or i == 2:\n        #     print \n            \n    return next_input\n\n\nclass Transformer(nn.Module):\n\n    def __init__(self, d_model, nhead, num_encoder_layers, num_decoder_layers, dim_feedforward, \n                 dropout, normalize_before, pad_token_id, num_classes, max_position_embeddings, \n                 return_intermediate_dec, num_bins, eos_index, activation=\"relu\"):\n        super(Transformer, self).__init__()\n        self.embedding = DecoderEmbeddings(num_classes, d_model, pad_token_id, max_position_embeddings, dropout)\n        if num_encoder_layers > 0:\n            encoder_layer = TransformerEncoderLayer(d_model, nhead, dim_feedforward,\n                                                    dropout, activation, normalize_before)\n            encoder_norm = nn.LayerNorm(d_model) if normalize_before else None\n            self.encoder = TransformerEncoder(encoder_layer, num_encoder_layers, encoder_norm)\n\n        decoder_layer = TransformerDecoderLayer(d_model, nhead, dim_feedforward,\n                                                dropout, activation, normalize_before)\n        decoder_norm = nn.LayerNorm(d_model)\n        self.decoder = TransformerDecoder(decoder_layer, num_decoder_layers, decoder_norm,\n                                        return_intermediate=return_intermediate_dec)\n        self._reset_parameters()\n\n        self.nhead = nhead\n        self.d_model = d_model\n        self.num_bins = num_bins\n        self.eos_index = eos_index\n        self.num_encoder_layers = num_encoder_layers\n        self.max_position_embeddings = max_position_embeddings\n\n    def _reset_parameters(self):\n        for p in self.parameters():\n            if p.dim() > 1:\n                nn.init.xavier_uniform_(p)\n\n    def forward(self, src, mask, pos_embed, seq, vocab_embed):\n        # flatten NxCxHxW to HWxNxC\n        bs, c, h, w = src.shape\n        src = src.flatten(2).permute(2, 0, 1)\n        pos_embed = pos_embed.flatten(2).permute(2, 0, 1)\n        mask = mask.flatten(1)\n        if self.num_encoder_layers > 0:\n            memory = self.encoder(src, src_key_padding_mask=mask, pos=pos_embed.half())\n        else:\n            memory = src\n\n        query_embed = self.embedding.position_embeddings.weight.unsqueeze(1)\n        query_embed = query_embed.repeat(1, bs, 1)\n        if self.training:\n            with torch.no_grad():\n                for i in range(3):\n                    # print(i)\n                    tgt = self.embedding(seq).permute(1, 0, 2)\n                    hs = self.decoder(tgt, memory, memory_key_padding_mask=mask,\n                                  pos=pos_embed, query_pos=query_embed[:len(tgt)],\n                                  tgt_mask=generate_square_subsequent_mask(len(tgt)).to(tgt.device))\n\n                    predicted_indices = convert_hs_to_indices(hs, vocab_embed)\n                    seq = mixer(seq, predicted_indices, sos_index=1098, eos_index=1097, pad_index=1096, max_len=hs.shape[1], k=i)\n            \n            tgt = self.embedding(seq).permute(1, 0, 2)\n            hs = self.decoder(tgt, memory, memory_key_padding_mask=mask,\n                              pos=pos_embed, query_pos=query_embed[:len(tgt)],\n                              tgt_mask=generate_square_subsequent_mask(len(tgt)).to(tgt.device))\n\n            return vocab_embed(hs[-1].transpose(0, 1))\n        else:\n            probs = []\n            for i in range(self.max_position_embeddings):\n                tgt = self.embedding(seq).permute(1, 0, 2)\n                hs = self.decoder(tgt, memory, memory_key_padding_mask=mask,\n                          pos=pos_embed, query_pos=query_embed[:len(tgt)],\n                          tgt_mask=generate_square_subsequent_mask(len(tgt)).to(tgt.device))\n                out = vocab_embed(hs.transpose(1, 2)[-1, :, -1, :])\n                out = out.softmax(-1)\n\n                # bins chars eos sos padding\n                if i % 27 == 0: # coordinate or eos\n                    out[:, self.num_bins:self.eos_index] = 0\n                    out[:, self.eos_index+1:] = 0\n                elif i % 27 == 1: # coordinate\n                    out = out[:, :self.num_bins]\n                else: # chars\n                    out[:, :self.num_bins] = 0\n                    out[:, self.eos_index:] = 0\n\n                prob, extra_seq = out.topk(dim=-1, k=1)\n                seq = torch.cat([seq, extra_seq], dim=-1)\n                probs.append(prob)                \n                if extra_seq[0] == self.eos_index:\n                    break\n            \n            seq = seq[:, 1:] # remove start index\n            return seq, torch.cat(probs, dim=-1)\n\n\nclass DecoderEmbeddings(nn.Module):\n    def __init__(self, vocab_size, hidden_dim, pad_token_id, max_position_embeddings, dropout):\n        super(DecoderEmbeddings, self).__init__()\n        self.word_embeddings = nn.Embedding(vocab_size, hidden_dim, padding_idx=pad_token_id)\n        self.position_embeddings = nn.Embedding(max_position_embeddings, hidden_dim)\n\n        self.LayerNorm = torch.nn.LayerNorm(hidden_dim)\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, x):\n        input_shape = x.size()\n        seq_length = input_shape[1]\n        device = x.device\n\n        position_ids = torch.arange(seq_length, dtype=torch.long, device=device)\n        position_ids = position_ids.unsqueeze(0).expand(input_shape)\n\n        input_embeds = self.word_embeddings(x)\n        position_embeds = self.position_embeddings(position_ids)\n\n        embeddings = input_embeds + position_embeds\n        embeddings = self.LayerNorm(embeddings)\n        embeddings = self.dropout(embeddings)\n\n        return embeddings\n\n\ndef generate_square_subsequent_mask(sz):\n    r\"\"\"Generate a square mask for the sequence. The masked positions are filled with float('-inf').\n        Unmasked positions are filled with float(0.0).\n    \"\"\"\n    mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n    return mask\n\n\nclass TransformerEncoder(nn.Module):\n\n    def __init__(self, encoder_layer, num_layers, norm=None):\n        super(TransformerEncoder, self).__init__()\n        self.layers = _get_clones(encoder_layer, num_layers)\n        self.num_layers = num_layers\n        self.norm = norm\n\n    def forward(self, src,\n                mask: Optional[Tensor] = None,\n                src_key_padding_mask: Optional[Tensor] = None,\n                pos: Optional[Tensor] = None):\n        output = src\n\n        for layer in self.layers:\n            output = layer(output, src_mask=mask,\n                           src_key_padding_mask=src_key_padding_mask, pos=pos)\n\n        if self.norm is not None:\n            output = self.norm(output)\n\n        return output\n\n\nclass TransformerDecoder(nn.Module):\n\n    def __init__(self, decoder_layer, num_layers, norm=None, return_intermediate=False):\n        super(TransformerDecoder, self).__init__()\n        self.layers = _get_clones(decoder_layer, num_layers)\n        self.num_layers = num_layers\n        self.norm = norm\n        self.return_intermediate = return_intermediate\n\n    def forward(self, tgt, memory,\n                tgt_mask: Optional[Tensor] = None,\n                memory_mask: Optional[Tensor] = None,\n                tgt_key_padding_mask: Optional[Tensor] = None,\n                memory_key_padding_mask: Optional[Tensor] = None,\n                pos: Optional[Tensor] = None,\n                query_pos: Optional[Tensor] = None):\n        output = tgt\n\n        intermediate = []\n\n        for layer in self.layers:\n            output = layer(output, memory, tgt_mask=tgt_mask,\n                           memory_mask=memory_mask,\n                           tgt_key_padding_mask=tgt_key_padding_mask,\n                           memory_key_padding_mask=memory_key_padding_mask,\n                           pos=pos, query_pos=query_pos)\n            if self.return_intermediate:\n                intermediate.append(self.norm(output))\n\n        if self.norm is not None:\n            output = self.norm(output)\n            if self.return_intermediate:\n                intermediate.pop()\n                intermediate.append(output)\n\n        if self.return_intermediate:\n            return torch.stack(intermediate)\n            \n        # print(\"HAHAHA\")\n\n        return output.unsqueeze(0)\n\n\nclass TransformerEncoderLayer(nn.Module):\n\n    def __init__(self, d_model, nhead, dim_feedforward=2048, dropout=0.1,\n                 activation=\"relu\", normalize_before=False):\n        super(TransformerEncoderLayer, self).__init__()\n        self.self_attn = nn.MultiheadAttention(d_model, nhead, dropout=dropout)\n        # Implementation of Feedforward model\n        self.linear1 = nn.Linear(d_model, dim_feedforward)\n        self.dropout = nn.Dropout(dropout)\n        self.linear2 = nn.Linear(dim_feedforward, d_model)\n\n        self.norm1 = nn.LayerNorm(d_model)\n        self.norm2 = nn.LayerNorm(d_model)\n        self.dropout1 = nn.Dropout(dropout)\n        self.dropout2 = nn.Dropout(dropout)\n\n        self.activation = _get_activation_fn(activation)\n        self.normalize_before = normalize_before\n\n    def with_pos_embed(self, tensor, pos: Optional[Tensor]):\n        return tensor if pos is None else tensor + pos\n\n    def forward_post(self,\n                     src,\n                     src_mask: Optional[Tensor] = None,\n                     src_key_padding_mask: Optional[Tensor] = None,\n                     pos: Optional[Tensor] = None):\n        q = k = self.with_pos_embed(src, pos)\n        src2 = self.self_attn(q, k, value=src, attn_mask=src_mask,\n                              key_padding_mask=src_key_padding_mask)[0]\n        src = src + self.dropout1(src2)\n        src = self.norm1(src)\n        src2 = self.linear2(self.dropout(self.activation(self.linear1(src))))\n        src = src + self.dropout2(src2)\n        src = self.norm2(src)\n        return src\n\n    def forward_pre(self, src,\n                    src_mask: Optional[Tensor] = None,\n                    src_key_padding_mask: Optional[Tensor] = None,\n                    pos: Optional[Tensor] = None):\n        src2 = self.norm1(src)\n        q = k = self.with_pos_embed(src2, pos)\n        src2 = self.self_attn(q, k, value=src2, attn_mask=src_mask,\n                              key_padding_mask=src_key_padding_mask)[0]\n        src = src + self.dropout1(src2)\n        src2 = self.norm2(src)\n        src2 = self.linear2(self.dropout(self.activation(self.linear1(src2))))\n        src = src + self.dropout2(src2)\n        return src\n\n    def forward(self, src,\n                src_mask: Optional[Tensor] = None,\n                src_key_padding_mask: Optional[Tensor] = None,\n                pos: Optional[Tensor] = None):\n        if self.normalize_before:\n            return self.forward_pre(src, src_mask, src_key_padding_mask, pos)\n        return self.forward_post(src, src_mask, src_key_padding_mask, pos)\n\n\nclass TransformerDecoderLayer(nn.Module):\n\n    def __init__(self, d_model, nhead, dim_feedforward=2048, dropout=0.1,\n                 activation=\"relu\", normalize_before=False):\n        super(TransformerDecoderLayer, self).__init__()\n        self.self_attn = nn.MultiheadAttention(d_model, nhead, dropout=dropout)\n        self.multihead_attn = nn.MultiheadAttention(d_model, nhead, dropout=dropout)\n        # Implementation of Feedforward model\n        self.linear1 = nn.Linear(d_model, dim_feedforward)\n        self.dropout = nn.Dropout(dropout)\n        self.linear2 = nn.Linear(dim_feedforward, d_model)\n\n        self.norm1 = nn.LayerNorm(d_model)\n        self.norm2 = nn.LayerNorm(d_model)\n        self.norm3 = nn.LayerNorm(d_model)\n        self.dropout1 = nn.Dropout(dropout)\n        self.dropout2 = nn.Dropout(dropout)\n        self.dropout3 = nn.Dropout(dropout)\n\n        self.activation = _get_activation_fn(activation)\n        self.normalize_before = normalize_before\n\n    def with_pos_embed(self, tensor, pos: Optional[Tensor]):\n        return tensor if pos is None else tensor + pos\n\n    def forward_post(self, tgt, memory,\n                     tgt_mask: Optional[Tensor] = None,\n                     memory_mask: Optional[Tensor] = None,\n                     tgt_key_padding_mask: Optional[Tensor] = None,\n                     memory_key_padding_mask: Optional[Tensor] = None,\n                     pos: Optional[Tensor] = None,\n                     query_pos: Optional[Tensor] = None):\n        q = k = self.with_pos_embed(tgt, query_pos)\n        tgt2 = self.self_attn(q, k, value=tgt, attn_mask=tgt_mask,\n                              key_padding_mask=tgt_key_padding_mask)[0]\n        tgt = tgt + self.dropout1(tgt2)\n        tgt = self.norm1(tgt)\n        tgt2 = self.multihead_attn(query=self.with_pos_embed(tgt, query_pos),\n                                   key=self.with_pos_embed(memory, pos),\n                                   value=memory, attn_mask=memory_mask,\n                                   key_padding_mask=memory_key_padding_mask)[0]\n        tgt = tgt + self.dropout2(tgt2)\n        tgt = self.norm2(tgt)\n        tgt2 = self.linear2(self.dropout(self.activation(self.linear1(tgt))))\n        tgt = tgt + self.dropout3(tgt2)\n        tgt = self.norm3(tgt)\n        return tgt\n\n    def forward_pre(self, tgt, memory,\n                    tgt_mask: Optional[Tensor] = None,\n                    memory_mask: Optional[Tensor] = None,\n                    tgt_key_padding_mask: Optional[Tensor] = None,\n                    memory_key_padding_mask: Optional[Tensor] = None,\n                    pos: Optional[Tensor] = None,\n                    query_pos: Optional[Tensor] = None):\n        tgt2 = self.norm1(tgt)\n        q = k = self.with_pos_embed(tgt2, query_pos)\n        tgt2 = self.self_attn(q, k, value=tgt2, attn_mask=tgt_mask,\n                              key_padding_mask=tgt_key_padding_mask)[0]\n        tgt = tgt + self.dropout1(tgt2)\n        tgt2 = self.norm2(tgt)\n        tgt2 = self.multihead_attn(query=self.with_pos_embed(tgt2, query_pos),\n                                   key=self.with_pos_embed(memory, pos),\n                                   value=memory, attn_mask=memory_mask,\n                                   key_padding_mask=memory_key_padding_mask)[0]\n        tgt = tgt + self.dropout2(tgt2)\n        tgt2 = self.norm3(tgt)\n        tgt2 = self.linear2(self.dropout(self.activation(self.linear1(tgt2))))\n        tgt = tgt + self.dropout3(tgt2)\n        return tgt\n\n    def forward(self, tgt, memory,\n                tgt_mask: Optional[Tensor] = None,\n                memory_mask: Optional[Tensor] = None,\n                tgt_key_padding_mask: Optional[Tensor] = None,\n                memory_key_padding_mask: Optional[Tensor] = None,\n                pos: Optional[Tensor] = None,\n                query_pos: Optional[Tensor] = None):\n        if self.normalize_before:\n            return self.forward_pre(tgt, memory, tgt_mask, memory_mask,\n                                    tgt_key_padding_mask, memory_key_padding_mask, pos, query_pos)\n        return self.forward_post(tgt, memory, tgt_mask, memory_mask,\n                                 tgt_key_padding_mask, memory_key_padding_mask, pos, query_pos)\n\n\ndef _get_clones(module, N):\n    return nn.ModuleList([copy.deepcopy(module) for i in range(N)])\n\n\ndef build_transformer(args):\n    max_position_embeddings = (2 + 25) * args.max_num_text_ins + 1\n    return Transformer(\n        d_model=args.tfm_hidden_dim,\n        nhead=args.tfm_nheads,\n        num_encoder_layers=args.tfm_enc_layers,\n        num_decoder_layers=args.tfm_dec_layers,\n        dim_feedforward=args.tfm_dim_feedforward,\n        dropout=args.tfm_dropout,\n        normalize_before=args.tfm_pre_norm,\n        pad_token_id=args.padding_index,\n        num_classes=args.num_classes,\n        max_position_embeddings=max_position_embeddings,\n        return_intermediate_dec=False,\n        num_bins=args.num_bins,\n        eos_index=args.eos_index,\n    )\n\n\ndef _get_activation_fn(activation):\n    \"\"\"Return an activation function given a string\"\"\"\n    if activation == \"relu\":\n        return F.relu\n    if activation == \"gelu\":\n        return F.gelu\n    if activation == \"glu\":\n        return F.glu\n    raise RuntimeError(F\"activation should be relu/gelu, not {activation}.\")\n''')\ntfm.close()","metadata":{"execution":{"iopub.status.busy":"2024-07-10T13:35:48.910699Z","iopub.execute_input":"2024-07-10T13:35:48.910968Z","iopub.status.idle":"2024-07-10T13:35:48.933757Z","shell.execute_reply.started":"2024-07-10T13:35:48.910944Z","shell.execute_reply":"2024-07-10T13:35:48.933018Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!{PYTHON} -m torch.distributed.launch --nproc_per_node=2 main.py --data_root ./data/ --train_dataset ic15_train --output_folder ./output/icdar2015/ --resume ./ic15.pth --lr 0.00001 --epochs 371 --checkpoint_freq 5 --freeze_bn --batch_aug --tfm_pre_norm --finetune ","metadata":{"execution":{"iopub.status.busy":"2024-07-10T13:35:48.934649Z","iopub.execute_input":"2024-07-10T13:35:48.934893Z","iopub.status.idle":"2024-07-10T13:35:48.950444Z","shell.execute_reply.started":"2024-07-10T13:35:48.934863Z","shell.execute_reply":"2024-07-10T13:35:48.949617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd evaluation\n!gdown 1ztyjczfn3YdBf6hpLuV2Vs2UJPlRdAjm\n!gdown 1JxmuDsOZ-x_WO5lck2ZQZHRcjoUtUiLo\n!unzip gt.zip\n!unzip lexicons.zip\n%cd ..","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 369","metadata":{}},{"cell_type":"code","source":"!{PYTHON} main.py --eval --data_root ./data/ --val_dataset ic15_val --output_folder ./ --resume ./output/icdar2015/checkpoints/checkpoint_ep0369.pth --tfm_pre_norm --visualize","metadata":{"execution":{"iopub.status.busy":"2024-07-10T13:35:57.816692Z","iopub.execute_input":"2024-07-10T13:35:57.817639Z","iopub.status.idle":"2024-07-10T13:46:55.080086Z","shell.execute_reply.started":"2024-07-10T13:35:57.817599Z","shell.execute_reply":"2024-07-10T13:46:55.079065Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!{PYTHON} evaluation/eval.py --result_path results/ep369/ic15_val.json --with_lexicon --lexicon_type 0 # used for ICDAR2013 and ICDAR2015. 0: Generic; 1: Weak; 2: Strong.","metadata":{"execution":{"iopub.status.busy":"2024-07-10T14:04:29.728481Z","iopub.execute_input":"2024-07-10T14:04:29.729279Z","iopub.status.idle":"2024-07-10T14:04:45.494150Z","shell.execute_reply.started":"2024-07-10T14:04:29.729242Z","shell.execute_reply":"2024-07-10T14:04:45.493192Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!{PYTHON} evaluation/eval.py --result_path results/ep369/ic15_val.json --with_lexicon --lexicon_type 1 # used for ICDAR2013 and ICDAR2015. 0: Generic; 1: Weak; 2: Strong.","metadata":{"execution":{"iopub.status.busy":"2024-07-10T13:50:48.214112Z","iopub.execute_input":"2024-07-10T13:50:48.214526Z","iopub.status.idle":"2024-07-10T13:50:49.234104Z","shell.execute_reply.started":"2024-07-10T13:50:48.214490Z","shell.execute_reply":"2024-07-10T13:50:49.233187Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!{PYTHON} evaluation/eval.py --result_path results/ep369/ic15_val.json --with_lexicon --lexicon_type 2 # used for ICDAR2013 and ICDAR2015. 0: Generic; 1: Weak; 2: Strong.","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 364","metadata":{}},{"cell_type":"code","source":"!{PYTHON} main.py --eval --data_root ./data/ --val_dataset ic15_val --output_folder ./ --resume ./output/icdar2015/checkpoints/checkpoint_ep0364.pth --tfm_pre_norm --visualize","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!{PYTHON} evaluation/eval.py --result_path results/ep364/ic15_val.json --with_lexicon --lexicon_type 0 # used for ICDAR2013 and ICDAR2015. 0: Generic; 1: Weak; 2: Strong.","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!{PYTHON} evaluation/eval.py --result_path results/ep364/ic15_val.json --with_lexicon --lexicon_type 1 # used for ICDAR2013 and ICDAR2015. 0: Generic; 1: Weak; 2: Strong.","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!{PYTHON} evaluation/eval.py --result_path results/ep364/ic15_val.json --with_lexicon --lexicon_type 2 # used for ICDAR2013 and ICDAR2015. 0: Generic; 1: Weak; 2: Strong.","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 359","metadata":{}},{"cell_type":"code","source":"!{PYTHON} main.py --eval --data_root ./data/ --val_dataset ic15_val --output_folder ./ --resume ./output/icdar2015/checkpoints/checkpoint_ep0359.pth --tfm_pre_norm --visualize","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!{PYTHON} evaluation/eval.py --result_path results/ep359/ic15_val.json --with_lexicon --lexicon_type 0 # used for ICDAR2013 and ICDAR2015. 0: Generic; 1: Weak; 2: Strong.","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!{PYTHON} evaluation/eval.py --result_path results/ep359/ic15_val.json --with_lexicon --lexicon_type 1 # used for ICDAR2013 and ICDAR2015. 0: Generic; 1: Weak; 2: Strong.","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!{PYTHON} evaluation/eval.py --result_path results/ep359/ic15_val.json --with_lexicon --lexicon_type 2 # used for ICDAR2013 and ICDAR2015. 0: Generic; 1: Weak; 2: Strong.","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 354","metadata":{}},{"cell_type":"code","source":"!{PYTHON} main.py --eval --data_root ./data/ --val_dataset ic15_val --output_folder ./ --resume ./output/icdar2015/checkpoints/checkpoint_ep0354.pth --tfm_pre_norm --visualize","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!{PYTHON} evaluation/eval.py --result_path results/ep354/ic15_val.json --with_lexicon --lexicon_type 0 # used for ICDAR2013 and ICDAR2015. 0: Generic; 1: Weak; 2: Strong.","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!{PYTHON} evaluation/eval.py --result_path results/ep354/ic15_val.json --with_lexicon --lexicon_type 1 # used for ICDAR2013 and ICDAR2015. 0: Generic; 1: Weak; 2: Strong.","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!{PYTHON} evaluation/eval.py --result_path results/ep354/ic15_val.json --with_lexicon --lexicon_type 2 # used for ICDAR2013 and ICDAR2015. 0: Generic; 1: Weak; 2: Strong.","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# None","metadata":{}},{"cell_type":"code","source":"!{PYTHON} evaluation/eval.py --result_path results/ep369/ic15_val.json # --with_lexicon --lexicon_type 2 # used for ICDAR2013 and ICDAR2015. 0: Generic; 1: Weak; 2: Strong.","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!{PYTHON} evaluation/eval.py --result_path results/ep364/ic15_val.json # --with_lexicon --lexicon_type 2 # used for ICDAR2013 and ICDAR2015. 0: Generic; 1: Weak; 2: Strong.","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!{PYTHON} evaluation/eval.py --result_path results/ep359/ic15_val.json # --with_lexicon --lexicon_type 2 # used for ICDAR2013 and ICDAR2015. 0: Generic; 1: Weak; 2: Strong.","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!{PYTHON} evaluation/eval.py --result_path results/ep354/ic15_val.json # --with_lexicon --lexicon_type 2 # used for ICDAR2013 and ICDAR2015. 0: Generic; 1: Weak; 2: Strong.","metadata":{},"execution_count":null,"outputs":[]}]}