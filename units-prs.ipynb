{"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Chuẩn bị (tải checkpoint, tải datasets, tải thư viện...)","metadata":{"id":"cMN1czSrF8K2"}},{"cell_type":"code","source":"!git clone https://github.com/clovaai/units.git","metadata":{"id":"fD4UBs8CYLSo","outputId":"3de508ad-028e-4e0a-ab5a-3c873e3c7b44","execution":{"iopub.status.busy":"2024-07-15T10:44:27.665779Z","iopub.execute_input":"2024-07-15T10:44:27.666583Z","iopub.status.idle":"2024-07-15T10:44:30.943023Z","shell.execute_reply.started":"2024-07-15T10:44:27.666538Z","shell.execute_reply":"2024-07-15T10:44:30.941944Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Cloning into 'units'...\nremote: Enumerating objects: 112, done.\u001b[K\nremote: Counting objects: 100% (13/13), done.\u001b[K\nremote: Compressing objects: 100% (8/8), done.\u001b[K\nremote: Total 112 (delta 5), reused 5 (delta 5), pack-reused 99\u001b[K\nReceiving objects: 100% (112/112), 27.84 MiB | 27.75 MiB/s, done.\nResolving deltas: 100% (10/10), done.\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install gdown\nimport gdown\nimport os\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport shutil\nfrom IPython.display import FileLink","metadata":{"id":"uXy-1Qb72Y1M","outputId":"310428d2-d12b-451a-ad84-626580422042","execution":{"iopub.status.busy":"2024-07-15T10:44:30.945415Z","iopub.execute_input":"2024-07-15T10:44:30.945799Z","iopub.status.idle":"2024-07-15T10:44:45.383324Z","shell.execute_reply.started":"2024-07-15T10:44:30.945757Z","shell.execute_reply":"2024-07-15T10:44:45.382336Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting gdown\n  Downloading gdown-5.2.0-py3-none-any.whl.metadata (5.8 kB)\nRequirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (from gdown) (4.12.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from gdown) (3.13.1)\nRequirement already satisfied: requests[socks] in /opt/conda/lib/python3.10/site-packages (from gdown) (2.32.3)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from gdown) (4.66.4)\nRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4->gdown) (2.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (2024.2.2)\nRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (1.7.1)\nDownloading gdown-5.2.0-py3-none-any.whl (18 kB)\nInstalling collected packages: gdown\nSuccessfully installed gdown-5.2.0\n","output_type":"stream"}]},{"cell_type":"code","source":"%cd units\n# %cd ../","metadata":{"id":"kLRDpUBSK-FA","outputId":"82ebef65-48d0-4faf-b27e-0e8b6317b51e","execution":{"iopub.status.busy":"2024-07-15T10:44:45.384608Z","iopub.execute_input":"2024-07-15T10:44:45.385044Z","iopub.status.idle":"2024-07-15T10:44:45.391533Z","shell.execute_reply.started":"2024-07-15T10:44:45.385016Z","shell.execute_reply":"2024-07-15T10:44:45.390416Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"/kaggle/working/units\n","output_type":"stream"}]},{"cell_type":"code","source":"print(os.getcwd())","metadata":{"execution":{"iopub.status.busy":"2024-07-15T10:44:45.393557Z","iopub.execute_input":"2024-07-15T10:44:45.393870Z","iopub.status.idle":"2024-07-15T10:44:45.403194Z","shell.execute_reply.started":"2024-07-15T10:44:45.393845Z","shell.execute_reply":"2024-07-15T10:44:45.402195Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"/kaggle/working/units\n","output_type":"stream"}]},{"cell_type":"code","source":"requirements = open(\"requirements.txt\", \"w\")\nrequirements.write('''torch\ntorchvision\npydantic==1.9.0\ntensorfn\nopencv-python==4.6.0.66\nlmdb==1.3.0\nShapely==1.8.1.post1\nPillow==9.0.1\nblack==23.3.0\nrapidfuzz==2.9.0\nPolygon3==3.0.9.1\neditdistance==0.6.2\nmatplotlib\norjson\nnumpy\nwandb\npycocotools''')\nrequirements.close()\n!pip install -r requirements.txt","metadata":{"execution":{"iopub.status.busy":"2024-07-15T10:44:45.404361Z","iopub.execute_input":"2024-07-15T10:44:45.404858Z","iopub.status.idle":"2024-07-15T10:45:21.809706Z","shell.execute_reply.started":"2024-07-15T10:44:45.404827Z","shell.execute_reply":"2024-07-15T10:45:21.808774Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 1)) (2.1.2)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 2)) (0.16.2)\nCollecting pydantic==1.9.0 (from -r requirements.txt (line 3))\n  Downloading pydantic-1.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (121 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.8/121.8 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hCollecting tensorfn (from -r requirements.txt (line 4))\n  Downloading tensorfn-0.1.28-py3-none-any.whl.metadata (441 bytes)\nCollecting opencv-python==4.6.0.66 (from -r requirements.txt (line 5))\n  Downloading opencv_python-4.6.0.66-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\nCollecting lmdb==1.3.0 (from -r requirements.txt (line 6))\n  Downloading lmdb-1.3.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (1.1 kB)\nCollecting Shapely==1.8.1.post1 (from -r requirements.txt (line 7))\n  Downloading Shapely-1.8.1.post1-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (41 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting Pillow==9.0.1 (from -r requirements.txt (line 8))\n  Downloading Pillow-9.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.6 kB)\nCollecting black==23.3.0 (from -r requirements.txt (line 9))\n  Downloading black-23.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting rapidfuzz==2.9.0 (from -r requirements.txt (line 10))\n  Downloading rapidfuzz-2.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.1 kB)\nCollecting Polygon3==3.0.9.1 (from -r requirements.txt (line 11))\n  Downloading Polygon3-3.0.9.1.tar.gz (39 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting editdistance==0.6.2 (from -r requirements.txt (line 12))\n  Downloading editdistance-0.6.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 13)) (3.7.5)\nRequirement already satisfied: orjson in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 14)) (3.9.10)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 15)) (1.26.4)\nRequirement already satisfied: wandb in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 16)) (0.17.0)\nCollecting pycocotools (from -r requirements.txt (line 17))\n  Downloading pycocotools-2.0.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.1 kB)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from pydantic==1.9.0->-r requirements.txt (line 3)) (4.9.0)\nRequirement already satisfied: click>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from black==23.3.0->-r requirements.txt (line 9)) (8.1.7)\nRequirement already satisfied: mypy-extensions>=0.4.3 in /opt/conda/lib/python3.10/site-packages (from black==23.3.0->-r requirements.txt (line 9)) (1.0.0)\nCollecting packaging>=22.0 (from black==23.3.0->-r requirements.txt (line 9))\n  Downloading packaging-24.1-py3-none-any.whl.metadata (3.2 kB)\nCollecting pathspec>=0.9.0 (from black==23.3.0->-r requirements.txt (line 9))\n  Downloading pathspec-0.12.1-py3-none-any.whl.metadata (21 kB)\nRequirement already satisfied: platformdirs>=2 in /opt/conda/lib/python3.10/site-packages (from black==23.3.0->-r requirements.txt (line 9)) (3.11.0)\nRequirement already satisfied: tomli>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from black==23.3.0->-r requirements.txt (line 9)) (2.0.1)\nCollecting jarowinkler<2.0.0,>=1.2.0 (from rapidfuzz==2.9.0->-r requirements.txt (line 10))\n  Downloading jarowinkler-1.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->-r requirements.txt (line 1)) (3.13.1)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->-r requirements.txt (line 1)) (1.12.1)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->-r requirements.txt (line 1)) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->-r requirements.txt (line 1)) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->-r requirements.txt (line 1)) (2024.3.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchvision->-r requirements.txt (line 2)) (2.32.3)\nCollecting pyhocon>=0.3.54 (from tensorfn->-r requirements.txt (line 4))\n  Downloading pyhocon-0.3.61-py3-none-any.whl.metadata (1.2 kB)\nRequirement already satisfied: termcolor in /opt/conda/lib/python3.10/site-packages (from tensorfn->-r requirements.txt (line 4)) (2.4.0)\nRequirement already satisfied: tabulate in /opt/conda/lib/python3.10/site-packages (from tensorfn->-r requirements.txt (line 4)) (0.9.0)\nRequirement already satisfied: boto3 in /opt/conda/lib/python3.10/site-packages (from tensorfn->-r requirements.txt (line 4)) (1.26.100)\nRequirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from tensorfn->-r requirements.txt (line 4)) (13.7.0)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 13)) (1.2.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 13)) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 13)) (4.47.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 13)) (1.4.5)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 13)) (3.1.1)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 13)) (2.9.0.post0)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from wandb->-r requirements.txt (line 16)) (0.4.0)\nRequirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb->-r requirements.txt (line 16)) (3.1.41)\nRequirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /opt/conda/lib/python3.10/site-packages (from wandb->-r requirements.txt (line 16)) (3.20.3)\nRequirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb->-r requirements.txt (line 16)) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from wandb->-r requirements.txt (line 16)) (6.0.1)\nRequirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb->-r requirements.txt (line 16)) (2.3.1)\nRequirement already satisfied: setproctitle in /opt/conda/lib/python3.10/site-packages (from wandb->-r requirements.txt (line 16)) (1.3.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from wandb->-r requirements.txt (line 16)) (69.0.3)\nRequirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb->-r requirements.txt (line 16)) (1.16.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 16)) (4.0.11)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision->-r requirements.txt (line 2)) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision->-r requirements.txt (line 2)) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision->-r requirements.txt (line 2)) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision->-r requirements.txt (line 2)) (2024.2.2)\nCollecting botocore<1.30.0,>=1.29.100 (from boto3->tensorfn->-r requirements.txt (line 4))\n  Downloading botocore-1.29.165-py3-none-any.whl.metadata (5.9 kB)\nRequirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from boto3->tensorfn->-r requirements.txt (line 4)) (1.0.1)\nRequirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from boto3->tensorfn->-r requirements.txt (line 4)) (0.6.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->-r requirements.txt (line 1)) (2.1.3)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->tensorfn->-r requirements.txt (line 4)) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->tensorfn->-r requirements.txt (line 4)) (2.17.2)\nRequirement already satisfied: mpmath<1.4.0,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->-r requirements.txt (line 1)) (1.3.0)\nRequirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 16)) (5.0.1)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->tensorfn->-r requirements.txt (line 4)) (0.1.2)\nDownloading pydantic-1.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m57.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading opencv_python-4.6.0.66-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (60.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.9/60.9 MB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading lmdb-1.3.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (306 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m306.5/306.5 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading Shapely-1.8.1.post1-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m66.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading Pillow-9.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading black-23.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m58.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading rapidfuzz-2.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m57.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading editdistance-0.6.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (282 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m282.6/282.6 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tensorfn-0.1.28-py3-none-any.whl (51 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.2/51.2 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pycocotools-2.0.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (427 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m427.8/427.8 kB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading jarowinkler-1.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading packaging-24.1-py3-none-any.whl (53 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pathspec-0.12.1-py3-none-any.whl (31 kB)\nDownloading pyhocon-0.3.61-py3-none-any.whl (25 kB)\nDownloading botocore-1.29.165-py3-none-any.whl (11.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.0/11.0 MB\u001b[0m \u001b[31m64.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: Polygon3\n  Building wheel for Polygon3 (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for Polygon3: filename=Polygon3-3.0.9.1-cp310-cp310-linux_x86_64.whl size=47849 sha256=4bd36043a7925f0cbe33bc36703b8c9816f0046a8480aeb0e7170647727d1195\n  Stored in directory: /root/.cache/pip/wheels/d8/b7/f6/b4e24f56a1cc9856dca98cc2fdc3915d7649b39b62f3dbca9e\nSuccessfully built Polygon3\nInstalling collected packages: Polygon3, lmdb, Shapely, pyhocon, pydantic, Pillow, pathspec, packaging, opencv-python, jarowinkler, editdistance, rapidfuzz, botocore, black, pycocotools, tensorfn\n  Attempting uninstall: Shapely\n    Found existing installation: Shapely 1.8.5.post1\n    Uninstalling Shapely-1.8.5.post1:\n      Successfully uninstalled Shapely-1.8.5.post1\n  Attempting uninstall: pydantic\n    Found existing installation: pydantic 2.5.3\n    Uninstalling pydantic-2.5.3:\n      Successfully uninstalled pydantic-2.5.3\n  Attempting uninstall: Pillow\n    Found existing installation: Pillow 9.5.0\n    Uninstalling Pillow-9.5.0:\n      Successfully uninstalled Pillow-9.5.0\n  Attempting uninstall: packaging\n    Found existing installation: packaging 21.3\n    Uninstalling packaging-21.3:\n      Successfully uninstalled packaging-21.3\n  Attempting uninstall: opencv-python\n    Found existing installation: opencv-python 4.10.0.82\n    Uninstalling opencv-python-4.10.0.82:\n      Successfully uninstalled opencv-python-4.10.0.82\n  Attempting uninstall: botocore\n    Found existing installation: botocore 1.34.106\n    Uninstalling botocore-1.34.106:\n      Successfully uninstalled botocore-1.34.106\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf 24.4.1 requires cubinlinker, which is not installed.\ncudf 24.4.1 requires cupy-cuda11x>=12.0.0, which is not installed.\ncudf 24.4.1 requires ptxcompiler, which is not installed.\ncuml 24.4.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ndask-cudf 24.4.1 requires cupy-cuda11x>=12.0.0, which is not installed.\nkeras-cv 0.9.0 requires keras-core, which is not installed.\nkeras-nlp 0.12.1 requires keras-core, which is not installed.\ntensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\naiobotocore 2.13.0 requires aiohttp<4.0.0,>=3.9.2, but you have aiohttp 3.9.1 which is incompatible.\naiobotocore 2.13.0 requires botocore<1.34.107,>=1.34.70, but you have botocore 1.29.165 which is incompatible.\nalbumentations 1.4.0 requires opencv-python>=4.9.0, but you have opencv-python 4.6.0.66 which is incompatible.\ncudf 24.4.1 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.5.0 which is incompatible.\ndistributed 2024.1.1 requires dask==2024.1.1, but you have dask 2024.5.2 which is incompatible.\ngoogle-cloud-bigquery 2.34.4 requires packaging<22.0dev,>=14.3, but you have packaging 24.1 which is incompatible.\njupyterlab 4.2.1 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\njupyterlab-lsp 5.1.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\nlibpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.1.post1 which is incompatible.\nmomepy 0.7.0 requires shapely>=2, but you have shapely 1.8.1.post1 which is incompatible.\nosmnx 1.9.3 requires shapely>=2.0, but you have shapely 1.8.1.post1 which is incompatible.\nrapids-dask-dependency 24.4.1a0 requires dask==2024.1.1, but you have dask 2024.5.2 which is incompatible.\nrapids-dask-dependency 24.4.1a0 requires dask-expr==0.4.0, but you have dask-expr 1.1.2 which is incompatible.\nspopt 0.6.0 requires shapely>=2.0.1, but you have shapely 1.8.1.post1 which is incompatible.\ntensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.3.3 which is incompatible.\nydata-profiling 4.6.4 requires numpy<1.26,>=1.16.0, but you have numpy 1.26.4 which is incompatible.\nydata-profiling 4.6.4 requires pydantic>=2, but you have pydantic 1.9.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed Pillow-9.0.1 Polygon3-3.0.9.1 Shapely-1.8.1.post1 black-23.3.0 botocore-1.29.165 editdistance-0.6.2 jarowinkler-1.2.3 lmdb-1.3.0 opencv-python-4.6.0.66 packaging-24.1 pathspec-0.12.1 pycocotools-2.0.8 pydantic-1.9.0 pyhocon-0.3.61 rapidfuzz-2.9.0 tensorfn-0.1.28\n","output_type":"stream"}]},{"cell_type":"code","source":"%cd ./TC\n!gdown https://ultralytics.com/assets/Arial.ttf\n%cd ..","metadata":{"execution":{"iopub.status.busy":"2024-07-15T10:45:21.811096Z","iopub.execute_input":"2024-07-15T10:45:21.811405Z","iopub.status.idle":"2024-07-15T10:45:23.884907Z","shell.execute_reply.started":"2024-07-15T10:45:21.811374Z","shell.execute_reply":"2024-07-15T10:45:23.883719Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"/kaggle/working/units/TC\nDownloading...\nFrom: https://ultralytics.com/assets/Arial.ttf\nTo: /kaggle/working/units/TC/Arial.ttf\n100%|████████████████████████████████████████| 773k/773k [00:00<00:00, 16.1MB/s]\n/kaggle/working/units\n","output_type":"stream"}]},{"cell_type":"code","source":"# %cd checkpoints\n# url = 'https://drive.google.com/uc?id=1K0aFp113j9MyC5Y6F4cEzBzsA7LfEy7o'\n# gdown.download(url, 'EV5000.pt', quiet=False)\n# %cd ..","metadata":{"execution":{"iopub.status.busy":"2024-07-13T02:53:58.064963Z","iopub.execute_input":"2024-07-13T02:53:58.065305Z","iopub.status.idle":"2024-07-13T02:53:58.069684Z","shell.execute_reply.started":"2024-07-13T02:53:58.065274Z","shell.execute_reply":"2024-07-13T02:53:58.068790Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"%cd checkpoints\nurl = 'https://drive.google.com/uc?id=1fQzEgDoyP9yeUOYzKrhqE6xJ4Ptz_8yW'\ngdown.download(url, 'final6000.pt', quiet=False)\n%cd ..","metadata":{"execution":{"iopub.status.busy":"2024-07-15T10:48:03.707401Z","iopub.execute_input":"2024-07-15T10:48:03.707811Z","iopub.status.idle":"2024-07-15T10:48:18.916470Z","shell.execute_reply.started":"2024-07-15T10:48:03.707775Z","shell.execute_reply":"2024-07-15T10:48:18.915560Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"/kaggle/working/units/checkpoints\n","output_type":"stream"},{"name":"stderr","text":"Downloading...\nFrom (original): https://drive.google.com/uc?id=1fQzEgDoyP9yeUOYzKrhqE6xJ4Ptz_8yW\nFrom (redirected): https://drive.google.com/uc?id=1fQzEgDoyP9yeUOYzKrhqE6xJ4Ptz_8yW&confirm=t&uuid=f0e0dc80-bc8b-4b17-b8dc-edf26a6ae8ce\nTo: /kaggle/working/units/checkpoints/final6000.pt\n100%|██████████| 1.21G/1.21G [00:11<00:00, 104MB/s] ","output_type":"stream"},{"name":"stdout","text":"/kaggle/working/units\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"# %cd checkpoints\n# url = 'https://drive.google.com/uc?id=1g_LoKYqepQNSKPwR3ygzdLJhk-KRMoez'\n# gdown.download(url, 'totaltext.pt', quiet=False)\n# %cd ..","metadata":{"execution":{"iopub.status.busy":"2024-07-13T02:53:58.108956Z","iopub.execute_input":"2024-07-13T02:53:58.109257Z","iopub.status.idle":"2024-07-13T02:53:58.117714Z","shell.execute_reply.started":"2024-07-13T02:53:58.109234Z","shell.execute_reply":"2024-07-13T02:53:58.116951Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# %cd checkpoints\n# url = 'https://drive.google.com/uc?id=1D42rZo4HJBp6wTikkOvcHCAAM8EKaWWk'\n# gdown.download(url, 'cwt.pt', quiet=False)\n# %cd ..","metadata":{"execution":{"iopub.status.busy":"2024-07-13T02:53:58.118784Z","iopub.execute_input":"2024-07-13T02:53:58.119122Z","iopub.status.idle":"2024-07-13T02:53:58.126218Z","shell.execute_reply.started":"2024-07-13T02:53:58.119093Z","shell.execute_reply":"2024-07-13T02:53:58.125395Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# %cd checkpoints\n# url = 'https://drive.google.com/uc?id=1XEBRaEBp3IRnd1P3lkfpVbBIQZIThMF0'\n# gdown.download(url, 'shared.pt', quiet=False)\n# %cd ..","metadata":{"id":"pX7805hkonlv","outputId":"91e7329a-0738-459f-e168-7b881c5ba996","execution":{"iopub.status.busy":"2024-07-13T02:53:58.127222Z","iopub.execute_input":"2024-07-13T02:53:58.127494Z","iopub.status.idle":"2024-07-13T02:53:58.135666Z","shell.execute_reply.started":"2024-07-13T02:53:58.127460Z","shell.execute_reply":"2024-07-13T02:53:58.134887Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# %cd checkpoints\n# url = 'https://drive.google.com/uc?id=1c76n9QvysA30q31KMzrDoa7I9bqLuBSa'\n# gdown.download(url, 'ic15.pt', quiet=False)\n# %cd ..","metadata":{"id":"LqHmSYRhE1s8","outputId":"0e9fc215-bb24-44e2-d3ca-8e9df34f2484","execution":{"iopub.status.busy":"2024-07-13T02:53:58.136593Z","iopub.execute_input":"2024-07-13T02:53:58.136890Z","iopub.status.idle":"2024-07-13T02:53:58.147282Z","shell.execute_reply.started":"2024-07-13T02:53:58.136867Z","shell.execute_reply":"2024-07-13T02:53:58.146535Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# %cd checkpoints\n# url = 'https://drive.google.com/uc?id=1RSuCVDK7dge9KPjyBLuOCIcNVvLyFUhD'\n# gdown.download(url, 'splv2.pt', quiet=False)\n# %cd ..","metadata":{"execution":{"iopub.status.busy":"2024-07-13T02:53:58.148494Z","iopub.execute_input":"2024-07-13T02:53:58.148770Z","iopub.status.idle":"2024-07-13T02:54:20.197617Z","shell.execute_reply.started":"2024-07-13T02:53:58.148742Z","shell.execute_reply":"2024-07-13T02:54:20.196740Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"/kaggle/working/units/checkpoints\n","output_type":"stream"},{"name":"stderr","text":"Downloading...\nFrom (original): https://drive.google.com/uc?id=1RSuCVDK7dge9KPjyBLuOCIcNVvLyFUhD\nFrom (redirected): https://drive.google.com/uc?id=1RSuCVDK7dge9KPjyBLuOCIcNVvLyFUhD&confirm=t&uuid=92d8753f-1cea-4529-ad6a-600fedccc457\nTo: /kaggle/working/units/checkpoints/splv2.pt\n100%|██████████| 1.21G/1.21G [00:18<00:00, 66.9MB/s]\n","output_type":"stream"},{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"'splv2.pt'"},"metadata":{}}]},{"cell_type":"code","source":"# %cd checkpoints\n# url = 'https://drive.google.com/uc?id=1TWZc_uLLBCzV2evrxZBdaN4HI_8eGtMK'\n# gdown.download(url, 'textocr.pt', quiet=False)\n# %cd ..","metadata":{"id":"-QRdE0gOJin8","outputId":"7f34d6dc-a9b6-4479-a272-a3a2a23ac530","execution":{"iopub.status.busy":"2024-07-13T02:54:20.198947Z","iopub.execute_input":"2024-07-13T02:54:20.199402Z","iopub.status.idle":"2024-07-13T02:54:20.203762Z","shell.execute_reply.started":"2024-07-13T02:54:20.199369Z","shell.execute_reply":"2024-07-13T02:54:20.202819Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"# ICDAR 15","metadata":{}},{"cell_type":"code","source":"!mv train_datasets z_kophaitraidatasets1\n!gdown 1AY9cL645HfIsL-KMqBQz0NhkJs2rMhJ8\n!unzip train_datasets.zip\n!gdown 10OuB7tb3cDCqR1qfhTurR2u1gssnxyIl\n!gdown 1REd-FKj8Ot0xhikWkVh1Dns0Dixzemmz\n!mv ./train_datasets/annotations/icdar15/ICDAR2015_Incidental_test.json ./train_datasets/annotations/icdar15/KHONGPHAI_ICDAR2015_Incidental_test.json\n!mv ./train_datasets/annotations/icdar15/ICDAR2015_Incidental_train.json ./train_datasets/annotations/icdar15/KHONGPHAI_ICDAR2015_Incidental_train.json\n!mv ./testfromtxt.json ./train_datasets/annotations/icdar15\n!mv ./trainingfromtxt.json ./train_datasets/annotations/icdar15\n!mv ./train_datasets/annotations/icdar15/testfromtxt.json ./train_datasets/annotations/icdar15/ICDAR2015_Incidental_test.json\n!mv ./train_datasets/annotations/icdar15/trainingfromtxt.json ./train_datasets/annotations/icdar15/ICDAR2015_Incidental_train.json","metadata":{"id":"nFSVfOPOPRxA","execution":{"iopub.status.busy":"2024-07-15T10:48:39.135518Z","iopub.execute_input":"2024-07-15T10:48:39.136171Z","iopub.status.idle":"2024-07-15T10:49:09.559544Z","shell.execute_reply.started":"2024-07-15T10:48:39.136138Z","shell.execute_reply":"2024-07-15T10:49:09.558273Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Downloading...\nFrom (original): https://drive.google.com/uc?id=1AY9cL645HfIsL-KMqBQz0NhkJs2rMhJ8\nFrom (redirected): https://drive.google.com/uc?id=1AY9cL645HfIsL-KMqBQz0NhkJs2rMhJ8&confirm=t&uuid=2bb8a416-a4f5-47c2-b4eb-4af904e132e0\nTo: /kaggle/working/units/train_datasets.zip\n100%|████████████████████████████████████████| 136M/136M [00:03<00:00, 36.0MB/s]\nArchive:  train_datasets.zip\n   creating: train_datasets/annotations/\n   creating: train_datasets/annotations/icdar15/\n  inflating: train_datasets/annotations/icdar15/ICDAR2015_Incidental_test.json  \n  inflating: train_datasets/annotations/icdar15/ICDAR2015_Incidental_train.json  \n   creating: train_datasets/images/\n   creating: train_datasets/images/icdar15/\n   creating: train_datasets/images/icdar15/test/\n  inflating: train_datasets/images/icdar15/test/img_1.jpg  \n  inflating: train_datasets/images/icdar15/test/img_10.jpg  \n  inflating: train_datasets/images/icdar15/test/img_100.jpg  \n  inflating: train_datasets/images/icdar15/test/img_101.jpg  \n  inflating: train_datasets/images/icdar15/test/img_102.jpg  \n  inflating: train_datasets/images/icdar15/test/img_103.jpg  \n  inflating: train_datasets/images/icdar15/test/img_104.jpg  \n  inflating: train_datasets/images/icdar15/test/img_105.jpg  \n  inflating: train_datasets/images/icdar15/test/img_106.jpg  \n  inflating: train_datasets/images/icdar15/test/img_107.jpg  \n  inflating: train_datasets/images/icdar15/test/img_108.jpg  \n  inflating: train_datasets/images/icdar15/test/img_109.jpg  \n  inflating: train_datasets/images/icdar15/test/img_11.jpg  \n  inflating: train_datasets/images/icdar15/test/img_110.jpg  \n  inflating: train_datasets/images/icdar15/test/img_111.jpg  \n  inflating: train_datasets/images/icdar15/test/img_112.jpg  \n  inflating: train_datasets/images/icdar15/test/img_113.jpg  \n  inflating: train_datasets/images/icdar15/test/img_114.jpg  \n  inflating: train_datasets/images/icdar15/test/img_115.jpg  \n  inflating: train_datasets/images/icdar15/test/img_116.jpg  \n  inflating: train_datasets/images/icdar15/test/img_117.jpg  \n  inflating: train_datasets/images/icdar15/test/img_118.jpg  \n  inflating: train_datasets/images/icdar15/test/img_119.jpg  \n  inflating: train_datasets/images/icdar15/test/img_12.jpg  \n  inflating: train_datasets/images/icdar15/test/img_120.jpg  \n  inflating: train_datasets/images/icdar15/test/img_121.jpg  \n  inflating: train_datasets/images/icdar15/test/img_122.jpg  \n  inflating: train_datasets/images/icdar15/test/img_123.jpg  \n  inflating: train_datasets/images/icdar15/test/img_124.jpg  \n  inflating: train_datasets/images/icdar15/test/img_125.jpg  \n  inflating: train_datasets/images/icdar15/test/img_126.jpg  \n  inflating: train_datasets/images/icdar15/test/img_127.jpg  \n  inflating: train_datasets/images/icdar15/test/img_128.jpg  \n  inflating: train_datasets/images/icdar15/test/img_129.jpg  \n  inflating: train_datasets/images/icdar15/test/img_13.jpg  \n  inflating: train_datasets/images/icdar15/test/img_130.jpg  \n  inflating: train_datasets/images/icdar15/test/img_131.jpg  \n  inflating: train_datasets/images/icdar15/test/img_132.jpg  \n  inflating: train_datasets/images/icdar15/test/img_133.jpg  \n  inflating: train_datasets/images/icdar15/test/img_134.jpg  \n  inflating: train_datasets/images/icdar15/test/img_135.jpg  \n  inflating: train_datasets/images/icdar15/test/img_136.jpg  \n  inflating: train_datasets/images/icdar15/test/img_137.jpg  \n  inflating: train_datasets/images/icdar15/test/img_138.jpg  \n  inflating: train_datasets/images/icdar15/test/img_139.jpg  \n  inflating: train_datasets/images/icdar15/test/img_14.jpg  \n  inflating: train_datasets/images/icdar15/test/img_140.jpg  \n  inflating: train_datasets/images/icdar15/test/img_141.jpg  \n  inflating: train_datasets/images/icdar15/test/img_142.jpg  \n  inflating: train_datasets/images/icdar15/test/img_143.jpg  \n  inflating: train_datasets/images/icdar15/test/img_144.jpg  \n  inflating: train_datasets/images/icdar15/test/img_145.jpg  \n  inflating: train_datasets/images/icdar15/test/img_146.jpg  \n  inflating: train_datasets/images/icdar15/test/img_147.jpg  \n  inflating: train_datasets/images/icdar15/test/img_148.jpg  \n  inflating: train_datasets/images/icdar15/test/img_149.jpg  \n  inflating: train_datasets/images/icdar15/test/img_15.jpg  \n  inflating: train_datasets/images/icdar15/test/img_150.jpg  \n  inflating: train_datasets/images/icdar15/test/img_151.jpg  \n  inflating: train_datasets/images/icdar15/test/img_152.jpg  \n  inflating: train_datasets/images/icdar15/test/img_153.jpg  \n  inflating: train_datasets/images/icdar15/test/img_154.jpg  \n  inflating: train_datasets/images/icdar15/test/img_155.jpg  \n  inflating: train_datasets/images/icdar15/test/img_156.jpg  \n  inflating: train_datasets/images/icdar15/test/img_157.jpg  \n  inflating: train_datasets/images/icdar15/test/img_158.jpg  \n  inflating: train_datasets/images/icdar15/test/img_159.jpg  \n  inflating: train_datasets/images/icdar15/test/img_16.jpg  \n  inflating: train_datasets/images/icdar15/test/img_160.jpg  \n  inflating: train_datasets/images/icdar15/test/img_161.jpg  \n  inflating: train_datasets/images/icdar15/test/img_162.jpg  \n  inflating: train_datasets/images/icdar15/test/img_163.jpg  \n  inflating: train_datasets/images/icdar15/test/img_164.jpg  \n  inflating: train_datasets/images/icdar15/test/img_165.jpg  \n  inflating: train_datasets/images/icdar15/test/img_166.jpg  \n  inflating: train_datasets/images/icdar15/test/img_167.jpg  \n  inflating: train_datasets/images/icdar15/test/img_168.jpg  \n  inflating: train_datasets/images/icdar15/test/img_169.jpg  \n  inflating: train_datasets/images/icdar15/test/img_17.jpg  \n  inflating: train_datasets/images/icdar15/test/img_170.jpg  \n  inflating: train_datasets/images/icdar15/test/img_171.jpg  \n  inflating: train_datasets/images/icdar15/test/img_172.jpg  \n  inflating: train_datasets/images/icdar15/test/img_173.jpg  \n  inflating: train_datasets/images/icdar15/test/img_174.jpg  \n  inflating: train_datasets/images/icdar15/test/img_175.jpg  \n  inflating: train_datasets/images/icdar15/test/img_176.jpg  \n  inflating: train_datasets/images/icdar15/test/img_177.jpg  \n  inflating: train_datasets/images/icdar15/test/img_178.jpg  \n  inflating: train_datasets/images/icdar15/test/img_179.jpg  \n  inflating: train_datasets/images/icdar15/test/img_18.jpg  \n  inflating: train_datasets/images/icdar15/test/img_180.jpg  \n  inflating: train_datasets/images/icdar15/test/img_181.jpg  \n  inflating: train_datasets/images/icdar15/test/img_182.jpg  \n  inflating: train_datasets/images/icdar15/test/img_183.jpg  \n  inflating: train_datasets/images/icdar15/test/img_184.jpg  \n  inflating: train_datasets/images/icdar15/test/img_185.jpg  \n  inflating: train_datasets/images/icdar15/test/img_186.jpg  \n  inflating: train_datasets/images/icdar15/test/img_187.jpg  \n  inflating: train_datasets/images/icdar15/test/img_188.jpg  \n  inflating: train_datasets/images/icdar15/test/img_189.jpg  \n  inflating: train_datasets/images/icdar15/test/img_19.jpg  \n  inflating: train_datasets/images/icdar15/test/img_190.jpg  \n  inflating: train_datasets/images/icdar15/test/img_191.jpg  \n  inflating: train_datasets/images/icdar15/test/img_192.jpg  \n  inflating: train_datasets/images/icdar15/test/img_193.jpg  \n  inflating: train_datasets/images/icdar15/test/img_194.jpg  \n  inflating: train_datasets/images/icdar15/test/img_195.jpg  \n  inflating: train_datasets/images/icdar15/test/img_196.jpg  \n  inflating: train_datasets/images/icdar15/test/img_197.jpg  \n  inflating: train_datasets/images/icdar15/test/img_198.jpg  \n  inflating: train_datasets/images/icdar15/test/img_199.jpg  \n  inflating: train_datasets/images/icdar15/test/img_2.jpg  \n  inflating: train_datasets/images/icdar15/test/img_20.jpg  \n  inflating: train_datasets/images/icdar15/test/img_200.jpg  \n  inflating: train_datasets/images/icdar15/test/img_201.jpg  \n  inflating: train_datasets/images/icdar15/test/img_202.jpg  \n  inflating: train_datasets/images/icdar15/test/img_203.jpg  \n  inflating: train_datasets/images/icdar15/test/img_204.jpg  \n  inflating: train_datasets/images/icdar15/test/img_205.jpg  \n  inflating: train_datasets/images/icdar15/test/img_206.jpg  \n  inflating: train_datasets/images/icdar15/test/img_207.jpg  \n  inflating: train_datasets/images/icdar15/test/img_208.jpg  \n  inflating: train_datasets/images/icdar15/test/img_209.jpg  \n  inflating: train_datasets/images/icdar15/test/img_21.jpg  \n  inflating: train_datasets/images/icdar15/test/img_210.jpg  \n  inflating: train_datasets/images/icdar15/test/img_211.jpg  \n  inflating: train_datasets/images/icdar15/test/img_212.jpg  \n  inflating: train_datasets/images/icdar15/test/img_213.jpg  \n  inflating: train_datasets/images/icdar15/test/img_214.jpg  \n  inflating: train_datasets/images/icdar15/test/img_215.jpg  \n  inflating: train_datasets/images/icdar15/test/img_216.jpg  \n  inflating: train_datasets/images/icdar15/test/img_217.jpg  \n  inflating: train_datasets/images/icdar15/test/img_218.jpg  \n  inflating: train_datasets/images/icdar15/test/img_219.jpg  \n  inflating: train_datasets/images/icdar15/test/img_22.jpg  \n  inflating: train_datasets/images/icdar15/test/img_220.jpg  \n  inflating: train_datasets/images/icdar15/test/img_221.jpg  \n  inflating: train_datasets/images/icdar15/test/img_222.jpg  \n  inflating: train_datasets/images/icdar15/test/img_223.jpg  \n  inflating: train_datasets/images/icdar15/test/img_224.jpg  \n  inflating: train_datasets/images/icdar15/test/img_225.jpg  \n  inflating: train_datasets/images/icdar15/test/img_226.jpg  \n  inflating: train_datasets/images/icdar15/test/img_227.jpg  \n  inflating: train_datasets/images/icdar15/test/img_228.jpg  \n  inflating: train_datasets/images/icdar15/test/img_229.jpg  \n  inflating: train_datasets/images/icdar15/test/img_23.jpg  \n  inflating: train_datasets/images/icdar15/test/img_230.jpg  \n  inflating: train_datasets/images/icdar15/test/img_231.jpg  \n  inflating: train_datasets/images/icdar15/test/img_232.jpg  \n  inflating: train_datasets/images/icdar15/test/img_233.jpg  \n  inflating: train_datasets/images/icdar15/test/img_234.jpg  \n  inflating: train_datasets/images/icdar15/test/img_235.jpg  \n  inflating: train_datasets/images/icdar15/test/img_236.jpg  \n  inflating: train_datasets/images/icdar15/test/img_237.jpg  \n  inflating: train_datasets/images/icdar15/test/img_238.jpg  \n  inflating: train_datasets/images/icdar15/test/img_239.jpg  \n  inflating: train_datasets/images/icdar15/test/img_24.jpg  \n  inflating: train_datasets/images/icdar15/test/img_240.jpg  \n  inflating: train_datasets/images/icdar15/test/img_241.jpg  \n  inflating: train_datasets/images/icdar15/test/img_242.jpg  \n  inflating: train_datasets/images/icdar15/test/img_243.jpg  \n  inflating: train_datasets/images/icdar15/test/img_244.jpg  \n  inflating: train_datasets/images/icdar15/test/img_245.jpg  \n  inflating: train_datasets/images/icdar15/test/img_246.jpg  \n  inflating: train_datasets/images/icdar15/test/img_247.jpg  \n  inflating: train_datasets/images/icdar15/test/img_248.jpg  \n  inflating: train_datasets/images/icdar15/test/img_249.jpg  \n  inflating: train_datasets/images/icdar15/test/img_25.jpg  \n  inflating: train_datasets/images/icdar15/test/img_250.jpg  \n  inflating: train_datasets/images/icdar15/test/img_251.jpg  \n  inflating: train_datasets/images/icdar15/test/img_252.jpg  \n  inflating: train_datasets/images/icdar15/test/img_253.jpg  \n  inflating: train_datasets/images/icdar15/test/img_254.jpg  \n  inflating: train_datasets/images/icdar15/test/img_255.jpg  \n  inflating: train_datasets/images/icdar15/test/img_256.jpg  \n  inflating: train_datasets/images/icdar15/test/img_257.jpg  \n  inflating: train_datasets/images/icdar15/test/img_258.jpg  \n  inflating: train_datasets/images/icdar15/test/img_259.jpg  \n  inflating: train_datasets/images/icdar15/test/img_26.jpg  \n  inflating: train_datasets/images/icdar15/test/img_260.jpg  \n  inflating: train_datasets/images/icdar15/test/img_261.jpg  \n  inflating: train_datasets/images/icdar15/test/img_262.jpg  \n  inflating: train_datasets/images/icdar15/test/img_263.jpg  \n  inflating: train_datasets/images/icdar15/test/img_264.jpg  \n  inflating: train_datasets/images/icdar15/test/img_265.jpg  \n  inflating: train_datasets/images/icdar15/test/img_266.jpg  \n  inflating: train_datasets/images/icdar15/test/img_267.jpg  \n  inflating: train_datasets/images/icdar15/test/img_268.jpg  \n  inflating: train_datasets/images/icdar15/test/img_269.jpg  \n  inflating: train_datasets/images/icdar15/test/img_27.jpg  \n  inflating: train_datasets/images/icdar15/test/img_270.jpg  \n  inflating: train_datasets/images/icdar15/test/img_271.jpg  \n  inflating: train_datasets/images/icdar15/test/img_272.jpg  \n  inflating: train_datasets/images/icdar15/test/img_273.jpg  \n  inflating: train_datasets/images/icdar15/test/img_274.jpg  \n  inflating: train_datasets/images/icdar15/test/img_275.jpg  \n  inflating: train_datasets/images/icdar15/test/img_276.jpg  \n  inflating: train_datasets/images/icdar15/test/img_277.jpg  \n  inflating: train_datasets/images/icdar15/test/img_278.jpg  \n  inflating: train_datasets/images/icdar15/test/img_279.jpg  \n  inflating: train_datasets/images/icdar15/test/img_28.jpg  \n  inflating: train_datasets/images/icdar15/test/img_280.jpg  \n  inflating: train_datasets/images/icdar15/test/img_281.jpg  \n  inflating: train_datasets/images/icdar15/test/img_282.jpg  \n  inflating: train_datasets/images/icdar15/test/img_283.jpg  \n  inflating: train_datasets/images/icdar15/test/img_284.jpg  \n  inflating: train_datasets/images/icdar15/test/img_285.jpg  \n  inflating: train_datasets/images/icdar15/test/img_286.jpg  \n  inflating: train_datasets/images/icdar15/test/img_287.jpg  \n  inflating: train_datasets/images/icdar15/test/img_288.jpg  \n  inflating: train_datasets/images/icdar15/test/img_289.jpg  \n  inflating: train_datasets/images/icdar15/test/img_29.jpg  \n  inflating: train_datasets/images/icdar15/test/img_290.jpg  \n  inflating: train_datasets/images/icdar15/test/img_291.jpg  \n  inflating: train_datasets/images/icdar15/test/img_292.jpg  \n  inflating: train_datasets/images/icdar15/test/img_293.jpg  \n  inflating: train_datasets/images/icdar15/test/img_294.jpg  \n  inflating: train_datasets/images/icdar15/test/img_295.jpg  \n  inflating: train_datasets/images/icdar15/test/img_296.jpg  \n  inflating: train_datasets/images/icdar15/test/img_297.jpg  \n  inflating: train_datasets/images/icdar15/test/img_298.jpg  \n  inflating: train_datasets/images/icdar15/test/img_299.jpg  \n  inflating: train_datasets/images/icdar15/test/img_3.jpg  \n  inflating: train_datasets/images/icdar15/test/img_30.jpg  \n  inflating: train_datasets/images/icdar15/test/img_300.jpg  \n  inflating: train_datasets/images/icdar15/test/img_301.jpg  \n  inflating: train_datasets/images/icdar15/test/img_302.jpg  \n  inflating: train_datasets/images/icdar15/test/img_303.jpg  \n  inflating: train_datasets/images/icdar15/test/img_304.jpg  \n  inflating: train_datasets/images/icdar15/test/img_305.jpg  \n  inflating: train_datasets/images/icdar15/test/img_306.jpg  \n  inflating: train_datasets/images/icdar15/test/img_307.jpg  \n  inflating: train_datasets/images/icdar15/test/img_308.jpg  \n  inflating: train_datasets/images/icdar15/test/img_309.jpg  \n  inflating: train_datasets/images/icdar15/test/img_31.jpg  \n  inflating: train_datasets/images/icdar15/test/img_310.jpg  \n  inflating: train_datasets/images/icdar15/test/img_311.jpg  \n  inflating: train_datasets/images/icdar15/test/img_312.jpg  \n  inflating: train_datasets/images/icdar15/test/img_313.jpg  \n  inflating: train_datasets/images/icdar15/test/img_314.jpg  \n  inflating: train_datasets/images/icdar15/test/img_315.jpg  \n  inflating: train_datasets/images/icdar15/test/img_316.jpg  \n  inflating: train_datasets/images/icdar15/test/img_317.jpg  \n  inflating: train_datasets/images/icdar15/test/img_318.jpg  \n  inflating: train_datasets/images/icdar15/test/img_319.jpg  \n  inflating: train_datasets/images/icdar15/test/img_32.jpg  \n  inflating: train_datasets/images/icdar15/test/img_320.jpg  \n  inflating: train_datasets/images/icdar15/test/img_321.jpg  \n  inflating: train_datasets/images/icdar15/test/img_322.jpg  \n  inflating: train_datasets/images/icdar15/test/img_323.jpg  \n  inflating: train_datasets/images/icdar15/test/img_324.jpg  \n  inflating: train_datasets/images/icdar15/test/img_325.jpg  \n  inflating: train_datasets/images/icdar15/test/img_326.jpg  \n  inflating: train_datasets/images/icdar15/test/img_327.jpg  \n  inflating: train_datasets/images/icdar15/test/img_328.jpg  \n  inflating: train_datasets/images/icdar15/test/img_329.jpg  \n  inflating: train_datasets/images/icdar15/test/img_33.jpg  \n  inflating: train_datasets/images/icdar15/test/img_330.jpg  \n  inflating: train_datasets/images/icdar15/test/img_331.jpg  \n  inflating: train_datasets/images/icdar15/test/img_332.jpg  \n  inflating: train_datasets/images/icdar15/test/img_333.jpg  \n  inflating: train_datasets/images/icdar15/test/img_334.jpg  \n  inflating: train_datasets/images/icdar15/test/img_335.jpg  \n  inflating: train_datasets/images/icdar15/test/img_336.jpg  \n  inflating: train_datasets/images/icdar15/test/img_337.jpg  \n  inflating: train_datasets/images/icdar15/test/img_338.jpg  \n  inflating: train_datasets/images/icdar15/test/img_339.jpg  \n  inflating: train_datasets/images/icdar15/test/img_34.jpg  \n  inflating: train_datasets/images/icdar15/test/img_340.jpg  \n  inflating: train_datasets/images/icdar15/test/img_341.jpg  \n  inflating: train_datasets/images/icdar15/test/img_342.jpg  \n  inflating: train_datasets/images/icdar15/test/img_343.jpg  \n  inflating: train_datasets/images/icdar15/test/img_344.jpg  \n  inflating: train_datasets/images/icdar15/test/img_345.jpg  \n  inflating: train_datasets/images/icdar15/test/img_346.jpg  \n  inflating: train_datasets/images/icdar15/test/img_347.jpg  \n  inflating: train_datasets/images/icdar15/test/img_348.jpg  \n  inflating: train_datasets/images/icdar15/test/img_349.jpg  \n  inflating: train_datasets/images/icdar15/test/img_35.jpg  \n  inflating: train_datasets/images/icdar15/test/img_350.jpg  \n  inflating: train_datasets/images/icdar15/test/img_351.jpg  \n  inflating: train_datasets/images/icdar15/test/img_352.jpg  \n  inflating: train_datasets/images/icdar15/test/img_353.jpg  \n  inflating: train_datasets/images/icdar15/test/img_354.jpg  \n  inflating: train_datasets/images/icdar15/test/img_355.jpg  \n  inflating: train_datasets/images/icdar15/test/img_356.jpg  \n  inflating: train_datasets/images/icdar15/test/img_357.jpg  \n  inflating: train_datasets/images/icdar15/test/img_358.jpg  \n  inflating: train_datasets/images/icdar15/test/img_359.jpg  \n  inflating: train_datasets/images/icdar15/test/img_36.jpg  \n  inflating: train_datasets/images/icdar15/test/img_360.jpg  \n  inflating: train_datasets/images/icdar15/test/img_361.jpg  \n  inflating: train_datasets/images/icdar15/test/img_362.jpg  \n  inflating: train_datasets/images/icdar15/test/img_363.jpg  \n  inflating: train_datasets/images/icdar15/test/img_364.jpg  \n  inflating: train_datasets/images/icdar15/test/img_365.jpg  \n  inflating: train_datasets/images/icdar15/test/img_366.jpg  \n  inflating: train_datasets/images/icdar15/test/img_367.jpg  \n  inflating: train_datasets/images/icdar15/test/img_368.jpg  \n  inflating: train_datasets/images/icdar15/test/img_369.jpg  \n  inflating: train_datasets/images/icdar15/test/img_37.jpg  \n  inflating: train_datasets/images/icdar15/test/img_370.jpg  \n  inflating: train_datasets/images/icdar15/test/img_371.jpg  \n  inflating: train_datasets/images/icdar15/test/img_372.jpg  \n  inflating: train_datasets/images/icdar15/test/img_373.jpg  \n  inflating: train_datasets/images/icdar15/test/img_374.jpg  \n  inflating: train_datasets/images/icdar15/test/img_375.jpg  \n  inflating: train_datasets/images/icdar15/test/img_376.jpg  \n  inflating: train_datasets/images/icdar15/test/img_377.jpg  \n  inflating: train_datasets/images/icdar15/test/img_378.jpg  \n  inflating: train_datasets/images/icdar15/test/img_379.jpg  \n  inflating: train_datasets/images/icdar15/test/img_38.jpg  \n  inflating: train_datasets/images/icdar15/test/img_380.jpg  \n  inflating: train_datasets/images/icdar15/test/img_381.jpg  \n  inflating: train_datasets/images/icdar15/test/img_382.jpg  \n  inflating: train_datasets/images/icdar15/test/img_383.jpg  \n  inflating: train_datasets/images/icdar15/test/img_384.jpg  \n  inflating: train_datasets/images/icdar15/test/img_385.jpg  \n  inflating: train_datasets/images/icdar15/test/img_386.jpg  \n  inflating: train_datasets/images/icdar15/test/img_387.jpg  \n  inflating: train_datasets/images/icdar15/test/img_388.jpg  \n  inflating: train_datasets/images/icdar15/test/img_389.jpg  \n  inflating: train_datasets/images/icdar15/test/img_39.jpg  \n  inflating: train_datasets/images/icdar15/test/img_390.jpg  \n  inflating: train_datasets/images/icdar15/test/img_391.jpg  \n  inflating: train_datasets/images/icdar15/test/img_392.jpg  \n  inflating: train_datasets/images/icdar15/test/img_393.jpg  \n  inflating: train_datasets/images/icdar15/test/img_394.jpg  \n  inflating: train_datasets/images/icdar15/test/img_395.jpg  \n  inflating: train_datasets/images/icdar15/test/img_396.jpg  \n  inflating: train_datasets/images/icdar15/test/img_397.jpg  \n  inflating: train_datasets/images/icdar15/test/img_398.jpg  \n  inflating: train_datasets/images/icdar15/test/img_399.jpg  \n  inflating: train_datasets/images/icdar15/test/img_4.jpg  \n  inflating: train_datasets/images/icdar15/test/img_40.jpg  \n  inflating: train_datasets/images/icdar15/test/img_400.jpg  \n  inflating: train_datasets/images/icdar15/test/img_401.jpg  \n  inflating: train_datasets/images/icdar15/test/img_402.jpg  \n  inflating: train_datasets/images/icdar15/test/img_403.jpg  \n  inflating: train_datasets/images/icdar15/test/img_404.jpg  \n  inflating: train_datasets/images/icdar15/test/img_405.jpg  \n  inflating: train_datasets/images/icdar15/test/img_406.jpg  \n  inflating: train_datasets/images/icdar15/test/img_407.jpg  \n  inflating: train_datasets/images/icdar15/test/img_408.jpg  \n  inflating: train_datasets/images/icdar15/test/img_409.jpg  \n  inflating: train_datasets/images/icdar15/test/img_41.jpg  \n  inflating: train_datasets/images/icdar15/test/img_410.jpg  \n  inflating: train_datasets/images/icdar15/test/img_411.jpg  \n  inflating: train_datasets/images/icdar15/test/img_412.jpg  \n  inflating: train_datasets/images/icdar15/test/img_413.jpg  \n  inflating: train_datasets/images/icdar15/test/img_414.jpg  \n  inflating: train_datasets/images/icdar15/test/img_415.jpg  \n  inflating: train_datasets/images/icdar15/test/img_416.jpg  \n  inflating: train_datasets/images/icdar15/test/img_417.jpg  \n  inflating: train_datasets/images/icdar15/test/img_418.jpg  \n  inflating: train_datasets/images/icdar15/test/img_419.jpg  \n  inflating: train_datasets/images/icdar15/test/img_42.jpg  \n  inflating: train_datasets/images/icdar15/test/img_420.jpg  \n  inflating: train_datasets/images/icdar15/test/img_421.jpg  \n  inflating: train_datasets/images/icdar15/test/img_422.jpg  \n  inflating: train_datasets/images/icdar15/test/img_423.jpg  \n  inflating: train_datasets/images/icdar15/test/img_424.jpg  \n  inflating: train_datasets/images/icdar15/test/img_425.jpg  \n  inflating: train_datasets/images/icdar15/test/img_426.jpg  \n  inflating: train_datasets/images/icdar15/test/img_427.jpg  \n  inflating: train_datasets/images/icdar15/test/img_428.jpg  \n  inflating: train_datasets/images/icdar15/test/img_429.jpg  \n  inflating: train_datasets/images/icdar15/test/img_43.jpg  \n  inflating: train_datasets/images/icdar15/test/img_430.jpg  \n  inflating: train_datasets/images/icdar15/test/img_431.jpg  \n  inflating: train_datasets/images/icdar15/test/img_432.jpg  \n  inflating: train_datasets/images/icdar15/test/img_433.jpg  \n  inflating: train_datasets/images/icdar15/test/img_434.jpg  \n  inflating: train_datasets/images/icdar15/test/img_435.jpg  \n  inflating: train_datasets/images/icdar15/test/img_436.jpg  \n  inflating: train_datasets/images/icdar15/test/img_437.jpg  \n  inflating: train_datasets/images/icdar15/test/img_438.jpg  \n  inflating: train_datasets/images/icdar15/test/img_439.jpg  \n  inflating: train_datasets/images/icdar15/test/img_44.jpg  \n  inflating: train_datasets/images/icdar15/test/img_440.jpg  \n  inflating: train_datasets/images/icdar15/test/img_441.jpg  \n  inflating: train_datasets/images/icdar15/test/img_442.jpg  \n  inflating: train_datasets/images/icdar15/test/img_443.jpg  \n  inflating: train_datasets/images/icdar15/test/img_444.jpg  \n  inflating: train_datasets/images/icdar15/test/img_445.jpg  \n  inflating: train_datasets/images/icdar15/test/img_446.jpg  \n  inflating: train_datasets/images/icdar15/test/img_447.jpg  \n  inflating: train_datasets/images/icdar15/test/img_448.jpg  \n  inflating: train_datasets/images/icdar15/test/img_449.jpg  \n  inflating: train_datasets/images/icdar15/test/img_45.jpg  \n  inflating: train_datasets/images/icdar15/test/img_450.jpg  \n  inflating: train_datasets/images/icdar15/test/img_451.jpg  \n  inflating: train_datasets/images/icdar15/test/img_452.jpg  \n  inflating: train_datasets/images/icdar15/test/img_453.jpg  \n  inflating: train_datasets/images/icdar15/test/img_454.jpg  \n  inflating: train_datasets/images/icdar15/test/img_455.jpg  \n  inflating: train_datasets/images/icdar15/test/img_456.jpg  \n  inflating: train_datasets/images/icdar15/test/img_457.jpg  \n  inflating: train_datasets/images/icdar15/test/img_458.jpg  \n  inflating: train_datasets/images/icdar15/test/img_459.jpg  \n  inflating: train_datasets/images/icdar15/test/img_46.jpg  \n  inflating: train_datasets/images/icdar15/test/img_460.jpg  \n  inflating: train_datasets/images/icdar15/test/img_461.jpg  \n  inflating: train_datasets/images/icdar15/test/img_462.jpg  \n  inflating: train_datasets/images/icdar15/test/img_463.jpg  \n  inflating: train_datasets/images/icdar15/test/img_464.jpg  \n  inflating: train_datasets/images/icdar15/test/img_465.jpg  \n  inflating: train_datasets/images/icdar15/test/img_466.jpg  \n  inflating: train_datasets/images/icdar15/test/img_467.jpg  \n  inflating: train_datasets/images/icdar15/test/img_468.jpg  \n  inflating: train_datasets/images/icdar15/test/img_469.jpg  \n  inflating: train_datasets/images/icdar15/test/img_47.jpg  \n  inflating: train_datasets/images/icdar15/test/img_470.jpg  \n  inflating: train_datasets/images/icdar15/test/img_471.jpg  \n  inflating: train_datasets/images/icdar15/test/img_472.jpg  \n  inflating: train_datasets/images/icdar15/test/img_473.jpg  \n  inflating: train_datasets/images/icdar15/test/img_474.jpg  \n  inflating: train_datasets/images/icdar15/test/img_475.jpg  \n  inflating: train_datasets/images/icdar15/test/img_476.jpg  \n  inflating: train_datasets/images/icdar15/test/img_477.jpg  \n  inflating: train_datasets/images/icdar15/test/img_478.jpg  \n  inflating: train_datasets/images/icdar15/test/img_479.jpg  \n  inflating: train_datasets/images/icdar15/test/img_48.jpg  \n  inflating: train_datasets/images/icdar15/test/img_480.jpg  \n  inflating: train_datasets/images/icdar15/test/img_481.jpg  \n  inflating: train_datasets/images/icdar15/test/img_482.jpg  \n  inflating: train_datasets/images/icdar15/test/img_483.jpg  \n  inflating: train_datasets/images/icdar15/test/img_484.jpg  \n  inflating: train_datasets/images/icdar15/test/img_485.jpg  \n  inflating: train_datasets/images/icdar15/test/img_486.jpg  \n  inflating: train_datasets/images/icdar15/test/img_487.jpg  \n  inflating: train_datasets/images/icdar15/test/img_488.jpg  \n  inflating: train_datasets/images/icdar15/test/img_489.jpg  \n  inflating: train_datasets/images/icdar15/test/img_49.jpg  \n  inflating: train_datasets/images/icdar15/test/img_490.jpg  \n  inflating: train_datasets/images/icdar15/test/img_491.jpg  \n  inflating: train_datasets/images/icdar15/test/img_492.jpg  \n  inflating: train_datasets/images/icdar15/test/img_493.jpg  \n  inflating: train_datasets/images/icdar15/test/img_494.jpg  \n  inflating: train_datasets/images/icdar15/test/img_495.jpg  \n  inflating: train_datasets/images/icdar15/test/img_496.jpg  \n  inflating: train_datasets/images/icdar15/test/img_497.jpg  \n  inflating: train_datasets/images/icdar15/test/img_498.jpg  \n  inflating: train_datasets/images/icdar15/test/img_499.jpg  \n  inflating: train_datasets/images/icdar15/test/img_5.jpg  \n  inflating: train_datasets/images/icdar15/test/img_50.jpg  \n  inflating: train_datasets/images/icdar15/test/img_500.jpg  \n  inflating: train_datasets/images/icdar15/test/img_51.jpg  \n  inflating: train_datasets/images/icdar15/test/img_52.jpg  \n  inflating: train_datasets/images/icdar15/test/img_53.jpg  \n  inflating: train_datasets/images/icdar15/test/img_54.jpg  \n  inflating: train_datasets/images/icdar15/test/img_55.jpg  \n  inflating: train_datasets/images/icdar15/test/img_56.jpg  \n  inflating: train_datasets/images/icdar15/test/img_57.jpg  \n  inflating: train_datasets/images/icdar15/test/img_58.jpg  \n  inflating: train_datasets/images/icdar15/test/img_59.jpg  \n  inflating: train_datasets/images/icdar15/test/img_6.jpg  \n  inflating: train_datasets/images/icdar15/test/img_60.jpg  \n  inflating: train_datasets/images/icdar15/test/img_61.jpg  \n  inflating: train_datasets/images/icdar15/test/img_62.jpg  \n  inflating: train_datasets/images/icdar15/test/img_63.jpg  \n  inflating: train_datasets/images/icdar15/test/img_64.jpg  \n  inflating: train_datasets/images/icdar15/test/img_65.jpg  \n  inflating: train_datasets/images/icdar15/test/img_66.jpg  \n  inflating: train_datasets/images/icdar15/test/img_67.jpg  \n  inflating: train_datasets/images/icdar15/test/img_68.jpg  \n  inflating: train_datasets/images/icdar15/test/img_69.jpg  \n  inflating: train_datasets/images/icdar15/test/img_7.jpg  \n  inflating: train_datasets/images/icdar15/test/img_70.jpg  \n  inflating: train_datasets/images/icdar15/test/img_71.jpg  \n  inflating: train_datasets/images/icdar15/test/img_72.jpg  \n  inflating: train_datasets/images/icdar15/test/img_73.jpg  \n  inflating: train_datasets/images/icdar15/test/img_74.jpg  \n  inflating: train_datasets/images/icdar15/test/img_75.jpg  \n  inflating: train_datasets/images/icdar15/test/img_76.jpg  \n  inflating: train_datasets/images/icdar15/test/img_77.jpg  \n  inflating: train_datasets/images/icdar15/test/img_78.jpg  \n  inflating: train_datasets/images/icdar15/test/img_79.jpg  \n  inflating: train_datasets/images/icdar15/test/img_8.jpg  \n  inflating: train_datasets/images/icdar15/test/img_80.jpg  \n  inflating: train_datasets/images/icdar15/test/img_81.jpg  \n  inflating: train_datasets/images/icdar15/test/img_82.jpg  \n  inflating: train_datasets/images/icdar15/test/img_83.jpg  \n  inflating: train_datasets/images/icdar15/test/img_84.jpg  \n  inflating: train_datasets/images/icdar15/test/img_85.jpg  \n  inflating: train_datasets/images/icdar15/test/img_86.jpg  \n  inflating: train_datasets/images/icdar15/test/img_87.jpg  \n  inflating: train_datasets/images/icdar15/test/img_88.jpg  \n  inflating: train_datasets/images/icdar15/test/img_89.jpg  \n  inflating: train_datasets/images/icdar15/test/img_9.jpg  \n  inflating: train_datasets/images/icdar15/test/img_90.jpg  \n  inflating: train_datasets/images/icdar15/test/img_91.jpg  \n  inflating: train_datasets/images/icdar15/test/img_92.jpg  \n  inflating: train_datasets/images/icdar15/test/img_93.jpg  \n  inflating: train_datasets/images/icdar15/test/img_94.jpg  \n  inflating: train_datasets/images/icdar15/test/img_95.jpg  \n  inflating: train_datasets/images/icdar15/test/img_96.jpg  \n  inflating: train_datasets/images/icdar15/test/img_97.jpg  \n  inflating: train_datasets/images/icdar15/test/img_98.jpg  \n  inflating: train_datasets/images/icdar15/test/img_99.jpg  \n   creating: train_datasets/images/icdar15/train/\n  inflating: train_datasets/images/icdar15/train/img_1.jpg  \n  inflating: train_datasets/images/icdar15/train/img_10.jpg  \n  inflating: train_datasets/images/icdar15/train/img_100.jpg  \n  inflating: train_datasets/images/icdar15/train/img_1000.jpg  \n  inflating: train_datasets/images/icdar15/train/img_101.jpg  \n  inflating: train_datasets/images/icdar15/train/img_102.jpg  \n  inflating: train_datasets/images/icdar15/train/img_103.jpg  \n  inflating: train_datasets/images/icdar15/train/img_104.jpg  \n  inflating: train_datasets/images/icdar15/train/img_105.jpg  \n  inflating: train_datasets/images/icdar15/train/img_106.jpg  \n  inflating: train_datasets/images/icdar15/train/img_107.jpg  \n  inflating: train_datasets/images/icdar15/train/img_108.jpg  \n  inflating: train_datasets/images/icdar15/train/img_109.jpg  \n  inflating: train_datasets/images/icdar15/train/img_11.jpg  \n  inflating: train_datasets/images/icdar15/train/img_110.jpg  \n  inflating: train_datasets/images/icdar15/train/img_111.jpg  \n  inflating: train_datasets/images/icdar15/train/img_112.jpg  \n  inflating: train_datasets/images/icdar15/train/img_113.jpg  \n  inflating: train_datasets/images/icdar15/train/img_114.jpg  \n  inflating: train_datasets/images/icdar15/train/img_115.jpg  \n  inflating: train_datasets/images/icdar15/train/img_116.jpg  \n  inflating: train_datasets/images/icdar15/train/img_117.jpg  \n  inflating: train_datasets/images/icdar15/train/img_118.jpg  \n  inflating: train_datasets/images/icdar15/train/img_119.jpg  \n  inflating: train_datasets/images/icdar15/train/img_12.jpg  \n  inflating: train_datasets/images/icdar15/train/img_120.jpg  \n  inflating: train_datasets/images/icdar15/train/img_121.jpg  \n  inflating: train_datasets/images/icdar15/train/img_122.jpg  \n  inflating: train_datasets/images/icdar15/train/img_123.jpg  \n  inflating: train_datasets/images/icdar15/train/img_124.jpg  \n  inflating: train_datasets/images/icdar15/train/img_125.jpg  \n  inflating: train_datasets/images/icdar15/train/img_126.jpg  \n  inflating: train_datasets/images/icdar15/train/img_127.jpg  \n  inflating: train_datasets/images/icdar15/train/img_128.jpg  \n  inflating: train_datasets/images/icdar15/train/img_129.jpg  \n  inflating: train_datasets/images/icdar15/train/img_13.jpg  \n  inflating: train_datasets/images/icdar15/train/img_130.jpg  \n  inflating: train_datasets/images/icdar15/train/img_131.jpg  \n  inflating: train_datasets/images/icdar15/train/img_132.jpg  \n  inflating: train_datasets/images/icdar15/train/img_133.jpg  \n  inflating: train_datasets/images/icdar15/train/img_134.jpg  \n  inflating: train_datasets/images/icdar15/train/img_135.jpg  \n  inflating: train_datasets/images/icdar15/train/img_136.jpg  \n  inflating: train_datasets/images/icdar15/train/img_137.jpg  \n  inflating: train_datasets/images/icdar15/train/img_138.jpg  \n  inflating: train_datasets/images/icdar15/train/img_139.jpg  \n  inflating: train_datasets/images/icdar15/train/img_14.jpg  \n  inflating: train_datasets/images/icdar15/train/img_140.jpg  \n  inflating: train_datasets/images/icdar15/train/img_141.jpg  \n  inflating: train_datasets/images/icdar15/train/img_142.jpg  \n  inflating: train_datasets/images/icdar15/train/img_143.jpg  \n  inflating: train_datasets/images/icdar15/train/img_144.jpg  \n  inflating: train_datasets/images/icdar15/train/img_145.jpg  \n  inflating: train_datasets/images/icdar15/train/img_146.jpg  \n  inflating: train_datasets/images/icdar15/train/img_147.jpg  \n  inflating: train_datasets/images/icdar15/train/img_148.jpg  \n  inflating: train_datasets/images/icdar15/train/img_149.jpg  \n  inflating: train_datasets/images/icdar15/train/img_15.jpg  \n  inflating: train_datasets/images/icdar15/train/img_150.jpg  \n  inflating: train_datasets/images/icdar15/train/img_151.jpg  \n  inflating: train_datasets/images/icdar15/train/img_152.jpg  \n  inflating: train_datasets/images/icdar15/train/img_153.jpg  \n  inflating: train_datasets/images/icdar15/train/img_154.jpg  \n  inflating: train_datasets/images/icdar15/train/img_155.jpg  \n  inflating: train_datasets/images/icdar15/train/img_156.jpg  \n  inflating: train_datasets/images/icdar15/train/img_157.jpg  \n  inflating: train_datasets/images/icdar15/train/img_158.jpg  \n  inflating: train_datasets/images/icdar15/train/img_159.jpg  \n  inflating: train_datasets/images/icdar15/train/img_16.jpg  \n  inflating: train_datasets/images/icdar15/train/img_160.jpg  \n  inflating: train_datasets/images/icdar15/train/img_161.jpg  \n  inflating: train_datasets/images/icdar15/train/img_162.jpg  \n  inflating: train_datasets/images/icdar15/train/img_163.jpg  \n  inflating: train_datasets/images/icdar15/train/img_164.jpg  \n  inflating: train_datasets/images/icdar15/train/img_165.jpg  \n  inflating: train_datasets/images/icdar15/train/img_166.jpg  \n  inflating: train_datasets/images/icdar15/train/img_167.jpg  \n  inflating: train_datasets/images/icdar15/train/img_168.jpg  \n  inflating: train_datasets/images/icdar15/train/img_169.jpg  \n  inflating: train_datasets/images/icdar15/train/img_17.jpg  \n  inflating: train_datasets/images/icdar15/train/img_170.jpg  \n  inflating: train_datasets/images/icdar15/train/img_171.jpg  \n  inflating: train_datasets/images/icdar15/train/img_172.jpg  \n  inflating: train_datasets/images/icdar15/train/img_173.jpg  \n  inflating: train_datasets/images/icdar15/train/img_174.jpg  \n  inflating: train_datasets/images/icdar15/train/img_175.jpg  \n  inflating: train_datasets/images/icdar15/train/img_176.jpg  \n  inflating: train_datasets/images/icdar15/train/img_177.jpg  \n  inflating: train_datasets/images/icdar15/train/img_178.jpg  \n  inflating: train_datasets/images/icdar15/train/img_179.jpg  \n  inflating: train_datasets/images/icdar15/train/img_18.jpg  \n  inflating: train_datasets/images/icdar15/train/img_180.jpg  \n  inflating: train_datasets/images/icdar15/train/img_181.jpg  \n  inflating: train_datasets/images/icdar15/train/img_182.jpg  \n  inflating: train_datasets/images/icdar15/train/img_183.jpg  \n  inflating: train_datasets/images/icdar15/train/img_184.jpg  \n  inflating: train_datasets/images/icdar15/train/img_185.jpg  \n  inflating: train_datasets/images/icdar15/train/img_186.jpg  \n  inflating: train_datasets/images/icdar15/train/img_187.jpg  \n  inflating: train_datasets/images/icdar15/train/img_188.jpg  \n  inflating: train_datasets/images/icdar15/train/img_189.jpg  \n  inflating: train_datasets/images/icdar15/train/img_19.jpg  \n  inflating: train_datasets/images/icdar15/train/img_190.jpg  \n  inflating: train_datasets/images/icdar15/train/img_191.jpg  \n  inflating: train_datasets/images/icdar15/train/img_192.jpg  \n  inflating: train_datasets/images/icdar15/train/img_193.jpg  \n  inflating: train_datasets/images/icdar15/train/img_194.jpg  \n  inflating: train_datasets/images/icdar15/train/img_195.jpg  \n  inflating: train_datasets/images/icdar15/train/img_196.jpg  \n  inflating: train_datasets/images/icdar15/train/img_197.jpg  \n  inflating: train_datasets/images/icdar15/train/img_198.jpg  \n  inflating: train_datasets/images/icdar15/train/img_199.jpg  \n  inflating: train_datasets/images/icdar15/train/img_2.jpg  \n  inflating: train_datasets/images/icdar15/train/img_20.jpg  \n  inflating: train_datasets/images/icdar15/train/img_200.jpg  \n  inflating: train_datasets/images/icdar15/train/img_201.jpg  \n  inflating: train_datasets/images/icdar15/train/img_202.jpg  \n  inflating: train_datasets/images/icdar15/train/img_203.jpg  \n  inflating: train_datasets/images/icdar15/train/img_204.jpg  \n  inflating: train_datasets/images/icdar15/train/img_205.jpg  \n  inflating: train_datasets/images/icdar15/train/img_206.jpg  \n  inflating: train_datasets/images/icdar15/train/img_207.jpg  \n  inflating: train_datasets/images/icdar15/train/img_208.jpg  \n  inflating: train_datasets/images/icdar15/train/img_209.jpg  \n  inflating: train_datasets/images/icdar15/train/img_21.jpg  \n  inflating: train_datasets/images/icdar15/train/img_210.jpg  \n  inflating: train_datasets/images/icdar15/train/img_211.jpg  \n  inflating: train_datasets/images/icdar15/train/img_212.jpg  \n  inflating: train_datasets/images/icdar15/train/img_213.jpg  \n  inflating: train_datasets/images/icdar15/train/img_214.jpg  \n  inflating: train_datasets/images/icdar15/train/img_215.jpg  \n  inflating: train_datasets/images/icdar15/train/img_216.jpg  \n  inflating: train_datasets/images/icdar15/train/img_217.jpg  \n  inflating: train_datasets/images/icdar15/train/img_218.jpg  \n  inflating: train_datasets/images/icdar15/train/img_219.jpg  \n  inflating: train_datasets/images/icdar15/train/img_22.jpg  \n  inflating: train_datasets/images/icdar15/train/img_220.jpg  \n  inflating: train_datasets/images/icdar15/train/img_221.jpg  \n  inflating: train_datasets/images/icdar15/train/img_222.jpg  \n  inflating: train_datasets/images/icdar15/train/img_223.jpg  \n  inflating: train_datasets/images/icdar15/train/img_224.jpg  \n  inflating: train_datasets/images/icdar15/train/img_225.jpg  \n  inflating: train_datasets/images/icdar15/train/img_226.jpg  \n  inflating: train_datasets/images/icdar15/train/img_227.jpg  \n  inflating: train_datasets/images/icdar15/train/img_228.jpg  \n  inflating: train_datasets/images/icdar15/train/img_229.jpg  \n  inflating: train_datasets/images/icdar15/train/img_23.jpg  \n  inflating: train_datasets/images/icdar15/train/img_230.jpg  \n  inflating: train_datasets/images/icdar15/train/img_231.jpg  \n  inflating: train_datasets/images/icdar15/train/img_232.jpg  \n  inflating: train_datasets/images/icdar15/train/img_233.jpg  \n  inflating: train_datasets/images/icdar15/train/img_234.jpg  \n  inflating: train_datasets/images/icdar15/train/img_235.jpg  \n  inflating: train_datasets/images/icdar15/train/img_236.jpg  \n  inflating: train_datasets/images/icdar15/train/img_237.jpg  \n  inflating: train_datasets/images/icdar15/train/img_238.jpg  \n  inflating: train_datasets/images/icdar15/train/img_239.jpg  \n  inflating: train_datasets/images/icdar15/train/img_24.jpg  \n  inflating: train_datasets/images/icdar15/train/img_240.jpg  \n  inflating: train_datasets/images/icdar15/train/img_241.jpg  \n  inflating: train_datasets/images/icdar15/train/img_242.jpg  \n  inflating: train_datasets/images/icdar15/train/img_243.jpg  \n  inflating: train_datasets/images/icdar15/train/img_244.jpg  \n  inflating: train_datasets/images/icdar15/train/img_245.jpg  \n  inflating: train_datasets/images/icdar15/train/img_246.jpg  \n  inflating: train_datasets/images/icdar15/train/img_247.jpg  \n  inflating: train_datasets/images/icdar15/train/img_248.jpg  \n  inflating: train_datasets/images/icdar15/train/img_249.jpg  \n  inflating: train_datasets/images/icdar15/train/img_25.jpg  \n  inflating: train_datasets/images/icdar15/train/img_250.jpg  \n  inflating: train_datasets/images/icdar15/train/img_251.jpg  \n  inflating: train_datasets/images/icdar15/train/img_252.jpg  \n  inflating: train_datasets/images/icdar15/train/img_253.jpg  \n  inflating: train_datasets/images/icdar15/train/img_254.jpg  \n  inflating: train_datasets/images/icdar15/train/img_255.jpg  \n  inflating: train_datasets/images/icdar15/train/img_256.jpg  \n  inflating: train_datasets/images/icdar15/train/img_257.jpg  \n  inflating: train_datasets/images/icdar15/train/img_258.jpg  \n  inflating: train_datasets/images/icdar15/train/img_259.jpg  \n  inflating: train_datasets/images/icdar15/train/img_26.jpg  \n  inflating: train_datasets/images/icdar15/train/img_260.jpg  \n  inflating: train_datasets/images/icdar15/train/img_261.jpg  \n  inflating: train_datasets/images/icdar15/train/img_262.jpg  \n  inflating: train_datasets/images/icdar15/train/img_263.jpg  \n  inflating: train_datasets/images/icdar15/train/img_264.jpg  \n  inflating: train_datasets/images/icdar15/train/img_265.jpg  \n  inflating: train_datasets/images/icdar15/train/img_266.jpg  \n  inflating: train_datasets/images/icdar15/train/img_267.jpg  \n  inflating: train_datasets/images/icdar15/train/img_268.jpg  \n  inflating: train_datasets/images/icdar15/train/img_269.jpg  \n  inflating: train_datasets/images/icdar15/train/img_27.jpg  \n  inflating: train_datasets/images/icdar15/train/img_270.jpg  \n  inflating: train_datasets/images/icdar15/train/img_271.jpg  \n  inflating: train_datasets/images/icdar15/train/img_272.jpg  \n  inflating: train_datasets/images/icdar15/train/img_273.jpg  \n  inflating: train_datasets/images/icdar15/train/img_274.jpg  \n  inflating: train_datasets/images/icdar15/train/img_275.jpg  \n  inflating: train_datasets/images/icdar15/train/img_276.jpg  \n  inflating: train_datasets/images/icdar15/train/img_277.jpg  \n  inflating: train_datasets/images/icdar15/train/img_278.jpg  \n  inflating: train_datasets/images/icdar15/train/img_279.jpg  \n  inflating: train_datasets/images/icdar15/train/img_28.jpg  \n  inflating: train_datasets/images/icdar15/train/img_280.jpg  \n  inflating: train_datasets/images/icdar15/train/img_281.jpg  \n  inflating: train_datasets/images/icdar15/train/img_282.jpg  \n  inflating: train_datasets/images/icdar15/train/img_283.jpg  \n  inflating: train_datasets/images/icdar15/train/img_284.jpg  \n  inflating: train_datasets/images/icdar15/train/img_285.jpg  \n  inflating: train_datasets/images/icdar15/train/img_286.jpg  \n  inflating: train_datasets/images/icdar15/train/img_287.jpg  \n  inflating: train_datasets/images/icdar15/train/img_288.jpg  \n  inflating: train_datasets/images/icdar15/train/img_289.jpg  \n  inflating: train_datasets/images/icdar15/train/img_29.jpg  \n  inflating: train_datasets/images/icdar15/train/img_290.jpg  \n  inflating: train_datasets/images/icdar15/train/img_291.jpg  \n  inflating: train_datasets/images/icdar15/train/img_292.jpg  \n  inflating: train_datasets/images/icdar15/train/img_293.jpg  \n  inflating: train_datasets/images/icdar15/train/img_294.jpg  \n  inflating: train_datasets/images/icdar15/train/img_295.jpg  \n  inflating: train_datasets/images/icdar15/train/img_296.jpg  \n  inflating: train_datasets/images/icdar15/train/img_297.jpg  \n  inflating: train_datasets/images/icdar15/train/img_298.jpg  \n  inflating: train_datasets/images/icdar15/train/img_299.jpg  \n  inflating: train_datasets/images/icdar15/train/img_3.jpg  \n  inflating: train_datasets/images/icdar15/train/img_30.jpg  \n  inflating: train_datasets/images/icdar15/train/img_300.jpg  \n  inflating: train_datasets/images/icdar15/train/img_301.jpg  \n  inflating: train_datasets/images/icdar15/train/img_302.jpg  \n  inflating: train_datasets/images/icdar15/train/img_303.jpg  \n  inflating: train_datasets/images/icdar15/train/img_304.jpg  \n  inflating: train_datasets/images/icdar15/train/img_305.jpg  \n  inflating: train_datasets/images/icdar15/train/img_306.jpg  \n  inflating: train_datasets/images/icdar15/train/img_307.jpg  \n  inflating: train_datasets/images/icdar15/train/img_308.jpg  \n  inflating: train_datasets/images/icdar15/train/img_309.jpg  \n  inflating: train_datasets/images/icdar15/train/img_31.jpg  \n  inflating: train_datasets/images/icdar15/train/img_310.jpg  \n  inflating: train_datasets/images/icdar15/train/img_311.jpg  \n  inflating: train_datasets/images/icdar15/train/img_312.jpg  \n  inflating: train_datasets/images/icdar15/train/img_313.jpg  \n  inflating: train_datasets/images/icdar15/train/img_314.jpg  \n  inflating: train_datasets/images/icdar15/train/img_315.jpg  \n  inflating: train_datasets/images/icdar15/train/img_316.jpg  \n  inflating: train_datasets/images/icdar15/train/img_317.jpg  \n  inflating: train_datasets/images/icdar15/train/img_318.jpg  \n  inflating: train_datasets/images/icdar15/train/img_319.jpg  \n  inflating: train_datasets/images/icdar15/train/img_32.jpg  \n  inflating: train_datasets/images/icdar15/train/img_320.jpg  \n  inflating: train_datasets/images/icdar15/train/img_321.jpg  \n  inflating: train_datasets/images/icdar15/train/img_322.jpg  \n  inflating: train_datasets/images/icdar15/train/img_323.jpg  \n  inflating: train_datasets/images/icdar15/train/img_324.jpg  \n  inflating: train_datasets/images/icdar15/train/img_325.jpg  \n  inflating: train_datasets/images/icdar15/train/img_326.jpg  \n  inflating: train_datasets/images/icdar15/train/img_327.jpg  \n  inflating: train_datasets/images/icdar15/train/img_328.jpg  \n  inflating: train_datasets/images/icdar15/train/img_329.jpg  \n  inflating: train_datasets/images/icdar15/train/img_33.jpg  \n  inflating: train_datasets/images/icdar15/train/img_330.jpg  \n  inflating: train_datasets/images/icdar15/train/img_331.jpg  \n  inflating: train_datasets/images/icdar15/train/img_332.jpg  \n  inflating: train_datasets/images/icdar15/train/img_333.jpg  \n  inflating: train_datasets/images/icdar15/train/img_334.jpg  \n  inflating: train_datasets/images/icdar15/train/img_335.jpg  \n  inflating: train_datasets/images/icdar15/train/img_336.jpg  \n  inflating: train_datasets/images/icdar15/train/img_337.jpg  \n  inflating: train_datasets/images/icdar15/train/img_338.jpg  \n  inflating: train_datasets/images/icdar15/train/img_339.jpg  \n  inflating: train_datasets/images/icdar15/train/img_34.jpg  \n  inflating: train_datasets/images/icdar15/train/img_340.jpg  \n  inflating: train_datasets/images/icdar15/train/img_341.jpg  \n  inflating: train_datasets/images/icdar15/train/img_342.jpg  \n  inflating: train_datasets/images/icdar15/train/img_343.jpg  \n  inflating: train_datasets/images/icdar15/train/img_344.jpg  \n  inflating: train_datasets/images/icdar15/train/img_345.jpg  \n  inflating: train_datasets/images/icdar15/train/img_346.jpg  \n  inflating: train_datasets/images/icdar15/train/img_347.jpg  \n  inflating: train_datasets/images/icdar15/train/img_348.jpg  \n  inflating: train_datasets/images/icdar15/train/img_349.jpg  \n  inflating: train_datasets/images/icdar15/train/img_35.jpg  \n  inflating: train_datasets/images/icdar15/train/img_350.jpg  \n  inflating: train_datasets/images/icdar15/train/img_351.jpg  \n  inflating: train_datasets/images/icdar15/train/img_352.jpg  \n  inflating: train_datasets/images/icdar15/train/img_353.jpg  \n  inflating: train_datasets/images/icdar15/train/img_354.jpg  \n  inflating: train_datasets/images/icdar15/train/img_355.jpg  \n  inflating: train_datasets/images/icdar15/train/img_356.jpg  \n  inflating: train_datasets/images/icdar15/train/img_357.jpg  \n  inflating: train_datasets/images/icdar15/train/img_358.jpg  \n  inflating: train_datasets/images/icdar15/train/img_359.jpg  \n  inflating: train_datasets/images/icdar15/train/img_36.jpg  \n  inflating: train_datasets/images/icdar15/train/img_360.jpg  \n  inflating: train_datasets/images/icdar15/train/img_361.jpg  \n  inflating: train_datasets/images/icdar15/train/img_362.jpg  \n  inflating: train_datasets/images/icdar15/train/img_363.jpg  \n  inflating: train_datasets/images/icdar15/train/img_364.jpg  \n  inflating: train_datasets/images/icdar15/train/img_365.jpg  \n  inflating: train_datasets/images/icdar15/train/img_366.jpg  \n  inflating: train_datasets/images/icdar15/train/img_367.jpg  \n  inflating: train_datasets/images/icdar15/train/img_368.jpg  \n  inflating: train_datasets/images/icdar15/train/img_369.jpg  \n  inflating: train_datasets/images/icdar15/train/img_37.jpg  \n  inflating: train_datasets/images/icdar15/train/img_370.jpg  \n  inflating: train_datasets/images/icdar15/train/img_371.jpg  \n  inflating: train_datasets/images/icdar15/train/img_372.jpg  \n  inflating: train_datasets/images/icdar15/train/img_373.jpg  \n  inflating: train_datasets/images/icdar15/train/img_374.jpg  \n  inflating: train_datasets/images/icdar15/train/img_375.jpg  \n  inflating: train_datasets/images/icdar15/train/img_376.jpg  \n  inflating: train_datasets/images/icdar15/train/img_377.jpg  \n  inflating: train_datasets/images/icdar15/train/img_378.jpg  \n  inflating: train_datasets/images/icdar15/train/img_379.jpg  \n  inflating: train_datasets/images/icdar15/train/img_38.jpg  \n  inflating: train_datasets/images/icdar15/train/img_380.jpg  \n  inflating: train_datasets/images/icdar15/train/img_381.jpg  \n  inflating: train_datasets/images/icdar15/train/img_382.jpg  \n  inflating: train_datasets/images/icdar15/train/img_383.jpg  \n  inflating: train_datasets/images/icdar15/train/img_384.jpg  \n  inflating: train_datasets/images/icdar15/train/img_385.jpg  \n  inflating: train_datasets/images/icdar15/train/img_386.jpg  \n  inflating: train_datasets/images/icdar15/train/img_387.jpg  \n  inflating: train_datasets/images/icdar15/train/img_388.jpg  \n  inflating: train_datasets/images/icdar15/train/img_389.jpg  \n  inflating: train_datasets/images/icdar15/train/img_39.jpg  \n  inflating: train_datasets/images/icdar15/train/img_390.jpg  \n  inflating: train_datasets/images/icdar15/train/img_391.jpg  \n  inflating: train_datasets/images/icdar15/train/img_392.jpg  \n  inflating: train_datasets/images/icdar15/train/img_393.jpg  \n  inflating: train_datasets/images/icdar15/train/img_394.jpg  \n  inflating: train_datasets/images/icdar15/train/img_395.jpg  \n  inflating: train_datasets/images/icdar15/train/img_396.jpg  \n  inflating: train_datasets/images/icdar15/train/img_397.jpg  \n  inflating: train_datasets/images/icdar15/train/img_398.jpg  \n  inflating: train_datasets/images/icdar15/train/img_399.jpg  \n  inflating: train_datasets/images/icdar15/train/img_4.jpg  \n  inflating: train_datasets/images/icdar15/train/img_40.jpg  \n  inflating: train_datasets/images/icdar15/train/img_400.jpg  \n  inflating: train_datasets/images/icdar15/train/img_401.jpg  \n  inflating: train_datasets/images/icdar15/train/img_402.jpg  \n  inflating: train_datasets/images/icdar15/train/img_403.jpg  \n  inflating: train_datasets/images/icdar15/train/img_404.jpg  \n  inflating: train_datasets/images/icdar15/train/img_405.jpg  \n  inflating: train_datasets/images/icdar15/train/img_406.jpg  \n  inflating: train_datasets/images/icdar15/train/img_407.jpg  \n  inflating: train_datasets/images/icdar15/train/img_408.jpg  \n  inflating: train_datasets/images/icdar15/train/img_409.jpg  \n  inflating: train_datasets/images/icdar15/train/img_41.jpg  \n  inflating: train_datasets/images/icdar15/train/img_410.jpg  \n  inflating: train_datasets/images/icdar15/train/img_411.jpg  \n  inflating: train_datasets/images/icdar15/train/img_412.jpg  \n  inflating: train_datasets/images/icdar15/train/img_413.jpg  \n  inflating: train_datasets/images/icdar15/train/img_414.jpg  \n  inflating: train_datasets/images/icdar15/train/img_415.jpg  \n  inflating: train_datasets/images/icdar15/train/img_416.jpg  \n  inflating: train_datasets/images/icdar15/train/img_417.jpg  \n  inflating: train_datasets/images/icdar15/train/img_418.jpg  \n  inflating: train_datasets/images/icdar15/train/img_419.jpg  \n  inflating: train_datasets/images/icdar15/train/img_42.jpg  \n  inflating: train_datasets/images/icdar15/train/img_420.jpg  \n  inflating: train_datasets/images/icdar15/train/img_421.jpg  \n  inflating: train_datasets/images/icdar15/train/img_422.jpg  \n  inflating: train_datasets/images/icdar15/train/img_423.jpg  \n  inflating: train_datasets/images/icdar15/train/img_424.jpg  \n  inflating: train_datasets/images/icdar15/train/img_425.jpg  \n  inflating: train_datasets/images/icdar15/train/img_426.jpg  \n  inflating: train_datasets/images/icdar15/train/img_427.jpg  \n  inflating: train_datasets/images/icdar15/train/img_428.jpg  \n  inflating: train_datasets/images/icdar15/train/img_429.jpg  \n  inflating: train_datasets/images/icdar15/train/img_43.jpg  \n  inflating: train_datasets/images/icdar15/train/img_430.jpg  \n  inflating: train_datasets/images/icdar15/train/img_431.jpg  \n  inflating: train_datasets/images/icdar15/train/img_432.jpg  \n  inflating: train_datasets/images/icdar15/train/img_433.jpg  \n  inflating: train_datasets/images/icdar15/train/img_434.jpg  \n  inflating: train_datasets/images/icdar15/train/img_435.jpg  \n  inflating: train_datasets/images/icdar15/train/img_436.jpg  \n  inflating: train_datasets/images/icdar15/train/img_437.jpg  \n  inflating: train_datasets/images/icdar15/train/img_438.jpg  \n  inflating: train_datasets/images/icdar15/train/img_439.jpg  \n  inflating: train_datasets/images/icdar15/train/img_44.jpg  \n  inflating: train_datasets/images/icdar15/train/img_440.jpg  \n  inflating: train_datasets/images/icdar15/train/img_441.jpg  \n  inflating: train_datasets/images/icdar15/train/img_442.jpg  \n  inflating: train_datasets/images/icdar15/train/img_443.jpg  \n  inflating: train_datasets/images/icdar15/train/img_444.jpg  \n  inflating: train_datasets/images/icdar15/train/img_445.jpg  \n  inflating: train_datasets/images/icdar15/train/img_446.jpg  \n  inflating: train_datasets/images/icdar15/train/img_447.jpg  \n  inflating: train_datasets/images/icdar15/train/img_448.jpg  \n  inflating: train_datasets/images/icdar15/train/img_449.jpg  \n  inflating: train_datasets/images/icdar15/train/img_45.jpg  \n  inflating: train_datasets/images/icdar15/train/img_450.jpg  \n  inflating: train_datasets/images/icdar15/train/img_451.jpg  \n  inflating: train_datasets/images/icdar15/train/img_452.jpg  \n  inflating: train_datasets/images/icdar15/train/img_453.jpg  \n  inflating: train_datasets/images/icdar15/train/img_454.jpg  \n  inflating: train_datasets/images/icdar15/train/img_455.jpg  \n  inflating: train_datasets/images/icdar15/train/img_456.jpg  \n  inflating: train_datasets/images/icdar15/train/img_457.jpg  \n  inflating: train_datasets/images/icdar15/train/img_458.jpg  \n  inflating: train_datasets/images/icdar15/train/img_459.jpg  \n  inflating: train_datasets/images/icdar15/train/img_46.jpg  \n  inflating: train_datasets/images/icdar15/train/img_460.jpg  \n  inflating: train_datasets/images/icdar15/train/img_461.jpg  \n  inflating: train_datasets/images/icdar15/train/img_462.jpg  \n  inflating: train_datasets/images/icdar15/train/img_463.jpg  \n  inflating: train_datasets/images/icdar15/train/img_464.jpg  \n  inflating: train_datasets/images/icdar15/train/img_465.jpg  \n  inflating: train_datasets/images/icdar15/train/img_466.jpg  \n  inflating: train_datasets/images/icdar15/train/img_467.jpg  \n  inflating: train_datasets/images/icdar15/train/img_468.jpg  \n  inflating: train_datasets/images/icdar15/train/img_469.jpg  \n  inflating: train_datasets/images/icdar15/train/img_47.jpg  \n  inflating: train_datasets/images/icdar15/train/img_470.jpg  \n  inflating: train_datasets/images/icdar15/train/img_471.jpg  \n  inflating: train_datasets/images/icdar15/train/img_472.jpg  \n  inflating: train_datasets/images/icdar15/train/img_473.jpg  \n  inflating: train_datasets/images/icdar15/train/img_474.jpg  \n  inflating: train_datasets/images/icdar15/train/img_475.jpg  \n  inflating: train_datasets/images/icdar15/train/img_476.jpg  \n  inflating: train_datasets/images/icdar15/train/img_477.jpg  \n  inflating: train_datasets/images/icdar15/train/img_478.jpg  \n  inflating: train_datasets/images/icdar15/train/img_479.jpg  \n  inflating: train_datasets/images/icdar15/train/img_48.jpg  \n  inflating: train_datasets/images/icdar15/train/img_480.jpg  \n  inflating: train_datasets/images/icdar15/train/img_481.jpg  \n  inflating: train_datasets/images/icdar15/train/img_482.jpg  \n  inflating: train_datasets/images/icdar15/train/img_483.jpg  \n  inflating: train_datasets/images/icdar15/train/img_484.jpg  \n  inflating: train_datasets/images/icdar15/train/img_485.jpg  \n  inflating: train_datasets/images/icdar15/train/img_486.jpg  \n  inflating: train_datasets/images/icdar15/train/img_487.jpg  \n  inflating: train_datasets/images/icdar15/train/img_488.jpg  \n  inflating: train_datasets/images/icdar15/train/img_489.jpg  \n  inflating: train_datasets/images/icdar15/train/img_49.jpg  \n  inflating: train_datasets/images/icdar15/train/img_490.jpg  \n  inflating: train_datasets/images/icdar15/train/img_491.jpg  \n  inflating: train_datasets/images/icdar15/train/img_492.jpg  \n  inflating: train_datasets/images/icdar15/train/img_493.jpg  \n  inflating: train_datasets/images/icdar15/train/img_494.jpg  \n  inflating: train_datasets/images/icdar15/train/img_495.jpg  \n  inflating: train_datasets/images/icdar15/train/img_496.jpg  \n  inflating: train_datasets/images/icdar15/train/img_497.jpg  \n  inflating: train_datasets/images/icdar15/train/img_498.jpg  \n  inflating: train_datasets/images/icdar15/train/img_499.jpg  \n  inflating: train_datasets/images/icdar15/train/img_5.jpg  \n  inflating: train_datasets/images/icdar15/train/img_50.jpg  \n  inflating: train_datasets/images/icdar15/train/img_500.jpg  \n  inflating: train_datasets/images/icdar15/train/img_501.jpg  \n  inflating: train_datasets/images/icdar15/train/img_502.jpg  \n  inflating: train_datasets/images/icdar15/train/img_503.jpg  \n  inflating: train_datasets/images/icdar15/train/img_504.jpg  \n  inflating: train_datasets/images/icdar15/train/img_505.jpg  \n  inflating: train_datasets/images/icdar15/train/img_506.jpg  \n  inflating: train_datasets/images/icdar15/train/img_507.jpg  \n  inflating: train_datasets/images/icdar15/train/img_508.jpg  \n  inflating: train_datasets/images/icdar15/train/img_509.jpg  \n  inflating: train_datasets/images/icdar15/train/img_51.jpg  \n  inflating: train_datasets/images/icdar15/train/img_510.jpg  \n  inflating: train_datasets/images/icdar15/train/img_511.jpg  \n  inflating: train_datasets/images/icdar15/train/img_512.jpg  \n  inflating: train_datasets/images/icdar15/train/img_513.jpg  \n  inflating: train_datasets/images/icdar15/train/img_514.jpg  \n  inflating: train_datasets/images/icdar15/train/img_515.jpg  \n  inflating: train_datasets/images/icdar15/train/img_516.jpg  \n  inflating: train_datasets/images/icdar15/train/img_517.jpg  \n  inflating: train_datasets/images/icdar15/train/img_518.jpg  \n  inflating: train_datasets/images/icdar15/train/img_519.jpg  \n  inflating: train_datasets/images/icdar15/train/img_52.jpg  \n  inflating: train_datasets/images/icdar15/train/img_520.jpg  \n  inflating: train_datasets/images/icdar15/train/img_521.jpg  \n  inflating: train_datasets/images/icdar15/train/img_522.jpg  \n  inflating: train_datasets/images/icdar15/train/img_523.jpg  \n  inflating: train_datasets/images/icdar15/train/img_524.jpg  \n  inflating: train_datasets/images/icdar15/train/img_525.jpg  \n  inflating: train_datasets/images/icdar15/train/img_526.jpg  \n  inflating: train_datasets/images/icdar15/train/img_527.jpg  \n  inflating: train_datasets/images/icdar15/train/img_528.jpg  \n  inflating: train_datasets/images/icdar15/train/img_529.jpg  \n  inflating: train_datasets/images/icdar15/train/img_53.jpg  \n  inflating: train_datasets/images/icdar15/train/img_530.jpg  \n  inflating: train_datasets/images/icdar15/train/img_531.jpg  \n  inflating: train_datasets/images/icdar15/train/img_532.jpg  \n  inflating: train_datasets/images/icdar15/train/img_533.jpg  \n  inflating: train_datasets/images/icdar15/train/img_534.jpg  \n  inflating: train_datasets/images/icdar15/train/img_535.jpg  \n  inflating: train_datasets/images/icdar15/train/img_536.jpg  \n  inflating: train_datasets/images/icdar15/train/img_537.jpg  \n  inflating: train_datasets/images/icdar15/train/img_538.jpg  \n  inflating: train_datasets/images/icdar15/train/img_539.jpg  \n  inflating: train_datasets/images/icdar15/train/img_54.jpg  \n  inflating: train_datasets/images/icdar15/train/img_540.jpg  \n  inflating: train_datasets/images/icdar15/train/img_541.jpg  \n  inflating: train_datasets/images/icdar15/train/img_542.jpg  \n  inflating: train_datasets/images/icdar15/train/img_543.jpg  \n  inflating: train_datasets/images/icdar15/train/img_544.jpg  \n  inflating: train_datasets/images/icdar15/train/img_545.jpg  \n  inflating: train_datasets/images/icdar15/train/img_546.jpg  \n  inflating: train_datasets/images/icdar15/train/img_547.jpg  \n  inflating: train_datasets/images/icdar15/train/img_548.jpg  \n  inflating: train_datasets/images/icdar15/train/img_549.jpg  \n  inflating: train_datasets/images/icdar15/train/img_55.jpg  \n  inflating: train_datasets/images/icdar15/train/img_550.jpg  \n  inflating: train_datasets/images/icdar15/train/img_551.jpg  \n  inflating: train_datasets/images/icdar15/train/img_552.jpg  \n  inflating: train_datasets/images/icdar15/train/img_553.jpg  \n  inflating: train_datasets/images/icdar15/train/img_554.jpg  \n  inflating: train_datasets/images/icdar15/train/img_555.jpg  \n  inflating: train_datasets/images/icdar15/train/img_556.jpg  \n  inflating: train_datasets/images/icdar15/train/img_557.jpg  \n  inflating: train_datasets/images/icdar15/train/img_558.jpg  \n  inflating: train_datasets/images/icdar15/train/img_559.jpg  \n  inflating: train_datasets/images/icdar15/train/img_56.jpg  \n  inflating: train_datasets/images/icdar15/train/img_560.jpg  \n  inflating: train_datasets/images/icdar15/train/img_561.jpg  \n  inflating: train_datasets/images/icdar15/train/img_562.jpg  \n  inflating: train_datasets/images/icdar15/train/img_563.jpg  \n  inflating: train_datasets/images/icdar15/train/img_564.jpg  \n  inflating: train_datasets/images/icdar15/train/img_565.jpg  \n  inflating: train_datasets/images/icdar15/train/img_566.jpg  \n  inflating: train_datasets/images/icdar15/train/img_567.jpg  \n  inflating: train_datasets/images/icdar15/train/img_568.jpg  \n  inflating: train_datasets/images/icdar15/train/img_569.jpg  \n  inflating: train_datasets/images/icdar15/train/img_57.jpg  \n  inflating: train_datasets/images/icdar15/train/img_570.jpg  \n  inflating: train_datasets/images/icdar15/train/img_571.jpg  \n  inflating: train_datasets/images/icdar15/train/img_572.jpg  \n  inflating: train_datasets/images/icdar15/train/img_573.jpg  \n  inflating: train_datasets/images/icdar15/train/img_574.jpg  \n  inflating: train_datasets/images/icdar15/train/img_575.jpg  \n  inflating: train_datasets/images/icdar15/train/img_576.jpg  \n  inflating: train_datasets/images/icdar15/train/img_577.jpg  \n  inflating: train_datasets/images/icdar15/train/img_578.jpg  \n  inflating: train_datasets/images/icdar15/train/img_579.jpg  \n  inflating: train_datasets/images/icdar15/train/img_58.jpg  \n  inflating: train_datasets/images/icdar15/train/img_580.jpg  \n  inflating: train_datasets/images/icdar15/train/img_581.jpg  \n  inflating: train_datasets/images/icdar15/train/img_582.jpg  \n  inflating: train_datasets/images/icdar15/train/img_583.jpg  \n  inflating: train_datasets/images/icdar15/train/img_584.jpg  \n  inflating: train_datasets/images/icdar15/train/img_585.jpg  \n  inflating: train_datasets/images/icdar15/train/img_586.jpg  \n  inflating: train_datasets/images/icdar15/train/img_587.jpg  \n  inflating: train_datasets/images/icdar15/train/img_588.jpg  \n  inflating: train_datasets/images/icdar15/train/img_589.jpg  \n  inflating: train_datasets/images/icdar15/train/img_59.jpg  \n  inflating: train_datasets/images/icdar15/train/img_590.jpg  \n  inflating: train_datasets/images/icdar15/train/img_591.jpg  \n  inflating: train_datasets/images/icdar15/train/img_592.jpg  \n  inflating: train_datasets/images/icdar15/train/img_593.jpg  \n  inflating: train_datasets/images/icdar15/train/img_594.jpg  \n  inflating: train_datasets/images/icdar15/train/img_595.jpg  \n  inflating: train_datasets/images/icdar15/train/img_596.jpg  \n  inflating: train_datasets/images/icdar15/train/img_597.jpg  \n  inflating: train_datasets/images/icdar15/train/img_598.jpg  \n  inflating: train_datasets/images/icdar15/train/img_599.jpg  \n  inflating: train_datasets/images/icdar15/train/img_6.jpg  \n  inflating: train_datasets/images/icdar15/train/img_60.jpg  \n  inflating: train_datasets/images/icdar15/train/img_600.jpg  \n  inflating: train_datasets/images/icdar15/train/img_601.jpg  \n  inflating: train_datasets/images/icdar15/train/img_602.jpg  \n  inflating: train_datasets/images/icdar15/train/img_603.jpg  \n  inflating: train_datasets/images/icdar15/train/img_604.jpg  \n  inflating: train_datasets/images/icdar15/train/img_605.jpg  \n  inflating: train_datasets/images/icdar15/train/img_606.jpg  \n  inflating: train_datasets/images/icdar15/train/img_607.jpg  \n  inflating: train_datasets/images/icdar15/train/img_608.jpg  \n  inflating: train_datasets/images/icdar15/train/img_609.jpg  \n  inflating: train_datasets/images/icdar15/train/img_61.jpg  \n  inflating: train_datasets/images/icdar15/train/img_610.jpg  \n  inflating: train_datasets/images/icdar15/train/img_611.jpg  \n  inflating: train_datasets/images/icdar15/train/img_612.jpg  \n  inflating: train_datasets/images/icdar15/train/img_613.jpg  \n  inflating: train_datasets/images/icdar15/train/img_614.jpg  \n  inflating: train_datasets/images/icdar15/train/img_615.jpg  \n  inflating: train_datasets/images/icdar15/train/img_616.jpg  \n  inflating: train_datasets/images/icdar15/train/img_617.jpg  \n  inflating: train_datasets/images/icdar15/train/img_618.jpg  \n  inflating: train_datasets/images/icdar15/train/img_619.jpg  \n  inflating: train_datasets/images/icdar15/train/img_62.jpg  \n  inflating: train_datasets/images/icdar15/train/img_620.jpg  \n  inflating: train_datasets/images/icdar15/train/img_621.jpg  \n  inflating: train_datasets/images/icdar15/train/img_622.jpg  \n  inflating: train_datasets/images/icdar15/train/img_623.jpg  \n  inflating: train_datasets/images/icdar15/train/img_624.jpg  \n  inflating: train_datasets/images/icdar15/train/img_625.jpg  \n  inflating: train_datasets/images/icdar15/train/img_626.jpg  \n  inflating: train_datasets/images/icdar15/train/img_627.jpg  \n  inflating: train_datasets/images/icdar15/train/img_628.jpg  \n  inflating: train_datasets/images/icdar15/train/img_629.jpg  \n  inflating: train_datasets/images/icdar15/train/img_63.jpg  \n  inflating: train_datasets/images/icdar15/train/img_630.jpg  \n  inflating: train_datasets/images/icdar15/train/img_631.jpg  \n  inflating: train_datasets/images/icdar15/train/img_632.jpg  \n  inflating: train_datasets/images/icdar15/train/img_633.jpg  \n  inflating: train_datasets/images/icdar15/train/img_634.jpg  \n  inflating: train_datasets/images/icdar15/train/img_635.jpg  \n  inflating: train_datasets/images/icdar15/train/img_636.jpg  \n  inflating: train_datasets/images/icdar15/train/img_637.jpg  \n  inflating: train_datasets/images/icdar15/train/img_638.jpg  \n  inflating: train_datasets/images/icdar15/train/img_639.jpg  \n  inflating: train_datasets/images/icdar15/train/img_64.jpg  \n  inflating: train_datasets/images/icdar15/train/img_640.jpg  \n  inflating: train_datasets/images/icdar15/train/img_641.jpg  \n  inflating: train_datasets/images/icdar15/train/img_642.jpg  \n  inflating: train_datasets/images/icdar15/train/img_643.jpg  \n  inflating: train_datasets/images/icdar15/train/img_644.jpg  \n  inflating: train_datasets/images/icdar15/train/img_645.jpg  \n  inflating: train_datasets/images/icdar15/train/img_646.jpg  \n  inflating: train_datasets/images/icdar15/train/img_647.jpg  \n  inflating: train_datasets/images/icdar15/train/img_648.jpg  \n  inflating: train_datasets/images/icdar15/train/img_649.jpg  \n  inflating: train_datasets/images/icdar15/train/img_65.jpg  \n  inflating: train_datasets/images/icdar15/train/img_650.jpg  \n  inflating: train_datasets/images/icdar15/train/img_651.jpg  \n  inflating: train_datasets/images/icdar15/train/img_652.jpg  \n  inflating: train_datasets/images/icdar15/train/img_653.jpg  \n  inflating: train_datasets/images/icdar15/train/img_654.jpg  \n  inflating: train_datasets/images/icdar15/train/img_655.jpg  \n  inflating: train_datasets/images/icdar15/train/img_656.jpg  \n  inflating: train_datasets/images/icdar15/train/img_657.jpg  \n  inflating: train_datasets/images/icdar15/train/img_658.jpg  \n  inflating: train_datasets/images/icdar15/train/img_659.jpg  \n  inflating: train_datasets/images/icdar15/train/img_66.jpg  \n  inflating: train_datasets/images/icdar15/train/img_660.jpg  \n  inflating: train_datasets/images/icdar15/train/img_661.jpg  \n  inflating: train_datasets/images/icdar15/train/img_662.jpg  \n  inflating: train_datasets/images/icdar15/train/img_663.jpg  \n  inflating: train_datasets/images/icdar15/train/img_664.jpg  \n  inflating: train_datasets/images/icdar15/train/img_665.jpg  \n  inflating: train_datasets/images/icdar15/train/img_666.jpg  \n  inflating: train_datasets/images/icdar15/train/img_667.jpg  \n  inflating: train_datasets/images/icdar15/train/img_668.jpg  \n  inflating: train_datasets/images/icdar15/train/img_669.jpg  \n  inflating: train_datasets/images/icdar15/train/img_67.jpg  \n  inflating: train_datasets/images/icdar15/train/img_670.jpg  \n  inflating: train_datasets/images/icdar15/train/img_671.jpg  \n  inflating: train_datasets/images/icdar15/train/img_672.jpg  \n  inflating: train_datasets/images/icdar15/train/img_673.jpg  \n  inflating: train_datasets/images/icdar15/train/img_674.jpg  \n  inflating: train_datasets/images/icdar15/train/img_675.jpg  \n  inflating: train_datasets/images/icdar15/train/img_676.jpg  \n  inflating: train_datasets/images/icdar15/train/img_677.jpg  \n  inflating: train_datasets/images/icdar15/train/img_678.jpg  \n  inflating: train_datasets/images/icdar15/train/img_679.jpg  \n  inflating: train_datasets/images/icdar15/train/img_68.jpg  \n  inflating: train_datasets/images/icdar15/train/img_680.jpg  \n  inflating: train_datasets/images/icdar15/train/img_681.jpg  \n  inflating: train_datasets/images/icdar15/train/img_682.jpg  \n  inflating: train_datasets/images/icdar15/train/img_683.jpg  \n  inflating: train_datasets/images/icdar15/train/img_684.jpg  \n  inflating: train_datasets/images/icdar15/train/img_685.jpg  \n  inflating: train_datasets/images/icdar15/train/img_686.jpg  \n  inflating: train_datasets/images/icdar15/train/img_687.jpg  \n  inflating: train_datasets/images/icdar15/train/img_688.jpg  \n  inflating: train_datasets/images/icdar15/train/img_689.jpg  \n  inflating: train_datasets/images/icdar15/train/img_69.jpg  \n  inflating: train_datasets/images/icdar15/train/img_690.jpg  \n  inflating: train_datasets/images/icdar15/train/img_691.jpg  \n  inflating: train_datasets/images/icdar15/train/img_692.jpg  \n  inflating: train_datasets/images/icdar15/train/img_693.jpg  \n  inflating: train_datasets/images/icdar15/train/img_694.jpg  \n  inflating: train_datasets/images/icdar15/train/img_695.jpg  \n  inflating: train_datasets/images/icdar15/train/img_696.jpg  \n  inflating: train_datasets/images/icdar15/train/img_697.jpg  \n  inflating: train_datasets/images/icdar15/train/img_698.jpg  \n  inflating: train_datasets/images/icdar15/train/img_699.jpg  \n  inflating: train_datasets/images/icdar15/train/img_7.jpg  \n  inflating: train_datasets/images/icdar15/train/img_70.jpg  \n  inflating: train_datasets/images/icdar15/train/img_700.jpg  \n  inflating: train_datasets/images/icdar15/train/img_701.jpg  \n  inflating: train_datasets/images/icdar15/train/img_702.jpg  \n  inflating: train_datasets/images/icdar15/train/img_703.jpg  \n  inflating: train_datasets/images/icdar15/train/img_704.jpg  \n  inflating: train_datasets/images/icdar15/train/img_705.jpg  \n  inflating: train_datasets/images/icdar15/train/img_706.jpg  \n  inflating: train_datasets/images/icdar15/train/img_707.jpg  \n  inflating: train_datasets/images/icdar15/train/img_708.jpg  \n  inflating: train_datasets/images/icdar15/train/img_709.jpg  \n  inflating: train_datasets/images/icdar15/train/img_71.jpg  \n  inflating: train_datasets/images/icdar15/train/img_710.jpg  \n  inflating: train_datasets/images/icdar15/train/img_711.jpg  \n  inflating: train_datasets/images/icdar15/train/img_712.jpg  \n  inflating: train_datasets/images/icdar15/train/img_713.jpg  \n  inflating: train_datasets/images/icdar15/train/img_714.jpg  \n  inflating: train_datasets/images/icdar15/train/img_715.jpg  \n  inflating: train_datasets/images/icdar15/train/img_716.jpg  \n  inflating: train_datasets/images/icdar15/train/img_717.jpg  \n  inflating: train_datasets/images/icdar15/train/img_718.jpg  \n  inflating: train_datasets/images/icdar15/train/img_719.jpg  \n  inflating: train_datasets/images/icdar15/train/img_72.jpg  \n  inflating: train_datasets/images/icdar15/train/img_720.jpg  \n  inflating: train_datasets/images/icdar15/train/img_721.jpg  \n  inflating: train_datasets/images/icdar15/train/img_722.jpg  \n  inflating: train_datasets/images/icdar15/train/img_723.jpg  \n  inflating: train_datasets/images/icdar15/train/img_724.jpg  \n  inflating: train_datasets/images/icdar15/train/img_725.jpg  \n  inflating: train_datasets/images/icdar15/train/img_726.jpg  \n  inflating: train_datasets/images/icdar15/train/img_727.jpg  \n  inflating: train_datasets/images/icdar15/train/img_728.jpg  \n  inflating: train_datasets/images/icdar15/train/img_729.jpg  \n  inflating: train_datasets/images/icdar15/train/img_73.jpg  \n  inflating: train_datasets/images/icdar15/train/img_730.jpg  \n  inflating: train_datasets/images/icdar15/train/img_731.jpg  \n  inflating: train_datasets/images/icdar15/train/img_732.jpg  \n  inflating: train_datasets/images/icdar15/train/img_733.jpg  \n  inflating: train_datasets/images/icdar15/train/img_734.jpg  \n  inflating: train_datasets/images/icdar15/train/img_735.jpg  \n  inflating: train_datasets/images/icdar15/train/img_736.jpg  \n  inflating: train_datasets/images/icdar15/train/img_737.jpg  \n  inflating: train_datasets/images/icdar15/train/img_738.jpg  \n  inflating: train_datasets/images/icdar15/train/img_739.jpg  \n  inflating: train_datasets/images/icdar15/train/img_74.jpg  \n  inflating: train_datasets/images/icdar15/train/img_740.jpg  \n  inflating: train_datasets/images/icdar15/train/img_741.jpg  \n  inflating: train_datasets/images/icdar15/train/img_742.jpg  \n  inflating: train_datasets/images/icdar15/train/img_743.jpg  \n  inflating: train_datasets/images/icdar15/train/img_744.jpg  \n  inflating: train_datasets/images/icdar15/train/img_745.jpg  \n  inflating: train_datasets/images/icdar15/train/img_746.jpg  \n  inflating: train_datasets/images/icdar15/train/img_747.jpg  \n  inflating: train_datasets/images/icdar15/train/img_748.jpg  \n  inflating: train_datasets/images/icdar15/train/img_749.jpg  \n  inflating: train_datasets/images/icdar15/train/img_75.jpg  \n  inflating: train_datasets/images/icdar15/train/img_750.jpg  \n  inflating: train_datasets/images/icdar15/train/img_751.jpg  \n  inflating: train_datasets/images/icdar15/train/img_752.jpg  \n  inflating: train_datasets/images/icdar15/train/img_753.jpg  \n  inflating: train_datasets/images/icdar15/train/img_754.jpg  \n  inflating: train_datasets/images/icdar15/train/img_755.jpg  \n  inflating: train_datasets/images/icdar15/train/img_756.jpg  \n  inflating: train_datasets/images/icdar15/train/img_757.jpg  \n  inflating: train_datasets/images/icdar15/train/img_758.jpg  \n  inflating: train_datasets/images/icdar15/train/img_759.jpg  \n  inflating: train_datasets/images/icdar15/train/img_76.jpg  \n  inflating: train_datasets/images/icdar15/train/img_760.jpg  \n  inflating: train_datasets/images/icdar15/train/img_761.jpg  \n  inflating: train_datasets/images/icdar15/train/img_762.jpg  \n  inflating: train_datasets/images/icdar15/train/img_763.jpg  \n  inflating: train_datasets/images/icdar15/train/img_764.jpg  \n  inflating: train_datasets/images/icdar15/train/img_765.jpg  \n  inflating: train_datasets/images/icdar15/train/img_766.jpg  \n  inflating: train_datasets/images/icdar15/train/img_767.jpg  \n  inflating: train_datasets/images/icdar15/train/img_768.jpg  \n  inflating: train_datasets/images/icdar15/train/img_769.jpg  \n  inflating: train_datasets/images/icdar15/train/img_77.jpg  \n  inflating: train_datasets/images/icdar15/train/img_770.jpg  \n  inflating: train_datasets/images/icdar15/train/img_771.jpg  \n  inflating: train_datasets/images/icdar15/train/img_772.jpg  \n  inflating: train_datasets/images/icdar15/train/img_773.jpg  \n  inflating: train_datasets/images/icdar15/train/img_774.jpg  \n  inflating: train_datasets/images/icdar15/train/img_775.jpg  \n  inflating: train_datasets/images/icdar15/train/img_776.jpg  \n  inflating: train_datasets/images/icdar15/train/img_777.jpg  \n  inflating: train_datasets/images/icdar15/train/img_778.jpg  \n  inflating: train_datasets/images/icdar15/train/img_779.jpg  \n  inflating: train_datasets/images/icdar15/train/img_78.jpg  \n  inflating: train_datasets/images/icdar15/train/img_780.jpg  \n  inflating: train_datasets/images/icdar15/train/img_781.jpg  \n  inflating: train_datasets/images/icdar15/train/img_782.jpg  \n  inflating: train_datasets/images/icdar15/train/img_783.jpg  \n  inflating: train_datasets/images/icdar15/train/img_784.jpg  \n  inflating: train_datasets/images/icdar15/train/img_785.jpg  \n  inflating: train_datasets/images/icdar15/train/img_786.jpg  \n  inflating: train_datasets/images/icdar15/train/img_787.jpg  \n  inflating: train_datasets/images/icdar15/train/img_788.jpg  \n  inflating: train_datasets/images/icdar15/train/img_789.jpg  \n  inflating: train_datasets/images/icdar15/train/img_79.jpg  \n  inflating: train_datasets/images/icdar15/train/img_790.jpg  \n  inflating: train_datasets/images/icdar15/train/img_791.jpg  \n  inflating: train_datasets/images/icdar15/train/img_792.jpg  \n  inflating: train_datasets/images/icdar15/train/img_793.jpg  \n  inflating: train_datasets/images/icdar15/train/img_794.jpg  \n  inflating: train_datasets/images/icdar15/train/img_795.jpg  \n  inflating: train_datasets/images/icdar15/train/img_796.jpg  \n  inflating: train_datasets/images/icdar15/train/img_797.jpg  \n  inflating: train_datasets/images/icdar15/train/img_798.jpg  \n  inflating: train_datasets/images/icdar15/train/img_799.jpg  \n  inflating: train_datasets/images/icdar15/train/img_8.jpg  \n  inflating: train_datasets/images/icdar15/train/img_80.jpg  \n  inflating: train_datasets/images/icdar15/train/img_800.jpg  \n  inflating: train_datasets/images/icdar15/train/img_801.jpg  \n  inflating: train_datasets/images/icdar15/train/img_802.jpg  \n  inflating: train_datasets/images/icdar15/train/img_803.jpg  \n  inflating: train_datasets/images/icdar15/train/img_804.jpg  \n  inflating: train_datasets/images/icdar15/train/img_805.jpg  \n  inflating: train_datasets/images/icdar15/train/img_806.jpg  \n  inflating: train_datasets/images/icdar15/train/img_807.jpg  \n  inflating: train_datasets/images/icdar15/train/img_808.jpg  \n  inflating: train_datasets/images/icdar15/train/img_809.jpg  \n  inflating: train_datasets/images/icdar15/train/img_81.jpg  \n  inflating: train_datasets/images/icdar15/train/img_810.jpg  \n  inflating: train_datasets/images/icdar15/train/img_811.jpg  \n  inflating: train_datasets/images/icdar15/train/img_812.jpg  \n  inflating: train_datasets/images/icdar15/train/img_813.jpg  \n  inflating: train_datasets/images/icdar15/train/img_814.jpg  \n  inflating: train_datasets/images/icdar15/train/img_815.jpg  \n  inflating: train_datasets/images/icdar15/train/img_816.jpg  \n  inflating: train_datasets/images/icdar15/train/img_817.jpg  \n  inflating: train_datasets/images/icdar15/train/img_818.jpg  \n  inflating: train_datasets/images/icdar15/train/img_819.jpg  \n  inflating: train_datasets/images/icdar15/train/img_82.jpg  \n  inflating: train_datasets/images/icdar15/train/img_820.jpg  \n  inflating: train_datasets/images/icdar15/train/img_821.jpg  \n  inflating: train_datasets/images/icdar15/train/img_822.jpg  \n  inflating: train_datasets/images/icdar15/train/img_823.jpg  \n  inflating: train_datasets/images/icdar15/train/img_824.jpg  \n  inflating: train_datasets/images/icdar15/train/img_825.jpg  \n  inflating: train_datasets/images/icdar15/train/img_826.jpg  \n  inflating: train_datasets/images/icdar15/train/img_827.jpg  \n  inflating: train_datasets/images/icdar15/train/img_828.jpg  \n  inflating: train_datasets/images/icdar15/train/img_829.jpg  \n  inflating: train_datasets/images/icdar15/train/img_83.jpg  \n  inflating: train_datasets/images/icdar15/train/img_830.jpg  \n  inflating: train_datasets/images/icdar15/train/img_831.jpg  \n  inflating: train_datasets/images/icdar15/train/img_832.jpg  \n  inflating: train_datasets/images/icdar15/train/img_833.jpg  \n  inflating: train_datasets/images/icdar15/train/img_834.jpg  \n  inflating: train_datasets/images/icdar15/train/img_835.jpg  \n  inflating: train_datasets/images/icdar15/train/img_836.jpg  \n  inflating: train_datasets/images/icdar15/train/img_837.jpg  \n  inflating: train_datasets/images/icdar15/train/img_838.jpg  \n  inflating: train_datasets/images/icdar15/train/img_839.jpg  \n  inflating: train_datasets/images/icdar15/train/img_84.jpg  \n  inflating: train_datasets/images/icdar15/train/img_840.jpg  \n  inflating: train_datasets/images/icdar15/train/img_841.jpg  \n  inflating: train_datasets/images/icdar15/train/img_842.jpg  \n  inflating: train_datasets/images/icdar15/train/img_843.jpg  \n  inflating: train_datasets/images/icdar15/train/img_844.jpg  \n  inflating: train_datasets/images/icdar15/train/img_845.jpg  \n  inflating: train_datasets/images/icdar15/train/img_846.jpg  \n  inflating: train_datasets/images/icdar15/train/img_847.jpg  \n  inflating: train_datasets/images/icdar15/train/img_848.jpg  \n  inflating: train_datasets/images/icdar15/train/img_849.jpg  \n  inflating: train_datasets/images/icdar15/train/img_85.jpg  \n  inflating: train_datasets/images/icdar15/train/img_850.jpg  \n  inflating: train_datasets/images/icdar15/train/img_851.jpg  \n  inflating: train_datasets/images/icdar15/train/img_852.jpg  \n  inflating: train_datasets/images/icdar15/train/img_853.jpg  \n  inflating: train_datasets/images/icdar15/train/img_854.jpg  \n  inflating: train_datasets/images/icdar15/train/img_855.jpg  \n  inflating: train_datasets/images/icdar15/train/img_856.jpg  \n  inflating: train_datasets/images/icdar15/train/img_857.jpg  \n  inflating: train_datasets/images/icdar15/train/img_858.jpg  \n  inflating: train_datasets/images/icdar15/train/img_859.jpg  \n  inflating: train_datasets/images/icdar15/train/img_86.jpg  \n  inflating: train_datasets/images/icdar15/train/img_860.jpg  \n  inflating: train_datasets/images/icdar15/train/img_861.jpg  \n  inflating: train_datasets/images/icdar15/train/img_862.jpg  \n  inflating: train_datasets/images/icdar15/train/img_863.jpg  \n  inflating: train_datasets/images/icdar15/train/img_864.jpg  \n  inflating: train_datasets/images/icdar15/train/img_865.jpg  \n  inflating: train_datasets/images/icdar15/train/img_866.jpg  \n  inflating: train_datasets/images/icdar15/train/img_867.jpg  \n  inflating: train_datasets/images/icdar15/train/img_868.jpg  \n  inflating: train_datasets/images/icdar15/train/img_869.jpg  \n  inflating: train_datasets/images/icdar15/train/img_87.jpg  \n  inflating: train_datasets/images/icdar15/train/img_870.jpg  \n  inflating: train_datasets/images/icdar15/train/img_871.jpg  \n  inflating: train_datasets/images/icdar15/train/img_872.jpg  \n  inflating: train_datasets/images/icdar15/train/img_873.jpg  \n  inflating: train_datasets/images/icdar15/train/img_874.jpg  \n  inflating: train_datasets/images/icdar15/train/img_875.jpg  \n  inflating: train_datasets/images/icdar15/train/img_876.jpg  \n  inflating: train_datasets/images/icdar15/train/img_877.jpg  \n  inflating: train_datasets/images/icdar15/train/img_878.jpg  \n  inflating: train_datasets/images/icdar15/train/img_879.jpg  \n  inflating: train_datasets/images/icdar15/train/img_88.jpg  \n  inflating: train_datasets/images/icdar15/train/img_880.jpg  \n  inflating: train_datasets/images/icdar15/train/img_881.jpg  \n  inflating: train_datasets/images/icdar15/train/img_882.jpg  \n  inflating: train_datasets/images/icdar15/train/img_883.jpg  \n  inflating: train_datasets/images/icdar15/train/img_884.jpg  \n  inflating: train_datasets/images/icdar15/train/img_885.jpg  \n  inflating: train_datasets/images/icdar15/train/img_886.jpg  \n  inflating: train_datasets/images/icdar15/train/img_887.jpg  \n  inflating: train_datasets/images/icdar15/train/img_888.jpg  \n  inflating: train_datasets/images/icdar15/train/img_889.jpg  \n  inflating: train_datasets/images/icdar15/train/img_89.jpg  \n  inflating: train_datasets/images/icdar15/train/img_890.jpg  \n  inflating: train_datasets/images/icdar15/train/img_891.jpg  \n  inflating: train_datasets/images/icdar15/train/img_892.jpg  \n  inflating: train_datasets/images/icdar15/train/img_893.jpg  \n  inflating: train_datasets/images/icdar15/train/img_894.jpg  \n  inflating: train_datasets/images/icdar15/train/img_895.jpg  \n  inflating: train_datasets/images/icdar15/train/img_896.jpg  \n  inflating: train_datasets/images/icdar15/train/img_897.jpg  \n  inflating: train_datasets/images/icdar15/train/img_898.jpg  \n  inflating: train_datasets/images/icdar15/train/img_899.jpg  \n  inflating: train_datasets/images/icdar15/train/img_9.jpg  \n  inflating: train_datasets/images/icdar15/train/img_90.jpg  \n  inflating: train_datasets/images/icdar15/train/img_900.jpg  \n  inflating: train_datasets/images/icdar15/train/img_901.jpg  \n  inflating: train_datasets/images/icdar15/train/img_902.jpg  \n  inflating: train_datasets/images/icdar15/train/img_903.jpg  \n  inflating: train_datasets/images/icdar15/train/img_904.jpg  \n  inflating: train_datasets/images/icdar15/train/img_905.jpg  \n  inflating: train_datasets/images/icdar15/train/img_906.jpg  \n  inflating: train_datasets/images/icdar15/train/img_907.jpg  \n  inflating: train_datasets/images/icdar15/train/img_908.jpg  \n  inflating: train_datasets/images/icdar15/train/img_909.jpg  \n  inflating: train_datasets/images/icdar15/train/img_91.jpg  \n  inflating: train_datasets/images/icdar15/train/img_910.jpg  \n  inflating: train_datasets/images/icdar15/train/img_911.jpg  \n  inflating: train_datasets/images/icdar15/train/img_912.jpg  \n  inflating: train_datasets/images/icdar15/train/img_913.jpg  \n  inflating: train_datasets/images/icdar15/train/img_914.jpg  \n  inflating: train_datasets/images/icdar15/train/img_915.jpg  \n  inflating: train_datasets/images/icdar15/train/img_916.jpg  \n  inflating: train_datasets/images/icdar15/train/img_917.jpg  \n  inflating: train_datasets/images/icdar15/train/img_918.jpg  \n  inflating: train_datasets/images/icdar15/train/img_919.jpg  \n  inflating: train_datasets/images/icdar15/train/img_92.jpg  \n  inflating: train_datasets/images/icdar15/train/img_920.jpg  \n  inflating: train_datasets/images/icdar15/train/img_921.jpg  \n  inflating: train_datasets/images/icdar15/train/img_922.jpg  \n  inflating: train_datasets/images/icdar15/train/img_923.jpg  \n  inflating: train_datasets/images/icdar15/train/img_924.jpg  \n  inflating: train_datasets/images/icdar15/train/img_925.jpg  \n  inflating: train_datasets/images/icdar15/train/img_926.jpg  \n  inflating: train_datasets/images/icdar15/train/img_927.jpg  \n  inflating: train_datasets/images/icdar15/train/img_928.jpg  \n  inflating: train_datasets/images/icdar15/train/img_929.jpg  \n  inflating: train_datasets/images/icdar15/train/img_93.jpg  \n  inflating: train_datasets/images/icdar15/train/img_930.jpg  \n  inflating: train_datasets/images/icdar15/train/img_931.jpg  \n  inflating: train_datasets/images/icdar15/train/img_932.jpg  \n  inflating: train_datasets/images/icdar15/train/img_933.jpg  \n  inflating: train_datasets/images/icdar15/train/img_934.jpg  \n  inflating: train_datasets/images/icdar15/train/img_935.jpg  \n  inflating: train_datasets/images/icdar15/train/img_936.jpg  \n  inflating: train_datasets/images/icdar15/train/img_937.jpg  \n  inflating: train_datasets/images/icdar15/train/img_938.jpg  \n  inflating: train_datasets/images/icdar15/train/img_939.jpg  \n  inflating: train_datasets/images/icdar15/train/img_94.jpg  \n  inflating: train_datasets/images/icdar15/train/img_940.jpg  \n  inflating: train_datasets/images/icdar15/train/img_941.jpg  \n  inflating: train_datasets/images/icdar15/train/img_942.jpg  \n  inflating: train_datasets/images/icdar15/train/img_943.jpg  \n  inflating: train_datasets/images/icdar15/train/img_944.jpg  \n  inflating: train_datasets/images/icdar15/train/img_945.jpg  \n  inflating: train_datasets/images/icdar15/train/img_946.jpg  \n  inflating: train_datasets/images/icdar15/train/img_947.jpg  \n  inflating: train_datasets/images/icdar15/train/img_948.jpg  \n  inflating: train_datasets/images/icdar15/train/img_949.jpg  \n  inflating: train_datasets/images/icdar15/train/img_95.jpg  \n  inflating: train_datasets/images/icdar15/train/img_950.jpg  \n  inflating: train_datasets/images/icdar15/train/img_951.jpg  \n  inflating: train_datasets/images/icdar15/train/img_952.jpg  \n  inflating: train_datasets/images/icdar15/train/img_953.jpg  \n  inflating: train_datasets/images/icdar15/train/img_954.jpg  \n  inflating: train_datasets/images/icdar15/train/img_955.jpg  \n  inflating: train_datasets/images/icdar15/train/img_956.jpg  \n  inflating: train_datasets/images/icdar15/train/img_957.jpg  \n  inflating: train_datasets/images/icdar15/train/img_958.jpg  \n  inflating: train_datasets/images/icdar15/train/img_959.jpg  \n  inflating: train_datasets/images/icdar15/train/img_96.jpg  \n  inflating: train_datasets/images/icdar15/train/img_960.jpg  \n  inflating: train_datasets/images/icdar15/train/img_961.jpg  \n  inflating: train_datasets/images/icdar15/train/img_962.jpg  \n  inflating: train_datasets/images/icdar15/train/img_963.jpg  \n  inflating: train_datasets/images/icdar15/train/img_964.jpg  \n  inflating: train_datasets/images/icdar15/train/img_965.jpg  \n  inflating: train_datasets/images/icdar15/train/img_966.jpg  \n  inflating: train_datasets/images/icdar15/train/img_967.jpg  \n  inflating: train_datasets/images/icdar15/train/img_968.jpg  \n  inflating: train_datasets/images/icdar15/train/img_969.jpg  \n  inflating: train_datasets/images/icdar15/train/img_97.jpg  \n  inflating: train_datasets/images/icdar15/train/img_970.jpg  \n  inflating: train_datasets/images/icdar15/train/img_971.jpg  \n  inflating: train_datasets/images/icdar15/train/img_972.jpg  \n  inflating: train_datasets/images/icdar15/train/img_973.jpg  \n  inflating: train_datasets/images/icdar15/train/img_974.jpg  \n  inflating: train_datasets/images/icdar15/train/img_975.jpg  \n  inflating: train_datasets/images/icdar15/train/img_976.jpg  \n  inflating: train_datasets/images/icdar15/train/img_977.jpg  \n  inflating: train_datasets/images/icdar15/train/img_978.jpg  \n  inflating: train_datasets/images/icdar15/train/img_979.jpg  \n  inflating: train_datasets/images/icdar15/train/img_98.jpg  \n  inflating: train_datasets/images/icdar15/train/img_980.jpg  \n  inflating: train_datasets/images/icdar15/train/img_981.jpg  \n  inflating: train_datasets/images/icdar15/train/img_982.jpg  \n  inflating: train_datasets/images/icdar15/train/img_983.jpg  \n  inflating: train_datasets/images/icdar15/train/img_984.jpg  \n  inflating: train_datasets/images/icdar15/train/img_985.jpg  \n  inflating: train_datasets/images/icdar15/train/img_986.jpg  \n  inflating: train_datasets/images/icdar15/train/img_987.jpg  \n  inflating: train_datasets/images/icdar15/train/img_988.jpg  \n  inflating: train_datasets/images/icdar15/train/img_989.jpg  \n  inflating: train_datasets/images/icdar15/train/img_99.jpg  \n  inflating: train_datasets/images/icdar15/train/img_990.jpg  \n  inflating: train_datasets/images/icdar15/train/img_991.jpg  \n  inflating: train_datasets/images/icdar15/train/img_992.jpg  \n  inflating: train_datasets/images/icdar15/train/img_993.jpg  \n  inflating: train_datasets/images/icdar15/train/img_994.jpg  \n  inflating: train_datasets/images/icdar15/train/img_995.jpg  \n  inflating: train_datasets/images/icdar15/train/img_996.jpg  \n  inflating: train_datasets/images/icdar15/train/img_997.jpg  \n  inflating: train_datasets/images/icdar15/train/img_998.jpg  \n  inflating: train_datasets/images/icdar15/train/img_999.jpg  \nDownloading...\nFrom: https://drive.google.com/uc?id=10OuB7tb3cDCqR1qfhTurR2u1gssnxyIl\nTo: /kaggle/working/units/trainingfromtxt.json\n100%|██████████████████████████████████████| 4.84M/4.84M [00:00<00:00, 30.3MB/s]\nDownloading...\nFrom: https://drive.google.com/uc?id=1REd-FKj8Ot0xhikWkVh1Dns0Dixzemmz\nTo: /kaggle/working/units/testfromtxt.json\n100%|███████████████████████████████████████| 2.14M/2.14M [00:00<00:00, 161MB/s]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Vintext","metadata":{}},{"cell_type":"code","source":"%cd train_datasets\n!gdown 1z9RNy5WLpqSSFwAjHpoDc8NRWesZ4Lo_\n!unzip vietnamese_original.zip\n%cd ..","metadata":{"execution":{"iopub.status.busy":"2024-07-15T10:49:09.561420Z","iopub.execute_input":"2024-07-15T10:49:09.561746Z","iopub.status.idle":"2024-07-15T10:49:34.366780Z","shell.execute_reply.started":"2024-07-15T10:49:09.561714Z","shell.execute_reply":"2024-07-15T10:49:34.365734Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"/kaggle/working/units/train_datasets\nDownloading...\nFrom (original): https://drive.google.com/uc?id=1z9RNy5WLpqSSFwAjHpoDc8NRWesZ4Lo_\nFrom (redirected): https://drive.google.com/uc?id=1z9RNy5WLpqSSFwAjHpoDc8NRWesZ4Lo_&confirm=t&uuid=615c3164-c732-47c0-873d-6bcfafa6bbf4\nTo: /kaggle/working/units/train_datasets/vietnamese_original.zip\n100%|███████████████████████████████████████| 1.05G/1.05G [00:10<00:00, 102MB/s]\nArchive:  vietnamese_original.zip\n   creating: vietnamese/\n  inflating: vietnamese/general_dict.txt  \n  inflating: vietnamese/vn_dictionary.txt  \n   creating: vietnamese/train_images/\n  inflating: vietnamese/train_images/im0722.jpg  \n  inflating: vietnamese/train_images/im0234.jpg  \n  inflating: vietnamese/train_images/im0781.jpg  \n  inflating: vietnamese/train_images/im0318.jpg  \n  inflating: vietnamese/train_images/im0851.jpg  \n  inflating: vietnamese/train_images/im1022.jpg  \n  inflating: vietnamese/train_images/im0041.jpg  \n  inflating: vietnamese/train_images/im1090.jpg  \n  inflating: vietnamese/train_images/im0674.jpg  \n  inflating: vietnamese/train_images/im1013.jpg  \n  inflating: vietnamese/train_images/im0200.jpg  \n  inflating: vietnamese/train_images/im1062.jpg  \n  inflating: vietnamese/train_images/im0190.jpg  \n  inflating: vietnamese/train_images/im1124.jpg  \n  inflating: vietnamese/train_images/im0754.jpg  \n  inflating: vietnamese/train_images/im0299.jpg  \n  inflating: vietnamese/train_images/im0104.jpg  \n  inflating: vietnamese/train_images/im0646.jpg  \n  inflating: vietnamese/train_images/im0545.jpg  \n  inflating: vietnamese/train_images/im0587.jpg  \n  inflating: vietnamese/train_images/im0573.jpg  \n  inflating: vietnamese/train_images/im0430.jpg  \n  inflating: vietnamese/train_images/im0870.jpg  \n  inflating: vietnamese/train_images/im0085.jpg  \n  inflating: vietnamese/train_images/im0003.jpg  \n  inflating: vietnamese/train_images/im0039.jpg  \n  inflating: vietnamese/train_images/im1078.jpg  \n  inflating: vietnamese/train_images/im0677.jpg  \n  inflating: vietnamese/train_images/im0706.jpg  \n  inflating: vietnamese/train_images/im0431.jpg  \n  inflating: vietnamese/train_images/im0551.jpg  \n  inflating: vietnamese/train_images/im0277.jpg  \n  inflating: vietnamese/train_images/im1097.jpg  \n  inflating: vietnamese/train_images/im0570.jpg  \n  inflating: vietnamese/train_images/im1025.jpg  \n  inflating: vietnamese/train_images/im1180.jpg  \n  inflating: vietnamese/train_images/im0869.jpg  \n  inflating: vietnamese/train_images/im0633.jpg  \n  inflating: vietnamese/train_images/im0937.jpg  \n  inflating: vietnamese/train_images/im0302.jpg  \n  inflating: vietnamese/train_images/im0651.jpg  \n  inflating: vietnamese/train_images/im0121.jpg  \n  inflating: vietnamese/train_images/im0391.jpg  \n  inflating: vietnamese/train_images/im0672.jpg  \n  inflating: vietnamese/train_images/im0936.jpg  \n  inflating: vietnamese/train_images/im0237.jpg  \n  inflating: vietnamese/train_images/im0780.jpg  \n  inflating: vietnamese/train_images/im0725.jpg  \n  inflating: vietnamese/train_images/im0177.jpg  \n  inflating: vietnamese/train_images/im0727.jpg  \n  inflating: vietnamese/train_images/im0534.jpg  \n  inflating: vietnamese/train_images/im0235.jpg  \n  inflating: vietnamese/train_images/im0150.jpg  \n  inflating: vietnamese/train_images/im0009.jpg  \n  inflating: vietnamese/train_images/im0634.jpg  \n  inflating: vietnamese/train_images/im0120.jpg  \n  inflating: vietnamese/train_images/im0736.jpg  \n  inflating: vietnamese/train_images/im0087.jpg  \n  inflating: vietnamese/train_images/im1187.jpg  \n  inflating: vietnamese/train_images/im0680.jpg  \n  inflating: vietnamese/train_images/im1073.jpg  \n  inflating: vietnamese/train_images/im0877.jpg  \n  inflating: vietnamese/train_images/im0432.jpg  \n  inflating: vietnamese/train_images/im1163.jpg  \n  inflating: vietnamese/train_images/im0627.jpg  \n  inflating: vietnamese/train_images/im1193.jpg  \n  inflating: vietnamese/train_images/im1119.jpg  \n  inflating: vietnamese/train_images/im0787.jpg  \n  inflating: vietnamese/train_images/im0369.jpg  \n  inflating: vietnamese/train_images/im1065.jpg  \n  inflating: vietnamese/train_images/im0678.jpg  \n  inflating: vietnamese/train_images/im1082.jpg  \n  inflating: vietnamese/train_images/im0001.jpg  \n  inflating: vietnamese/train_images/im0323.jpg  \n  inflating: vietnamese/train_images/im0653.jpg  \n  inflating: vietnamese/train_images/im0367.jpg  \n  inflating: vietnamese/train_images/im0131.jpg  \n  inflating: vietnamese/train_images/im0708.jpg  \n  inflating: vietnamese/train_images/im0395.jpg  \n  inflating: vietnamese/train_images/im0891.jpg  \n  inflating: vietnamese/train_images/im0274.jpg  \n  inflating: vietnamese/train_images/im0140.jpg  \n  inflating: vietnamese/train_images/im1102.jpg  \n  inflating: vietnamese/train_images/im0718.jpg  \n  inflating: vietnamese/train_images/im0303.jpg  \n  inflating: vietnamese/train_images/im0414.jpg  \n  inflating: vietnamese/train_images/im0733.jpg  \n  inflating: vietnamese/train_images/im0934.jpg  \n  inflating: vietnamese/train_images/im0902.jpg  \n  inflating: vietnamese/train_images/im0661.jpg  \n  inflating: vietnamese/train_images/im0645.jpg  \n  inflating: vietnamese/train_images/im0972.jpg  \n  inflating: vietnamese/train_images/im0066.jpg  \n  inflating: vietnamese/train_images/im0188.jpg  \n  inflating: vietnamese/train_images/im0748.jpg  \n  inflating: vietnamese/train_images/im1027.jpg  \n  inflating: vietnamese/train_images/im0732.jpg  \n  inflating: vietnamese/train_images/im0138.jpg  \n  inflating: vietnamese/train_images/im1058.jpg  \n  inflating: vietnamese/train_images/im0376.jpg  \n  inflating: vietnamese/train_images/im0159.jpg  \n  inflating: vietnamese/train_images/im0157.jpg  \n  inflating: vietnamese/train_images/im0827.jpg  \n  inflating: vietnamese/train_images/im0511.jpg  \n  inflating: vietnamese/train_images/im0309.jpg  \n  inflating: vietnamese/train_images/im0187.jpg  \n  inflating: vietnamese/train_images/im0294.jpg  \n  inflating: vietnamese/train_images/im0796.jpg  \n  inflating: vietnamese/train_images/im0556.jpg  \n  inflating: vietnamese/train_images/im1072.jpg  \n  inflating: vietnamese/train_images/im0883.jpg  \n  inflating: vietnamese/train_images/im0147.jpg  \n  inflating: vietnamese/train_images/im1101.jpg  \n  inflating: vietnamese/train_images/im0989.jpg  \n  inflating: vietnamese/train_images/im0878.jpg  \n  inflating: vietnamese/train_images/im0547.jpg  \n  inflating: vietnamese/train_images/im0958.jpg  \n  inflating: vietnamese/train_images/im0230.jpg  \n  inflating: vietnamese/train_images/im0826.jpg  \n  inflating: vietnamese/train_images/im0449.jpg  \n  inflating: vietnamese/train_images/im0164.jpg  \n  inflating: vietnamese/train_images/im0929.jpg  \n  inflating: vietnamese/train_images/im0115.jpg  \n  inflating: vietnamese/train_images/im0712.jpg  \n  inflating: vietnamese/train_images/im0575.jpg  \n  inflating: vietnamese/train_images/im0097.jpg  \n  inflating: vietnamese/train_images/im0441.jpg  \n  inflating: vietnamese/train_images/im0970.jpg  \n  inflating: vietnamese/train_images/im0720.jpg  \n  inflating: vietnamese/train_images/im0290.jpg  \n  inflating: vietnamese/train_images/im1053.jpg  \n  inflating: vietnamese/train_images/im0969.jpg  \n  inflating: vietnamese/train_images/im0467.jpg  \n  inflating: vietnamese/train_images/im0193.jpg  \n  inflating: vietnamese/train_images/im0559.jpg  \n  inflating: vietnamese/train_images/im0501.jpg  \n  inflating: vietnamese/train_images/im0631.jpg  \n  inflating: vietnamese/train_images/im0681.jpg  \n  inflating: vietnamese/train_images/im0133.jpg  \n  inflating: vietnamese/train_images/im1042.jpg  \n  inflating: vietnamese/train_images/im0020.jpg  \n  inflating: vietnamese/train_images/im0762.jpg  \n  inflating: vietnamese/train_images/im0526.jpg  \n  inflating: vietnamese/train_images/im1010.jpg  \n  inflating: vietnamese/train_images/im0673.jpg  \n  inflating: vietnamese/train_images/im1046.jpg  \n  inflating: vietnamese/train_images/im0433.jpg  \n  inflating: vietnamese/train_images/im0488.jpg  \n  inflating: vietnamese/train_images/im0986.jpg  \n  inflating: vietnamese/train_images/im0059.jpg  \n  inflating: vietnamese/train_images/im0137.jpg  \n  inflating: vietnamese/train_images/im0067.jpg  \n  inflating: vietnamese/train_images/im0993.jpg  \n  inflating: vietnamese/train_images/im0126.jpg  \n  inflating: vietnamese/train_images/im0037.jpg  \n  inflating: vietnamese/train_images/im0082.jpg  \n  inflating: vietnamese/train_images/im0763.jpg  \n  inflating: vietnamese/train_images/im1044.jpg  \n  inflating: vietnamese/train_images/im1110.jpg  \n  inflating: vietnamese/train_images/im0390.jpg  \n  inflating: vietnamese/train_images/im1014.jpg  \n  inflating: vietnamese/train_images/im0244.jpg  \n  inflating: vietnamese/train_images/im0944.jpg  \n  inflating: vietnamese/train_images/im0380.jpg  \n  inflating: vietnamese/train_images/im0805.jpg  \n  inflating: vietnamese/train_images/im0621.jpg  \n  inflating: vietnamese/train_images/im0114.jpg  \n  inflating: vietnamese/train_images/im0452.jpg  \n  inflating: vietnamese/train_images/im1063.jpg  \n  inflating: vietnamese/train_images/im0782.jpg  \n  inflating: vietnamese/train_images/im0223.jpg  \n  inflating: vietnamese/train_images/im0389.jpg  \n  inflating: vietnamese/train_images/im0832.jpg  \n  inflating: vietnamese/train_images/im0250.jpg  \n  inflating: vietnamese/train_images/im1149.jpg  \n  inflating: vietnamese/train_images/im0839.jpg  \n  inflating: vietnamese/train_images/im1089.jpg  \n  inflating: vietnamese/train_images/im0182.jpg  \n  inflating: vietnamese/train_images/im0266.jpg  \n  inflating: vietnamese/train_images/im0571.jpg  \n  inflating: vietnamese/train_images/im1083.jpg  \n  inflating: vietnamese/train_images/im1162.jpg  \n  inflating: vietnamese/train_images/im1155.jpg  \n  inflating: vietnamese/train_images/im1177.jpg  \n  inflating: vietnamese/train_images/im0203.jpg  \n  inflating: vietnamese/train_images/im0694.jpg  \n  inflating: vietnamese/train_images/im1138.jpg  \n  inflating: vietnamese/train_images/im0960.jpg  \n  inflating: vietnamese/train_images/im0847.jpg  \n  inflating: vietnamese/train_images/im0283.jpg  \n  inflating: vietnamese/train_images/im0469.jpg  \n  inflating: vietnamese/train_images/im0739.jpg  \n  inflating: vietnamese/train_images/im0617.jpg  \n  inflating: vietnamese/train_images/im0603.jpg  \n  inflating: vietnamese/train_images/im0139.jpg  \n  inflating: vietnamese/train_images/im0402.jpg  \n  inflating: vietnamese/train_images/im0509.jpg  \n  inflating: vietnamese/train_images/im0347.jpg  \n  inflating: vietnamese/train_images/im0654.jpg  \n  inflating: vietnamese/train_images/im1114.jpg  \n  inflating: vietnamese/train_images/im0743.jpg  \n  inflating: vietnamese/train_images/im0371.jpg  \n  inflating: vietnamese/train_images/im0136.jpg  \n  inflating: vietnamese/train_images/im0112.jpg  \n  inflating: vietnamese/train_images/im0846.jpg  \n  inflating: vietnamese/train_images/im1121.jpg  \n  inflating: vietnamese/train_images/im0687.jpg  \n  inflating: vietnamese/train_images/im0664.jpg  \n  inflating: vietnamese/train_images/im0638.jpg  \n  inflating: vietnamese/train_images/im0096.jpg  \n  inflating: vietnamese/train_images/im0243.jpg  \n  inflating: vietnamese/train_images/im0356.jpg  \n  inflating: vietnamese/train_images/im0707.jpg  \n  inflating: vietnamese/train_images/im0668.jpg  \n  inflating: vietnamese/train_images/im0035.jpg  \n  inflating: vietnamese/train_images/im0926.jpg  \n  inflating: vietnamese/train_images/im0264.jpg  \n  inflating: vietnamese/train_images/im0852.jpg  \n  inflating: vietnamese/train_images/im0460.jpg  \n  inflating: vietnamese/train_images/im1103.jpg  \n  inflating: vietnamese/train_images/im0069.jpg  \n  inflating: vietnamese/train_images/im0055.jpg  \n  inflating: vietnamese/train_images/im0955.jpg  \n  inflating: vietnamese/train_images/im0613.jpg  \n  inflating: vietnamese/train_images/im0737.jpg  \n  inflating: vietnamese/train_images/im0876.jpg  \n  inflating: vietnamese/train_images/im0215.jpg  \n  inflating: vietnamese/train_images/im0225.jpg  \n  inflating: vietnamese/train_images/im0297.jpg  \n  inflating: vietnamese/train_images/im1154.jpg  \n  inflating: vietnamese/train_images/im0352.jpg  \n  inflating: vietnamese/train_images/im0074.jpg  \n  inflating: vietnamese/train_images/im0038.jpg  \n  inflating: vietnamese/train_images/im0119.jpg  \n  inflating: vietnamese/train_images/im0378.jpg  \n  inflating: vietnamese/train_images/im0060.jpg  \n  inflating: vietnamese/train_images/im0698.jpg  \n  inflating: vietnamese/train_images/im1106.jpg  \n  inflating: vietnamese/train_images/im0325.jpg  \n  inflating: vietnamese/train_images/im0435.jpg  \n  inflating: vietnamese/train_images/im0907.jpg  \n  inflating: vietnamese/train_images/im1032.jpg  \n  inflating: vietnamese/train_images/im0794.jpg  \n  inflating: vietnamese/train_images/im0476.jpg  \n  inflating: vietnamese/train_images/im0954.jpg  \n  inflating: vietnamese/train_images/im0310.jpg  \n  inflating: vietnamese/train_images/im0168.jpg  \n  inflating: vietnamese/train_images/im0705.jpg  \n  inflating: vietnamese/train_images/im0775.jpg  \n  inflating: vietnamese/train_images/im0562.jpg  \n  inflating: vietnamese/train_images/im1109.jpg  \n  inflating: vietnamese/train_images/im0484.jpg  \n  inflating: vietnamese/train_images/im0974.jpg  \n  inflating: vietnamese/train_images/im0595.jpg  \n  inflating: vietnamese/train_images/im0784.jpg  \n  inflating: vietnamese/train_images/im0951.jpg  \n  inflating: vietnamese/train_images/im0845.jpg  \n  inflating: vietnamese/train_images/im0482.jpg  \n  inflating: vietnamese/train_images/im0867.jpg  \n  inflating: vietnamese/train_images/im0609.jpg  \n  inflating: vietnamese/train_images/im1077.jpg  \n  inflating: vietnamese/train_images/im0874.jpg  \n  inflating: vietnamese/train_images/im0682.jpg  \n  inflating: vietnamese/train_images/im0101.jpg  \n  inflating: vietnamese/train_images/im0370.jpg  \n  inflating: vietnamese/train_images/im0419.jpg  \n  inflating: vietnamese/train_images/im0084.jpg  \n  inflating: vietnamese/train_images/im0212.jpg  \n  inflating: vietnamese/train_images/im0642.jpg  \n  inflating: vietnamese/train_images/im0032.jpg  \n  inflating: vietnamese/train_images/im0959.jpg  \n  inflating: vietnamese/train_images/im0854.jpg  \n  inflating: vietnamese/train_images/im0799.jpg  \n  inflating: vietnamese/train_images/im1123.jpg  \n  inflating: vietnamese/train_images/im1074.jpg  \n  inflating: vietnamese/train_images/im0723.jpg  \n  inflating: vietnamese/train_images/im0377.jpg  \n  inflating: vietnamese/train_images/im0253.jpg  \n  inflating: vietnamese/train_images/im1066.jpg  \n  inflating: vietnamese/train_images/im0327.jpg  \n  inflating: vietnamese/train_images/im0567.jpg  \n  inflating: vietnamese/train_images/im0983.jpg  \n  inflating: vietnamese/train_images/im0973.jpg  \n  inflating: vietnamese/train_images/im0516.jpg  \n  inflating: vietnamese/train_images/im0923.jpg  \n  inflating: vietnamese/train_images/im1093.jpg  \n  inflating: vietnamese/train_images/im0882.jpg  \n  inflating: vietnamese/train_images/im0583.jpg  \n  inflating: vietnamese/train_images/im0859.jpg  \n  inflating: vietnamese/train_images/im0372.jpg  \n  inflating: vietnamese/train_images/im0443.jpg  \n  inflating: vietnamese/train_images/im0079.jpg  \n  inflating: vietnamese/train_images/im1141.jpg  \n  inflating: vietnamese/train_images/im1190.jpg  \n  inflating: vietnamese/train_images/im1147.jpg  \n  inflating: vietnamese/train_images/im0879.jpg  \n  inflating: vietnamese/train_images/im0808.jpg  \n  inflating: vietnamese/train_images/im1086.jpg  \n  inflating: vietnamese/train_images/im1054.jpg  \n  inflating: vietnamese/train_images/im1160.jpg  \n  inflating: vietnamese/train_images/im0004.jpg  \n  inflating: vietnamese/train_images/im0005.jpg  \n  inflating: vietnamese/train_images/im0849.jpg  \n  inflating: vietnamese/train_images/im0170.jpg  \n  inflating: vietnamese/train_images/im0475.jpg  \n  inflating: vietnamese/train_images/im0434.jpg  \n  inflating: vietnamese/train_images/im0729.jpg  \n  inflating: vietnamese/train_images/im0255.jpg  \n  inflating: vietnamese/train_images/im0871.jpg  \n  inflating: vietnamese/train_images/im0614.jpg  \n  inflating: vietnamese/train_images/im0893.jpg  \n  inflating: vietnamese/train_images/im0769.jpg  \n  inflating: vietnamese/train_images/im0920.jpg  \n  inflating: vietnamese/train_images/im0385.jpg  \n  inflating: vietnamese/train_images/im0809.jpg  \n  inflating: vietnamese/train_images/im1113.jpg  \n  inflating: vietnamese/train_images/im1129.jpg  \n  inflating: vietnamese/train_images/im0597.jpg  \n  inflating: vietnamese/train_images/im0994.jpg  \n  inflating: vietnamese/train_images/im1135.jpg  \n  inflating: vietnamese/train_images/im0635.jpg  \n  inflating: vietnamese/train_images/im0345.jpg  \n  inflating: vietnamese/train_images/im0594.jpg  \n  inflating: vietnamese/train_images/im0165.jpg  \n  inflating: vietnamese/train_images/im0246.jpg  \n  inflating: vietnamese/train_images/im0755.jpg  \n  inflating: vietnamese/train_images/im0388.jpg  \n  inflating: vietnamese/train_images/im0582.jpg  \n  inflating: vietnamese/train_images/im0022.jpg  \n  inflating: vietnamese/train_images/im0019.jpg  \n  inflating: vietnamese/train_images/im1067.jpg  \n  inflating: vietnamese/train_images/im0888.jpg  \n  inflating: vietnamese/train_images/im0045.jpg  \n  inflating: vietnamese/train_images/im0910.jpg  \n  inflating: vietnamese/train_images/im0946.jpg  \n  inflating: vietnamese/train_images/im1117.jpg  \n  inflating: vietnamese/train_images/im0500.jpg  \n  inflating: vietnamese/train_images/im0153.jpg  \n  inflating: vietnamese/train_images/im0268.jpg  \n  inflating: vietnamese/train_images/im0334.jpg  \n  inflating: vietnamese/train_images/im0577.jpg  \n  inflating: vietnamese/train_images/im0546.jpg  \n  inflating: vietnamese/train_images/im0532.jpg  \n  inflating: vietnamese/train_images/im0127.jpg  \n  inflating: vietnamese/train_images/im0403.jpg  \n  inflating: vietnamese/train_images/im0640.jpg  \n  inflating: vietnamese/train_images/im0021.jpg  \n  inflating: vietnamese/train_images/im0709.jpg  \n  inflating: vietnamese/train_images/im0298.jpg  \n  inflating: vietnamese/train_images/im0220.jpg  \n  inflating: vietnamese/train_images/im0606.jpg  \n  inflating: vietnamese/train_images/im1168.jpg  \n  inflating: vietnamese/train_images/im0176.jpg  \n  inflating: vietnamese/train_images/im0281.jpg  \n  inflating: vietnamese/train_images/im0346.jpg  \n  inflating: vietnamese/train_images/im0537.jpg  \n  inflating: vietnamese/train_images/im0561.jpg  \n  inflating: vietnamese/train_images/im0152.jpg  \n  inflating: vietnamese/train_images/im0142.jpg  \n  inflating: vietnamese/train_images/im0105.jpg  \n  inflating: vietnamese/train_images/im0953.jpg  \n  inflating: vietnamese/train_images/im0895.jpg  \n  inflating: vietnamese/train_images/im0512.jpg  \n  inflating: vietnamese/train_images/im0566.jpg  \n  inflating: vietnamese/train_images/im0211.jpg  \n  inflating: vietnamese/train_images/im0355.jpg  \n  inflating: vietnamese/train_images/im1009.jpg  \n  inflating: vietnamese/train_images/im0013.jpg  \n  inflating: vietnamese/train_images/im1047.jpg  \n  inflating: vietnamese/train_images/im0025.jpg  \n  inflating: vietnamese/train_images/im0667.jpg  \n  inflating: vietnamese/train_images/im1131.jpg  \n  inflating: vietnamese/train_images/im0071.jpg  \n  inflating: vietnamese/train_images/im0199.jpg  \n  inflating: vietnamese/train_images/im0312.jpg  \n  inflating: vietnamese/train_images/im0473.jpg  \n  inflating: vietnamese/train_images/im0204.jpg  \n  inflating: vietnamese/train_images/im0656.jpg  \n  inflating: vietnamese/train_images/im1136.jpg  \n  inflating: vietnamese/train_images/im0965.jpg  \n  inflating: vietnamese/train_images/im0128.jpg  \n  inflating: vietnamese/train_images/im1076.jpg  \n  inflating: vietnamese/train_images/im0026.jpg  \n  inflating: vietnamese/train_images/im1112.jpg  \n  inflating: vietnamese/train_images/im0588.jpg  \n  inflating: vietnamese/train_images/im0898.jpg  \n  inflating: vietnamese/train_images/im0420.jpg  \n  inflating: vietnamese/train_images/im0773.jpg  \n  inflating: vietnamese/train_images/im0462.jpg  \n  inflating: vietnamese/train_images/im0175.jpg  \n  inflating: vietnamese/train_images/im0463.jpg  \n  inflating: vietnamese/train_images/im1173.jpg  \n  inflating: vietnamese/train_images/im0078.jpg  \n  inflating: vietnamese/train_images/im0861.jpg  \n  inflating: vietnamese/train_images/im0821.jpg  \n  inflating: vietnamese/train_images/im1128.jpg  \n  inflating: vietnamese/train_images/im0335.jpg  \n  inflating: vietnamese/train_images/im0517.jpg  \n  inflating: vietnamese/train_images/im0424.jpg  \n  inflating: vietnamese/train_images/im0472.jpg  \n  inflating: vietnamese/train_images/im0717.jpg  \n  inflating: vietnamese/train_images/im0585.jpg  \n  inflating: vietnamese/train_images/im0625.jpg  \n  inflating: vietnamese/train_images/im0924.jpg  \n  inflating: vietnamese/train_images/im1045.jpg  \n  inflating: vietnamese/train_images/im0657.jpg  \n  inflating: vietnamese/train_images/im0591.jpg  \n  inflating: vietnamese/train_images/im0767.jpg  \n  inflating: vietnamese/train_images/im0384.jpg  \n  inflating: vietnamese/train_images/im1030.jpg  \n  inflating: vietnamese/train_images/im0636.jpg  \n  inflating: vietnamese/train_images/im1165.jpg  \n  inflating: vietnamese/train_images/im0458.jpg  \n  inflating: vietnamese/train_images/im0442.jpg  \n  inflating: vietnamese/train_images/im0670.jpg  \n  inflating: vietnamese/train_images/im0660.jpg  \n  inflating: vietnamese/train_images/im0793.jpg  \n  inflating: vietnamese/train_images/im0831.jpg  \n  inflating: vietnamese/train_images/im0381.jpg  \n  inflating: vietnamese/train_images/im0259.jpg  \n  inflating: vietnamese/train_images/im0855.jpg  \n  inflating: vietnamese/train_images/im0195.jpg  \n  inflating: vietnamese/train_images/im0641.jpg  \n  inflating: vietnamese/train_images/im0697.jpg  \n  inflating: vietnamese/train_images/im0689.jpg  \n  inflating: vietnamese/train_images/im0611.jpg  \n  inflating: vietnamese/train_images/im0864.jpg  \n  inflating: vietnamese/train_images/im0998.jpg  \n  inflating: vietnamese/train_images/im0161.jpg  \n  inflating: vietnamese/train_images/im1049.jpg  \n  inflating: vietnamese/train_images/im1164.jpg  \n  inflating: vietnamese/train_images/im0601.jpg  \n  inflating: vietnamese/train_images/im0950.jpg  \n  inflating: vietnamese/train_images/im0409.jpg  \n  inflating: vietnamese/train_images/im0917.jpg  \n  inflating: vietnamese/train_images/im0715.jpg  \n  inflating: vietnamese/train_images/im0822.jpg  \n  inflating: vietnamese/train_images/im0816.jpg  \n  inflating: vietnamese/train_images/im0600.jpg  \n  inflating: vietnamese/train_images/im0011.jpg  \n  inflating: vietnamese/train_images/im0745.jpg  \n  inflating: vietnamese/train_images/im0332.jpg  \n  inflating: vietnamese/train_images/im0171.jpg  \n  inflating: vietnamese/train_images/im1166.jpg  \n  inflating: vietnamese/train_images/im1122.jpg  \n  inflating: vietnamese/train_images/im0956.jpg  \n  inflating: vietnamese/train_images/im1169.jpg  \n  inflating: vietnamese/train_images/im1192.jpg  \n  inflating: vietnamese/train_images/im0590.jpg  \n  inflating: vietnamese/train_images/im0453.jpg  \n  inflating: vietnamese/train_images/im0015.jpg  \n  inflating: vietnamese/train_images/im0905.jpg  \n  inflating: vietnamese/train_images/im0491.jpg  \n  inflating: vietnamese/train_images/im1043.jpg  \n  inflating: vietnamese/train_images/im0464.jpg  \n  inflating: vietnamese/train_images/im1146.jpg  \n  inflating: vietnamese/train_images/im0440.jpg  \n  inflating: vietnamese/train_images/im0966.jpg  \n  inflating: vietnamese/train_images/im1184.jpg  \n  inflating: vietnamese/train_images/im0825.jpg  \n  inflating: vietnamese/train_images/im0848.jpg  \n  inflating: vietnamese/train_images/im0056.jpg  \n  inflating: vietnamese/train_images/im0522.jpg  \n  inflating: vietnamese/train_images/im0798.jpg  \n  inflating: vietnamese/train_images/im0447.jpg  \n  inflating: vietnamese/train_images/im0278.jpg  \n  inflating: vietnamese/train_images/im0396.jpg  \n  inflating: vietnamese/train_images/im0863.jpg  \n  inflating: vietnamese/train_images/im0493.jpg  \n  inflating: vietnamese/train_images/im0548.jpg  \n  inflating: vietnamese/train_images/im0411.jpg  \n  inflating: vietnamese/train_images/im0768.jpg  \n  inflating: vietnamese/train_images/im1002.jpg  \n  inflating: vietnamese/train_images/im0688.jpg  \n  inflating: vietnamese/train_images/im0906.jpg  \n  inflating: vietnamese/train_images/im1041.jpg  \n  inflating: vietnamese/train_images/im0169.jpg  \n  inflating: vietnamese/train_images/im0206.jpg  \n  inflating: vietnamese/train_images/im0490.jpg  \n  inflating: vietnamese/train_images/im0144.jpg  \n  inflating: vietnamese/train_images/im0979.jpg  \n  inflating: vietnamese/train_images/im0791.jpg  \n  inflating: vietnamese/train_images/im0238.jpg  \n  inflating: vietnamese/train_images/im1111.jpg  \n  inflating: vietnamese/train_images/im0062.jpg  \n  inflating: vietnamese/train_images/im0282.jpg  \n  inflating: vietnamese/train_images/im0592.jpg  \n  inflating: vietnamese/train_images/im0572.jpg  \n  inflating: vietnamese/train_images/im0964.jpg  \n  inflating: vietnamese/train_images/im1137.jpg  \n  inflating: vietnamese/train_images/im0671.jpg  \n  inflating: vietnamese/train_images/im0524.jpg  \n  inflating: vietnamese/train_images/im0248.jpg  \n  inflating: vietnamese/train_images/im0693.jpg  \n  inflating: vietnamese/train_images/im0080.jpg  \n  inflating: vietnamese/train_images/im0049.jpg  \n  inflating: vietnamese/train_images/im0988.jpg  \n  inflating: vietnamese/train_images/im1191.jpg  \n  inflating: vietnamese/train_images/im0357.jpg  \n  inflating: vietnamese/train_images/im0807.jpg  \n  inflating: vietnamese/train_images/im1035.jpg  \n  inflating: vietnamese/train_images/im0028.jpg  \n  inflating: vietnamese/train_images/im0438.jpg  \n  inflating: vietnamese/train_images/im0392.jpg  \n  inflating: vietnamese/train_images/im0487.jpg  \n  inflating: vietnamese/train_images/im0296.jpg  \n  inflating: vietnamese/train_images/im0076.jpg  \n  inflating: vietnamese/train_images/im0485.jpg  \n  inflating: vietnamese/train_images/im1115.jpg  \n  inflating: vietnamese/train_images/im0108.jpg  \n  inflating: vietnamese/train_images/im1091.jpg  \n  inflating: vietnamese/train_images/im0913.jpg  \n  inflating: vietnamese/train_images/im0933.jpg  \n  inflating: vietnamese/train_images/im0146.jpg  \n  inflating: vietnamese/train_images/im0811.jpg  \n  inflating: vietnamese/train_images/im0853.jpg  \n  inflating: vietnamese/train_images/im0337.jpg  \n  inflating: vietnamese/train_images/im0257.jpg  \n  inflating: vietnamese/train_images/im1081.jpg  \n  inflating: vietnamese/train_images/im0315.jpg  \n  inflating: vietnamese/train_images/im0675.jpg  \n  inflating: vietnamese/train_images/im0655.jpg  \n  inflating: vietnamese/train_images/im1034.jpg  \n  inflating: vietnamese/train_images/im1070.jpg  \n  inflating: vietnamese/train_images/im0451.jpg  \n  inflating: vietnamese/train_images/im0429.jpg  \n  inflating: vietnamese/train_images/im0014.jpg  \n  inflating: vietnamese/train_images/im0379.jpg  \n  inflating: vietnamese/train_images/im0241.jpg  \n  inflating: vietnamese/train_images/im1194.jpg  \n  inflating: vietnamese/train_images/im0052.jpg  \n  inflating: vietnamese/train_images/im0783.jpg  \n  inflating: vietnamese/train_images/im0992.jpg  \n  inflating: vietnamese/train_images/im0348.jpg  \n  inflating: vietnamese/train_images/im1188.jpg  \n  inflating: vietnamese/train_images/im0903.jpg  \n  inflating: vietnamese/train_images/im0321.jpg  \n  inflating: vietnamese/train_images/im0418.jpg  \n  inflating: vietnamese/train_images/im0881.jpg  \n  inflating: vietnamese/train_images/im1028.jpg  \n  inflating: vietnamese/train_images/im0018.jpg  \n  inflating: vietnamese/train_images/im1038.jpg  \n  inflating: vietnamese/train_images/im0528.jpg  \n  inflating: vietnamese/train_images/im0860.jpg  \n  inflating: vietnamese/train_images/im0151.jpg  \n  inflating: vietnamese/train_images/im0911.jpg  \n  inflating: vietnamese/train_images/im0777.jpg  \n  inflating: vietnamese/train_images/im0968.jpg  \n  inflating: vietnamese/train_images/im0446.jpg  \n  inflating: vietnamese/train_images/im0820.jpg  \n  inflating: vietnamese/train_images/im0405.jpg  \n  inflating: vietnamese/train_images/im0229.jpg  \n  inflating: vietnamese/train_images/im0865.jpg  \n  inflating: vietnamese/train_images/im0239.jpg  \n  inflating: vietnamese/train_images/im0445.jpg  \n  inflating: vietnamese/train_images/im0130.jpg  \n  inflating: vietnamese/train_images/im0160.jpg  \n  inflating: vietnamese/train_images/im0437.jpg  \n  inflating: vietnamese/train_images/im1170.jpg  \n  inflating: vietnamese/train_images/im0110.jpg  \n  inflating: vietnamese/train_images/im0174.jpg  \n  inflating: vietnamese/train_images/im0288.jpg  \n  inflating: vietnamese/train_images/im1108.jpg  \n  inflating: vietnamese/train_images/im1161.jpg  \n  inflating: vietnamese/train_images/im0006.jpg  \n  inflating: vietnamese/train_images/im1079.jpg  \n  inflating: vietnamese/train_images/im0263.jpg  \n  inflating: vietnamese/train_images/im0304.jpg  \n  inflating: vietnamese/train_images/im0098.jpg  \n  inflating: vietnamese/train_images/im0251.jpg  \n  inflating: vietnamese/train_images/im0842.jpg  \n  inflating: vietnamese/train_images/im0406.jpg  \n  inflating: vietnamese/train_images/im1107.jpg  \n  inflating: vietnamese/train_images/im1152.jpg  \n  inflating: vietnamese/train_images/im0751.jpg  \n  inflating: vietnamese/train_images/im0978.jpg  \n  inflating: vietnamese/train_images/im0676.jpg  \n  inflating: vietnamese/train_images/im0192.jpg  \n  inflating: vietnamese/train_images/im0185.jpg  \n  inflating: vietnamese/train_images/im0685.jpg  \n  inflating: vietnamese/train_images/im0734.jpg  \n  inflating: vietnamese/train_images/im0666.jpg  \n  inflating: vietnamese/train_images/im1150.jpg  \n  inflating: vietnamese/train_images/im0513.jpg  \n  inflating: vietnamese/train_images/im1004.jpg  \n  inflating: vietnamese/train_images/im0644.jpg  \n  inflating: vietnamese/train_images/im0494.jpg  \n  inflating: vietnamese/train_images/im1068.jpg  \n  inflating: vietnamese/train_images/im1178.jpg  \n  inflating: vietnamese/train_images/im0213.jpg  \n  inflating: vietnamese/train_images/im0818.jpg  \n  inflating: vietnamese/train_images/im0527.jpg  \n  inflating: vietnamese/train_images/im0186.jpg  \n  inflating: vietnamese/train_images/im0415.jpg  \n  inflating: vietnamese/train_images/im0914.jpg  \n  inflating: vietnamese/train_images/im0840.jpg  \n  inflating: vietnamese/train_images/im0576.jpg  \n  inflating: vietnamese/train_images/im1158.jpg  \n  inflating: vietnamese/train_images/im0996.jpg  \n  inflating: vietnamese/train_images/im0686.jpg  \n  inflating: vietnamese/train_images/im0981.jpg  \n  inflating: vietnamese/train_images/im0002.jpg  \n  inflating: vietnamese/train_images/im1105.jpg  \n  inflating: vietnamese/train_images/im0023.jpg  \n  inflating: vietnamese/train_images/im0300.jpg  \n  inflating: vietnamese/train_images/im0320.jpg  \n  inflating: vietnamese/train_images/im0221.jpg  \n  inflating: vietnamese/train_images/im0216.jpg  \n  inflating: vietnamese/train_images/im0952.jpg  \n  inflating: vietnamese/train_images/im1197.jpg  \n  inflating: vietnamese/train_images/im0129.jpg  \n  inflating: vietnamese/train_images/im0145.jpg  \n  inflating: vietnamese/train_images/im0549.jpg  \n  inflating: vietnamese/train_images/im0135.jpg  \n  inflating: vietnamese/train_images/im0713.jpg  \n  inflating: vietnamese/train_images/im0326.jpg  \n  inflating: vietnamese/train_images/im1196.jpg  \n  inflating: vietnamese/train_images/im1092.jpg  \n  inflating: vietnamese/train_images/im0543.jpg  \n  inflating: vietnamese/train_images/im0010.jpg  \n  inflating: vietnamese/train_images/im0275.jpg  \n  inflating: vietnamese/train_images/im0210.jpg  \n  inflating: vietnamese/train_images/im0125.jpg  \n  inflating: vietnamese/train_images/im0772.jpg  \n  inflating: vietnamese/train_images/im0088.jpg  \n  inflating: vietnamese/train_images/im0829.jpg  \n  inflating: vietnamese/train_images/im0663.jpg  \n  inflating: vietnamese/train_images/im0047.jpg  \n  inflating: vietnamese/train_images/im0247.jpg  \n  inflating: vietnamese/train_images/im0196.jpg  \n  inflating: vietnamese/train_images/im0568.jpg  \n  inflating: vietnamese/train_images/im0048.jpg  \n  inflating: vietnamese/train_images/im0894.jpg  \n  inflating: vietnamese/train_images/im0531.jpg  \n  inflating: vietnamese/train_images/im0835.jpg  \n  inflating: vietnamese/train_images/im0336.jpg  \n  inflating: vietnamese/train_images/im0495.jpg  \n  inflating: vietnamese/train_images/im0401.jpg  \n  inflating: vietnamese/train_images/im0901.jpg  \n  inflating: vietnamese/train_images/im0227.jpg  \n  inflating: vietnamese/train_images/im0909.jpg  \n  inflating: vietnamese/train_images/im0313.jpg  \n  inflating: vietnamese/train_images/im0198.jpg  \n  inflating: vietnamese/train_images/im1020.jpg  \n  inflating: vietnamese/train_images/im0044.jpg  \n  inflating: vietnamese/train_images/im0141.jpg  \n  inflating: vietnamese/train_images/im0496.jpg  \n  inflating: vietnamese/train_images/im0027.jpg  \n  inflating: vietnamese/train_images/im0802.jpg  \n  inflating: vietnamese/train_images/im1189.jpg  \n  inflating: vietnamese/train_images/im0593.jpg  \n  inflating: vietnamese/train_images/im0692.jpg  \n  inflating: vietnamese/train_images/im0771.jpg  \n  inflating: vietnamese/train_images/im0092.jpg  \n  inflating: vietnamese/train_images/im0343.jpg  \n  inflating: vietnamese/train_images/im0525.jpg  \n  inflating: vietnamese/train_images/im0789.jpg  \n  inflating: vietnamese/train_images/im1039.jpg  \n  inflating: vietnamese/train_images/im1095.jpg  \n  inflating: vietnamese/train_images/im0455.jpg  \n  inflating: vietnamese/train_images/im0117.jpg  \n  inflating: vietnamese/train_images/im0457.jpg  \n  inflating: vietnamese/train_images/im0194.jpg  \n  inflating: vietnamese/train_images/im0823.jpg  \n  inflating: vietnamese/train_images/im1133.jpg  \n  inflating: vietnamese/train_images/im0436.jpg  \n  inflating: vietnamese/train_images/im1036.jpg  \n  inflating: vietnamese/train_images/im0749.jpg  \n  inflating: vietnamese/train_images/im0872.jpg  \n  inflating: vietnamese/train_images/im0393.jpg  \n  inflating: vietnamese/train_images/im0581.jpg  \n  inflating: vietnamese/train_images/im1007.jpg  \n  inflating: vietnamese/train_images/im0995.jpg  \n  inflating: vietnamese/train_images/im0180.jpg  \n  inflating: vietnamese/train_images/im1142.jpg  \n  inflating: vietnamese/train_images/im0624.jpg  \n  inflating: vietnamese/train_images/im0623.jpg  \n  inflating: vietnamese/train_images/im0604.jpg  \n  inflating: vietnamese/train_images/im1015.jpg  \n  inflating: vietnamese/train_images/im0421.jpg  \n  inflating: vietnamese/train_images/im0770.jpg  \n  inflating: vietnamese/train_images/im0510.jpg  \n  inflating: vietnamese/train_images/im0620.jpg  \n  inflating: vietnamese/train_images/im0386.jpg  \n  inflating: vietnamese/train_images/im0077.jpg  \n  inflating: vietnamese/train_images/im0815.jpg  \n  inflating: vietnamese/train_images/im0075.jpg  \n  inflating: vietnamese/train_images/im0828.jpg  \n  inflating: vietnamese/train_images/im0292.jpg  \n  inflating: vietnamese/train_images/im0353.jpg  \n  inflating: vietnamese/train_images/im0311.jpg  \n  inflating: vietnamese/train_images/im0947.jpg  \n  inflating: vietnamese/train_images/im0505.jpg  \n  inflating: vietnamese/train_images/im0317.jpg  \n  inflating: vietnamese/train_images/im0932.jpg  \n  inflating: vietnamese/train_images/im0844.jpg  \n  inflating: vietnamese/train_images/im0191.jpg  \n  inflating: vietnamese/train_images/im0454.jpg  \n  inflating: vietnamese/train_images/im1186.jpg  \n  inflating: vietnamese/train_images/im0949.jpg  \n  inflating: vietnamese/train_images/im0222.jpg  \n  inflating: vietnamese/train_images/im0643.jpg  \n  inflating: vietnamese/train_images/im0271.jpg  \n  inflating: vietnamese/train_images/im0287.jpg  \n  inflating: vietnamese/train_images/im0423.jpg  \n  inflating: vietnamese/train_images/im0535.jpg  \n  inflating: vietnamese/train_images/im0544.jpg  \n  inflating: vietnamese/train_images/im0795.jpg  \n  inflating: vietnamese/train_images/im0908.jpg  \n  inflating: vietnamese/train_images/im0506.jpg  \n  inflating: vietnamese/train_images/im0459.jpg  \n  inflating: vietnamese/train_images/im0148.jpg  \n  inflating: vietnamese/train_images/im0398.jpg  \n  inflating: vietnamese/train_images/im1024.jpg  \n  inflating: vietnamese/train_images/im0181.jpg  \n  inflating: vietnamese/train_images/im0558.jpg  \n  inflating: vietnamese/train_images/im1195.jpg  \n  inflating: vietnamese/train_images/im1185.jpg  \n  inflating: vietnamese/train_images/im0753.jpg  \n  inflating: vietnamese/train_images/im0650.jpg  \n  inflating: vietnamese/train_images/im0711.jpg  \n  inflating: vietnamese/train_images/im1145.jpg  \n  inflating: vietnamese/train_images/im0291.jpg  \n  inflating: vietnamese/train_images/im0589.jpg  \n  inflating: vietnamese/train_images/im1098.jpg  \n  inflating: vietnamese/train_images/im0404.jpg  \n  inflating: vietnamese/train_images/im0363.jpg  \n  inflating: vietnamese/train_images/im0810.jpg  \n  inflating: vietnamese/train_images/im0046.jpg  \n  inflating: vietnamese/train_images/im0214.jpg  \n  inflating: vietnamese/train_images/im0622.jpg  \n  inflating: vietnamese/train_images/im0361.jpg  \n  inflating: vietnamese/train_images/im0124.jpg  \n  inflating: vietnamese/train_images/im0696.jpg  \n  inflating: vietnamese/train_images/im0208.jpg  \n  inflating: vietnamese/train_images/im0971.jpg  \n  inflating: vietnamese/train_images/im0100.jpg  \n  inflating: vietnamese/train_images/im0483.jpg  \n  inflating: vietnamese/train_images/im0316.jpg  \n  inflating: vietnamese/train_images/im0468.jpg  \n  inflating: vietnamese/train_images/im0143.jpg  \n  inflating: vietnamese/train_images/im0416.jpg  \n  inflating: vietnamese/train_images/im1037.jpg  \n  inflating: vietnamese/train_images/im0058.jpg  \n  inflating: vietnamese/train_images/im1159.jpg  \n  inflating: vietnamese/train_images/im0322.jpg  \n  inflating: vietnamese/train_images/im0269.jpg  \n  inflating: vietnamese/train_images/im0868.jpg  \n  inflating: vietnamese/train_images/im0179.jpg  \n  inflating: vietnamese/train_images/im0900.jpg  \n  inflating: vietnamese/train_images/im0285.jpg  \n  inflating: vietnamese/train_images/im0057.jpg  \n  inflating: vietnamese/train_images/im1012.jpg  \n  inflating: vietnamese/train_images/im1080.jpg  \n  inflating: vietnamese/train_images/im0374.jpg  \n  inflating: vietnamese/train_images/im0030.jpg  \n  inflating: vietnamese/train_images/im0375.jpg  \n  inflating: vietnamese/train_images/im0580.jpg  \n  inflating: vietnamese/train_images/im1087.jpg  \n  inflating: vietnamese/train_images/im0102.jpg  \n  inflating: vietnamese/train_images/im0984.jpg  \n  inflating: vietnamese/train_images/im0684.jpg  \n  inflating: vietnamese/train_images/im0536.jpg  \n  inflating: vietnamese/train_images/im0779.jpg  \n  inflating: vietnamese/train_images/im0439.jpg  \n  inflating: vietnamese/train_images/im0118.jpg  \n  inflating: vietnamese/train_images/im0647.jpg  \n  inflating: vietnamese/train_images/im0260.jpg  \n  inflating: vietnamese/train_images/im0205.jpg  \n  inflating: vietnamese/train_images/im0261.jpg  \n  inflating: vietnamese/train_images/im1104.jpg  \n  inflating: vietnamese/train_images/im0308.jpg  \n  inflating: vietnamese/train_images/im0034.jpg  \n  inflating: vietnamese/train_images/im0639.jpg  \n  inflating: vietnamese/train_images/im0293.jpg  \n  inflating: vietnamese/train_images/im0086.jpg  \n  inflating: vietnamese/train_images/im1033.jpg  \n  inflating: vietnamese/train_images/im0448.jpg  \n  inflating: vietnamese/train_images/im1143.jpg  \n  inflating: vietnamese/train_images/im1011.jpg  \n  inflating: vietnamese/train_images/im0383.jpg  \n  inflating: vietnamese/train_images/im0209.jpg  \n  inflating: vietnamese/train_images/im0364.jpg  \n  inflating: vietnamese/train_images/im1069.jpg  \n  inflating: vietnamese/train_images/im0563.jpg  \n  inflating: vietnamese/train_images/im0053.jpg  \n  inflating: vietnamese/train_images/im0033.jpg  \n  inflating: vietnamese/train_images/im0806.jpg  \n  inflating: vietnamese/train_images/im0812.jpg  \n  inflating: vietnamese/train_images/im0518.jpg  \n  inflating: vietnamese/train_images/im0529.jpg  \n  inflating: vietnamese/train_images/im0991.jpg  \n  inflating: vietnamese/train_images/im0919.jpg  \n  inflating: vietnamese/train_images/im0095.jpg  \n  inflating: vietnamese/train_images/im0301.jpg  \n  inflating: vietnamese/train_images/im0731.jpg  \n  inflating: vietnamese/train_images/im0012.jpg  \n  inflating: vietnamese/train_images/im0515.jpg  \n  inflating: vietnamese/train_images/im0249.jpg  \n  inflating: vietnamese/train_images/im0040.jpg  \n  inflating: vietnamese/train_images/im1151.jpg  \n  inflating: vietnamese/train_images/im0113.jpg  \n  inflating: vietnamese/train_images/im0324.jpg  \n  inflating: vietnamese/train_images/im0758.jpg  \n  inflating: vietnamese/train_images/im0741.jpg  \n  inflating: vietnamese/train_images/im0957.jpg  \n  inflating: vietnamese/train_images/im1075.jpg  \n  inflating: vietnamese/train_images/im0648.jpg  \n  inflating: vietnamese/train_images/im0557.jpg  \n  inflating: vietnamese/train_images/im0444.jpg  \n  inflating: vietnamese/train_images/im1134.jpg  \n  inflating: vietnamese/train_images/im0890.jpg  \n  inflating: vietnamese/train_images/im0070.jpg  \n  inflating: vietnamese/train_images/im1175.jpg  \n  inflating: vietnamese/train_images/im0156.jpg  \n  inflating: vietnamese/train_images/im0521.jpg  \n  inflating: vietnamese/train_images/im0470.jpg  \n  inflating: vietnamese/train_images/im1153.jpg  \n  inflating: vietnamese/train_images/im0295.jpg  \n  inflating: vietnamese/train_images/im0837.jpg  \n  inflating: vietnamese/train_images/im0605.jpg  \n  inflating: vietnamese/train_images/im0523.jpg  \n  inflating: vietnamese/train_images/im0785.jpg  \n  inflating: vietnamese/train_images/im0202.jpg  \n  inflating: vietnamese/train_images/im0461.jpg  \n  inflating: vietnamese/train_images/im0766.jpg  \n  inflating: vietnamese/train_images/im0985.jpg  \n  inflating: vietnamese/train_images/im0064.jpg  \n  inflating: vietnamese/train_images/im0123.jpg  \n  inflating: vietnamese/train_images/im0158.jpg  \n  inflating: vietnamese/train_images/im0340.jpg  \n  inflating: vietnamese/train_images/im0742.jpg  \n  inflating: vietnamese/train_images/im0319.jpg  \n  inflating: vietnamese/train_images/im0270.jpg  \n  inflating: vietnamese/train_images/im0520.jpg  \n  inflating: vietnamese/train_images/im0977.jpg  \n  inflating: vietnamese/train_images/im0408.jpg  \n  inflating: vietnamese/train_images/im0132.jpg  \n  inflating: vietnamese/train_images/im1183.jpg  \n  inflating: vietnamese/train_images/im0502.jpg  \n  inflating: vietnamese/train_images/im0740.jpg  \n  inflating: vietnamese/train_images/im0382.jpg  \n  inflating: vietnamese/train_images/im0368.jpg  \n  inflating: vietnamese/train_images/im0555.jpg  \n  inflating: vietnamese/train_images/im0167.jpg  \n  inflating: vietnamese/train_images/im0699.jpg  \n  inflating: vietnamese/train_images/im0252.jpg  \n  inflating: vietnamese/train_images/im0987.jpg  \n  inflating: vietnamese/train_images/im1120.jpg  \n  inflating: vietnamese/train_images/im0703.jpg  \n  inflating: vietnamese/train_images/im0245.jpg  \n  inflating: vietnamese/train_images/im0897.jpg  \n  inflating: vietnamese/train_images/im0397.jpg  \n  inflating: vietnamese/train_images/im0813.jpg  \n  inflating: vietnamese/train_images/im0880.jpg  \n  inflating: vietnamese/train_images/im0228.jpg  \n  inflating: vietnamese/train_images/im0834.jpg  \n  inflating: vietnamese/train_images/im0154.jpg  \n  inflating: vietnamese/train_images/im0201.jpg  \n  inflating: vietnamese/train_images/im1182.jpg  \n  inflating: vietnamese/train_images/im0450.jpg  \n  inflating: vietnamese/train_images/im0093.jpg  \n  inflating: vietnamese/train_images/im0394.jpg  \n  inflating: vietnamese/train_images/im0116.jpg  \n  inflating: vietnamese/train_images/im0350.jpg  \n  inflating: vietnamese/train_images/im0875.jpg  \n  inflating: vietnamese/train_images/im0218.jpg  \n  inflating: vietnamese/train_images/im0280.jpg  \n  inflating: vietnamese/train_images/im0471.jpg  \n  inflating: vietnamese/train_images/im0618.jpg  \n  inflating: vietnamese/train_images/im0774.jpg  \n  inflating: vietnamese/train_images/im0024.jpg  \n  inflating: vietnamese/train_images/im0043.jpg  \n  inflating: vietnamese/train_images/im1040.jpg  \n  inflating: vietnamese/train_images/im0918.jpg  \n  inflating: vietnamese/train_images/im0224.jpg  \n  inflating: vietnamese/train_images/im0111.jpg  \n  inflating: vietnamese/train_images/im0051.jpg  \n  inflating: vietnamese/train_images/im0400.jpg  \n  inflating: vietnamese/train_images/im0976.jpg  \n  inflating: vietnamese/train_images/im0286.jpg  \n  inflating: vietnamese/train_images/im0492.jpg  \n  inflating: vietnamese/train_images/im0658.jpg  \n  inflating: vietnamese/train_images/im1085.jpg  \n  inflating: vietnamese/train_images/im0426.jpg  \n  inflating: vietnamese/train_images/im0530.jpg  \n  inflating: vietnamese/train_images/im1026.jpg  \n  inflating: vietnamese/train_images/im0819.jpg  \n  inflating: vietnamese/train_images/im0498.jpg  \n  inflating: vietnamese/train_images/im0584.jpg  \n  inflating: vietnamese/train_images/im0226.jpg  \n  inflating: vietnamese/train_images/im0814.jpg  \n  inflating: vietnamese/train_images/im0552.jpg  \n  inflating: vietnamese/train_images/im0073.jpg  \n  inflating: vietnamese/train_images/im1118.jpg  \n  inflating: vietnamese/train_images/im0841.jpg  \n  inflating: vietnamese/train_images/im0735.jpg  \n  inflating: vietnamese/train_images/im0258.jpg  \n  inflating: vietnamese/train_images/im1048.jpg  \n  inflating: vietnamese/train_images/im1099.jpg  \n  inflating: vietnamese/train_images/im0329.jpg  \n  inflating: vietnamese/train_images/im1126.jpg  \n  inflating: vietnamese/train_images/im1008.jpg  \n  inflating: vietnamese/train_images/im0207.jpg  \n  inflating: vietnamese/train_images/im0836.jpg  \n  inflating: vietnamese/train_images/im0915.jpg  \n  inflating: vietnamese/train_images/im0857.jpg  \n  inflating: vietnamese/train_images/im0109.jpg  \n  inflating: vietnamese/train_images/im0565.jpg  \n  inflating: vietnamese/train_images/im1006.jpg  \n  inflating: vietnamese/train_images/im0652.jpg  \n  inflating: vietnamese/train_images/im0579.jpg  \n  inflating: vietnamese/train_images/im0090.jpg  \n  inflating: vietnamese/train_images/im0099.jpg  \n  inflating: vietnamese/train_images/im1199.jpg  \n  inflating: vietnamese/train_images/im0107.jpg  \n  inflating: vietnamese/train_images/im0786.jpg  \n  inflating: vietnamese/train_images/im0896.jpg  \n  inflating: vietnamese/train_images/im0843.jpg  \n  inflating: vietnamese/train_images/im0068.jpg  \n  inflating: vietnamese/train_images/im0626.jpg  \n  inflating: vietnamese/train_images/im1005.jpg  \n  inflating: vietnamese/train_images/im0072.jpg  \n  inflating: vietnamese/train_images/im0930.jpg  \n  inflating: vietnamese/train_images/im0428.jpg  \n  inflating: vietnamese/train_images/im0351.jpg  \n  inflating: vietnamese/train_images/im0081.jpg  \n  inflating: vietnamese/train_images/im1127.jpg  \n  inflating: vietnamese/train_images/im0873.jpg  \n  inflating: vietnamese/train_images/im0615.jpg  \n  inflating: vietnamese/train_images/im0803.jpg  \n  inflating: vietnamese/train_images/im0307.jpg  \n  inflating: vietnamese/train_images/im0886.jpg  \n  inflating: vietnamese/train_images/im0889.jpg  \n  inflating: vietnamese/train_images/im0542.jpg  \n  inflating: vietnamese/train_images/im0927.jpg  \n  inflating: vietnamese/train_images/im1016.jpg  \n  inflating: vietnamese/train_images/im0155.jpg  \n  inflating: vietnamese/train_images/im0659.jpg  \n  inflating: vietnamese/train_images/im1061.jpg  \n  inflating: vietnamese/train_images/im0922.jpg  \n  inflating: vietnamese/train_images/im0328.jpg  \n  inflating: vietnamese/train_images/im1130.jpg  \n  inflating: vietnamese/train_images/im0425.jpg  \n  inflating: vietnamese/train_images/im1176.jpg  \n  inflating: vietnamese/train_images/im1198.jpg  \n  inflating: vietnamese/train_images/im0931.jpg  \n  inflating: vietnamese/train_images/im0599.jpg  \n  inflating: vietnamese/train_images/im0899.jpg  \n  inflating: vietnamese/train_images/im0050.jpg  \n  inflating: vietnamese/train_images/im0217.jpg  \n  inflating: vietnamese/train_images/im1174.jpg  \n  inflating: vietnamese/train_images/im0912.jpg  \n  inflating: vietnamese/train_images/im0800.jpg  \n  inflating: vietnamese/train_images/im1031.jpg  \n  inflating: vietnamese/train_images/im0940.jpg  \n  inflating: vietnamese/train_images/im0219.jpg  \n  inflating: vietnamese/train_images/im0990.jpg  \n  inflating: vietnamese/train_images/im0856.jpg  \n  inflating: vietnamese/train_images/im0710.jpg  \n  inflating: vietnamese/train_images/im0366.jpg  \n  inflating: vietnamese/train_images/im0412.jpg  \n  inflating: vietnamese/train_images/im1172.jpg  \n  inflating: vietnamese/train_images/im0982.jpg  \n  inflating: vietnamese/train_images/im0550.jpg  \n  inflating: vietnamese/train_images/im1200.jpg  \n  inflating: vietnamese/train_images/im0399.jpg  \n  inflating: vietnamese/train_images/im0962.jpg  \n  inflating: vietnamese/train_images/im0163.jpg  \n  inflating: vietnamese/train_images/im0942.jpg  \n  inflating: vietnamese/train_images/im0884.jpg  \n  inflating: vietnamese/train_images/im0602.jpg  \n  inflating: vietnamese/train_images/im0162.jpg  \n  inflating: vietnamese/train_images/im0610.jpg  \n  inflating: vietnamese/train_images/im0939.jpg  \n  inflating: vietnamese/train_images/im0256.jpg  \n  inflating: vietnamese/train_images/im0963.jpg  \n  inflating: vietnamese/train_images/im0553.jpg  \n  inflating: vietnamese/train_images/im0338.jpg  \n  inflating: vietnamese/train_images/im0726.jpg  \n  inflating: vietnamese/train_images/im1071.jpg  \n  inflating: vietnamese/train_images/im0980.jpg  \n  inflating: vietnamese/train_images/im0349.jpg  \n  inflating: vietnamese/train_images/im0612.jpg  \n  inflating: vietnamese/train_images/im0716.jpg  \n  inflating: vietnamese/train_images/im0422.jpg  \n  inflating: vietnamese/train_images/im0344.jpg  \n  inflating: vietnamese/train_images/im0331.jpg  \n  inflating: vietnamese/train_images/im0975.jpg  \n  inflating: vietnamese/train_images/im0305.jpg  \n  inflating: vietnamese/train_images/im0413.jpg  \n  inflating: vietnamese/train_images/im0619.jpg  \n  inflating: vietnamese/train_images/im0183.jpg  \n  inflating: vietnamese/train_images/im1179.jpg  \n  inflating: vietnamese/train_images/im0730.jpg  \n  inflating: vietnamese/train_images/im1144.jpg  \n  inflating: vietnamese/train_images/im0662.jpg  \n  inflating: vietnamese/train_images/im0997.jpg  \n  inflating: vietnamese/train_images/im0106.jpg  \n  inflating: vietnamese/train_images/im0031.jpg  \n  inflating: vietnamese/train_images/im0541.jpg  \n  inflating: vietnamese/train_images/im1148.jpg  \n  inflating: vietnamese/train_images/im0756.jpg  \n  inflating: vietnamese/train_images/im1001.jpg  \n  inflating: vietnamese/train_images/im1094.jpg  \n  inflating: vietnamese/train_images/im0938.jpg  \n  inflating: vietnamese/train_images/im0333.jpg  \n  inflating: vietnamese/train_images/im0765.jpg  \n  inflating: vietnamese/train_images/im0417.jpg  \n  inflating: vietnamese/train_images/im0790.jpg  \n  inflating: vietnamese/train_images/im0679.jpg  \n  inflating: vietnamese/train_images/im0554.jpg  \n  inflating: vietnamese/train_images/im1139.jpg  \n  inflating: vietnamese/train_images/im0427.jpg  \n  inflating: vietnamese/train_images/im0276.jpg  \n  inflating: vietnamese/train_images/im0061.jpg  \n  inflating: vietnamese/train_images/im0054.jpg  \n  inflating: vietnamese/train_images/im0866.jpg  \n  inflating: vietnamese/train_images/im0481.jpg  \n  inflating: vietnamese/train_images/im0474.jpg  \n  inflating: vietnamese/train_images/im0465.jpg  \n  inflating: vietnamese/train_images/im0539.jpg  \n  inflating: vietnamese/train_images/im1140.jpg  \n  inflating: vietnamese/train_images/im0504.jpg  \n  inflating: vietnamese/train_images/im1181.jpg  \n  inflating: vietnamese/train_images/im0941.jpg  \n  inflating: vietnamese/train_images/im0801.jpg  \n  inflating: vietnamese/train_images/im1132.jpg  \n  inflating: vietnamese/train_images/im0904.jpg  \n  inflating: vietnamese/train_images/im0637.jpg  \n  inflating: vietnamese/train_images/im0788.jpg  \n  inflating: vietnamese/train_images/im0669.jpg  \n  inflating: vietnamese/train_images/im1050.jpg  \n  inflating: vietnamese/train_images/im0778.jpg  \n  inflating: vietnamese/train_images/im0456.jpg  \n  inflating: vietnamese/train_images/im1171.jpg  \n  inflating: vietnamese/train_images/im0721.jpg  \n  inflating: vietnamese/train_images/im1060.jpg  \n  inflating: vietnamese/train_images/im0478.jpg  \n  inflating: vietnamese/train_images/im0916.jpg  \n  inflating: vietnamese/train_images/im0569.jpg  \n  inflating: vietnamese/train_images/im0231.jpg  \n  inflating: vietnamese/train_images/im0354.jpg  \n  inflating: vietnamese/train_images/im0892.jpg  \n  inflating: vietnamese/train_images/im0887.jpg  \n  inflating: vietnamese/train_images/im0166.jpg  \n  inflating: vietnamese/train_images/im0499.jpg  \n  inflating: vietnamese/train_images/im0752.jpg  \n  inflating: vietnamese/train_images/im0761.jpg  \n  inflating: vietnamese/train_images/im1064.jpg  \n  inflating: vietnamese/train_images/im0065.jpg  \n  inflating: vietnamese/train_images/im0607.jpg  \n  inflating: vietnamese/train_images/im1167.jpg  \n  inflating: vietnamese/train_images/im0533.jpg  \n  inflating: vietnamese/train_images/im0273.jpg  \n  inflating: vietnamese/train_images/im0519.jpg  \n  inflating: vietnamese/train_images/im1051.jpg  \n  inflating: vietnamese/train_images/im0306.jpg  \n  inflating: vietnamese/train_images/im1029.jpg  \n  inflating: vietnamese/train_images/im0178.jpg  \n  inflating: vietnamese/train_images/im1052.jpg  \n  inflating: vietnamese/train_images/im0265.jpg  \n  inflating: vietnamese/train_images/im0540.jpg  \n  inflating: vietnamese/train_images/im0596.jpg  \n  inflating: vietnamese/train_images/im0314.jpg  \n  inflating: vietnamese/train_images/im0574.jpg  \n  inflating: vietnamese/train_images/im0746.jpg  \n  inflating: vietnamese/train_images/im0586.jpg  \n  inflating: vietnamese/train_images/im0776.jpg  \n  inflating: vietnamese/train_images/im0757.jpg  \n  inflating: vietnamese/train_images/im0365.jpg  \n  inflating: vietnamese/train_images/im0507.jpg  \n  inflating: vietnamese/train_images/im0948.jpg  \n  inflating: vietnamese/train_images/im0486.jpg  \n  inflating: vietnamese/train_images/im0007.jpg  \n  inflating: vietnamese/train_images/im0341.jpg  \n  inflating: vietnamese/train_images/im0704.jpg  \n  inflating: vietnamese/train_images/im0578.jpg  \n  inflating: vietnamese/train_images/im0838.jpg  \n  inflating: vietnamese/train_images/im0103.jpg  \n  inflating: vietnamese/train_images/im0272.jpg  \n  inflating: vietnamese/train_images/im0242.jpg  \n  inflating: vietnamese/train_images/im0564.jpg  \n  inflating: vietnamese/train_images/im0760.jpg  \n  inflating: vietnamese/train_images/im1059.jpg  \n  inflating: vietnamese/train_images/im0240.jpg  \n  inflating: vietnamese/train_images/im0173.jpg  \n  inflating: vietnamese/train_images/im1157.jpg  \n  inflating: vietnamese/train_images/im1003.jpg  \n  inflating: vietnamese/train_images/im0560.jpg  \n  inflating: vietnamese/train_images/im0598.jpg  \n  inflating: vietnamese/train_images/im0358.jpg  \n  inflating: vietnamese/train_images/im0925.jpg  \n  inflating: vietnamese/train_images/im0824.jpg  \n  inflating: vietnamese/train_images/im0172.jpg  \n  inflating: vietnamese/train_images/im1000.jpg  \n  inflating: vietnamese/train_images/im0764.jpg  \n  inflating: vietnamese/train_images/im0714.jpg  \n  inflating: vietnamese/train_images/im0330.jpg  \n  inflating: vietnamese/train_images/im1100.jpg  \n  inflating: vietnamese/train_images/im0608.jpg  \n  inflating: vietnamese/train_images/im0042.jpg  \n  inflating: vietnamese/train_images/im1156.jpg  \n  inflating: vietnamese/train_images/im0083.jpg  \n  inflating: vietnamese/train_images/im0410.jpg  \n  inflating: vietnamese/train_images/im0862.jpg  \n  inflating: vietnamese/train_images/im0719.jpg  \n  inflating: vietnamese/train_images/im0885.jpg  \n  inflating: vietnamese/train_images/im0017.jpg  \n  inflating: vietnamese/train_images/im0036.jpg  \n  inflating: vietnamese/train_images/im0359.jpg  \n  inflating: vietnamese/train_images/im0665.jpg  \n  inflating: vietnamese/train_images/im0016.jpg  \n  inflating: vietnamese/train_images/im1056.jpg  \n  inflating: vietnamese/train_images/im0630.jpg  \n  inflating: vietnamese/train_images/im0747.jpg  \n  inflating: vietnamese/train_images/im0858.jpg  \n  inflating: vietnamese/train_images/im0189.jpg  \n  inflating: vietnamese/train_images/im1021.jpg  \n  inflating: vietnamese/train_images/im0921.jpg  \n  inflating: vietnamese/train_images/im0339.jpg  \n  inflating: vietnamese/train_images/im0254.jpg  \n  inflating: vietnamese/train_images/im0691.jpg  \n  inflating: vietnamese/train_images/im1116.jpg  \n  inflating: vietnamese/train_images/im0850.jpg  \n  inflating: vietnamese/train_images/im0797.jpg  \n  inflating: vietnamese/train_images/im0407.jpg  \n  inflating: vietnamese/train_images/im0514.jpg  \n  inflating: vietnamese/train_images/im0122.jpg  \n  inflating: vietnamese/train_images/im0497.jpg  \n  inflating: vietnamese/train_images/im0628.jpg  \n  inflating: vietnamese/train_images/im0063.jpg  \n  inflating: vietnamese/train_images/im0091.jpg  \n  inflating: vietnamese/train_images/im0695.jpg  \n  inflating: vietnamese/train_images/im0503.jpg  \n  inflating: vietnamese/train_images/im0935.jpg  \n  inflating: vietnamese/train_images/im0284.jpg  \n  inflating: vietnamese/train_images/im0197.jpg  \n  inflating: vietnamese/train_images/im0262.jpg  \n  inflating: vietnamese/train_images/im1055.jpg  \n  inflating: vietnamese/train_images/im0750.jpg  \n  inflating: vietnamese/train_images/im0267.jpg  \n  inflating: vietnamese/train_images/im0387.jpg  \n  inflating: vietnamese/train_images/im0373.jpg  \n  inflating: vietnamese/train_images/im0149.jpg  \n  inflating: vietnamese/train_images/im0943.jpg  \n  inflating: vietnamese/train_images/im0094.jpg  \n  inflating: vietnamese/train_images/im0342.jpg  \n  inflating: vietnamese/train_images/im0508.jpg  \n  inflating: vietnamese/train_images/im0738.jpg  \n  inflating: vietnamese/train_images/im0744.jpg  \n  inflating: vietnamese/train_images/im0089.jpg  \n  inflating: vietnamese/train_images/im0632.jpg  \n  inflating: vietnamese/train_images/im0724.jpg  \n  inflating: vietnamese/train_images/im0945.jpg  \n  inflating: vietnamese/train_images/im0616.jpg  \n  inflating: vietnamese/train_images/im0728.jpg  \n  inflating: vietnamese/train_images/im0236.jpg  \n  inflating: vietnamese/train_images/im0362.jpg  \n  inflating: vietnamese/train_images/im0538.jpg  \n  inflating: vietnamese/train_images/im0649.jpg  \n  inflating: vietnamese/train_images/im1125.jpg  \n  inflating: vietnamese/train_images/im0792.jpg  \n  inflating: vietnamese/train_images/im1017.jpg  \n  inflating: vietnamese/train_images/im0967.jpg  \n  inflating: vietnamese/train_images/im0690.jpg  \n  inflating: vietnamese/train_images/im0830.jpg  \n  inflating: vietnamese/train_images/im0233.jpg  \n  inflating: vietnamese/train_images/im0134.jpg  \n  inflating: vietnamese/train_images/im0029.jpg  \n  inflating: vietnamese/train_images/im0232.jpg  \n  inflating: vietnamese/train_images/im0466.jpg  \n  inflating: vietnamese/train_images/im1019.jpg  \n  inflating: vietnamese/train_images/im1084.jpg  \n  inflating: vietnamese/train_images/im0804.jpg  \n  inflating: vietnamese/train_images/im0928.jpg  \n  inflating: vietnamese/train_images/im1023.jpg  \n  inflating: vietnamese/train_images/im0961.jpg  \n  inflating: vietnamese/train_images/im1088.jpg  \n  inflating: vietnamese/train_images/im0184.jpg  \n  inflating: vietnamese/train_images/im0360.jpg  \n  inflating: vietnamese/train_images/im1096.jpg  \n  inflating: vietnamese/train_images/im0833.jpg  \n  inflating: vietnamese/train_images/im0489.jpg  \n  inflating: vietnamese/train_images/im0477.jpg  \n  inflating: vietnamese/train_images/im1018.jpg  \n  inflating: vietnamese/train_images/im0700.jpg  \n  inflating: vietnamese/train_images/im0683.jpg  \n  inflating: vietnamese/train_images/im0817.jpg  \n  inflating: vietnamese/train_images/im0702.jpg  \n  inflating: vietnamese/train_images/im1057.jpg  \n  inflating: vietnamese/train_images/im0759.jpg  \n  inflating: vietnamese/train_images/im0008.jpg  \n  inflating: vietnamese/train_images/im0701.jpg  \n  inflating: vietnamese/train_images/im0479.jpg  \n  inflating: vietnamese/train_images/im0999.jpg  \n  inflating: vietnamese/train_images/im0279.jpg  \n  inflating: vietnamese/train_images/im0289.jpg  \n  inflating: vietnamese/train_images/im0629.jpg  \n  inflating: vietnamese/train_images/im0480.jpg  \n   creating: vietnamese/test_image/\n  inflating: vietnamese/test_image/im1420.jpg  \n  inflating: vietnamese/test_image/im1413.jpg  \n  inflating: vietnamese/test_image/im1245.jpg  \n  inflating: vietnamese/test_image/im1479.jpg  \n  inflating: vietnamese/test_image/im1256.jpg  \n  inflating: vietnamese/test_image/im1216.jpg  \n  inflating: vietnamese/test_image/im1295.jpg  \n  inflating: vietnamese/test_image/im1214.jpg  \n  inflating: vietnamese/test_image/im1265.jpg  \n  inflating: vietnamese/test_image/im1490.jpg  \n  inflating: vietnamese/test_image/im1269.jpg  \n  inflating: vietnamese/test_image/im1484.jpg  \n  inflating: vietnamese/test_image/im1260.jpg  \n  inflating: vietnamese/test_image/im1487.jpg  \n  inflating: vietnamese/test_image/im1376.jpg  \n  inflating: vietnamese/test_image/im1291.jpg  \n  inflating: vietnamese/test_image/im1278.jpg  \n  inflating: vietnamese/test_image/im1219.jpg  \n  inflating: vietnamese/test_image/im1264.jpg  \n  inflating: vietnamese/test_image/im1389.jpg  \n  inflating: vietnamese/test_image/im1400.jpg  \n  inflating: vietnamese/test_image/im1336.jpg  \n  inflating: vietnamese/test_image/im1478.jpg  \n  inflating: vietnamese/test_image/im1393.jpg  \n  inflating: vietnamese/test_image/im1391.jpg  \n  inflating: vietnamese/test_image/im1472.jpg  \n  inflating: vietnamese/test_image/im1451.jpg  \n  inflating: vietnamese/test_image/im1204.jpg  \n  inflating: vietnamese/test_image/im1418.jpg  \n  inflating: vietnamese/test_image/im1398.jpg  \n  inflating: vietnamese/test_image/im1445.jpg  \n  inflating: vietnamese/test_image/im1251.jpg  \n  inflating: vietnamese/test_image/im1469.jpg  \n  inflating: vietnamese/test_image/im1258.jpg  \n  inflating: vietnamese/test_image/im1215.jpg  \n  inflating: vietnamese/test_image/im1363.jpg  \n  inflating: vietnamese/test_image/im1369.jpg  \n  inflating: vietnamese/test_image/im1272.jpg  \n  inflating: vietnamese/test_image/im1325.jpg  \n  inflating: vietnamese/test_image/im1329.jpg  \n  inflating: vietnamese/test_image/im1494.jpg  \n  inflating: vietnamese/test_image/im1274.jpg  \n  inflating: vietnamese/test_image/im1497.jpg  \n  inflating: vietnamese/test_image/im1248.jpg  \n  inflating: vietnamese/test_image/im1364.jpg  \n  inflating: vietnamese/test_image/im1212.jpg  \n  inflating: vietnamese/test_image/im1235.jpg  \n  inflating: vietnamese/test_image/im1319.jpg  \n  inflating: vietnamese/test_image/im1315.jpg  \n  inflating: vietnamese/test_image/im1444.jpg  \n  inflating: vietnamese/test_image/im1244.jpg  \n  inflating: vietnamese/test_image/im1281.jpg  \n  inflating: vietnamese/test_image/im1422.jpg  \n  inflating: vietnamese/test_image/im1263.jpg  \n  inflating: vietnamese/test_image/im1249.jpg  \n  inflating: vietnamese/test_image/im1464.jpg  \n  inflating: vietnamese/test_image/im1301.jpg  \n  inflating: vietnamese/test_image/im1333.jpg  \n  inflating: vietnamese/test_image/im1321.jpg  \n  inflating: vietnamese/test_image/im1271.jpg  \n  inflating: vietnamese/test_image/im1243.jpg  \n  inflating: vietnamese/test_image/im1223.jpg  \n  inflating: vietnamese/test_image/im1446.jpg  \n  inflating: vietnamese/test_image/im1273.jpg  \n  inflating: vietnamese/test_image/im1426.jpg  \n  inflating: vietnamese/test_image/im1498.jpg  \n  inflating: vietnamese/test_image/im1361.jpg  \n  inflating: vietnamese/test_image/im1344.jpg  \n  inflating: vietnamese/test_image/im1324.jpg  \n  inflating: vietnamese/test_image/im1296.jpg  \n  inflating: vietnamese/test_image/im1399.jpg  \n  inflating: vietnamese/test_image/im1224.jpg  \n  inflating: vietnamese/test_image/im1380.jpg  \n  inflating: vietnamese/test_image/im1342.jpg  \n  inflating: vietnamese/test_image/im1409.jpg  \n  inflating: vietnamese/test_image/im1328.jpg  \n  inflating: vietnamese/test_image/im1457.jpg  \n  inflating: vietnamese/test_image/im1254.jpg  \n  inflating: vietnamese/test_image/im1383.jpg  \n  inflating: vietnamese/test_image/im1323.jpg  \n  inflating: vietnamese/test_image/im1312.jpg  \n  inflating: vietnamese/test_image/im1372.jpg  \n  inflating: vietnamese/test_image/im1270.jpg  \n  inflating: vietnamese/test_image/im1313.jpg  \n  inflating: vietnamese/test_image/im1343.jpg  \n  inflating: vietnamese/test_image/im1423.jpg  \n  inflating: vietnamese/test_image/im1429.jpg  \n  inflating: vietnamese/test_image/im1427.jpg  \n  inflating: vietnamese/test_image/im1332.jpg  \n  inflating: vietnamese/test_image/im1327.jpg  \n  inflating: vietnamese/test_image/im1371.jpg  \n  inflating: vietnamese/test_image/im1495.jpg  \n  inflating: vietnamese/test_image/im1381.jpg  \n  inflating: vietnamese/test_image/im1339.jpg  \n  inflating: vietnamese/test_image/im1496.jpg  \n  inflating: vietnamese/test_image/im1384.jpg  \n  inflating: vietnamese/test_image/im1279.jpg  \n  inflating: vietnamese/test_image/im1436.jpg  \n  inflating: vietnamese/test_image/im1213.jpg  \n  inflating: vietnamese/test_image/im1431.jpg  \n  inflating: vietnamese/test_image/im1362.jpg  \n  inflating: vietnamese/test_image/im1220.jpg  \n  inflating: vietnamese/test_image/im1355.jpg  \n  inflating: vietnamese/test_image/im1425.jpg  \n  inflating: vietnamese/test_image/im1308.jpg  \n  inflating: vietnamese/test_image/im1282.jpg  \n  inflating: vietnamese/test_image/im1290.jpg  \n  inflating: vietnamese/test_image/im1443.jpg  \n  inflating: vietnamese/test_image/im1299.jpg  \n  inflating: vietnamese/test_image/im1402.jpg  \n  inflating: vietnamese/test_image/im1222.jpg  \n  inflating: vietnamese/test_image/im1390.jpg  \n  inflating: vietnamese/test_image/im1365.jpg  \n  inflating: vietnamese/test_image/im1428.jpg  \n  inflating: vietnamese/test_image/im1317.jpg  \n  inflating: vietnamese/test_image/im1481.jpg  \n  inflating: vietnamese/test_image/im1207.jpg  \n  inflating: vietnamese/test_image/im1225.jpg  \n  inflating: vietnamese/test_image/im1460.jpg  \n  inflating: vietnamese/test_image/im1405.jpg  \n  inflating: vietnamese/test_image/im1442.jpg  \n  inflating: vietnamese/test_image/im1358.jpg  \n  inflating: vietnamese/test_image/im1309.jpg  \n  inflating: vietnamese/test_image/im1449.jpg  \n  inflating: vietnamese/test_image/im1326.jpg  \n  inflating: vietnamese/test_image/im1476.jpg  \n  inflating: vietnamese/test_image/im1236.jpg  \n  inflating: vietnamese/test_image/im1229.jpg  \n  inflating: vietnamese/test_image/im1471.jpg  \n  inflating: vietnamese/test_image/im1382.jpg  \n  inflating: vietnamese/test_image/im1277.jpg  \n  inflating: vietnamese/test_image/im1262.jpg  \n  inflating: vietnamese/test_image/im1441.jpg  \n  inflating: vietnamese/test_image/im1211.jpg  \n  inflating: vietnamese/test_image/im1240.jpg  \n  inflating: vietnamese/test_image/im1350.jpg  \n  inflating: vietnamese/test_image/im1303.jpg  \n  inflating: vietnamese/test_image/im1318.jpg  \n  inflating: vietnamese/test_image/im1456.jpg  \n  inflating: vietnamese/test_image/im1386.jpg  \n  inflating: vietnamese/test_image/im1404.jpg  \n  inflating: vietnamese/test_image/im1337.jpg  \n  inflating: vietnamese/test_image/im1470.jpg  \n  inflating: vietnamese/test_image/im1310.jpg  \n  inflating: vietnamese/test_image/im1500.jpg  \n  inflating: vietnamese/test_image/im1304.jpg  \n  inflating: vietnamese/test_image/im1230.jpg  \n  inflating: vietnamese/test_image/im1403.jpg  \n  inflating: vietnamese/test_image/im1242.jpg  \n  inflating: vietnamese/test_image/im1379.jpg  \n  inflating: vietnamese/test_image/im1289.jpg  \n  inflating: vietnamese/test_image/im1201.jpg  \n  inflating: vietnamese/test_image/im1228.jpg  \n  inflating: vietnamese/test_image/im1354.jpg  \n  inflating: vietnamese/test_image/im1283.jpg  \n  inflating: vietnamese/test_image/im1241.jpg  \n  inflating: vietnamese/test_image/im1416.jpg  \n  inflating: vietnamese/test_image/im1298.jpg  \n  inflating: vietnamese/test_image/im1217.jpg  \n  inflating: vietnamese/test_image/im1246.jpg  \n  inflating: vietnamese/test_image/im1459.jpg  \n  inflating: vietnamese/test_image/im1454.jpg  \n  inflating: vietnamese/test_image/im1255.jpg  \n  inflating: vietnamese/test_image/im1297.jpg  \n  inflating: vietnamese/test_image/im1360.jpg  \n  inflating: vietnamese/test_image/im1334.jpg  \n  inflating: vietnamese/test_image/im1489.jpg  \n  inflating: vietnamese/test_image/im1406.jpg  \n  inflating: vietnamese/test_image/im1450.jpg  \n  inflating: vietnamese/test_image/im1294.jpg  \n  inflating: vietnamese/test_image/im1455.jpg  \n  inflating: vietnamese/test_image/im1421.jpg  \n  inflating: vietnamese/test_image/im1388.jpg  \n  inflating: vietnamese/test_image/im1415.jpg  \n  inflating: vietnamese/test_image/im1335.jpg  \n  inflating: vietnamese/test_image/im1414.jpg  \n  inflating: vietnamese/test_image/im1440.jpg  \n  inflating: vietnamese/test_image/im1367.jpg  \n  inflating: vietnamese/test_image/im1302.jpg  \n  inflating: vietnamese/test_image/im1408.jpg  \n  inflating: vietnamese/test_image/im1221.jpg  \n  inflating: vietnamese/test_image/im1438.jpg  \n  inflating: vietnamese/test_image/im1208.jpg  \n  inflating: vietnamese/test_image/im1483.jpg  \n  inflating: vietnamese/test_image/im1356.jpg  \n  inflating: vietnamese/test_image/im1314.jpg  \n  inflating: vietnamese/test_image/im1351.jpg  \n  inflating: vietnamese/test_image/im1320.jpg  \n  inflating: vietnamese/test_image/im1202.jpg  \n  inflating: vietnamese/test_image/im1452.jpg  \n  inflating: vietnamese/test_image/im1392.jpg  \n  inflating: vietnamese/test_image/im1473.jpg  \n  inflating: vietnamese/test_image/im1348.jpg  \n  inflating: vietnamese/test_image/im1293.jpg  \n  inflating: vietnamese/test_image/im1435.jpg  \n  inflating: vietnamese/test_image/im1267.jpg  \n  inflating: vietnamese/test_image/im1266.jpg  \n  inflating: vietnamese/test_image/im1252.jpg  \n  inflating: vietnamese/test_image/im1491.jpg  \n  inflating: vietnamese/test_image/im1430.jpg  \n  inflating: vietnamese/test_image/im1259.jpg  \n  inflating: vietnamese/test_image/im1373.jpg  \n  inflating: vietnamese/test_image/im1410.jpg  \n  inflating: vietnamese/test_image/im1461.jpg  \n  inflating: vietnamese/test_image/im1387.jpg  \n  inflating: vietnamese/test_image/im1238.jpg  \n  inflating: vietnamese/test_image/im1368.jpg  \n  inflating: vietnamese/test_image/im1253.jpg  \n  inflating: vietnamese/test_image/im1247.jpg  \n  inflating: vietnamese/test_image/im1349.jpg  \n  inflating: vietnamese/test_image/im1237.jpg  \n  inflating: vietnamese/test_image/im1417.jpg  \n  inflating: vietnamese/test_image/im1210.jpg  \n  inflating: vietnamese/test_image/im1347.jpg  \n  inflating: vietnamese/test_image/im1257.jpg  \n  inflating: vietnamese/test_image/im1466.jpg  \n  inflating: vietnamese/test_image/im1300.jpg  \n  inflating: vietnamese/test_image/im1316.jpg  \n  inflating: vietnamese/test_image/im1411.jpg  \n  inflating: vietnamese/test_image/im1467.jpg  \n  inflating: vietnamese/test_image/im1434.jpg  \n  inflating: vietnamese/test_image/im1287.jpg  \n  inflating: vietnamese/test_image/im1206.jpg  \n  inflating: vietnamese/test_image/im1331.jpg  \n  inflating: vietnamese/test_image/im1385.jpg  \n  inflating: vietnamese/test_image/im1250.jpg  \n  inflating: vietnamese/test_image/im1285.jpg  \n  inflating: vietnamese/test_image/im1366.jpg  \n  inflating: vietnamese/test_image/im1463.jpg  \n  inflating: vietnamese/test_image/im1330.jpg  \n  inflating: vietnamese/test_image/im1205.jpg  \n  inflating: vietnamese/test_image/im1232.jpg  \n  inflating: vietnamese/test_image/im1227.jpg  \n  inflating: vietnamese/test_image/im1275.jpg  \n  inflating: vietnamese/test_image/im1374.jpg  \n  inflating: vietnamese/test_image/im1359.jpg  \n  inflating: vietnamese/test_image/im1407.jpg  \n  inflating: vietnamese/test_image/im1276.jpg  \n  inflating: vietnamese/test_image/im1341.jpg  \n  inflating: vietnamese/test_image/im1305.jpg  \n  inflating: vietnamese/test_image/im1439.jpg  \n  inflating: vietnamese/test_image/im1231.jpg  \n  inflating: vietnamese/test_image/im1322.jpg  \n  inflating: vietnamese/test_image/im1480.jpg  \n  inflating: vietnamese/test_image/im1475.jpg  \n  inflating: vietnamese/test_image/im1486.jpg  \n  inflating: vietnamese/test_image/im1345.jpg  \n  inflating: vietnamese/test_image/im1377.jpg  \n  inflating: vietnamese/test_image/im1307.jpg  \n  inflating: vietnamese/test_image/im1419.jpg  \n  inflating: vietnamese/test_image/im1233.jpg  \n  inflating: vietnamese/test_image/im1209.jpg  \n  inflating: vietnamese/test_image/im1352.jpg  \n  inflating: vietnamese/test_image/im1357.jpg  \n  inflating: vietnamese/test_image/im1437.jpg  \n  inflating: vietnamese/test_image/im1447.jpg  \n  inflating: vietnamese/test_image/im1395.jpg  \n  inflating: vietnamese/test_image/im1396.jpg  \n  inflating: vietnamese/test_image/im1424.jpg  \n  inflating: vietnamese/test_image/im1353.jpg  \n  inflating: vietnamese/test_image/im1412.jpg  \n  inflating: vietnamese/test_image/im1492.jpg  \n  inflating: vietnamese/test_image/im1370.jpg  \n  inflating: vietnamese/test_image/im1453.jpg  \n  inflating: vietnamese/test_image/im1468.jpg  \n  inflating: vietnamese/test_image/im1488.jpg  \n  inflating: vietnamese/test_image/im1448.jpg  \n  inflating: vietnamese/test_image/im1203.jpg  \n  inflating: vietnamese/test_image/im1239.jpg  \n  inflating: vietnamese/test_image/im1311.jpg  \n  inflating: vietnamese/test_image/im1458.jpg  \n  inflating: vietnamese/test_image/im1465.jpg  \n  inflating: vietnamese/test_image/im1397.jpg  \n  inflating: vietnamese/test_image/im1485.jpg  \n  inflating: vietnamese/test_image/im1218.jpg  \n  inflating: vietnamese/test_image/im1401.jpg  \n  inflating: vietnamese/test_image/im1378.jpg  \n  inflating: vietnamese/test_image/im1306.jpg  \n  inflating: vietnamese/test_image/im1346.jpg  \n  inflating: vietnamese/test_image/im1375.jpg  \n  inflating: vietnamese/test_image/im1268.jpg  \n  inflating: vietnamese/test_image/im1292.jpg  \n  inflating: vietnamese/test_image/im1493.jpg  \n  inflating: vietnamese/test_image/im1482.jpg  \n  inflating: vietnamese/test_image/im1394.jpg  \n  inflating: vietnamese/test_image/im1477.jpg  \n  inflating: vietnamese/test_image/im1288.jpg  \n  inflating: vietnamese/test_image/im1338.jpg  \n  inflating: vietnamese/test_image/im1286.jpg  \n  inflating: vietnamese/test_image/im1462.jpg  \n  inflating: vietnamese/test_image/im1340.jpg  \n  inflating: vietnamese/test_image/im1432.jpg  \n  inflating: vietnamese/test_image/im1474.jpg  \n  inflating: vietnamese/test_image/im1226.jpg  \n  inflating: vietnamese/test_image/im1433.jpg  \n  inflating: vietnamese/test_image/im1261.jpg  \n  inflating: vietnamese/test_image/im1284.jpg  \n  inflating: vietnamese/test_image/im1499.jpg  \n  inflating: vietnamese/test_image/im1234.jpg  \n  inflating: vietnamese/test_image/im1280.jpg  \n   creating: vietnamese/unseen_test_images/\n  inflating: vietnamese/unseen_test_images/im1501.jpg  \n  inflating: vietnamese/unseen_test_images/im1502.jpg  \n  inflating: vietnamese/unseen_test_images/im1503.jpg  \n  inflating: vietnamese/unseen_test_images/im1504.jpg  \n  inflating: vietnamese/unseen_test_images/im1505.jpg  \n  inflating: vietnamese/unseen_test_images/im1506.jpg  \n  inflating: vietnamese/unseen_test_images/im1507.jpg  \n  inflating: vietnamese/unseen_test_images/im1508.jpg  \n  inflating: vietnamese/unseen_test_images/im1509.jpg  \n  inflating: vietnamese/unseen_test_images/im1510.jpg  \n  inflating: vietnamese/unseen_test_images/im1511.jpg  \n  inflating: vietnamese/unseen_test_images/im1512.jpg  \n  inflating: vietnamese/unseen_test_images/im1513.jpg  \n  inflating: vietnamese/unseen_test_images/im1514.jpg  \n  inflating: vietnamese/unseen_test_images/im1515.jpg  \n  inflating: vietnamese/unseen_test_images/im1516.jpg  \n  inflating: vietnamese/unseen_test_images/im1517.jpg  \n  inflating: vietnamese/unseen_test_images/im1518.jpg  \n  inflating: vietnamese/unseen_test_images/im1519.jpg  \n  inflating: vietnamese/unseen_test_images/im1520.jpg  \n  inflating: vietnamese/unseen_test_images/im1521.jpg  \n  inflating: vietnamese/unseen_test_images/im1522.jpg  \n  inflating: vietnamese/unseen_test_images/im1523.jpg  \n  inflating: vietnamese/unseen_test_images/im1524.jpg  \n  inflating: vietnamese/unseen_test_images/im1525.jpg  \n  inflating: vietnamese/unseen_test_images/im1526.jpg  \n  inflating: vietnamese/unseen_test_images/im1527.jpg  \n  inflating: vietnamese/unseen_test_images/im1528.jpg  \n  inflating: vietnamese/unseen_test_images/im1529.jpg  \n  inflating: vietnamese/unseen_test_images/im1530.jpg  \n  inflating: vietnamese/unseen_test_images/im1531.jpg  \n  inflating: vietnamese/unseen_test_images/im1532.jpg  \n  inflating: vietnamese/unseen_test_images/im1533.jpg  \n  inflating: vietnamese/unseen_test_images/im1534.jpg  \n  inflating: vietnamese/unseen_test_images/im1535.jpg  \n  inflating: vietnamese/unseen_test_images/im1536.jpg  \n  inflating: vietnamese/unseen_test_images/im1537.jpg  \n  inflating: vietnamese/unseen_test_images/im1538.jpg  \n  inflating: vietnamese/unseen_test_images/im1539.jpg  \n  inflating: vietnamese/unseen_test_images/im1540.jpg  \n  inflating: vietnamese/unseen_test_images/im1541.jpg  \n  inflating: vietnamese/unseen_test_images/im1542.jpg  \n  inflating: vietnamese/unseen_test_images/im1543.jpg  \n  inflating: vietnamese/unseen_test_images/im1544.jpg  \n  inflating: vietnamese/unseen_test_images/im1545.jpg  \n  inflating: vietnamese/unseen_test_images/im1546.jpg  \n  inflating: vietnamese/unseen_test_images/im1547.jpg  \n  inflating: vietnamese/unseen_test_images/im1548.jpg  \n  inflating: vietnamese/unseen_test_images/im1549.jpg  \n  inflating: vietnamese/unseen_test_images/im1550.jpg  \n  inflating: vietnamese/unseen_test_images/im1551.jpg  \n  inflating: vietnamese/unseen_test_images/im1552.jpg  \n  inflating: vietnamese/unseen_test_images/im1553.jpg  \n  inflating: vietnamese/unseen_test_images/im1554.jpg  \n  inflating: vietnamese/unseen_test_images/im1555.jpg  \n  inflating: vietnamese/unseen_test_images/im1556.jpg  \n  inflating: vietnamese/unseen_test_images/im1557.jpg  \n  inflating: vietnamese/unseen_test_images/im1558.jpg  \n  inflating: vietnamese/unseen_test_images/im1559.jpg  \n  inflating: vietnamese/unseen_test_images/im1560.jpg  \n  inflating: vietnamese/unseen_test_images/im1561.jpg  \n  inflating: vietnamese/unseen_test_images/im1562.jpg  \n  inflating: vietnamese/unseen_test_images/im1563.jpg  \n  inflating: vietnamese/unseen_test_images/im1564.jpg  \n  inflating: vietnamese/unseen_test_images/im1565.jpg  \n  inflating: vietnamese/unseen_test_images/im1566.jpg  \n  inflating: vietnamese/unseen_test_images/im1567.jpg  \n  inflating: vietnamese/unseen_test_images/im1568.jpg  \n  inflating: vietnamese/unseen_test_images/im1569.jpg  \n  inflating: vietnamese/unseen_test_images/im1570.jpg  \n  inflating: vietnamese/unseen_test_images/im1571.jpg  \n  inflating: vietnamese/unseen_test_images/im1572.jpg  \n  inflating: vietnamese/unseen_test_images/im1573.jpg  \n  inflating: vietnamese/unseen_test_images/im1574.jpg  \n  inflating: vietnamese/unseen_test_images/im1575.jpg  \n  inflating: vietnamese/unseen_test_images/im1576.jpg  \n  inflating: vietnamese/unseen_test_images/im1577.jpg  \n  inflating: vietnamese/unseen_test_images/im1578.jpg  \n  inflating: vietnamese/unseen_test_images/im1579.jpg  \n  inflating: vietnamese/unseen_test_images/im1580.jpg  \n  inflating: vietnamese/unseen_test_images/im1581.jpg  \n  inflating: vietnamese/unseen_test_images/im1582.jpg  \n  inflating: vietnamese/unseen_test_images/im1583.jpg  \n  inflating: vietnamese/unseen_test_images/im1584.jpg  \n  inflating: vietnamese/unseen_test_images/im1585.jpg  \n  inflating: vietnamese/unseen_test_images/im1586.jpg  \n  inflating: vietnamese/unseen_test_images/im1587.jpg  \n  inflating: vietnamese/unseen_test_images/im1588.jpg  \n  inflating: vietnamese/unseen_test_images/im1589.jpg  \n  inflating: vietnamese/unseen_test_images/im1590.jpg  \n  inflating: vietnamese/unseen_test_images/im1591.jpg  \n  inflating: vietnamese/unseen_test_images/im1592.jpg  \n  inflating: vietnamese/unseen_test_images/im1593.jpg  \n  inflating: vietnamese/unseen_test_images/im1594.jpg  \n  inflating: vietnamese/unseen_test_images/im1595.jpg  \n  inflating: vietnamese/unseen_test_images/im1596.jpg  \n  inflating: vietnamese/unseen_test_images/im1597.jpg  \n  inflating: vietnamese/unseen_test_images/im1598.jpg  \n  inflating: vietnamese/unseen_test_images/im1599.jpg  \n  inflating: vietnamese/unseen_test_images/im1600.jpg  \n  inflating: vietnamese/unseen_test_images/im1601.jpg  \n  inflating: vietnamese/unseen_test_images/im1602.jpg  \n  inflating: vietnamese/unseen_test_images/im1603.jpg  \n  inflating: vietnamese/unseen_test_images/im1604.jpg  \n  inflating: vietnamese/unseen_test_images/im1605.jpg  \n  inflating: vietnamese/unseen_test_images/im1606.jpg  \n  inflating: vietnamese/unseen_test_images/im1607.jpg  \n  inflating: vietnamese/unseen_test_images/im1608.jpg  \n  inflating: vietnamese/unseen_test_images/im1609.jpg  \n  inflating: vietnamese/unseen_test_images/im1610.jpg  \n  inflating: vietnamese/unseen_test_images/im1611.jpg  \n  inflating: vietnamese/unseen_test_images/im1612.jpg  \n  inflating: vietnamese/unseen_test_images/im1613.jpg  \n  inflating: vietnamese/unseen_test_images/im1614.jpg  \n  inflating: vietnamese/unseen_test_images/im1615.jpg  \n  inflating: vietnamese/unseen_test_images/im1616.jpg  \n  inflating: vietnamese/unseen_test_images/im1617.jpg  \n  inflating: vietnamese/unseen_test_images/im1618.jpg  \n  inflating: vietnamese/unseen_test_images/im1619.jpg  \n  inflating: vietnamese/unseen_test_images/im1620.jpg  \n  inflating: vietnamese/unseen_test_images/im1621.jpg  \n  inflating: vietnamese/unseen_test_images/im1622.jpg  \n  inflating: vietnamese/unseen_test_images/im1623.jpg  \n  inflating: vietnamese/unseen_test_images/im1624.jpg  \n  inflating: vietnamese/unseen_test_images/im1625.jpg  \n  inflating: vietnamese/unseen_test_images/im1626.jpg  \n  inflating: vietnamese/unseen_test_images/im1627.jpg  \n  inflating: vietnamese/unseen_test_images/im1628.jpg  \n  inflating: vietnamese/unseen_test_images/im1629.jpg  \n  inflating: vietnamese/unseen_test_images/im1630.jpg  \n  inflating: vietnamese/unseen_test_images/im1631.jpg  \n  inflating: vietnamese/unseen_test_images/im1632.jpg  \n  inflating: vietnamese/unseen_test_images/im1633.jpg  \n  inflating: vietnamese/unseen_test_images/im1634.jpg  \n  inflating: vietnamese/unseen_test_images/im1635.jpg  \n  inflating: vietnamese/unseen_test_images/im1636.jpg  \n  inflating: vietnamese/unseen_test_images/im1637.jpg  \n  inflating: vietnamese/unseen_test_images/im1638.jpg  \n  inflating: vietnamese/unseen_test_images/im1639.jpg  \n  inflating: vietnamese/unseen_test_images/im1640.jpg  \n  inflating: vietnamese/unseen_test_images/im1641.jpg  \n  inflating: vietnamese/unseen_test_images/im1642.jpg  \n  inflating: vietnamese/unseen_test_images/im1643.jpg  \n  inflating: vietnamese/unseen_test_images/im1644.jpg  \n  inflating: vietnamese/unseen_test_images/im1645.jpg  \n  inflating: vietnamese/unseen_test_images/im1646.jpg  \n  inflating: vietnamese/unseen_test_images/im1647.jpg  \n  inflating: vietnamese/unseen_test_images/im1648.jpg  \n  inflating: vietnamese/unseen_test_images/im1649.jpg  \n  inflating: vietnamese/unseen_test_images/im1650.jpg  \n  inflating: vietnamese/unseen_test_images/im1651.jpg  \n  inflating: vietnamese/unseen_test_images/im1652.jpg  \n  inflating: vietnamese/unseen_test_images/im1653.jpg  \n  inflating: vietnamese/unseen_test_images/im1654.jpg  \n  inflating: vietnamese/unseen_test_images/im1655.jpg  \n  inflating: vietnamese/unseen_test_images/im1656.jpg  \n  inflating: vietnamese/unseen_test_images/im1657.jpg  \n  inflating: vietnamese/unseen_test_images/im1658.jpg  \n  inflating: vietnamese/unseen_test_images/im1659.jpg  \n  inflating: vietnamese/unseen_test_images/im1660.jpg  \n  inflating: vietnamese/unseen_test_images/im1661.jpg  \n  inflating: vietnamese/unseen_test_images/im1662.jpg  \n  inflating: vietnamese/unseen_test_images/im1663.jpg  \n  inflating: vietnamese/unseen_test_images/im1664.jpg  \n  inflating: vietnamese/unseen_test_images/im1665.jpg  \n  inflating: vietnamese/unseen_test_images/im1666.jpg  \n  inflating: vietnamese/unseen_test_images/im1667.jpg  \n  inflating: vietnamese/unseen_test_images/im1668.jpg  \n  inflating: vietnamese/unseen_test_images/im1669.jpg  \n  inflating: vietnamese/unseen_test_images/im1670.jpg  \n  inflating: vietnamese/unseen_test_images/im1671.jpg  \n  inflating: vietnamese/unseen_test_images/im1672.jpg  \n  inflating: vietnamese/unseen_test_images/im1673.jpg  \n  inflating: vietnamese/unseen_test_images/im1674.jpg  \n  inflating: vietnamese/unseen_test_images/im1675.jpg  \n  inflating: vietnamese/unseen_test_images/im1676.jpg  \n  inflating: vietnamese/unseen_test_images/im1677.jpg  \n  inflating: vietnamese/unseen_test_images/im1678.jpg  \n  inflating: vietnamese/unseen_test_images/im1679.jpg  \n  inflating: vietnamese/unseen_test_images/im1680.jpg  \n  inflating: vietnamese/unseen_test_images/im1681.jpg  \n  inflating: vietnamese/unseen_test_images/im1682.jpg  \n  inflating: vietnamese/unseen_test_images/im1683.jpg  \n  inflating: vietnamese/unseen_test_images/im1684.jpg  \n  inflating: vietnamese/unseen_test_images/im1685.jpg  \n  inflating: vietnamese/unseen_test_images/im1686.jpg  \n  inflating: vietnamese/unseen_test_images/im1687.jpg  \n  inflating: vietnamese/unseen_test_images/im1688.jpg  \n  inflating: vietnamese/unseen_test_images/im1689.jpg  \n  inflating: vietnamese/unseen_test_images/im1690.jpg  \n  inflating: vietnamese/unseen_test_images/im1691.jpg  \n  inflating: vietnamese/unseen_test_images/im1692.jpg  \n  inflating: vietnamese/unseen_test_images/im1693.jpg  \n  inflating: vietnamese/unseen_test_images/im1694.jpg  \n  inflating: vietnamese/unseen_test_images/im1695.jpg  \n  inflating: vietnamese/unseen_test_images/im1696.jpg  \n  inflating: vietnamese/unseen_test_images/im1697.jpg  \n  inflating: vietnamese/unseen_test_images/im1698.jpg  \n  inflating: vietnamese/unseen_test_images/im1699.jpg  \n  inflating: vietnamese/unseen_test_images/im1700.jpg  \n  inflating: vietnamese/unseen_test_images/im1701.jpg  \n  inflating: vietnamese/unseen_test_images/im1702.jpg  \n  inflating: vietnamese/unseen_test_images/im1703.jpg  \n  inflating: vietnamese/unseen_test_images/im1704.jpg  \n  inflating: vietnamese/unseen_test_images/im1705.jpg  \n  inflating: vietnamese/unseen_test_images/im1706.jpg  \n  inflating: vietnamese/unseen_test_images/im1707.jpg  \n  inflating: vietnamese/unseen_test_images/im1708.jpg  \n  inflating: vietnamese/unseen_test_images/im1709.jpg  \n  inflating: vietnamese/unseen_test_images/im1710.jpg  \n  inflating: vietnamese/unseen_test_images/im1711.jpg  \n  inflating: vietnamese/unseen_test_images/im1712.jpg  \n  inflating: vietnamese/unseen_test_images/im1713.jpg  \n  inflating: vietnamese/unseen_test_images/im1714.jpg  \n  inflating: vietnamese/unseen_test_images/im1715.jpg  \n  inflating: vietnamese/unseen_test_images/im1716.jpg  \n  inflating: vietnamese/unseen_test_images/im1717.jpg  \n  inflating: vietnamese/unseen_test_images/im1718.jpg  \n  inflating: vietnamese/unseen_test_images/im1719.jpg  \n  inflating: vietnamese/unseen_test_images/im1720.jpg  \n  inflating: vietnamese/unseen_test_images/im1721.jpg  \n  inflating: vietnamese/unseen_test_images/im1722.jpg  \n  inflating: vietnamese/unseen_test_images/im1723.jpg  \n  inflating: vietnamese/unseen_test_images/im1724.jpg  \n  inflating: vietnamese/unseen_test_images/im1725.jpg  \n  inflating: vietnamese/unseen_test_images/im1726.jpg  \n  inflating: vietnamese/unseen_test_images/im1727.jpg  \n  inflating: vietnamese/unseen_test_images/im1728.jpg  \n  inflating: vietnamese/unseen_test_images/im1729.jpg  \n  inflating: vietnamese/unseen_test_images/im1730.jpg  \n  inflating: vietnamese/unseen_test_images/im1731.jpg  \n  inflating: vietnamese/unseen_test_images/im1732.jpg  \n  inflating: vietnamese/unseen_test_images/im1733.jpg  \n  inflating: vietnamese/unseen_test_images/im1734.jpg  \n  inflating: vietnamese/unseen_test_images/im1735.jpg  \n  inflating: vietnamese/unseen_test_images/im1736.jpg  \n  inflating: vietnamese/unseen_test_images/im1737.jpg  \n  inflating: vietnamese/unseen_test_images/im1738.jpg  \n  inflating: vietnamese/unseen_test_images/im1739.jpg  \n  inflating: vietnamese/unseen_test_images/im1740.jpg  \n  inflating: vietnamese/unseen_test_images/im1741.jpg  \n  inflating: vietnamese/unseen_test_images/im1742.jpg  \n  inflating: vietnamese/unseen_test_images/im1743.jpg  \n  inflating: vietnamese/unseen_test_images/im1744.jpg  \n  inflating: vietnamese/unseen_test_images/im1745.jpg  \n  inflating: vietnamese/unseen_test_images/im1746.jpg  \n  inflating: vietnamese/unseen_test_images/im1747.jpg  \n  inflating: vietnamese/unseen_test_images/im1748.jpg  \n  inflating: vietnamese/unseen_test_images/im1749.jpg  \n  inflating: vietnamese/unseen_test_images/im1750.jpg  \n  inflating: vietnamese/unseen_test_images/im1751.jpg  \n  inflating: vietnamese/unseen_test_images/im1752.jpg  \n  inflating: vietnamese/unseen_test_images/im1753.jpg  \n  inflating: vietnamese/unseen_test_images/im1754.jpg  \n  inflating: vietnamese/unseen_test_images/im1755.jpg  \n  inflating: vietnamese/unseen_test_images/im1756.jpg  \n  inflating: vietnamese/unseen_test_images/im1757.jpg  \n  inflating: vietnamese/unseen_test_images/im1758.jpg  \n  inflating: vietnamese/unseen_test_images/im1759.jpg  \n  inflating: vietnamese/unseen_test_images/im1760.jpg  \n  inflating: vietnamese/unseen_test_images/im1761.jpg  \n  inflating: vietnamese/unseen_test_images/im1762.jpg  \n  inflating: vietnamese/unseen_test_images/im1763.jpg  \n  inflating: vietnamese/unseen_test_images/im1764.jpg  \n  inflating: vietnamese/unseen_test_images/im1765.jpg  \n  inflating: vietnamese/unseen_test_images/im1766.jpg  \n  inflating: vietnamese/unseen_test_images/im1767.jpg  \n  inflating: vietnamese/unseen_test_images/im1768.jpg  \n  inflating: vietnamese/unseen_test_images/im1769.jpg  \n  inflating: vietnamese/unseen_test_images/im1770.jpg  \n  inflating: vietnamese/unseen_test_images/im1771.jpg  \n  inflating: vietnamese/unseen_test_images/im1772.jpg  \n  inflating: vietnamese/unseen_test_images/im1773.jpg  \n  inflating: vietnamese/unseen_test_images/im1774.jpg  \n  inflating: vietnamese/unseen_test_images/im1775.jpg  \n  inflating: vietnamese/unseen_test_images/im1776.jpg  \n  inflating: vietnamese/unseen_test_images/im1777.jpg  \n  inflating: vietnamese/unseen_test_images/im1778.jpg  \n  inflating: vietnamese/unseen_test_images/im1779.jpg  \n  inflating: vietnamese/unseen_test_images/im1780.jpg  \n  inflating: vietnamese/unseen_test_images/im1781.jpg  \n  inflating: vietnamese/unseen_test_images/im1782.jpg  \n  inflating: vietnamese/unseen_test_images/im1783.jpg  \n  inflating: vietnamese/unseen_test_images/im1784.jpg  \n  inflating: vietnamese/unseen_test_images/im1785.jpg  \n  inflating: vietnamese/unseen_test_images/im1786.jpg  \n  inflating: vietnamese/unseen_test_images/im1787.jpg  \n  inflating: vietnamese/unseen_test_images/im1788.jpg  \n  inflating: vietnamese/unseen_test_images/im1789.jpg  \n  inflating: vietnamese/unseen_test_images/im1790.jpg  \n  inflating: vietnamese/unseen_test_images/im1791.jpg  \n  inflating: vietnamese/unseen_test_images/im1792.jpg  \n  inflating: vietnamese/unseen_test_images/im1793.jpg  \n  inflating: vietnamese/unseen_test_images/im1794.jpg  \n  inflating: vietnamese/unseen_test_images/im1795.jpg  \n  inflating: vietnamese/unseen_test_images/im1796.jpg  \n  inflating: vietnamese/unseen_test_images/im1797.jpg  \n  inflating: vietnamese/unseen_test_images/im1798.jpg  \n  inflating: vietnamese/unseen_test_images/im1799.jpg  \n  inflating: vietnamese/unseen_test_images/im1800.jpg  \n  inflating: vietnamese/unseen_test_images/im1801.jpg  \n  inflating: vietnamese/unseen_test_images/im1802.jpg  \n  inflating: vietnamese/unseen_test_images/im1803.jpg  \n  inflating: vietnamese/unseen_test_images/im1804.jpg  \n  inflating: vietnamese/unseen_test_images/im1805.jpg  \n  inflating: vietnamese/unseen_test_images/im1806.jpg  \n  inflating: vietnamese/unseen_test_images/im1807.jpg  \n  inflating: vietnamese/unseen_test_images/im1808.jpg  \n  inflating: vietnamese/unseen_test_images/im1809.jpg  \n  inflating: vietnamese/unseen_test_images/im1810.jpg  \n  inflating: vietnamese/unseen_test_images/im1811.jpg  \n  inflating: vietnamese/unseen_test_images/im1812.jpg  \n  inflating: vietnamese/unseen_test_images/im1813.jpg  \n  inflating: vietnamese/unseen_test_images/im1814.jpg  \n  inflating: vietnamese/unseen_test_images/im1815.jpg  \n  inflating: vietnamese/unseen_test_images/im1816.jpg  \n  inflating: vietnamese/unseen_test_images/im1817.jpg  \n  inflating: vietnamese/unseen_test_images/im1818.jpg  \n  inflating: vietnamese/unseen_test_images/im1819.jpg  \n  inflating: vietnamese/unseen_test_images/im1820.jpg  \n  inflating: vietnamese/unseen_test_images/im1821.jpg  \n  inflating: vietnamese/unseen_test_images/im1822.jpg  \n  inflating: vietnamese/unseen_test_images/im1823.jpg  \n  inflating: vietnamese/unseen_test_images/im1824.jpg  \n  inflating: vietnamese/unseen_test_images/im1825.jpg  \n  inflating: vietnamese/unseen_test_images/im1826.jpg  \n  inflating: vietnamese/unseen_test_images/im1827.jpg  \n  inflating: vietnamese/unseen_test_images/im1828.jpg  \n  inflating: vietnamese/unseen_test_images/im1829.jpg  \n  inflating: vietnamese/unseen_test_images/im1830.jpg  \n  inflating: vietnamese/unseen_test_images/im1831.jpg  \n  inflating: vietnamese/unseen_test_images/im1832.jpg  \n  inflating: vietnamese/unseen_test_images/im1833.jpg  \n  inflating: vietnamese/unseen_test_images/im1834.jpg  \n  inflating: vietnamese/unseen_test_images/im1835.jpg  \n  inflating: vietnamese/unseen_test_images/im1836.jpg  \n  inflating: vietnamese/unseen_test_images/im1837.jpg  \n  inflating: vietnamese/unseen_test_images/im1838.jpg  \n  inflating: vietnamese/unseen_test_images/im1839.jpg  \n  inflating: vietnamese/unseen_test_images/im1840.jpg  \n  inflating: vietnamese/unseen_test_images/im1841.jpg  \n  inflating: vietnamese/unseen_test_images/im1842.jpg  \n  inflating: vietnamese/unseen_test_images/im1843.jpg  \n  inflating: vietnamese/unseen_test_images/im1844.jpg  \n  inflating: vietnamese/unseen_test_images/im1845.jpg  \n  inflating: vietnamese/unseen_test_images/im1846.jpg  \n  inflating: vietnamese/unseen_test_images/im1847.jpg  \n  inflating: vietnamese/unseen_test_images/im1848.jpg  \n  inflating: vietnamese/unseen_test_images/im1849.jpg  \n  inflating: vietnamese/unseen_test_images/im1850.jpg  \n  inflating: vietnamese/unseen_test_images/im1851.jpg  \n  inflating: vietnamese/unseen_test_images/im1852.jpg  \n  inflating: vietnamese/unseen_test_images/im1853.jpg  \n  inflating: vietnamese/unseen_test_images/im1854.jpg  \n  inflating: vietnamese/unseen_test_images/im1855.jpg  \n  inflating: vietnamese/unseen_test_images/im1856.jpg  \n  inflating: vietnamese/unseen_test_images/im1857.jpg  \n  inflating: vietnamese/unseen_test_images/im1858.jpg  \n  inflating: vietnamese/unseen_test_images/im1859.jpg  \n  inflating: vietnamese/unseen_test_images/im1860.jpg  \n  inflating: vietnamese/unseen_test_images/im1861.jpg  \n  inflating: vietnamese/unseen_test_images/im1862.jpg  \n  inflating: vietnamese/unseen_test_images/im1863.jpg  \n  inflating: vietnamese/unseen_test_images/im1864.jpg  \n  inflating: vietnamese/unseen_test_images/im1865.jpg  \n  inflating: vietnamese/unseen_test_images/im1866.jpg  \n  inflating: vietnamese/unseen_test_images/im1867.jpg  \n  inflating: vietnamese/unseen_test_images/im1868.jpg  \n  inflating: vietnamese/unseen_test_images/im1869.jpg  \n  inflating: vietnamese/unseen_test_images/im1870.jpg  \n  inflating: vietnamese/unseen_test_images/im1871.jpg  \n  inflating: vietnamese/unseen_test_images/im1872.jpg  \n  inflating: vietnamese/unseen_test_images/im1873.jpg  \n  inflating: vietnamese/unseen_test_images/im1874.jpg  \n  inflating: vietnamese/unseen_test_images/im1875.jpg  \n  inflating: vietnamese/unseen_test_images/im1876.jpg  \n  inflating: vietnamese/unseen_test_images/im1877.jpg  \n  inflating: vietnamese/unseen_test_images/im1878.jpg  \n  inflating: vietnamese/unseen_test_images/im1879.jpg  \n  inflating: vietnamese/unseen_test_images/im1880.jpg  \n  inflating: vietnamese/unseen_test_images/im1881.jpg  \n  inflating: vietnamese/unseen_test_images/im1882.jpg  \n  inflating: vietnamese/unseen_test_images/im1883.jpg  \n  inflating: vietnamese/unseen_test_images/im1884.jpg  \n  inflating: vietnamese/unseen_test_images/im1885.jpg  \n  inflating: vietnamese/unseen_test_images/im1886.jpg  \n  inflating: vietnamese/unseen_test_images/im1887.jpg  \n  inflating: vietnamese/unseen_test_images/im1888.jpg  \n  inflating: vietnamese/unseen_test_images/im1889.jpg  \n  inflating: vietnamese/unseen_test_images/im1890.jpg  \n  inflating: vietnamese/unseen_test_images/im1891.jpg  \n  inflating: vietnamese/unseen_test_images/im1892.jpg  \n  inflating: vietnamese/unseen_test_images/im1893.jpg  \n  inflating: vietnamese/unseen_test_images/im1894.jpg  \n  inflating: vietnamese/unseen_test_images/im1895.jpg  \n  inflating: vietnamese/unseen_test_images/im1896.jpg  \n  inflating: vietnamese/unseen_test_images/im1897.jpg  \n  inflating: vietnamese/unseen_test_images/im1898.jpg  \n  inflating: vietnamese/unseen_test_images/im1899.jpg  \n  inflating: vietnamese/unseen_test_images/im1900.jpg  \n  inflating: vietnamese/unseen_test_images/im1901.jpg  \n  inflating: vietnamese/unseen_test_images/im1902.jpg  \n  inflating: vietnamese/unseen_test_images/im1903.jpg  \n  inflating: vietnamese/unseen_test_images/im1904.jpg  \n  inflating: vietnamese/unseen_test_images/im1905.jpg  \n  inflating: vietnamese/unseen_test_images/im1906.jpg  \n  inflating: vietnamese/unseen_test_images/im1907.jpg  \n  inflating: vietnamese/unseen_test_images/im1908.jpg  \n  inflating: vietnamese/unseen_test_images/im1909.jpg  \n  inflating: vietnamese/unseen_test_images/im1910.jpg  \n  inflating: vietnamese/unseen_test_images/im1911.jpg  \n  inflating: vietnamese/unseen_test_images/im1912.jpg  \n  inflating: vietnamese/unseen_test_images/im1913.jpg  \n  inflating: vietnamese/unseen_test_images/im1914.jpg  \n  inflating: vietnamese/unseen_test_images/im1915.jpg  \n  inflating: vietnamese/unseen_test_images/im1916.jpg  \n  inflating: vietnamese/unseen_test_images/im1917.jpg  \n  inflating: vietnamese/unseen_test_images/im1918.jpg  \n  inflating: vietnamese/unseen_test_images/im1919.jpg  \n  inflating: vietnamese/unseen_test_images/im1920.jpg  \n  inflating: vietnamese/unseen_test_images/im1921.jpg  \n  inflating: vietnamese/unseen_test_images/im1922.jpg  \n  inflating: vietnamese/unseen_test_images/im1923.jpg  \n  inflating: vietnamese/unseen_test_images/im1924.jpg  \n  inflating: vietnamese/unseen_test_images/im1925.jpg  \n  inflating: vietnamese/unseen_test_images/im1926.jpg  \n  inflating: vietnamese/unseen_test_images/im1927.jpg  \n  inflating: vietnamese/unseen_test_images/im1928.jpg  \n  inflating: vietnamese/unseen_test_images/im1929.jpg  \n  inflating: vietnamese/unseen_test_images/im1930.jpg  \n  inflating: vietnamese/unseen_test_images/im1931.jpg  \n  inflating: vietnamese/unseen_test_images/im1932.jpg  \n  inflating: vietnamese/unseen_test_images/im1933.jpg  \n  inflating: vietnamese/unseen_test_images/im1934.jpg  \n  inflating: vietnamese/unseen_test_images/im1935.jpg  \n  inflating: vietnamese/unseen_test_images/im1936.jpg  \n  inflating: vietnamese/unseen_test_images/im1937.jpg  \n  inflating: vietnamese/unseen_test_images/im1938.jpg  \n  inflating: vietnamese/unseen_test_images/im1939.jpg  \n  inflating: vietnamese/unseen_test_images/im1940.jpg  \n  inflating: vietnamese/unseen_test_images/im1941.jpg  \n  inflating: vietnamese/unseen_test_images/im1942.jpg  \n  inflating: vietnamese/unseen_test_images/im1943.jpg  \n  inflating: vietnamese/unseen_test_images/im1944.jpg  \n  inflating: vietnamese/unseen_test_images/im1945.jpg  \n  inflating: vietnamese/unseen_test_images/im1946.jpg  \n  inflating: vietnamese/unseen_test_images/im1947.jpg  \n  inflating: vietnamese/unseen_test_images/im1948.jpg  \n  inflating: vietnamese/unseen_test_images/im1949.jpg  \n  inflating: vietnamese/unseen_test_images/im1950.jpg  \n  inflating: vietnamese/unseen_test_images/im1951.jpg  \n  inflating: vietnamese/unseen_test_images/im1952.jpg  \n  inflating: vietnamese/unseen_test_images/im1953.jpg  \n  inflating: vietnamese/unseen_test_images/im1954.jpg  \n  inflating: vietnamese/unseen_test_images/im1955.jpg  \n  inflating: vietnamese/unseen_test_images/im1956.jpg  \n  inflating: vietnamese/unseen_test_images/im1957.jpg  \n  inflating: vietnamese/unseen_test_images/im1958.jpg  \n  inflating: vietnamese/unseen_test_images/im1959.jpg  \n  inflating: vietnamese/unseen_test_images/im1960.jpg  \n  inflating: vietnamese/unseen_test_images/im1961.jpg  \n  inflating: vietnamese/unseen_test_images/im1962.jpg  \n  inflating: vietnamese/unseen_test_images/im1963.jpg  \n  inflating: vietnamese/unseen_test_images/im1964.jpg  \n  inflating: vietnamese/unseen_test_images/im1965.jpg  \n  inflating: vietnamese/unseen_test_images/im1966.jpg  \n  inflating: vietnamese/unseen_test_images/im1967.jpg  \n  inflating: vietnamese/unseen_test_images/im1968.jpg  \n  inflating: vietnamese/unseen_test_images/im1969.jpg  \n  inflating: vietnamese/unseen_test_images/im1970.jpg  \n  inflating: vietnamese/unseen_test_images/im1971.jpg  \n  inflating: vietnamese/unseen_test_images/im1972.jpg  \n  inflating: vietnamese/unseen_test_images/im1973.jpg  \n  inflating: vietnamese/unseen_test_images/im1974.jpg  \n  inflating: vietnamese/unseen_test_images/im1975.jpg  \n  inflating: vietnamese/unseen_test_images/im1976.jpg  \n  inflating: vietnamese/unseen_test_images/im1977.jpg  \n  inflating: vietnamese/unseen_test_images/im1978.jpg  \n  inflating: vietnamese/unseen_test_images/im1979.jpg  \n  inflating: vietnamese/unseen_test_images/im1980.jpg  \n  inflating: vietnamese/unseen_test_images/im1981.jpg  \n  inflating: vietnamese/unseen_test_images/im1982.jpg  \n  inflating: vietnamese/unseen_test_images/im1983.jpg  \n  inflating: vietnamese/unseen_test_images/im1984.jpg  \n  inflating: vietnamese/unseen_test_images/im1985.jpg  \n  inflating: vietnamese/unseen_test_images/im1986.jpg  \n  inflating: vietnamese/unseen_test_images/im1987.jpg  \n  inflating: vietnamese/unseen_test_images/im1988.jpg  \n  inflating: vietnamese/unseen_test_images/im1989.jpg  \n  inflating: vietnamese/unseen_test_images/im1990.jpg  \n  inflating: vietnamese/unseen_test_images/im1991.jpg  \n  inflating: vietnamese/unseen_test_images/im1992.jpg  \n  inflating: vietnamese/unseen_test_images/im1993.jpg  \n  inflating: vietnamese/unseen_test_images/im1994.jpg  \n  inflating: vietnamese/unseen_test_images/im1995.jpg  \n  inflating: vietnamese/unseen_test_images/im1996.jpg  \n  inflating: vietnamese/unseen_test_images/im1997.jpg  \n  inflating: vietnamese/unseen_test_images/im1998.jpg  \n  inflating: vietnamese/unseen_test_images/im1999.jpg  \n  inflating: vietnamese/unseen_test_images/im2000.jpg  \n   creating: vietnamese/labels/\n  inflating: vietnamese/labels/gt_461.txt  \n  inflating: vietnamese/labels/gt_1971.txt  \n  inflating: vietnamese/labels/gt_1044.txt  \n  inflating: vietnamese/labels/gt_803.txt  \n  inflating: vietnamese/labels/gt_769.txt  \n  inflating: vietnamese/labels/gt_1706.txt  \n  inflating: vietnamese/labels/gt_1585.txt  \n  inflating: vietnamese/labels/gt_1960.txt  \n  inflating: vietnamese/labels/gt_249.txt  \n  inflating: vietnamese/labels/gt_1478.txt  \n  inflating: vietnamese/labels/gt_1783.txt  \n  inflating: vietnamese/labels/gt_114.txt  \n  inflating: vietnamese/labels/gt_224.txt  \n  inflating: vietnamese/labels/gt_1164.txt  \n  inflating: vietnamese/labels/gt_938.txt  \n  inflating: vietnamese/labels/gt_1432.txt  \n  inflating: vietnamese/labels/gt_1981.txt  \n  inflating: vietnamese/labels/gt_282.txt  \n  inflating: vietnamese/labels/gt_1727.txt  \n  inflating: vietnamese/labels/gt_677.txt  \n  inflating: vietnamese/labels/gt_1926.txt  \n  inflating: vietnamese/labels/gt_913.txt  \n  inflating: vietnamese/labels/gt_635.txt  \n  inflating: vietnamese/labels/gt_164.txt  \n  inflating: vietnamese/labels/gt_1525.txt  \n  inflating: vietnamese/labels/gt_1109.txt  \n  inflating: vietnamese/labels/gt_997.txt  \n  inflating: vietnamese/labels/gt_263.txt  \n  inflating: vietnamese/labels/gt_1066.txt  \n  inflating: vietnamese/labels/gt_633.txt  \n  inflating: vietnamese/labels/gt_1297.txt  \n  inflating: vietnamese/labels/gt_1070.txt  \n  inflating: vietnamese/labels/gt_1544.txt  \n  inflating: vietnamese/labels/gt_360.txt  \n  inflating: vietnamese/labels/gt_522.txt  \n  inflating: vietnamese/labels/gt_4.txt  \n  inflating: vietnamese/labels/gt_104.txt  \n  inflating: vietnamese/labels/gt_710.txt  \n  inflating: vietnamese/labels/gt_1060.txt  \n  inflating: vietnamese/labels/gt_952.txt  \n  inflating: vietnamese/labels/gt_948.txt  \n  inflating: vietnamese/labels/gt_949.txt  \n  inflating: vietnamese/labels/gt_107.txt  \n  inflating: vietnamese/labels/gt_930.txt  \n  inflating: vietnamese/labels/gt_446.txt  \n  inflating: vietnamese/labels/gt_245.txt  \n  inflating: vietnamese/labels/gt_169.txt  \n  inflating: vietnamese/labels/gt_161.txt  \n  inflating: vietnamese/labels/gt_711.txt  \n  inflating: vietnamese/labels/gt_1839.txt  \n  inflating: vietnamese/labels/gt_1895.txt  \n  inflating: vietnamese/labels/gt_416.txt  \n  inflating: vietnamese/labels/gt_260.txt  \n  inflating: vietnamese/labels/gt_571.txt  \n  inflating: vietnamese/labels/gt_174.txt  \n  inflating: vietnamese/labels/gt_1833.txt  \n  inflating: vietnamese/labels/gt_1327.txt  \n  inflating: vietnamese/labels/gt_1834.txt  \n  inflating: vietnamese/labels/gt_1754.txt  \n  inflating: vietnamese/labels/gt_886.txt  \n  inflating: vietnamese/labels/gt_1572.txt  \n  inflating: vietnamese/labels/gt_1891.txt  \n  inflating: vietnamese/labels/gt_1160.txt  \n  inflating: vietnamese/labels/gt_1078.txt  \n  inflating: vietnamese/labels/gt_537.txt  \n  inflating: vietnamese/labels/gt_1079.txt  \n  inflating: vietnamese/labels/gt_532.txt  \n  inflating: vietnamese/labels/gt_651.txt  \n  inflating: vietnamese/labels/gt_1579.txt  \n  inflating: vietnamese/labels/gt_495.txt  \n  inflating: vietnamese/labels/gt_1145.txt  \n  inflating: vietnamese/labels/gt_858.txt  \n  inflating: vietnamese/labels/gt_1370.txt  \n  inflating: vietnamese/labels/gt_1718.txt  \n  inflating: vietnamese/labels/gt_132.txt  \n  inflating: vietnamese/labels/gt_530.txt  \n  inflating: vietnamese/labels/gt_1717.txt  \n  inflating: vietnamese/labels/gt_1469.txt  \n  inflating: vietnamese/labels/gt_219.txt  \n  inflating: vietnamese/labels/gt_1601.txt  \n  inflating: vietnamese/labels/gt_1810.txt  \n  inflating: vietnamese/labels/gt_1072.txt  \n  inflating: vietnamese/labels/gt_227.txt  \n  inflating: vietnamese/labels/gt_875.txt  \n  inflating: vietnamese/labels/gt_1117.txt  \n  inflating: vietnamese/labels/gt_1150.txt  \n  inflating: vietnamese/labels/gt_603.txt  \n  inflating: vietnamese/labels/gt_1461.txt  \n  inflating: vietnamese/labels/gt_1315.txt  \n  inflating: vietnamese/labels/gt_1075.txt  \n  inflating: vietnamese/labels/gt_103.txt  \n  inflating: vietnamese/labels/gt_1408.txt  \n  inflating: vietnamese/labels/gt_1092.txt  \n  inflating: vietnamese/labels/gt_1850.txt  \n  inflating: vietnamese/labels/gt_100.txt  \n  inflating: vietnamese/labels/gt_1798.txt  \n  inflating: vietnamese/labels/gt_1812.txt  \n  inflating: vietnamese/labels/gt_1196.txt  \n  inflating: vietnamese/labels/gt_1905.txt  \n  inflating: vietnamese/labels/gt_1377.txt  \n  inflating: vietnamese/labels/gt_1631.txt  \n  inflating: vietnamese/labels/gt_1021.txt  \n  inflating: vietnamese/labels/gt_909.txt  \n  inflating: vietnamese/labels/gt_1953.txt  \n  inflating: vietnamese/labels/gt_397.txt  \n  inflating: vietnamese/labels/gt_1738.txt  \n  inflating: vietnamese/labels/gt_457.txt  \n  inflating: vietnamese/labels/gt_128.txt  \n  inflating: vietnamese/labels/gt_1734.txt  \n  inflating: vietnamese/labels/gt_1283.txt  \n  inflating: vietnamese/labels/gt_376.txt  \n  inflating: vietnamese/labels/gt_1001.txt  \n  inflating: vietnamese/labels/gt_1869.txt  \n  inflating: vietnamese/labels/gt_693.txt  \n  inflating: vietnamese/labels/gt_1405.txt  \n  inflating: vietnamese/labels/gt_569.txt  \n  inflating: vietnamese/labels/gt_1548.txt  \n  inflating: vietnamese/labels/gt_1690.txt  \n  inflating: vietnamese/labels/gt_1031.txt  \n  inflating: vietnamese/labels/gt_607.txt  \n  inflating: vietnamese/labels/gt_694.txt  \n  inflating: vietnamese/labels/gt_261.txt  \n  inflating: vietnamese/labels/gt_143.txt  \n  inflating: vietnamese/labels/gt_697.txt  \n  inflating: vietnamese/labels/gt_543.txt  \n  inflating: vietnamese/labels/gt_1102.txt  \n  inflating: vietnamese/labels/gt_1071.txt  \n  inflating: vietnamese/labels/gt_1709.txt  \n  inflating: vietnamese/labels/gt_1385.txt  \n  inflating: vietnamese/labels/gt_444.txt  \n  inflating: vietnamese/labels/gt_1303.txt  \n  inflating: vietnamese/labels/gt_1343.txt  \n  inflating: vietnamese/labels/gt_1217.txt  \n  inflating: vietnamese/labels/gt_908.txt  \n  inflating: vietnamese/labels/gt_503.txt  \n  inflating: vietnamese/labels/gt_735.txt  \n  inflating: vietnamese/labels/gt_203.txt  \n  inflating: vietnamese/labels/gt_728.txt  \n  inflating: vietnamese/labels/gt_468.txt  \n  inflating: vietnamese/labels/gt_1205.txt  \n  inflating: vietnamese/labels/gt_856.txt  \n  inflating: vietnamese/labels/gt_1495.txt  \n  inflating: vietnamese/labels/gt_534.txt  \n  inflating: vietnamese/labels/gt_1016.txt  \n  inflating: vietnamese/labels/gt_211.txt  \n  inflating: vietnamese/labels/gt_1531.txt  \n  inflating: vietnamese/labels/gt_1005.txt  \n  inflating: vietnamese/labels/gt_509.txt  \n  inflating: vietnamese/labels/gt_1434.txt  \n  inflating: vietnamese/labels/gt_630.txt  \n  inflating: vietnamese/labels/gt_339.txt  \n  inflating: vietnamese/labels/gt_972.txt  \n  inflating: vietnamese/labels/gt_405.txt  \n  inflating: vietnamese/labels/gt_1182.txt  \n  inflating: vietnamese/labels/gt_1602.txt  \n  inflating: vietnamese/labels/gt_1262.txt  \n  inflating: vietnamese/labels/gt_1120.txt  \n  inflating: vietnamese/labels/gt_1198.txt  \n  inflating: vietnamese/labels/gt_798.txt  \n  inflating: vietnamese/labels/gt_407.txt  \n  inflating: vietnamese/labels/gt_366.txt  \n  inflating: vietnamese/labels/gt_689.txt  \n  inflating: vietnamese/labels/gt_1046.txt  \n  inflating: vietnamese/labels/gt_759.txt  \n  inflating: vietnamese/labels/gt_877.txt  \n  inflating: vietnamese/labels/gt_1721.txt  \n  inflating: vietnamese/labels/gt_474.txt  \n  inflating: vietnamese/labels/gt_424.txt  \n  inflating: vietnamese/labels/gt_891.txt  \n  inflating: vietnamese/labels/gt_1969.txt  \n  inflating: vietnamese/labels/gt_215.txt  \n  inflating: vietnamese/labels/gt_583.txt  \n  inflating: vietnamese/labels/gt_157.txt  \n  inflating: vietnamese/labels/gt_1672.txt  \n  inflating: vietnamese/labels/gt_346.txt  \n  inflating: vietnamese/labels/gt_863.txt  \n  inflating: vietnamese/labels/gt_1399.txt  \n  inflating: vietnamese/labels/gt_1700.txt  \n  inflating: vietnamese/labels/gt_1871.txt  \n  inflating: vietnamese/labels/gt_82.txt  \n  inflating: vietnamese/labels/gt_634.txt  \n  inflating: vietnamese/labels/gt_336.txt  \n  inflating: vietnamese/labels/gt_328.txt  \n  inflating: vietnamese/labels/gt_278.txt  \n  inflating: vietnamese/labels/gt_596.txt  \n  inflating: vietnamese/labels/gt_202.txt  \n  inflating: vietnamese/labels/gt_362.txt  \n  inflating: vietnamese/labels/gt_1422.txt  \n  inflating: vietnamese/labels/gt_613.txt  \n  inflating: vietnamese/labels/gt_344.txt  \n  inflating: vietnamese/labels/gt_831.txt  \n  inflating: vietnamese/labels/gt_1591.txt  \n  inflating: vietnamese/labels/gt_1775.txt  \n  inflating: vietnamese/labels/gt_1650.txt  \n  inflating: vietnamese/labels/gt_1879.txt  \n  inflating: vietnamese/labels/gt_924.txt  \n  inflating: vietnamese/labels/gt_148.txt  \n  inflating: vietnamese/labels/gt_1183.txt  \n  inflating: vietnamese/labels/gt_764.txt  \n  inflating: vietnamese/labels/gt_1172.txt  \n  inflating: vietnamese/labels/gt_911.txt  \n  inflating: vietnamese/labels/gt_1455.txt  \n  inflating: vietnamese/labels/gt_367.txt  \n  inflating: vietnamese/labels/gt_725.txt  \n  inflating: vietnamese/labels/gt_1956.txt  \n  inflating: vietnamese/labels/gt_399.txt  \n  inflating: vietnamese/labels/gt_286.txt  \n  inflating: vietnamese/labels/gt_1948.txt  \n  inflating: vietnamese/labels/gt_601.txt  \n  inflating: vietnamese/labels/gt_1975.txt  \n  inflating: vietnamese/labels/gt_1142.txt  \n  inflating: vietnamese/labels/gt_1308.txt  \n  inflating: vietnamese/labels/gt_475.txt  \n  inflating: vietnamese/labels/gt_1577.txt  \n  inflating: vietnamese/labels/gt_1874.txt  \n  inflating: vietnamese/labels/gt_1875.txt  \n  inflating: vietnamese/labels/gt_688.txt  \n  inflating: vietnamese/labels/gt_1549.txt  \n  inflating: vietnamese/labels/gt_844.txt  \n  inflating: vietnamese/labels/gt_279.txt  \n  inflating: vietnamese/labels/gt_218.txt  \n  inflating: vietnamese/labels/gt_1636.txt  \n  inflating: vietnamese/labels/gt_484.txt  \n  inflating: vietnamese/labels/gt_815.txt  \n  inflating: vietnamese/labels/gt_1685.txt  \n  inflating: vietnamese/labels/gt_738.txt  \n  inflating: vietnamese/labels/gt_511.txt  \n  inflating: vietnamese/labels/gt_982.txt  \n  inflating: vietnamese/labels/gt_1870.txt  \n  inflating: vietnamese/labels/gt_52.txt  \n  inflating: vietnamese/labels/gt_960.txt  \n  inflating: vietnamese/labels/gt_1674.txt  \n  inflating: vietnamese/labels/gt_1725.txt  \n  inflating: vietnamese/labels/gt_680.txt  \n  inflating: vietnamese/labels/gt_1923.txt  \n  inflating: vietnamese/labels/gt_1786.txt  \n  inflating: vietnamese/labels/gt_408.txt  \n  inflating: vietnamese/labels/gt_1022.txt  \n  inflating: vietnamese/labels/gt_679.txt  \n  inflating: vietnamese/labels/gt_1225.txt  \n  inflating: vietnamese/labels/gt_175.txt  \n  inflating: vietnamese/labels/gt_1716.txt  \n  inflating: vietnamese/labels/gt_1296.txt  \n  inflating: vietnamese/labels/gt_676.txt  \n  inflating: vietnamese/labels/gt_1207.txt  \n  inflating: vietnamese/labels/gt_1105.txt  \n  inflating: vietnamese/labels/gt_1173.txt  \n  inflating: vietnamese/labels/gt_1054.txt  \n  inflating: vietnamese/labels/gt_1210.txt  \n  inflating: vietnamese/labels/gt_71.txt  \n  inflating: vietnamese/labels/gt_1547.txt  \n  inflating: vietnamese/labels/gt_1083.txt  \n  inflating: vietnamese/labels/gt_632.txt  \n  inflating: vietnamese/labels/gt_1532.txt  \n  inflating: vietnamese/labels/gt_1224.txt  \n  inflating: vietnamese/labels/gt_1788.txt  \n  inflating: vietnamese/labels/gt_1114.txt  \n  inflating: vietnamese/labels/gt_1829.txt  \n  inflating: vietnamese/labels/gt_1940.txt  \n  inflating: vietnamese/labels/gt_1168.txt  \n  inflating: vietnamese/labels/gt_819.txt  \n  inflating: vietnamese/labels/gt_1161.txt  \n  inflating: vietnamese/labels/gt_833.txt  \n  inflating: vietnamese/labels/gt_1963.txt  \n  inflating: vietnamese/labels/gt_1477.txt  \n  inflating: vietnamese/labels/gt_1569.txt  \n  inflating: vietnamese/labels/gt_220.txt  \n  inflating: vietnamese/labels/gt_942.txt  \n  inflating: vietnamese/labels/gt_1613.txt  \n  inflating: vietnamese/labels/gt_1009.txt  \n  inflating: vietnamese/labels/gt_1479.txt  \n  inflating: vietnamese/labels/gt_295.txt  \n  inflating: vietnamese/labels/gt_1645.txt  \n  inflating: vietnamese/labels/gt_1462.txt  \n  inflating: vietnamese/labels/gt_691.txt  \n  inflating: vietnamese/labels/gt_622.txt  \n  inflating: vietnamese/labels/gt_492.txt  \n  inflating: vietnamese/labels/gt_578.txt  \n  inflating: vietnamese/labels/gt_505.txt  \n  inflating: vietnamese/labels/gt_1856.txt  \n  inflating: vietnamese/labels/gt_1966.txt  \n  inflating: vietnamese/labels/gt_756.txt  \n  inflating: vietnamese/labels/gt_253.txt  \n  inflating: vietnamese/labels/gt_763.txt  \n  inflating: vietnamese/labels/gt_1491.txt  \n  inflating: vietnamese/labels/gt_1804.txt  \n  inflating: vietnamese/labels/gt_1233.txt  \n  inflating: vietnamese/labels/gt_1448.txt  \n  inflating: vietnamese/labels/gt_1387.txt  \n  inflating: vietnamese/labels/gt_1594.txt  \n  inflating: vietnamese/labels/gt_713.txt  \n  inflating: vietnamese/labels/gt_1389.txt  \n  inflating: vietnamese/labels/gt_1026.txt  \n  inflating: vietnamese/labels/gt_423.txt  \n  inflating: vietnamese/labels/gt_1562.txt  \n  inflating: vietnamese/labels/gt_1090.txt  \n  inflating: vietnamese/labels/gt_838.txt  \n  inflating: vietnamese/labels/gt_58.txt  \n  inflating: vietnamese/labels/gt_1163.txt  \n  inflating: vietnamese/labels/gt_501.txt  \n  inflating: vietnamese/labels/gt_1433.txt  \n  inflating: vietnamese/labels/gt_412.txt  \n  inflating: vietnamese/labels/gt_1838.txt  \n  inflating: vietnamese/labels/gt_1600.txt  \n  inflating: vietnamese/labels/gt_1696.txt  \n  inflating: vietnamese/labels/gt_248.txt  \n  inflating: vietnamese/labels/gt_1030.txt  \n  inflating: vietnamese/labels/gt_1480.txt  \n  inflating: vietnamese/labels/gt_757.txt  \n  inflating: vietnamese/labels/gt_225.txt  \n  inflating: vietnamese/labels/gt_97.txt  \n  inflating: vietnamese/labels/gt_1068.txt  \n  inflating: vietnamese/labels/gt_882.txt  \n  inflating: vietnamese/labels/gt_456.txt  \n  inflating: vietnamese/labels/gt_228.txt  \n  inflating: vietnamese/labels/gt_1865.txt  \n  inflating: vietnamese/labels/gt_172.txt  \n  inflating: vietnamese/labels/gt_1862.txt  \n  inflating: vietnamese/labels/gt_801.txt  \n  inflating: vietnamese/labels/gt_1316.txt  \n  inflating: vietnamese/labels/gt_1866.txt  \n  inflating: vietnamese/labels/gt_850.txt  \n  inflating: vietnamese/labels/gt_645.txt  \n  inflating: vietnamese/labels/gt_1880.txt  \n  inflating: vietnamese/labels/gt_931.txt  \n  inflating: vietnamese/labels/gt_353.txt  \n  inflating: vietnamese/labels/gt_1515.txt  \n  inflating: vietnamese/labels/gt_1459.txt  \n  inflating: vietnamese/labels/gt_335.txt  \n  inflating: vietnamese/labels/gt_1214.txt  \n  inflating: vietnamese/labels/gt_708.txt  \n  inflating: vietnamese/labels/gt_1864.txt  \n  inflating: vietnamese/labels/gt_127.txt  \n  inflating: vietnamese/labels/gt_1617.txt  \n  inflating: vietnamese/labels/gt_388.txt  \n  inflating: vietnamese/labels/gt_1756.txt  \n  inflating: vietnamese/labels/gt_1776.txt  \n  inflating: vietnamese/labels/gt_1472.txt  \n  inflating: vietnamese/labels/gt_1312.txt  \n  inflating: vietnamese/labels/gt_1648.txt  \n  inflating: vietnamese/labels/gt_189.txt  \n  inflating: vietnamese/labels/gt_1415.txt  \n  inflating: vietnamese/labels/gt_998.txt  \n  inflating: vietnamese/labels/gt_1319.txt  \n  inflating: vietnamese/labels/gt_666.txt  \n  inflating: vietnamese/labels/gt_1353.txt  \n  inflating: vietnamese/labels/gt_137.txt  \n  inflating: vietnamese/labels/gt_771.txt  \n  inflating: vietnamese/labels/gt_208.txt  \n  inflating: vietnamese/labels/gt_921.txt  \n  inflating: vietnamese/labels/gt_477.txt  \n  inflating: vietnamese/labels/gt_993.txt  \n  inflating: vietnamese/labels/gt_1096.txt  \n  inflating: vietnamese/labels/gt_775.txt  \n  inflating: vietnamese/labels/gt_318.txt  \n  inflating: vietnamese/labels/gt_145.txt  \n  inflating: vietnamese/labels/gt_947.txt  \n  inflating: vietnamese/labels/gt_843.txt  \n  inflating: vietnamese/labels/gt_427.txt  \n  inflating: vietnamese/labels/gt_737.txt  \n  inflating: vietnamese/labels/gt_1772.txt  \n  inflating: vietnamese/labels/gt_327.txt  \n  inflating: vietnamese/labels/gt_1396.txt  \n  inflating: vietnamese/labels/gt_314.txt  \n  inflating: vietnamese/labels/gt_465.txt  \n  inflating: vietnamese/labels/gt_1758.txt  \n  inflating: vietnamese/labels/gt_521.txt  \n  inflating: vietnamese/labels/gt_1511.txt  \n  inflating: vietnamese/labels/gt_199.txt  \n  inflating: vietnamese/labels/gt_1333.txt  \n  inflating: vietnamese/labels/gt_32.txt  \n  inflating: vietnamese/labels/gt_895.txt  \n  inflating: vietnamese/labels/gt_1059.txt  \n  inflating: vietnamese/labels/gt_1272.txt  \n  inflating: vietnamese/labels/gt_1254.txt  \n  inflating: vietnamese/labels/gt_564.txt  \n  inflating: vietnamese/labels/gt_89.txt  \n  inflating: vietnamese/labels/gt_1279.txt  \n  inflating: vietnamese/labels/gt_1132.txt  \n  inflating: vietnamese/labels/gt_1882.txt  \n  inflating: vietnamese/labels/gt_1076.txt  \n  inflating: vietnamese/labels/gt_115.txt  \n  inflating: vietnamese/labels/gt_1435.txt  \n  inflating: vietnamese/labels/gt_267.txt  \n  inflating: vietnamese/labels/gt_1438.txt  \n  inflating: vietnamese/labels/gt_1590.txt  \n  inflating: vietnamese/labels/gt_610.txt  \n  inflating: vietnamese/labels/gt_1752.txt  \n  inflating: vietnamese/labels/gt_685.txt  \n  inflating: vietnamese/labels/gt_1625.txt  \n  inflating: vietnamese/labels/gt_904.txt  \n  inflating: vietnamese/labels/gt_1104.txt  \n  inflating: vietnamese/labels/gt_268.txt  \n  inflating: vietnamese/labels/gt_1578.txt  \n  inflating: vietnamese/labels/gt_789.txt  \n  inflating: vietnamese/labels/gt_113.txt  \n  inflating: vietnamese/labels/gt_1106.txt  \n  inflating: vietnamese/labels/gt_1131.txt  \n  inflating: vietnamese/labels/gt_38.txt  \n  inflating: vietnamese/labels/gt_1255.txt  \n  inflating: vietnamese/labels/gt_1456.txt  \n  inflating: vietnamese/labels/gt_162.txt  \n  inflating: vietnamese/labels/gt_486.txt  \n  inflating: vietnamese/labels/gt_1212.txt  \n  inflating: vietnamese/labels/gt_928.txt  \n  inflating: vietnamese/labels/gt_1069.txt  \n  inflating: vietnamese/labels/gt_1425.txt  \n  inflating: vietnamese/labels/gt_1589.txt  \n  inflating: vietnamese/labels/gt_1496.txt  \n  inflating: vietnamese/labels/gt_977.txt  \n  inflating: vietnamese/labels/gt_1937.txt  \n  inflating: vietnamese/labels/gt_926.txt  \n  inflating: vietnamese/labels/gt_393.txt  \n  inflating: vietnamese/labels/gt_1421.txt  \n  inflating: vietnamese/labels/gt_183.txt  \n  inflating: vietnamese/labels/gt_916.txt  \n  inflating: vietnamese/labels/gt_542.txt  \n  inflating: vietnamese/labels/gt_867.txt  \n  inflating: vietnamese/labels/gt_1867.txt  \n  inflating: vietnamese/labels/gt_1393.txt  \n  inflating: vietnamese/labels/gt_1994.txt  \n  inflating: vietnamese/labels/gt_1424.txt  \n  inflating: vietnamese/labels/gt_1406.txt  \n  inflating: vietnamese/labels/gt_1429.txt  \n  inflating: vietnamese/labels/gt_210.txt  \n  inflating: vietnamese/labels/gt_879.txt  \n  inflating: vietnamese/labels/gt_765.txt  \n  inflating: vietnamese/labels/gt_1237.txt  \n  inflating: vietnamese/labels/gt_29.txt  \n  inflating: vietnamese/labels/gt_1014.txt  \n  inflating: vietnamese/labels/gt_1523.txt  \n  inflating: vietnamese/labels/gt_26.txt  \n  inflating: vietnamese/labels/gt_41.txt  \n  inflating: vietnamese/labels/gt_1241.txt  \n  inflating: vietnamese/labels/gt_546.txt  \n  inflating: vietnamese/labels/gt_567.txt  \n  inflating: vietnamese/labels/gt_1950.txt  \n  inflating: vietnamese/labels/gt_1896.txt  \n  inflating: vietnamese/labels/gt_1592.txt  \n  inflating: vietnamese/labels/gt_900.txt  \n  inflating: vietnamese/labels/gt_541.txt  \n  inflating: vietnamese/labels/gt_383.txt  \n  inflating: vietnamese/labels/gt_1501.txt  \n  inflating: vietnamese/labels/gt_160.txt  \n  inflating: vietnamese/labels/gt_1510.txt  \n  inflating: vietnamese/labels/gt_1554.txt  \n  inflating: vietnamese/labels/gt_306.txt  \n  inflating: vietnamese/labels/gt_1959.txt  \n  inflating: vietnamese/labels/gt_265.txt  \n  inflating: vietnamese/labels/gt_1737.txt  \n  inflating: vietnamese/labels/gt_1454.txt  \n  inflating: vietnamese/labels/gt_1581.txt  \n  inflating: vietnamese/labels/gt_1985.txt  \n  inflating: vietnamese/labels/gt_497.txt  \n  inflating: vietnamese/labels/gt_1640.txt  \n  inflating: vietnamese/labels/gt_535.txt  \n  inflating: vietnamese/labels/gt_290.txt  \n  inflating: vietnamese/labels/gt_1086.txt  \n  inflating: vietnamese/labels/gt_384.txt  \n  inflating: vietnamese/labels/gt_1388.txt  \n  inflating: vietnamese/labels/gt_553.txt  \n  inflating: vietnamese/labels/gt_1261.txt  \n  inflating: vietnamese/labels/gt_1380.txt  \n  inflating: vietnamese/labels/gt_112.txt  \n  inflating: vietnamese/labels/gt_687.txt  \n  inflating: vietnamese/labels/gt_1252.txt  \n  inflating: vietnamese/labels/gt_1141.txt  \n  inflating: vietnamese/labels/gt_1346.txt  \n  inflating: vietnamese/labels/gt_1112.txt  \n  inflating: vietnamese/labels/gt_617.txt  \n  inflating: vietnamese/labels/gt_562.txt  \n  inflating: vietnamese/labels/gt_55.txt  \n  inflating: vietnamese/labels/gt_1352.txt  \n  inflating: vietnamese/labels/gt_1326.txt  \n  inflating: vietnamese/labels/gt_1527.txt  \n  inflating: vietnamese/labels/gt_1064.txt  \n  inflating: vietnamese/labels/gt_707.txt  \n  inflating: vietnamese/labels/gt_758.txt  \n  inflating: vietnamese/labels/gt_42.txt  \n  inflating: vietnamese/labels/gt_78.txt  \n  inflating: vietnamese/labels/gt_1986.txt  \n  inflating: vietnamese/labels/gt_885.txt  \n  inflating: vietnamese/labels/gt_1277.txt  \n  inflating: vietnamese/labels/gt_99.txt  \n  inflating: vietnamese/labels/gt_566.txt  \n  inflating: vietnamese/labels/gt_1557.txt  \n  inflating: vietnamese/labels/gt_386.txt  \n  inflating: vietnamese/labels/gt_402.txt  \n  inflating: vietnamese/labels/gt_1218.txt  \n  inflating: vietnamese/labels/gt_790.txt  \n  inflating: vietnamese/labels/gt_1428.txt  \n  inflating: vietnamese/labels/gt_605.txt  \n  inflating: vietnamese/labels/gt_1050.txt  \n  inflating: vietnamese/labels/gt_615.txt  \n  inflating: vietnamese/labels/gt_878.txt  \n  inflating: vietnamese/labels/gt_307.txt  \n  inflating: vietnamese/labels/gt_905.txt  \n  inflating: vietnamese/labels/gt_1962.txt  \n  inflating: vietnamese/labels/gt_15.txt  \n  inflating: vietnamese/labels/gt_1692.txt  \n  inflating: vietnamese/labels/gt_870.txt  \n  inflating: vietnamese/labels/gt_1655.txt  \n  inflating: vietnamese/labels/gt_826.txt  \n  inflating: vietnamese/labels/gt_28.txt  \n  inflating: vietnamese/labels/gt_665.txt  \n  inflating: vietnamese/labels/gt_1624.txt  \n  inflating: vietnamese/labels/gt_1298.txt  \n  inflating: vietnamese/labels/gt_1386.txt  \n  inflating: vietnamese/labels/gt_599.txt  \n  inflating: vietnamese/labels/gt_109.txt  \n  inflating: vietnamese/labels/gt_1289.txt  \n  inflating: vietnamese/labels/gt_783.txt  \n  inflating: vietnamese/labels/gt_1707.txt  \n  inflating: vietnamese/labels/gt_868.txt  \n  inflating: vietnamese/labels/gt_319.txt  \n  inflating: vietnamese/labels/gt_292.txt  \n  inflating: vietnamese/labels/gt_959.txt  \n  inflating: vietnamese/labels/gt_1099.txt  \n  inflating: vietnamese/labels/gt_1597.txt  \n  inflating: vietnamese/labels/gt_1058.txt  \n  inflating: vietnamese/labels/gt_995.txt  \n  inflating: vietnamese/labels/gt_754.txt  \n  inflating: vietnamese/labels/gt_1654.txt  \n  inflating: vietnamese/labels/gt_1748.txt  \n  inflating: vietnamese/labels/gt_136.txt  \n  inflating: vietnamese/labels/gt_1313.txt  \n  inflating: vietnamese/labels/gt_1646.txt  \n  inflating: vietnamese/labels/gt_1623.txt  \n  inflating: vietnamese/labels/gt_561.txt  \n  inflating: vietnamese/labels/gt_1177.txt  \n  inflating: vietnamese/labels/gt_247.txt  \n  inflating: vietnamese/labels/gt_958.txt  \n  inflating: vietnamese/labels/gt_936.txt  \n  inflating: vietnamese/labels/gt_1174.txt  \n  inflating: vietnamese/labels/gt_356.txt  \n  inflating: vietnamese/labels/gt_358.txt  \n  inflating: vietnamese/labels/gt_1720.txt  \n  inflating: vietnamese/labels/gt_922.txt  \n  inflating: vietnamese/labels/gt_752.txt  \n  inflating: vietnamese/labels/gt_1509.txt  \n  inflating: vietnamese/labels/gt_1687.txt  \n  inflating: vietnamese/labels/gt_304.txt  \n  inflating: vietnamese/labels/gt_129.txt  \n  inflating: vietnamese/labels/gt_1101.txt  \n  inflating: vietnamese/labels/gt_126.txt  \n  inflating: vietnamese/labels/gt_1925.txt  \n  inflating: vietnamese/labels/gt_1181.txt  \n  inflating: vietnamese/labels/gt_514.txt  \n  inflating: vietnamese/labels/gt_1204.txt  \n  inflating: vietnamese/labels/gt_1847.txt  \n  inflating: vietnamese/labels/gt_629.txt  \n  inflating: vietnamese/labels/gt_1018.txt  \n  inflating: vietnamese/labels/gt_122.txt  \n  inflating: vietnamese/labels/gt_1818.txt  \n  inflating: vietnamese/labels/gt_1139.txt  \n  inflating: vietnamese/labels/gt_1180.txt  \n  inflating: vietnamese/labels/gt_672.txt  \n  inflating: vietnamese/labels/gt_987.txt  \n  inflating: vietnamese/labels/gt_47.txt  \n  inflating: vietnamese/labels/gt_1430.txt  \n  inflating: vietnamese/labels/gt_372.txt  \n  inflating: vietnamese/labels/gt_649.txt  \n  inflating: vietnamese/labels/gt_550.txt  \n  inflating: vietnamese/labels/gt_1846.txt  \n  inflating: vietnamese/labels/gt_1130.txt  \n  inflating: vietnamese/labels/gt_1676.txt  \n  inflating: vietnamese/labels/gt_25.txt  \n  inflating: vietnamese/labels/gt_2.txt  \n  inflating: vietnamese/labels/gt_1567.txt  \n  inflating: vietnamese/labels/gt_628.txt  \n  inflating: vietnamese/labels/gt_880.txt  \n  inflating: vietnamese/labels/gt_30.txt  \n  inflating: vietnamese/labels/gt_1998.txt  \n  inflating: vietnamese/labels/gt_1528.txt  \n  inflating: vietnamese/labels/gt_700.txt  \n  inflating: vietnamese/labels/gt_624.txt  \n  inflating: vietnamese/labels/gt_1722.txt  \n  inflating: vietnamese/labels/gt_312.txt  \n  inflating: vietnamese/labels/gt_403.txt  \n  inflating: vietnamese/labels/gt_1619.txt  \n  inflating: vietnamese/labels/gt_1304.txt  \n  inflating: vietnamese/labels/gt_469.txt  \n  inflating: vietnamese/labels/gt_641.txt  \n  inflating: vietnamese/labels/gt_827.txt  \n  inflating: vietnamese/labels/gt_494.txt  \n  inflating: vietnamese/labels/gt_834.txt  \n  inflating: vietnamese/labels/gt_1097.txt  \n  inflating: vietnamese/labels/gt_417.txt  \n  inflating: vietnamese/labels/gt_1503.txt  \n  inflating: vietnamese/labels/gt_180.txt  \n  inflating: vietnamese/labels/gt_920.txt  \n  inflating: vietnamese/labels/gt_1235.txt  \n  inflating: vietnamese/labels/gt_1027.txt  \n  inflating: vietnamese/labels/gt_777.txt  \n  inflating: vietnamese/labels/gt_1629.txt  \n  inflating: vietnamese/labels/gt_813.txt  \n  inflating: vietnamese/labels/gt_462.txt  \n  inflating: vietnamese/labels/gt_1443.txt  \n  inflating: vietnamese/labels/gt_455.txt  \n  inflating: vietnamese/labels/gt_1647.txt  \n  inflating: vietnamese/labels/gt_1791.txt  \n  inflating: vietnamese/labels/gt_190.txt  \n  inflating: vietnamese/labels/gt_156.txt  \n  inflating: vietnamese/labels/gt_854.txt  \n  inflating: vietnamese/labels/gt_526.txt  \n  inflating: vietnamese/labels/gt_394.txt  \n  inflating: vietnamese/labels/gt_956.txt  \n  inflating: vietnamese/labels/gt_182.txt  \n  inflating: vietnamese/labels/gt_809.txt  \n  inflating: vietnamese/labels/gt_381.txt  \n  inflating: vietnamese/labels/gt_611.txt  \n  inflating: vietnamese/labels/gt_1129.txt  \n  inflating: vietnamese/labels/gt_1339.txt  \n  inflating: vietnamese/labels/gt_1179.txt  \n  inflating: vietnamese/labels/gt_1799.txt  \n  inflating: vietnamese/labels/gt_1247.txt  \n  inflating: vietnamese/labels/gt_1360.txt  \n  inflating: vietnamese/labels/gt_929.txt  \n  inflating: vietnamese/labels/gt_1019.txt  \n  inflating: vietnamese/labels/gt_1723.txt  \n  inflating: vietnamese/labels/gt_684.txt  \n  inflating: vietnamese/labels/gt_84.txt  \n  inflating: vietnamese/labels/gt_1996.txt  \n  inflating: vietnamese/labels/gt_517.txt  \n  inflating: vietnamese/labels/gt_1143.txt  \n  inflating: vietnamese/labels/gt_848.txt  \n  inflating: vietnamese/labels/gt_971.txt  \n  inflating: vietnamese/labels/gt_19.txt  \n  inflating: vietnamese/labels/gt_1074.txt  \n  inflating: vietnamese/labels/gt_1366.txt  \n  inflating: vietnamese/labels/gt_1637.txt  \n  inflating: vietnamese/labels/gt_975.txt  \n  inflating: vietnamese/labels/gt_340.txt  \n  inflating: vietnamese/labels/gt_816.txt  \n  inflating: vietnamese/labels/gt_237.txt  \n  inflating: vietnamese/labels/gt_1643.txt  \n  inflating: vietnamese/labels/gt_698.txt  \n  inflating: vietnamese/labels/gt_1897.txt  \n  inflating: vietnamese/labels/gt_1934.txt  \n  inflating: vietnamese/labels/gt_670.txt  \n  inflating: vietnamese/labels/gt_1392.txt  \n  inflating: vietnamese/labels/gt_1282.txt  \n  inflating: vietnamese/labels/gt_1815.txt  \n  inflating: vietnamese/labels/gt_1351.txt  \n  inflating: vietnamese/labels/gt_579.txt  \n  inflating: vietnamese/labels/gt_1582.txt  \n  inflating: vietnamese/labels/gt_1750.txt  \n  inflating: vietnamese/labels/gt_490.txt  \n  inflating: vietnamese/labels/gt_119.txt  \n  inflating: vietnamese/labels/gt_458.txt  \n  inflating: vietnamese/labels/gt_1837.txt  \n  inflating: vietnamese/labels/gt_1201.txt  \n  inflating: vietnamese/labels/gt_1797.txt  \n  inflating: vietnamese/labels/gt_1383.txt  \n  inflating: vietnamese/labels/gt_232.txt  \n  inflating: vietnamese/labels/gt_1711.txt  \n  inflating: vietnamese/labels/gt_1552.txt  \n  inflating: vietnamese/labels/gt_1489.txt  \n  inflating: vietnamese/labels/gt_1976.txt  \n  inflating: vietnamese/labels/gt_212.txt  \n  inflating: vietnamese/labels/gt_1568.txt  \n  inflating: vietnamese/labels/gt_709.txt  \n  inflating: vietnamese/labels/gt_1641.txt  \n  inflating: vietnamese/labels/gt_196.txt  \n  inflating: vietnamese/labels/gt_673.txt  \n  inflating: vietnamese/labels/gt_800.txt  \n  inflating: vietnamese/labels/gt_146.txt  \n  inflating: vietnamese/labels/gt_650.txt  \n  inflating: vietnamese/labels/gt_207.txt  \n  inflating: vietnamese/labels/gt_197.txt  \n  inflating: vietnamese/labels/gt_1125.txt  \n  inflating: vietnamese/labels/gt_1803.txt  \n  inflating: vietnamese/labels/gt_352.txt  \n  inflating: vietnamese/labels/gt_785.txt  \n  inflating: vietnamese/labels/gt_139.txt  \n  inflating: vietnamese/labels/gt_1703.txt  \n  inflating: vietnamese/labels/gt_744.txt  \n  inflating: vietnamese/labels/gt_1324.txt  \n  inflating: vietnamese/labels/gt_1992.txt  \n  inflating: vietnamese/labels/gt_1784.txt  \n  inflating: vietnamese/labels/gt_258.txt  \n  inflating: vietnamese/labels/gt_861.txt  \n  inflating: vietnamese/labels/gt_664.txt  \n  inflating: vietnamese/labels/gt_994.txt  \n  inflating: vietnamese/labels/gt_1546.txt  \n  inflating: vietnamese/labels/gt_1314.txt  \n  inflating: vietnamese/labels/gt_1200.txt  \n  inflating: vietnamese/labels/gt_1954.txt  \n  inflating: vietnamese/labels/gt_935.txt  \n  inflating: vietnamese/labels/gt_1113.txt  \n  inflating: vietnamese/labels/gt_448.txt  \n  inflating: vietnamese/labels/gt_351.txt  \n  inflating: vietnamese/labels/gt_493.txt  \n  inflating: vietnamese/labels/gt_918.txt  \n  inflating: vietnamese/labels/gt_1944.txt  \n  inflating: vietnamese/labels/gt_1220.txt  \n  inflating: vietnamese/labels/gt_1941.txt  \n  inflating: vietnamese/labels/gt_178.txt  \n  inflating: vietnamese/labels/gt_779.txt  \n  inflating: vietnamese/labels/gt_311.txt  \n  inflating: vietnamese/labels/gt_1189.txt  \n  inflating: vietnamese/labels/gt_923.txt  \n  inflating: vietnamese/labels/gt_1583.txt  \n  inflating: vietnamese/labels/gt_396.txt  \n  inflating: vietnamese/labels/gt_1329.txt  \n  inflating: vietnamese/labels/gt_638.txt  \n  inflating: vietnamese/labels/gt_984.txt  \n  inflating: vietnamese/labels/gt_1638.txt  \n  inflating: vietnamese/labels/gt_300.txt  \n  inflating: vietnamese/labels/gt_1302.txt  \n  inflating: vietnamese/labels/gt_1598.txt  \n  inflating: vietnamese/labels/gt_1575.txt  \n  inflating: vietnamese/labels/gt_730.txt  \n  inflating: vietnamese/labels/gt_976.txt  \n  inflating: vietnamese/labels/gt_1780.txt  \n  inflating: vietnamese/labels/gt_1379.txt  \n  inflating: vietnamese/labels/gt_301.txt  \n  inflating: vietnamese/labels/gt_1063.txt  \n  inflating: vietnamese/labels/gt_152.txt  \n  inflating: vietnamese/labels/gt_1284.txt  \n  inflating: vietnamese/labels/gt_1367.txt  \n  inflating: vietnamese/labels/gt_702.txt  \n  inflating: vietnamese/labels/gt_1061.txt  \n  inflating: vietnamese/labels/gt_637.txt  \n  inflating: vietnamese/labels/gt_1436.txt  \n  inflating: vietnamese/labels/gt_760.txt  \n  inflating: vietnamese/labels/gt_787.txt  \n  inflating: vietnamese/labels/gt_770.txt  \n  inflating: vietnamese/labels/gt_354.txt  \n  inflating: vietnamese/labels/gt_1317.txt  \n  inflating: vietnamese/labels/gt_85.txt  \n  inflating: vietnamese/labels/gt_341.txt  \n  inflating: vietnamese/labels/gt_715.txt  \n  inflating: vietnamese/labels/gt_1983.txt  \n  inflating: vietnamese/labels/gt_1909.txt  \n  inflating: vietnamese/labels/gt_1793.txt  \n  inflating: vietnamese/labels/gt_400.txt  \n  inflating: vietnamese/labels/gt_1213.txt  \n  inflating: vietnamese/labels/gt_945.txt  \n  inflating: vietnamese/labels/gt_1677.txt  \n  inflating: vietnamese/labels/gt_1474.txt  \n  inflating: vietnamese/labels/gt_62.txt  \n  inflating: vietnamese/labels/gt_1260.txt  \n  inflating: vietnamese/labels/gt_1281.txt  \n  inflating: vietnamese/labels/gt_433.txt  \n  inflating: vietnamese/labels/gt_321.txt  \n  inflating: vietnamese/labels/gt_51.txt  \n  inflating: vietnamese/labels/gt_1688.txt  \n  inflating: vietnamese/labels/gt_747.txt  \n  inflating: vietnamese/labels/gt_1244.txt  \n  inflating: vietnamese/labels/gt_86.txt  \n  inflating: vietnamese/labels/gt_479.txt  \n  inflating: vietnamese/labels/gt_804.txt  \n  inflating: vietnamese/labels/gt_1375.txt  \n  inflating: vietnamese/labels/gt_750.txt  \n  inflating: vietnamese/labels/gt_1931.txt  \n  inflating: vietnamese/labels/gt_1115.txt  \n  inflating: vietnamese/labels/gt_654.txt  \n  inflating: vietnamese/labels/gt_519.txt  \n  inflating: vietnamese/labels/gt_1924.txt  \n  inflating: vietnamese/labels/gt_1820.txt  \n  inflating: vietnamese/labels/gt_48.txt  \n  inflating: vietnamese/labels/gt_980.txt  \n  inflating: vietnamese/labels/gt_668.txt  \n  inflating: vietnamese/labels/gt_1610.txt  \n  inflating: vietnamese/labels/gt_1039.txt  \n  inflating: vietnamese/labels/gt_1185.txt  \n  inflating: vietnamese/labels/gt_380.txt  \n  inflating: vietnamese/labels/gt_731.txt  \n  inflating: vietnamese/labels/gt_903.txt  \n  inflating: vietnamese/labels/gt_1404.txt  \n  inflating: vietnamese/labels/gt_592.txt  \n  inflating: vietnamese/labels/gt_333.txt  \n  inflating: vietnamese/labels/gt_594.txt  \n  inflating: vietnamese/labels/gt_310.txt  \n  inflating: vietnamese/labels/gt_1287.txt  \n  inflating: vietnamese/labels/gt_1035.txt  \n  inflating: vietnamese/labels/gt_1412.txt  \n  inflating: vietnamese/labels/gt_1843.txt  \n  inflating: vietnamese/labels/gt_1795.txt  \n  inflating: vietnamese/labels/gt_1034.txt  \n  inflating: vietnamese/labels/gt_696.txt  \n  inflating: vietnamese/labels/gt_1134.txt  \n  inflating: vietnamese/labels/gt_814.txt  \n  inflating: vietnamese/labels/gt_1884.txt  \n  inflating: vietnamese/labels/gt_1604.txt  \n  inflating: vietnamese/labels/gt_348.txt  \n  inflating: vietnamese/labels/gt_1513.txt  \n  inflating: vietnamese/labels/gt_150.txt  \n  inflating: vietnamese/labels/gt_1344.txt  \n  inflating: vietnamese/labels/gt_91.txt  \n  inflating: vietnamese/labels/gt_1915.txt  \n  inflating: vietnamese/labels/gt_316.txt  \n  inflating: vietnamese/labels/gt_1011.txt  \n  inflating: vietnamese/labels/gt_1522.txt  \n  inflating: vietnamese/labels/gt_195.txt  \n  inflating: vietnamese/labels/gt_377.txt  \n  inflating: vietnamese/labels/gt_1151.txt  \n  inflating: vietnamese/labels/gt_892.txt  \n  inflating: vietnamese/labels/gt_1767.txt  \n  inflating: vietnamese/labels/gt_1553.txt  \n  inflating: vietnamese/labels/gt_1175.txt  \n  inflating: vietnamese/labels/gt_1771.txt  \n  inflating: vietnamese/labels/gt_1502.txt  \n  inflating: vietnamese/labels/gt_1913.txt  \n  inflating: vietnamese/labels/gt_231.txt  \n  inflating: vietnamese/labels/gt_658.txt  \n  inflating: vietnamese/labels/gt_1735.txt  \n  inflating: vietnamese/labels/gt_1770.txt  \n  inflating: vietnamese/labels/gt_1457.txt  \n  inflating: vietnamese/labels/gt_1221.txt  \n  inflating: vietnamese/labels/gt_1187.txt  \n  inflating: vietnamese/labels/gt_552.txt  \n  inflating: vietnamese/labels/gt_1609.txt  \n  inflating: vietnamese/labels/gt_206.txt  \n  inflating: vietnamese/labels/gt_269.txt  \n  inflating: vietnamese/labels/gt_1595.txt  \n  inflating: vietnamese/labels/gt_1152.txt  \n  inflating: vietnamese/labels/gt_123.txt  \n  inflating: vietnamese/labels/gt_1364.txt  \n  inflating: vietnamese/labels/gt_270.txt  \n  inflating: vietnamese/labels/gt_768.txt  \n  inflating: vietnamese/labels/gt_93.txt  \n  inflating: vietnamese/labels/gt_825.txt  \n  inflating: vietnamese/labels/gt_1612.txt  \n  inflating: vietnamese/labels/gt_973.txt  \n  inflating: vietnamese/labels/gt_832.txt  \n  inflating: vietnamese/labels/gt_1714.txt  \n  inflating: vietnamese/labels/gt_576.txt  \n  inflating: vietnamese/labels/gt_1140.txt  \n  inflating: vietnamese/labels/gt_1698.txt  \n  inflating: vietnamese/labels/gt_1563.txt  \n  inflating: vietnamese/labels/gt_34.txt  \n  inflating: vietnamese/labels/gt_1037.txt  \n  inflating: vietnamese/labels/gt_1984.txt  \n  inflating: vietnamese/labels/gt_445.txt  \n  inflating: vietnamese/labels/gt_8.txt  \n  inflating: vietnamese/labels/gt_1603.txt  \n  inflating: vietnamese/labels/gt_749.txt  \n  inflating: vietnamese/labels/gt_1710.txt  \n  inflating: vietnamese/labels/gt_1732.txt  \n  inflating: vietnamese/labels/gt_1226.txt  \n  inflating: vietnamese/labels/gt_1642.txt  \n  inflating: vietnamese/labels/gt_631.txt  \n  inflating: vietnamese/labels/gt_1165.txt  \n  inflating: vietnamese/labels/gt_94.txt  \n  inflating: vietnamese/labels/gt_1274.txt  \n  inflating: vietnamese/labels/gt_438.txt  \n  inflating: vietnamese/labels/gt_806.txt  \n  inflating: vietnamese/labels/gt_1813.txt  \n  inflating: vietnamese/labels/gt_1368.txt  \n  inflating: vietnamese/labels/gt_1310.txt  \n  inflating: vietnamese/labels/gt_1808.txt  \n  inflating: vietnamese/labels/gt_66.txt  \n  inflating: vietnamese/labels/gt_1012.txt  \n  inflating: vietnamese/labels/gt_1745.txt  \n  inflating: vietnamese/labels/gt_678.txt  \n  inflating: vietnamese/labels/gt_236.txt  \n  inflating: vietnamese/labels/gt_176.txt  \n  inflating: vietnamese/labels/gt_1278.txt  \n  inflating: vietnamese/labels/gt_860.txt  \n  inflating: vietnamese/labels/gt_1460.txt  \n  inflating: vietnamese/labels/gt_518.txt  \n  inflating: vietnamese/labels/gt_1504.txt  \n  inflating: vietnamese/labels/gt_105.txt  \n  inflating: vietnamese/labels/gt_1211.txt  \n  inflating: vietnamese/labels/gt_810.txt  \n  inflating: vietnamese/labels/gt_791.txt  \n  inflating: vietnamese/labels/gt_1860.txt  \n  inflating: vietnamese/labels/gt_1085.txt  \n  inflating: vietnamese/labels/gt_999.txt  \n  inflating: vietnamese/labels/gt_334.txt  \n  inflating: vietnamese/labels/gt_1192.txt  \n  inflating: vietnamese/labels/gt_636.txt  \n  inflating: vietnamese/labels/gt_1853.txt  \n  inflating: vietnamese/labels/gt_963.txt  \n  inflating: vietnamese/labels/gt_961.txt  \n  inflating: vietnamese/labels/gt_598.txt  \n  inflating: vietnamese/labels/gt_313.txt  \n  inflating: vietnamese/labels/gt_155.txt  \n  inflating: vietnamese/labels/gt_281.txt  \n  inflating: vietnamese/labels/gt_704.txt  \n  inflating: vietnamese/labels/gt_324.txt  \n  inflating: vietnamese/labels/gt_591.txt  \n  inflating: vietnamese/labels/gt_573.txt  \n  inflating: vietnamese/labels/gt_587.txt  \n  inflating: vietnamese/labels/gt_496.txt  \n  inflating: vietnamese/labels/gt_657.txt  \n  inflating: vietnamese/labels/gt_1208.txt  \n  inflating: vietnamese/labels/gt_1091.txt  \n  inflating: vietnamese/labels/gt_1848.txt  \n  inflating: vietnamese/labels/gt_840.txt  \n  inflating: vietnamese/labels/gt_1411.txt  \n  inflating: vietnamese/labels/gt_1359.txt  \n  inflating: vietnamese/labels/gt_1042.txt  \n  inflating: vietnamese/labels/gt_1371.txt  \n  inflating: vietnamese/labels/gt_1291.txt  \n  inflating: vietnamese/labels/gt_500.txt  \n  inflating: vietnamese/labels/gt_1223.txt  \n  inflating: vietnamese/labels/gt_1033.txt  \n  inflating: vietnamese/labels/gt_309.txt  \n  inflating: vietnamese/labels/gt_915.txt  \n  inflating: vietnamese/labels/gt_1410.txt  \n  inflating: vietnamese/labels/gt_1667.txt  \n  inflating: vietnamese/labels/gt_1620.txt  \n  inflating: vietnamese/labels/gt_1465.txt  \n  inflating: vietnamese/labels/gt_1473.txt  \n  inflating: vietnamese/labels/gt_1243.txt  \n  inflating: vietnamese/labels/gt_329.txt  \n  inflating: vietnamese/labels/gt_31.txt  \n  inflating: vietnamese/labels/gt_675.txt  \n  inflating: vietnamese/labels/gt_812.txt  \n  inflating: vietnamese/labels/gt_257.txt  \n  inflating: vietnamese/labels/gt_1881.txt  \n  inflating: vietnamese/labels/gt_1081.txt  \n  inflating: vietnamese/labels/gt_191.txt  \n  inflating: vietnamese/labels/gt_727.txt  \n  inflating: vietnamese/labels/gt_1100.txt  \n  inflating: vietnamese/labels/gt_846.txt  \n  inflating: vietnamese/labels/gt_901.txt  \n  inflating: vietnamese/labels/gt_837.txt  \n  inflating: vietnamese/labels/gt_226.txt  \n  inflating: vietnamese/labels/gt_914.txt  \n  inflating: vietnamese/labels/gt_734.txt  \n  inflating: vietnamese/labels/gt_144.txt  \n  inflating: vietnamese/labels/gt_1123.txt  \n  inflating: vietnamese/labels/gt_1267.txt  \n  inflating: vietnamese/labels/gt_851.txt  \n  inflating: vietnamese/labels/gt_1028.txt  \n  inflating: vietnamese/labels/gt_1332.txt  \n  inflating: vietnamese/labels/gt_363.txt  \n  inflating: vietnamese/labels/gt_49.txt  \n  inflating: vietnamese/labels/gt_1530.txt  \n  inflating: vietnamese/labels/gt_96.txt  \n  inflating: vietnamese/labels/gt_1246.txt  \n  inflating: vietnamese/labels/gt_1995.txt  \n  inflating: vietnamese/labels/gt_729.txt  \n  inflating: vietnamese/labels/gt_1712.txt  \n  inflating: vietnamese/labels/gt_1852.txt  \n  inflating: vietnamese/labels/gt_1526.txt  \n  inflating: vietnamese/labels/gt_618.txt  \n  inflating: vietnamese/labels/gt_1691.txt  \n  inflating: vietnamese/labels/gt_291.txt  \n  inflating: vietnamese/labels/gt_1087.txt  \n  inflating: vietnamese/labels/gt_43.txt  \n  inflating: vietnamese/labels/gt_1807.txt  \n  inflating: vietnamese/labels/gt_1922.txt  \n  inflating: vietnamese/labels/gt_163.txt  \n  inflating: vietnamese/labels/gt_276.txt  \n  inflating: vietnamese/labels/gt_1341.txt  \n  inflating: vietnamese/labels/gt_767.txt  \n  inflating: vietnamese/labels/gt_1057.txt  \n  inflating: vietnamese/labels/gt_1259.txt  \n  inflating: vietnamese/labels/gt_570.txt  \n  inflating: vietnamese/labels/gt_1728.txt  \n  inflating: vietnamese/labels/gt_1413.txt  \n  inflating: vietnamese/labels/gt_11.txt  \n  inflating: vietnamese/labels/gt_9.txt  \n  inflating: vietnamese/labels/gt_751.txt  \n  inflating: vietnamese/labels/gt_349.txt  \n  inflating: vietnamese/labels/gt_883.txt  \n  inflating: vietnamese/labels/gt_1082.txt  \n  inflating: vietnamese/labels/gt_184.txt  \n  inflating: vietnamese/labels/gt_147.txt  \n  inflating: vietnamese/labels/gt_899.txt  \n  inflating: vietnamese/labels/gt_17.txt  \n  inflating: vietnamese/labels/gt_1736.txt  \n  inflating: vietnamese/labels/gt_1186.txt  \n  inflating: vietnamese/labels/gt_1451.txt  \n  inflating: vietnamese/labels/gt_950.txt  \n  inflating: vietnamese/labels/gt_1309.txt  \n  inflating: vietnamese/labels/gt_476.txt  \n  inflating: vietnamese/labels/gt_706.txt  \n  inflating: vietnamese/labels/gt_876.txt  \n  inflating: vietnamese/labels/gt_1053.txt  \n  inflating: vietnamese/labels/gt_1147.txt  \n  inflating: vietnamese/labels/gt_460.txt  \n  inflating: vietnamese/labels/gt_1824.txt  \n  inflating: vietnamese/labels/gt_1023.txt  \n  inflating: vietnamese/labels/gt_3.txt  \n  inflating: vietnamese/labels/gt_898.txt  \n  inflating: vietnamese/labels/gt_272.txt  \n  inflating: vietnamese/labels/gt_1494.txt  \n  inflating: vietnamese/labels/gt_1683.txt  \n  inflating: vietnamese/labels/gt_1400.txt  \n  inflating: vietnamese/labels/gt_1321.txt  \n  inflating: vietnamese/labels/gt_748.txt  \n  inflating: vietnamese/labels/gt_1354.txt  \n  inflating: vietnamese/labels/gt_1608.txt  \n  inflating: vietnamese/labels/gt_20.txt  \n  inflating: vietnamese/labels/gt_273.txt  \n  inflating: vietnamese/labels/gt_1550.txt  \n  inflating: vietnamese/labels/gt_98.txt  \n  inflating: vietnamese/labels/gt_277.txt  \n  inflating: vietnamese/labels/gt_1902.txt  \n  inflating: vietnamese/labels/gt_1537.txt  \n  inflating: vietnamese/labels/gt_953.txt  \n  inflating: vietnamese/labels/gt_656.txt  \n  inflating: vietnamese/labels/gt_1943.txt  \n  inflating: vietnamese/labels/gt_1232.txt  \n  inflating: vietnamese/labels/gt_1664.txt  \n  inflating: vietnamese/labels/gt_466.txt  \n  inflating: vietnamese/labels/gt_1666.txt  \n  inflating: vietnamese/labels/gt_1453.txt  \n  inflating: vietnamese/labels/gt_925.txt  \n  inflating: vietnamese/labels/gt_836.txt  \n  inflating: vietnamese/labels/gt_1972.txt  \n  inflating: vietnamese/labels/gt_647.txt  \n  inflating: vietnamese/labels/gt_510.txt  \n  inflating: vietnamese/labels/gt_1484.txt  \n  inflating: vietnamese/labels/gt_1929.txt  \n  inflating: vietnamese/labels/gt_159.txt  \n  inflating: vietnamese/labels/gt_16.txt  \n  inflating: vietnamese/labels/gt_238.txt  \n  inflating: vietnamese/labels/gt_808.txt  \n  inflating: vietnamese/labels/gt_65.txt  \n  inflating: vietnamese/labels/gt_986.txt  \n  inflating: vietnamese/labels/gt_538.txt  \n  inflating: vietnamese/labels/gt_1148.txt  \n  inflating: vietnamese/labels/gt_422.txt  \n  inflating: vietnamese/labels/gt_106.txt  \n  inflating: vietnamese/labels/gt_13.txt  \n  inflating: vietnamese/labels/gt_864.txt  \n  inflating: vietnamese/labels/gt_897.txt  \n  inflating: vietnamese/labels/gt_347.txt  \n  inflating: vietnamese/labels/gt_612.txt  \n  inflating: vietnamese/labels/gt_498.txt  \n  inflating: vietnamese/labels/gt_577.txt  \n  inflating: vietnamese/labels/gt_585.txt  \n  inflating: vietnamese/labels/gt_823.txt  \n  inflating: vietnamese/labels/gt_1713.txt  \n  inflating: vietnamese/labels/gt_1680.txt  \n  inflating: vietnamese/labels/gt_67.txt  \n  inflating: vietnamese/labels/gt_72.txt  \n  inflating: vietnamese/labels/gt_1275.txt  \n  inflating: vietnamese/labels/gt_1311.txt  \n  inflating: vietnamese/labels/gt_1777.txt  \n  inflating: vietnamese/labels/gt_1873.txt  \n  inflating: vietnamese/labels/gt_695.txt  \n  inflating: vietnamese/labels/gt_1947.txt  \n  inflating: vietnamese/labels/gt_547.txt  \n  inflating: vietnamese/labels/gt_811.txt  \n  inflating: vietnamese/labels/gt_411.txt  \n  inflating: vietnamese/labels/gt_933.txt  \n  inflating: vietnamese/labels/gt_1127.txt  \n  inflating: vietnamese/labels/gt_1036.txt  \n  inflating: vietnamese/labels/gt_1242.txt  \n  inflating: vietnamese/labels/gt_991.txt  \n  inflating: vietnamese/labels/gt_1927.txt  \n  inflating: vietnamese/labels/gt_1763.txt  \n  inflating: vietnamese/labels/gt_1403.txt  \n  inflating: vietnamese/labels/gt_1819.txt  \n  inflating: vietnamese/labels/gt_1195.txt  \n  inflating: vietnamese/labels/gt_1215.txt  \n  inflating: vietnamese/labels/gt_1468.txt  \n  inflating: vietnamese/labels/gt_242.txt  \n  inflating: vietnamese/labels/gt_1662.txt  \n  inflating: vietnamese/labels/gt_516.txt  \n  inflating: vietnamese/labels/gt_1135.txt  \n  inflating: vietnamese/labels/gt_1466.txt  \n  inflating: vietnamese/labels/gt_75.txt  \n  inflating: vietnamese/labels/gt_859.txt  \n  inflating: vietnamese/labels/gt_1894.txt  \n  inflating: vietnamese/labels/gt_1946.txt  \n  inflating: vietnamese/labels/gt_179.txt  \n  inflating: vietnamese/labels/gt_39.txt  \n  inflating: vietnamese/labels/gt_188.txt  \n  inflating: vietnamese/labels/gt_1499.txt  \n  inflating: vietnamese/labels/gt_430.txt  \n  inflating: vietnamese/labels/gt_1439.txt  \n  inflating: vietnamese/labels/gt_1357.txt  \n  inflating: vietnamese/labels/gt_1584.txt  \n  inflating: vietnamese/labels/gt_586.txt  \n  inflating: vietnamese/labels/gt_893.txt  \n  inflating: vietnamese/labels/gt_371.txt  \n  inflating: vietnamese/labels/gt_1907.txt  \n  inflating: vietnamese/labels/gt_992.txt  \n  inflating: vietnamese/labels/gt_1003.txt  \n  inflating: vietnamese/labels/gt_847.txt  \n  inflating: vietnamese/labels/gt_1851.txt  \n  inflating: vietnamese/labels/gt_491.txt  \n  inflating: vietnamese/labels/gt_1257.txt  \n  inflating: vietnamese/labels/gt_1519.txt  \n  inflating: vietnamese/labels/gt_315.txt  \n  inflating: vietnamese/labels/gt_766.txt  \n  inflating: vietnamese/labels/gt_1908.txt  \n  inflating: vietnamese/labels/gt_173.txt  \n  inflating: vietnamese/labels/gt_134.txt  \n  inflating: vietnamese/labels/gt_382.txt  \n  inflating: vietnamese/labels/gt_1323.txt  \n  inflating: vietnamese/labels/gt_332.txt  \n  inflating: vietnamese/labels/gt_289.txt  \n  inflating: vietnamese/labels/gt_320.txt  \n  inflating: vietnamese/labels/gt_1427.txt  \n  inflating: vietnamese/labels/gt_64.txt  \n  inflating: vietnamese/labels/gt_7.txt  \n  inflating: vietnamese/labels/gt_989.txt  \n  inflating: vietnamese/labels/gt_1089.txt  \n  inflating: vietnamese/labels/gt_1498.txt  \n  inflating: vietnamese/labels/gt_221.txt  \n  inflating: vietnamese/labels/gt_1350.txt  \n  inflating: vietnamese/labels/gt_1542.txt  \n  inflating: vietnamese/labels/gt_472.txt  \n  inflating: vietnamese/labels/gt_1358.txt  \n  inflating: vietnamese/labels/gt_481.txt  \n  inflating: vietnamese/labels/gt_1095.txt  \n  inflating: vietnamese/labels/gt_1825.txt  \n  inflating: vietnamese/labels/gt_297.txt  \n  inflating: vietnamese/labels/gt_964.txt  \n  inflating: vietnamese/labels/gt_1445.txt  \n  inflating: vietnamese/labels/gt_35.txt  \n  inflating: vietnamese/labels/gt_593.txt  \n  inflating: vietnamese/labels/gt_557.txt  \n  inflating: vietnamese/labels/gt_454.txt  \n  inflating: vietnamese/labels/gt_857.txt  \n  inflating: vietnamese/labels/gt_1796.txt  \n  inflating: vietnamese/labels/gt_544.txt  \n  inflating: vietnamese/labels/gt_1988.txt  \n  inflating: vietnamese/labels/gt_1614.txt  \n  inflating: vietnamese/labels/gt_966.txt  \n  inflating: vietnamese/labels/gt_1356.txt  \n  inflating: vietnamese/labels/gt_364.txt  \n  inflating: vietnamese/labels/gt_1792.txt  \n  inflating: vietnamese/labels/gt_663.txt  \n  inflating: vietnamese/labels/gt_962.txt  \n  inflating: vietnamese/labels/gt_563.txt  \n  inflating: vietnamese/labels/gt_1073.txt  \n  inflating: vietnamese/labels/gt_606.txt  \n  inflating: vietnamese/labels/gt_120.txt  \n  inflating: vietnamese/labels/gt_1705.txt  \n  inflating: vietnamese/labels/gt_1098.txt  \n  inflating: vietnamese/labels/gt_436.txt  \n  inflating: vietnamese/labels/gt_1382.txt  \n  inflating: vietnamese/labels/gt_884.txt  \n  inflating: vietnamese/labels/gt_1190.txt  \n  inflating: vietnamese/labels/gt_1991.txt  \n  inflating: vietnamese/labels/gt_746.txt  \n  inflating: vietnamese/labels/gt_682.txt  \n  inflating: vietnamese/labels/gt_1447.txt  \n  inflating: vietnamese/labels/gt_705.txt  \n  inflating: vietnamese/labels/gt_1077.txt  \n  inflating: vietnamese/labels/gt_1423.txt  \n  inflating: vietnamese/labels/gt_154.txt  \n  inflating: vietnamese/labels/gt_61.txt  \n  inflating: vietnamese/labels/gt_1361.txt  \n  inflating: vietnamese/labels/gt_404.txt  \n  inflating: vietnamese/labels/gt_410.txt  \n  inflating: vietnamese/labels/gt_1452.txt  \n  inflating: vietnamese/labels/gt_1048.txt  \n  inflating: vietnamese/labels/gt_1762.txt  \n  inflating: vietnamese/labels/gt_54.txt  \n  inflating: vietnamese/labels/gt_1133.txt  \n  inflating: vietnamese/labels/gt_940.txt  \n  inflating: vietnamese/labels/gt_894.txt  \n  inflating: vietnamese/labels/gt_1573.txt  \n  inflating: vietnamese/labels/gt_1678.txt  \n  inflating: vietnamese/labels/gt_1238.txt  \n  inflating: vietnamese/labels/gt_201.txt  \n  inflating: vietnamese/labels/gt_198.txt  \n  inflating: vietnamese/labels/gt_92.txt  \n  inflating: vietnamese/labels/gt_1167.txt  \n  inflating: vietnamese/labels/gt_988.txt  \n  inflating: vietnamese/labels/gt_1827.txt  \n  inflating: vietnamese/labels/gt_1540.txt  \n  inflating: vietnamese/labels/gt_1299.txt  \n  inflating: vietnamese/labels/gt_515.txt  \n  inflating: vietnamese/labels/gt_919.txt  \n  inflating: vietnamese/labels/gt_625.txt  \n  inflating: vietnamese/labels/gt_1529.txt  \n  inflating: vietnamese/labels/gt_323.txt  \n  inflating: vietnamese/labels/gt_1868.txt  \n  inflating: vietnamese/labels/gt_118.txt  \n  inflating: vietnamese/labels/gt_1911.txt  \n  inflating: vietnamese/labels/gt_974.txt  \n  inflating: vietnamese/labels/gt_1362.txt  \n  inflating: vietnamese/labels/gt_229.txt  \n  inflating: vietnamese/labels/gt_1418.txt  \n  inflating: vietnamese/labels/gt_1159.txt  \n  inflating: vietnamese/labels/gt_954.txt  \n  inflating: vietnamese/labels/gt_1663.txt  \n  inflating: vietnamese/labels/gt_1349.txt  \n  inflating: vietnamese/labels/gt_554.txt  \n  inflating: vietnamese/labels/gt_955.txt  \n  inflating: vietnamese/labels/gt_1049.txt  \n  inflating: vietnamese/labels/gt_1661.txt  \n  inflating: vietnamese/labels/gt_1951.txt  \n  inflating: vietnamese/labels/gt_520.txt  \n  inflating: vietnamese/labels/gt_1490.txt  \n  inflating: vietnamese/labels/gt_1176.txt  \n  inflating: vietnamese/labels/gt_556.txt  \n  inflating: vietnamese/labels/gt_1307.txt  \n  inflating: vietnamese/labels/gt_508.txt  \n  inflating: vietnamese/labels/gt_1485.txt  \n  inflating: vietnamese/labels/gt_796.txt  \n  inflating: vietnamese/labels/gt_797.txt  \n  inflating: vietnamese/labels/gt_627.txt  \n  inflating: vietnamese/labels/gt_1761.txt  \n  inflating: vietnamese/labels/gt_1821.txt  \n  inflating: vietnamese/labels/gt_683.txt  \n  inflating: vietnamese/labels/gt_584.txt  \n  inflating: vietnamese/labels/gt_1669.txt  \n  inflating: vietnamese/labels/gt_293.txt  \n  inflating: vietnamese/labels/gt_1854.txt  \n  inflating: vietnamese/labels/gt_241.txt  \n  inflating: vietnamese/labels/gt_820.txt  \n  inflating: vietnamese/labels/gt_1993.txt  \n  inflating: vietnamese/labels/gt_732.txt  \n  inflating: vietnamese/labels/gt_780.txt  \n  inflating: vietnamese/labels/gt_1397.txt  \n  inflating: vietnamese/labels/gt_1990.txt  \n  inflating: vietnamese/labels/gt_259.txt  \n  inflating: vietnamese/labels/gt_135.txt  \n  inflating: vietnamese/labels/gt_1118.txt  \n  inflating: vietnamese/labels/gt_1779.txt  \n  inflating: vietnamese/labels/gt_1817.txt  \n  inflating: vietnamese/labels/gt_1264.txt  \n  inflating: vietnamese/labels/gt_1659.txt  \n  inflating: vietnamese/labels/gt_1288.txt  \n  inflating: vietnamese/labels/gt_483.txt  \n  inflating: vietnamese/labels/gt_1845.txt  \n  inflating: vietnamese/labels/gt_865.txt  \n  inflating: vietnamese/labels/gt_387.txt  \n  inflating: vietnamese/labels/gt_1320.txt  \n  inflating: vietnamese/labels/gt_1512.txt  \n  inflating: vietnamese/labels/gt_299.txt  \n  inflating: vietnamese/labels/gt_1240.txt  \n  inflating: vietnamese/labels/gt_296.txt  \n  inflating: vietnamese/labels/gt_1921.txt  \n  inflating: vietnamese/labels/gt_488.txt  \n  inflating: vietnamese/labels/gt_1561.txt  \n  inflating: vietnamese/labels/gt_1781.txt  \n  inflating: vietnamese/labels/gt_1900.txt  \n  inflating: vietnamese/labels/gt_957.txt  \n  inflating: vietnamese/labels/gt_391.txt  \n  inflating: vietnamese/labels/gt_1828.txt  \n  inflating: vietnamese/labels/gt_1290.txt  \n  inflating: vietnamese/labels/gt_1749.txt  \n  inflating: vietnamese/labels/gt_1265.txt  \n  inflating: vietnamese/labels/gt_239.txt  \n  inflating: vietnamese/labels/gt_337.txt  \n  inflating: vietnamese/labels/gt_1742.txt  \n  inflating: vietnamese/labels/gt_1888.txt  \n  inflating: vietnamese/labels/gt_1191.txt  \n  inflating: vietnamese/labels/gt_1739.txt  \n  inflating: vietnamese/labels/gt_1743.txt  \n  inflating: vietnamese/labels/gt_1444.txt  \n  inflating: vietnamese/labels/gt_648.txt  \n  inflating: vietnamese/labels/gt_482.txt  \n  inflating: vietnamese/labels/gt_539.txt  \n  inflating: vietnamese/labels/gt_1363.txt  \n  inflating: vietnamese/labels/gt_1746.txt  \n  inflating: vietnamese/labels/gt_560.txt  \n  inflating: vietnamese/labels/gt_818.txt  \n  inflating: vietnamese/labels/gt_254.txt  \n  inflating: vietnamese/labels/gt_1040.txt  \n  inflating: vietnamese/labels/gt_574.txt  \n  inflating: vietnamese/labels/gt_1701.txt  \n  inflating: vietnamese/labels/gt_489.txt  \n  inflating: vietnamese/labels/gt_888.txt  \n  inflating: vietnamese/labels/gt_487.txt  \n  inflating: vietnamese/labels/gt_45.txt  \n  inflating: vietnamese/labels/gt_1805.txt  \n  inflating: vietnamese/labels/gt_1146.txt  \n  inflating: vietnamese/labels/gt_506.txt  \n  inflating: vietnamese/labels/gt_671.txt  \n  inflating: vietnamese/labels/gt_1209.txt  \n  inflating: vietnamese/labels/gt_1918.txt  \n  inflating: vietnamese/labels/gt_889.txt  \n  inflating: vietnamese/labels/gt_869.txt  \n  inflating: vietnamese/labels/gt_142.txt  \n  inflating: vietnamese/labels/gt_1334.txt  \n  inflating: vietnamese/labels/gt_1890.txt  \n  inflating: vietnamese/labels/gt_369.txt  \n  inflating: vietnamese/labels/gt_459.txt  \n  inflating: vietnamese/labels/gt_280.txt  \n  inflating: vietnamese/labels/gt_470.txt  \n  inflating: vietnamese/labels/gt_170.txt  \n  inflating: vietnamese/labels/gt_795.txt  \n  inflating: vietnamese/labels/gt_441.txt  \n  inflating: vietnamese/labels/gt_1336.txt  \n  inflating: vietnamese/labels/gt_1576.txt  \n  inflating: vietnamese/labels/gt_1043.txt  \n  inflating: vietnamese/labels/gt_1517.txt  \n  inflating: vietnamese/labels/gt_1416.txt  \n  inflating: vietnamese/labels/gt_531.txt  \n  inflating: vietnamese/labels/gt_572.txt  \n  inflating: vietnamese/labels/gt_1790.txt  \n  inflating: vietnamese/labels/gt_1753.txt  \n  inflating: vietnamese/labels/gt_1004.txt  \n  inflating: vietnamese/labels/gt_1488.txt  \n  inflating: vietnamese/labels/gt_401.txt  \n  inflating: vietnamese/labels/gt_559.txt  \n  inflating: vietnamese/labels/gt_1665.txt  \n  inflating: vietnamese/labels/gt_1840.txt  \n  inflating: vietnamese/labels/gt_1973.txt  \n  inflating: vietnamese/labels/gt_1188.txt  \n  inflating: vietnamese/labels/gt_317.txt  \n  inflating: vietnamese/labels/gt_1535.txt  \n  inflating: vietnamese/labels/gt_525.txt  \n  inflating: vietnamese/labels/gt_1051.txt  \n  inflating: vietnamese/labels/gt_1263.txt  \n  inflating: vietnamese/labels/gt_614.txt  \n  inflating: vietnamese/labels/gt_1565.txt  \n  inflating: vietnamese/labels/gt_322.txt  \n  inflating: vietnamese/labels/gt_786.txt  \n  inflating: vietnamese/labels/gt_415.txt  \n  inflating: vietnamese/labels/gt_1580.txt  \n  inflating: vietnamese/labels/gt_1889.txt  \n  inflating: vietnamese/labels/gt_1431.txt  \n  inflating: vietnamese/labels/gt_243.txt  \n  inflating: vietnamese/labels/gt_375.txt  \n  inflating: vietnamese/labels/gt_69.txt  \n  inflating: vietnamese/labels/gt_1497.txt  \n  inflating: vietnamese/labels/gt_1668.txt  \n  inflating: vietnamese/labels/gt_428.txt  \n  inflating: vietnamese/labels/gt_1029.txt  \n  inflating: vietnamese/labels/gt_507.txt  \n  inflating: vietnamese/labels/gt_602.txt  \n  inflating: vietnamese/labels/gt_158.txt  \n  inflating: vietnamese/labels/gt_1898.txt  \n  inflating: vietnamese/labels/gt_1194.txt  \n  inflating: vietnamese/labels/gt_1116.txt  \n  inflating: vietnamese/labels/gt_1967.txt  \n  inflating: vietnamese/labels/gt_718.txt  \n  inflating: vietnamese/labels/gt_1236.txt  \n  inflating: vietnamese/labels/gt_937.txt  \n  inflating: vietnamese/labels/gt_1292.txt  \n  inflating: vietnamese/labels/gt_1157.txt  \n  inflating: vietnamese/labels/gt_1500.txt  \n  inflating: vietnamese/labels/gt_10.txt  \n  inflating: vietnamese/labels/gt_418.txt  \n  inflating: vietnamese/labels/gt_807.txt  \n  inflating: vietnamese/labels/gt_1155.txt  \n  inflating: vietnamese/labels/gt_726.txt  \n  inflating: vietnamese/labels/gt_283.txt  \n  inflating: vietnamese/labels/gt_1912.txt  \n  inflating: vietnamese/labels/gt_794.txt  \n  inflating: vietnamese/labels/gt_70.txt  \n  inflating: vietnamese/labels/gt_1835.txt  \n  inflating: vietnamese/labels/gt_338.txt  \n  inflating: vietnamese/labels/gt_1470.txt  \n  inflating: vietnamese/labels/gt_1942.txt  \n  inflating: vietnamese/labels/gt_1508.txt  \n  inflating: vietnamese/labels/gt_355.txt  \n  inflating: vietnamese/labels/gt_1015.txt  \n  inflating: vietnamese/labels/gt_1402.txt  \n  inflating: vietnamese/labels/gt_1467.txt  \n  inflating: vietnamese/labels/gt_1193.txt  \n  inflating: vietnamese/labels/gt_471.txt  \n  inflating: vietnamese/labels/gt_1395.txt  \n  inflating: vietnamese/labels/gt_1228.txt  \n  inflating: vietnamese/labels/gt_50.txt  \n  inflating: vietnamese/labels/gt_1295.txt  \n  inflating: vietnamese/labels/gt_1555.txt  \n  inflating: vietnamese/labels/gt_194.txt  \n  inflating: vietnamese/labels/gt_660.txt  \n  inflating: vietnamese/labels/gt_33.txt  \n  inflating: vietnamese/labels/gt_828.txt  \n  inflating: vietnamese/labels/gt_192.txt  \n  inflating: vietnamese/labels/gt_1863.txt  \n  inflating: vietnamese/labels/gt_1605.txt  \n  inflating: vietnamese/labels/gt_60.txt  \n  inflating: vietnamese/labels/gt_5.txt  \n  inflating: vietnamese/labels/gt_1328.txt  \n  inflating: vietnamese/labels/gt_619.txt  \n  inflating: vietnamese/labels/gt_902.txt  \n  inflating: vietnamese/labels/gt_125.txt  \n  inflating: vietnamese/labels/gt_1342.txt  \n  inflating: vietnamese/labels/gt_1219.txt  \n  inflating: vietnamese/labels/gt_1216.txt  \n  inflating: vietnamese/labels/gt_1285.txt  \n  inflating: vietnamese/labels/gt_1153.txt  \n  inflating: vietnamese/labels/gt_1935.txt  \n  inflating: vietnamese/labels/gt_551.txt  \n  inflating: vietnamese/labels/gt_855.txt  \n  inflating: vietnamese/labels/gt_1747.txt  \n  inflating: vietnamese/labels/gt_849.txt  \n  inflating: vietnamese/labels/gt_435.txt  \n  inflating: vietnamese/labels/gt_1543.txt  \n  inflating: vietnamese/labels/gt_1293.txt  \n  inflating: vietnamese/labels/gt_1769.txt  \n  inflating: vietnamese/labels/gt_1374.txt  \n  inflating: vietnamese/labels/gt_1032.txt  \n  inflating: vietnamese/labels/gt_549.txt  \n  inflating: vietnamese/labels/gt_1178.txt  \n  inflating: vietnamese/labels/gt_1166.txt  \n  inflating: vietnamese/labels/gt_1965.txt  \n  inflating: vietnamese/labels/gt_68.txt  \n  inflating: vietnamese/labels/gt_640.txt  \n  inflating: vietnamese/labels/gt_1337.txt  \n  inflating: vietnamese/labels/gt_1506.txt  \n  inflating: vietnamese/labels/gt_1978.txt  \n  inflating: vietnamese/labels/gt_1103.txt  \n  inflating: vietnamese/labels/gt_1481.txt  \n  inflating: vietnamese/labels/gt_177.txt  \n  inflating: vietnamese/labels/gt_1744.txt  \n  inflating: vietnamese/labels/gt_699.txt  \n  inflating: vietnamese/labels/gt_1731.txt  \n  inflating: vietnamese/labels/gt_168.txt  \n  inflating: vietnamese/labels/gt_917.txt  \n  inflating: vietnamese/labels/gt_1381.txt  \n  inflating: vietnamese/labels/gt_1904.txt  \n  inflating: vietnamese/labels/gt_1340.txt  \n  inflating: vietnamese/labels/gt_2000.txt  \n  inflating: vietnamese/labels/gt_792.txt  \n  inflating: vietnamese/labels/gt_1222.txt  \n  inflating: vietnamese/labels/gt_214.txt  \n  inflating: vietnamese/labels/gt_1886.txt  \n  inflating: vietnamese/labels/gt_1052.txt  \n  inflating: vietnamese/labels/gt_1632.txt  \n  inflating: vietnamese/labels/gt_1318.txt  \n  inflating: vietnamese/labels/gt_1206.txt  \n  inflating: vietnamese/labels/gt_1987.txt  \n  inflating: vietnamese/labels/gt_1253.txt  \n  inflating: vietnamese/labels/gt_504.txt  \n  inflating: vietnamese/labels/gt_692.txt  \n  inflating: vietnamese/labels/gt_639.txt  \n  inflating: vietnamese/labels/gt_1514.txt  \n  inflating: vietnamese/labels/gt_264.txt  \n  inflating: vietnamese/labels/gt_1760.txt  \n  inflating: vietnamese/labels/gt_873.txt  \n  inflating: vietnamese/labels/gt_1475.txt  \n  inflating: vietnamese/labels/gt_719.txt  \n  inflating: vietnamese/labels/gt_1977.txt  \n  inflating: vietnamese/labels/gt_1446.txt  \n  inflating: vietnamese/labels/gt_1426.txt  \n  inflating: vietnamese/labels/gt_1330.txt  \n  inflating: vietnamese/labels/gt_642.txt  \n  inflating: vietnamese/labels/gt_589.txt  \n  inflating: vietnamese/labels/gt_256.txt  \n  inflating: vietnamese/labels/gt_1463.txt  \n  inflating: vietnamese/labels/gt_101.txt  \n  inflating: vietnamese/labels/gt_116.txt  \n  inflating: vietnamese/labels/gt_1486.txt  \n  inflating: vietnamese/labels/gt_1301.txt  \n  inflating: vietnamese/labels/gt_581.txt  \n  inflating: vietnamese/labels/gt_181.txt  \n  inflating: vietnamese/labels/gt_1938.txt  \n  inflating: vietnamese/labels/gt_193.txt  \n  inflating: vietnamese/labels/gt_414.txt  \n  inflating: vietnamese/labels/gt_1300.txt  \n  inflating: vietnamese/labels/gt_1755.txt  \n  inflating: vietnamese/labels/gt_1505.txt  \n  inflating: vietnamese/labels/gt_1814.txt  \n  inflating: vietnamese/labels/gt_1686.txt  \n  inflating: vietnamese/labels/gt_1607.txt  \n  inflating: vietnamese/labels/gt_1041.txt  \n  inflating: vietnamese/labels/gt_761.txt  \n  inflating: vietnamese/labels/gt_1249.txt  \n  inflating: vietnamese/labels/gt_1989.txt  \n  inflating: vietnamese/labels/gt_1789.txt  \n  inflating: vietnamese/labels/gt_1630.txt  \n  inflating: vietnamese/labels/gt_432.txt  \n  inflating: vietnamese/labels/gt_478.txt  \n  inflating: vietnamese/labels/gt_774.txt  \n  inflating: vietnamese/labels/gt_1156.txt  \n  inflating: vietnamese/labels/gt_1633.txt  \n  inflating: vietnamese/labels/gt_1065.txt  \n  inflating: vietnamese/labels/gt_499.txt  \n  inflating: vietnamese/labels/gt_1679.txt  \n  inflating: vietnamese/labels/gt_712.txt  \n  inflating: vietnamese/labels/gt_1203.txt  \n  inflating: vietnamese/labels/gt_80.txt  \n  inflating: vietnamese/labels/gt_1759.txt  \n  inflating: vietnamese/labels/gt_79.txt  \n  inflating: vietnamese/labels/gt_835.txt  \n  inflating: vietnamese/labels/gt_782.txt  \n  inflating: vietnamese/labels/gt_1280.txt  \n  inflating: vietnamese/labels/gt_406.txt  \n  inflating: vietnamese/labels/gt_1773.txt  \n  inflating: vietnamese/labels/gt_845.txt  \n  inflating: vietnamese/labels/gt_485.txt  \n  inflating: vietnamese/labels/gt_1765.txt  \n  inflating: vietnamese/labels/gt_1144.txt  \n  inflating: vietnamese/labels/gt_662.txt  \n  inflating: vietnamese/labels/gt_979.txt  \n  inflating: vietnamese/labels/gt_1733.txt  \n  inflating: vietnamese/labels/gt_234.txt  \n  inflating: vietnamese/labels/gt_1653.txt  \n  inflating: vietnamese/labels/gt_1055.txt  \n  inflating: vietnamese/labels/gt_392.txt  \n  inflating: vietnamese/labels/gt_1516.txt  \n  inflating: vietnamese/labels/gt_1158.txt  \n  inflating: vietnamese/labels/gt_1450.txt  \n  inflating: vietnamese/labels/gt_802.txt  \n  inflating: vietnamese/labels/gt_1704.txt  \n  inflating: vietnamese/labels/gt_453.txt  \n  inflating: vietnamese/labels/gt_1741.txt  \n  inflating: vietnamese/labels/gt_1056.txt  \n  inflating: vietnamese/labels/gt_714.txt  \n  inflating: vietnamese/labels/gt_1910.txt  \n  inflating: vietnamese/labels/gt_1622.txt  \n  inflating: vietnamese/labels/gt_1681.txt  \n  inflating: vietnamese/labels/gt_1197.txt  \n  inflating: vietnamese/labels/gt_512.txt  \n  inflating: vietnamese/labels/gt_409.txt  \n  inflating: vietnamese/labels/gt_77.txt  \n  inflating: vietnamese/labels/gt_575.txt  \n  inflating: vietnamese/labels/gt_821.txt  \n  inflating: vietnamese/labels/gt_379.txt  \n  inflating: vietnamese/labels/gt_690.txt  \n  inflating: vietnamese/labels/gt_1437.txt  \n  inflating: vietnamese/labels/gt_6.txt  \n  inflating: vietnamese/labels/gt_1724.txt  \n  inflating: vietnamese/labels/gt_1811.txt  \n  inflating: vietnamese/labels/gt_1507.txt  \n  inflating: vietnamese/labels/gt_1409.txt  \n  inflating: vietnamese/labels/gt_1730.txt  \n  inflating: vietnamese/labels/gt_1376.txt  \n  inflating: vietnamese/labels/gt_420.txt  \n  inflating: vietnamese/labels/gt_1878.txt  \n  inflating: vietnamese/labels/gt_1121.txt  \n  inflating: vietnamese/labels/gt_374.txt  \n  inflating: vietnamese/labels/gt_788.txt  \n  inflating: vietnamese/labels/gt_451.txt  \n  inflating: vietnamese/labels/gt_330.txt  \n  inflating: vietnamese/labels/gt_568.txt  \n  inflating: vietnamese/labels/gt_1441.txt  \n  inflating: vietnamese/labels/gt_1649.txt  \n  inflating: vietnamese/labels/gt_426.txt  \n  inflating: vietnamese/labels/gt_871.txt  \n  inflating: vietnamese/labels/gt_1933.txt  \n  inflating: vietnamese/labels/gt_1458.txt  \n  inflating: vietnamese/labels/gt_1961.txt  \n  inflating: vietnamese/labels/gt_153.txt  \n  inflating: vietnamese/labels/gt_230.txt  \n  inflating: vietnamese/labels/gt_733.txt  \n  inflating: vietnamese/labels/gt_1067.txt  \n  inflating: vietnamese/labels/gt_350.txt  \n  inflating: vietnamese/labels/gt_1634.txt  \n  inflating: vietnamese/labels/gt_1162.txt  \n  inflating: vietnamese/labels/gt_736.txt  \n  inflating: vietnamese/labels/gt_149.txt  \n  inflating: vietnamese/labels/gt_1047.txt  \n  inflating: vietnamese/labels/gt_1560.txt  \n  inflating: vietnamese/labels/gt_1000.txt  \n  inflating: vietnamese/labels/gt_450.txt  \n  inflating: vietnamese/labels/gt_275.txt  \n  inflating: vietnamese/labels/gt_342.txt  \n  inflating: vietnamese/labels/gt_659.txt  \n  inflating: vietnamese/labels/gt_513.txt  \n  inflating: vietnamese/labels/gt_419.txt  \n  inflating: vietnamese/labels/gt_1482.txt  \n  inflating: vietnamese/labels/gt_1979.txt  \n  inflating: vietnamese/labels/gt_1270.txt  \n  inflating: vietnamese/labels/gt_1476.txt  \n  inflating: vietnamese/labels/gt_1541.txt  \n  inflating: vietnamese/labels/gt_1844.txt  \n  inflating: vietnamese/labels/gt_389.txt  \n  inflating: vietnamese/labels/gt_951.txt  \n  inflating: vietnamese/labels/gt_110.txt  \n  inflating: vietnamese/labels/gt_186.txt  \n  inflating: vietnamese/labels/gt_1787.txt  \n  inflating: vietnamese/labels/gt_1885.txt  \n  inflating: vietnamese/labels/gt_799.txt  \n  inflating: vietnamese/labels/gt_361.txt  \n  inflating: vietnamese/labels/gt_1266.txt  \n  inflating: vietnamese/labels/gt_250.txt  \n  inflating: vietnamese/labels/gt_251.txt  \n  inflating: vietnamese/labels/gt_1558.txt  \n  inflating: vietnamese/labels/gt_1574.txt  \n  inflating: vietnamese/labels/gt_246.txt  \n  inflating: vietnamese/labels/gt_1258.txt  \n  inflating: vietnamese/labels/gt_1699.txt  \n  inflating: vietnamese/labels/gt_1251.txt  \n  inflating: vietnamese/labels/gt_138.txt  \n  inflating: vietnamese/labels/gt_390.txt  \n  inflating: vietnamese/labels/gt_1008.txt  \n  inflating: vietnamese/labels/gt_643.txt  \n  inflating: vietnamese/labels/gt_1570.txt  \n  inflating: vietnamese/labels/gt_1999.txt  \n  inflating: vietnamese/labels/gt_413.txt  \n  inflating: vietnamese/labels/gt_425.txt  \n  inflating: vietnamese/labels/gt_331.txt  \n  inflating: vietnamese/labels/gt_839.txt  \n  inflating: vietnamese/labels/gt_1949.txt  \n  inflating: vietnamese/labels/gt_776.txt  \n  inflating: vietnamese/labels/gt_1137.txt  \n  inflating: vietnamese/labels/gt_1338.txt  \n  inflating: vietnamese/labels/gt_439.txt  \n  inflating: vietnamese/labels/gt_1045.txt  \n  inflating: vietnamese/labels/gt_1414.txt  \n  inflating: vietnamese/labels/gt_1639.txt  \n  inflating: vietnamese/labels/gt_23.txt  \n  inflating: vietnamese/labels/gt_985.txt  \n  inflating: vietnamese/labels/gt_204.txt  \n  inflating: vietnamese/labels/gt_1551.txt  \n  inflating: vietnamese/labels/gt_1656.txt  \n  inflating: vietnamese/labels/gt_359.txt  \n  inflating: vietnamese/labels/gt_1487.txt  \n  inflating: vietnamese/labels/gt_216.txt  \n  inflating: vietnamese/labels/gt_27.txt  \n  inflating: vietnamese/labels/gt_1545.txt  \n  inflating: vietnamese/labels/gt_667.txt  \n  inflating: vietnamese/labels/gt_305.txt  \n  inflating: vietnamese/labels/gt_1464.txt  \n  inflating: vietnamese/labels/gt_1694.txt  \n  inflating: vietnamese/labels/gt_288.txt  \n  inflating: vietnamese/labels/gt_1419.txt  \n  inflating: vietnamese/labels/gt_1539.txt  \n  inflating: vietnamese/labels/gt_385.txt  \n  inflating: vietnamese/labels/gt_1751.txt  \n  inflating: vietnamese/labels/gt_773.txt  \n  inflating: vietnamese/labels/gt_939.txt  \n  inflating: vietnamese/labels/gt_1271.txt  \n  inflating: vietnamese/labels/gt_829.txt  \n  inflating: vietnamese/labels/gt_1596.txt  \n  inflating: vietnamese/labels/gt_1276.txt  \n  inflating: vietnamese/labels/gt_345.txt  \n  inflating: vietnamese/labels/gt_1088.txt  \n  inflating: vietnamese/labels/gt_805.txt  \n  inflating: vietnamese/labels/gt_881.txt  \n  inflating: vietnamese/labels/gt_1128.txt  \n  inflating: vietnamese/labels/gt_1013.txt  \n  inflating: vietnamese/labels/gt_910.txt  \n  inflating: vietnamese/labels/gt_102.txt  \n  inflating: vietnamese/labels/gt_1599.txt  \n  inflating: vietnamese/labels/gt_1766.txt  \n  inflating: vietnamese/labels/gt_255.txt  \n  inflating: vietnamese/labels/gt_1378.txt  \n  inflating: vietnamese/labels/gt_1111.txt  \n  inflating: vietnamese/labels/gt_1768.txt  \n  inflating: vietnamese/labels/gt_623.txt  \n  inflating: vietnamese/labels/gt_480.txt  \n  inflating: vietnamese/labels/gt_1171.txt  \n  inflating: vietnamese/labels/gt_1726.txt  \n  inflating: vietnamese/labels/gt_1826.txt  \n  inflating: vietnamese/labels/gt_784.txt  \n  inflating: vietnamese/labels/gt_527.txt  \n  inflating: vietnamese/labels/gt_53.txt  \n  inflating: vietnamese/labels/gt_1286.txt  \n  inflating: vietnamese/labels/gt_1124.txt  \n  inflating: vietnamese/labels/gt_817.txt  \n  inflating: vietnamese/labels/gt_1970.txt  \n  inflating: vietnamese/labels/gt_781.txt  \n  inflating: vietnamese/labels/gt_240.txt  \n  inflating: vietnamese/labels/gt_395.txt  \n  inflating: vietnamese/labels/gt_701.txt  \n  inflating: vietnamese/labels/gt_1682.txt  \n  inflating: vietnamese/labels/gt_21.txt  \n  inflating: vietnamese/labels/gt_1658.txt  \n  inflating: vietnamese/labels/gt_720.txt  \n  inflating: vietnamese/labels/gt_1932.txt  \n  inflating: vietnamese/labels/gt_1294.txt  \n  inflating: vietnamese/labels/gt_970.txt  \n  inflating: vietnamese/labels/gt_1849.txt  \n  inflating: vietnamese/labels/gt_1627.txt  \n  inflating: vietnamese/labels/gt_1945.txt  \n  inflating: vietnamese/labels/gt_217.txt  \n  inflating: vietnamese/labels/gt_1587.txt  \n  inflating: vietnamese/labels/gt_965.txt  \n  inflating: vietnamese/labels/gt_1566.txt  \n  inflating: vietnamese/labels/gt_325.txt  \n  inflating: vietnamese/labels/gt_440.txt  \n  inflating: vietnamese/labels/gt_1675.txt  \n  inflating: vietnamese/labels/gt_1957.txt  \n  inflating: vietnamese/labels/gt_1928.txt  \n  inflating: vietnamese/labels/gt_523.txt  \n  inflating: vietnamese/labels/gt_1801.txt  \n  inflating: vietnamese/labels/gt_669.txt  \n  inflating: vietnamese/labels/gt_213.txt  \n  inflating: vietnamese/labels/gt_1920.txt  \n  inflating: vietnamese/labels/gt_1322.txt  \n  inflating: vietnamese/labels/gt_1887.txt  \n  inflating: vietnamese/labels/gt_1919.txt  \n  inflating: vietnamese/labels/gt_1952.txt  \n  inflating: vietnamese/labels/gt_545.txt  \n  inflating: vietnamese/labels/gt_934.txt  \n  inflating: vietnamese/labels/gt_762.txt  \n  inflating: vietnamese/labels/gt_452.txt  \n  inflating: vietnamese/labels/gt_1836.txt  \n  inflating: vietnamese/labels/gt_874.txt  \n  inflating: vietnamese/labels/gt_655.txt  \n  inflating: vietnamese/labels/gt_824.txt  \n  inflating: vietnamese/labels/gt_830.txt  \n  inflating: vietnamese/labels/gt_1239.txt  \n  inflating: vietnamese/labels/gt_40.txt  \n  inflating: vietnamese/labels/gt_1347.txt  \n  inflating: vietnamese/labels/gt_1858.txt  \n  inflating: vietnamese/labels/gt_46.txt  \n  inflating: vietnamese/labels/gt_130.txt  \n  inflating: vietnamese/labels/gt_1248.txt  \n  inflating: vietnamese/labels/gt_166.txt  \n  inflating: vietnamese/labels/gt_723.txt  \n  inflating: vietnamese/labels/gt_990.txt  \n  inflating: vietnamese/labels/gt_932.txt  \n  inflating: vietnamese/labels/gt_1010.txt  \n  inflating: vietnamese/labels/gt_266.txt  \n  inflating: vietnamese/labels/gt_588.txt  \n  inflating: vietnamese/labels/gt_1729.txt  \n  inflating: vietnamese/labels/gt_443.txt  \n  inflating: vietnamese/labels/gt_1369.txt  \n  inflating: vietnamese/labels/gt_1611.txt  \n  inflating: vietnamese/labels/gt_1877.txt  \n  inflating: vietnamese/labels/gt_1626.txt  \n  inflating: vietnamese/labels/gt_1306.txt  \n  inflating: vietnamese/labels/gt_717.txt  \n  inflating: vietnamese/labels/gt_252.txt  \n  inflating: vietnamese/labels/gt_565.txt  \n  inflating: vietnamese/labels/gt_582.txt  \n  inflating: vietnamese/labels/gt_1778.txt  \n  inflating: vietnamese/labels/gt_1586.txt  \n  inflating: vietnamese/labels/gt_1149.txt  \n  inflating: vietnamese/labels/gt_463.txt  \n  inflating: vietnamese/labels/gt_1390.txt  \n  inflating: vietnamese/labels/gt_83.txt  \n  inflating: vietnamese/labels/gt_652.txt  \n  inflating: vietnamese/labels/gt_1964.txt  \n  inflating: vietnamese/labels/gt_1122.txt  \n  inflating: vietnamese/labels/gt_1384.txt  \n  inflating: vietnamese/labels/gt_1588.txt  \n  inflating: vietnamese/labels/gt_88.txt  \n  inflating: vietnamese/labels/gt_597.txt  \n  inflating: vietnamese/labels/gt_1997.txt  \n  inflating: vietnamese/labels/gt_1901.txt  \n  inflating: vietnamese/labels/gt_1483.txt  \n  inflating: vietnamese/labels/gt_1534.txt  \n  inflating: vietnamese/labels/gt_1657.txt  \n  inflating: vietnamese/labels/gt_1024.txt  \n  inflating: vietnamese/labels/gt_1859.txt  \n  inflating: vietnamese/labels/gt_1493.txt  \n  inflating: vietnamese/labels/gt_866.txt  \n  inflating: vietnamese/labels/gt_1855.txt  \n  inflating: vietnamese/labels/gt_1651.txt  \n  inflating: vietnamese/labels/gt_595.txt  \n  inflating: vietnamese/labels/gt_131.txt  \n  inflating: vietnamese/labels/gt_294.txt  \n  inflating: vietnamese/labels/gt_912.txt  \n  inflating: vietnamese/labels/gt_533.txt  \n  inflating: vietnamese/labels/gt_1980.txt  \n  inflating: vietnamese/labels/gt_1169.txt  \n  inflating: vietnamese/labels/gt_841.txt  \n  inflating: vietnamese/labels/gt_464.txt  \n  inflating: vietnamese/labels/gt_1524.txt  \n  inflating: vietnamese/labels/gt_772.txt  \n  inflating: vietnamese/labels/gt_205.txt  \n  inflating: vietnamese/labels/gt_621.txt  \n  inflating: vietnamese/labels/gt_200.txt  \n  inflating: vietnamese/labels/gt_1084.txt  \n  inflating: vietnamese/labels/gt_1126.txt  \n  inflating: vietnamese/labels/gt_1670.txt  \n  inflating: vietnamese/labels/gt_653.txt  \n  inflating: vietnamese/labels/gt_502.txt  \n  inflating: vietnamese/labels/gt_1689.txt  \n  inflating: vietnamese/labels/gt_1273.txt  \n  inflating: vietnamese/labels/gt_14.txt  \n  inflating: vietnamese/labels/gt_151.txt  \n  inflating: vietnamese/labels/gt_608.txt  \n  inflating: vietnamese/labels/gt_887.txt  \n  inflating: vietnamese/labels/gt_365.txt  \n  inflating: vietnamese/labels/gt_1521.txt  \n  inflating: vietnamese/labels/gt_524.txt  \n  inflating: vietnamese/labels/gt_1536.txt  \n  inflating: vietnamese/labels/gt_1644.txt  \n  inflating: vietnamese/labels/gt_1822.txt  \n  inflating: vietnamese/labels/gt_1635.txt  \n  inflating: vietnamese/labels/gt_616.txt  \n  inflating: vietnamese/labels/gt_1621.txt  \n  inflating: vietnamese/labels/gt_793.txt  \n  inflating: vietnamese/labels/gt_1892.txt  \n  inflating: vietnamese/labels/gt_1876.txt  \n  inflating: vietnamese/labels/gt_59.txt  \n  inflating: vietnamese/labels/gt_890.txt  \n  inflating: vietnamese/labels/gt_1939.txt  \n  inflating: vietnamese/labels/gt_1110.txt  \n  inflating: vietnamese/labels/gt_1268.txt  \n  inflating: vietnamese/labels/gt_1038.txt  \n  inflating: vietnamese/labels/gt_1671.txt  \n  inflating: vietnamese/labels/gt_1245.txt  \n  inflating: vietnamese/labels/gt_87.txt  \n  inflating: vietnamese/labels/gt_686.txt  \n  inflating: vietnamese/labels/gt_1684.txt  \n  inflating: vietnamese/labels/gt_722.txt  \n  inflating: vietnamese/labels/gt_896.txt  \n  inflating: vietnamese/labels/gt_1593.txt  \n  inflating: vietnamese/labels/gt_943.txt  \n  inflating: vietnamese/labels/gt_1269.txt  \n  inflating: vietnamese/labels/gt_1883.txt  \n  inflating: vietnamese/labels/gt_1017.txt  \n  inflating: vietnamese/labels/gt_862.txt  \n  inflating: vietnamese/labels/gt_536.txt  \n  inflating: vietnamese/labels/gt_124.txt  \n  inflating: vietnamese/labels/gt_298.txt  \n  inflating: vietnamese/labels/gt_703.txt  \n  inflating: vietnamese/labels/gt_721.txt  \n  inflating: vietnamese/labels/gt_716.txt  \n  inflating: vietnamese/labels/gt_1806.txt  \n  inflating: vietnamese/labels/gt_1616.txt  \n  inflating: vietnamese/labels/gt_853.txt  \n  inflating: vietnamese/labels/gt_1893.txt  \n  inflating: vietnamese/labels/gt_1782.txt  \n  inflating: vietnamese/labels/gt_1170.txt  \n  inflating: vietnamese/labels/gt_842.txt  \n  inflating: vietnamese/labels/gt_302.txt  \n  inflating: vietnamese/labels/gt_437.txt  \n  inflating: vietnamese/labels/gt_1348.txt  \n  inflating: vietnamese/labels/gt_1842.txt  \n  inflating: vietnamese/labels/gt_1.txt  \n  inflating: vietnamese/labels/gt_540.txt  \n  inflating: vietnamese/labels/gt_1903.txt  \n  inflating: vietnamese/labels/gt_778.txt  \n  inflating: vietnamese/labels/gt_742.txt  \n  inflating: vietnamese/labels/gt_1615.txt  \n  inflating: vietnamese/labels/gt_18.txt  \n  inflating: vietnamese/labels/gt_1391.txt  \n  inflating: vietnamese/labels/gt_467.txt  \n  inflating: vietnamese/labels/gt_473.txt  \n  inflating: vietnamese/labels/gt_449.txt  \n  inflating: vietnamese/labels/gt_753.txt  \n  inflating: vietnamese/labels/gt_743.txt  \n  inflating: vietnamese/labels/gt_1234.txt  \n  inflating: vietnamese/labels/gt_76.txt  \n  inflating: vietnamese/labels/gt_1372.txt  \n  inflating: vietnamese/labels/gt_1968.txt  \n  inflating: vietnamese/labels/gt_1740.txt  \n  inflating: vietnamese/labels/gt_1345.txt  \n  inflating: vietnamese/labels/gt_303.txt  \n  inflating: vietnamese/labels/gt_1618.txt  \n  inflating: vietnamese/labels/gt_1398.txt  \n  inflating: vietnamese/labels/gt_661.txt  \n  inflating: vietnamese/labels/gt_262.txt  \n  inflating: vietnamese/labels/gt_644.txt  \n  inflating: vietnamese/labels/gt_1229.txt  \n  inflating: vietnamese/labels/gt_1119.txt  \n  inflating: vietnamese/labels/gt_1652.txt  \n  inflating: vietnamese/labels/gt_1230.txt  \n  inflating: vietnamese/labels/gt_74.txt  \n  inflating: vietnamese/labels/gt_741.txt  \n  inflating: vietnamese/labels/gt_447.txt  \n  inflating: vietnamese/labels/gt_1002.txt  \n  inflating: vietnamese/labels/gt_185.txt  \n  inflating: vietnamese/labels/gt_233.txt  \n  inflating: vietnamese/labels/gt_44.txt  \n  inflating: vietnamese/labels/gt_1401.txt  \n  inflating: vietnamese/labels/gt_1199.txt  \n  inflating: vietnamese/labels/gt_1606.txt  \n  inflating: vietnamese/labels/gt_36.txt  \n  inflating: vietnamese/labels/gt_1025.txt  \n  inflating: vietnamese/labels/gt_580.txt  \n  inflating: vietnamese/labels/gt_1982.txt  \n  inflating: vietnamese/labels/gt_1394.txt  \n  inflating: vietnamese/labels/gt_1538.txt  \n  inflating: vietnamese/labels/gt_1442.txt  \n  inflating: vietnamese/labels/gt_12.txt  \n  inflating: vietnamese/labels/gt_284.txt  \n  inflating: vietnamese/labels/gt_852.txt  \n  inflating: vietnamese/labels/gt_167.txt  \n  inflating: vietnamese/labels/gt_1861.txt  \n  inflating: vietnamese/labels/gt_1006.txt  \n  inflating: vietnamese/labels/gt_222.txt  \n  inflating: vietnamese/labels/gt_1899.txt  \n  inflating: vietnamese/labels/gt_187.txt  \n  inflating: vietnamese/labels/gt_1325.txt  \n  inflating: vietnamese/labels/gt_1719.txt  \n  inflating: vietnamese/labels/gt_1417.txt  \n  inflating: vietnamese/labels/gt_140.txt  \n  inflating: vietnamese/labels/gt_1823.txt  \n  inflating: vietnamese/labels/gt_996.txt  \n  inflating: vietnamese/labels/gt_1202.txt  \n  inflating: vietnamese/labels/gt_287.txt  \n  inflating: vietnamese/labels/gt_967.txt  \n  inflating: vietnamese/labels/gt_343.txt  \n  inflating: vietnamese/labels/gt_1673.txt  \n  inflating: vietnamese/labels/gt_528.txt  \n  inflating: vietnamese/labels/gt_1693.txt  \n  inflating: vietnamese/labels/gt_1571.txt  \n  inflating: vietnamese/labels/gt_370.txt  \n  inflating: vietnamese/labels/gt_378.txt  \n  inflating: vietnamese/labels/gt_1184.txt  \n  inflating: vietnamese/labels/gt_1914.txt  \n  inflating: vietnamese/labels/gt_1794.txt  \n  inflating: vietnamese/labels/gt_1974.txt  \n  inflating: vietnamese/labels/gt_681.txt  \n  inflating: vietnamese/labels/gt_1094.txt  \n  inflating: vietnamese/labels/gt_421.txt  \n  inflating: vietnamese/labels/gt_442.txt  \n  inflating: vietnamese/labels/gt_357.txt  \n  inflating: vietnamese/labels/gt_1420.txt  \n  inflating: vietnamese/labels/gt_739.txt  \n  inflating: vietnamese/labels/gt_285.txt  \n  inflating: vietnamese/labels/gt_368.txt  \n  inflating: vietnamese/labels/gt_1449.txt  \n  inflating: vietnamese/labels/gt_1107.txt  \n  inflating: vietnamese/labels/gt_941.txt  \n  inflating: vietnamese/labels/gt_944.txt  \n  inflating: vietnamese/labels/gt_872.txt  \n  inflating: vietnamese/labels/gt_646.txt  \n  inflating: vietnamese/labels/gt_674.txt  \n  inflating: vietnamese/labels/gt_271.txt  \n  inflating: vietnamese/labels/gt_22.txt  \n  inflating: vietnamese/labels/gt_1533.txt  \n  inflating: vietnamese/labels/gt_95.txt  \n  inflating: vietnamese/labels/gt_434.txt  \n  inflating: vietnamese/labels/gt_969.txt  \n  inflating: vietnamese/labels/gt_1695.txt  \n  inflating: vietnamese/labels/gt_111.txt  \n  inflating: vietnamese/labels/gt_1831.txt  \n  inflating: vietnamese/labels/gt_1136.txt  \n  inflating: vietnamese/labels/gt_1440.txt  \n  inflating: vietnamese/labels/gt_1800.txt  \n  inflating: vietnamese/labels/gt_1906.txt  \n  inflating: vietnamese/labels/gt_398.txt  \n  inflating: vietnamese/labels/gt_600.txt  \n  inflating: vietnamese/labels/gt_56.txt  \n  inflating: vietnamese/labels/gt_626.txt  \n  inflating: vietnamese/labels/gt_1227.txt  \n  inflating: vietnamese/labels/gt_604.txt  \n  inflating: vietnamese/labels/gt_1407.txt  \n  inflating: vietnamese/labels/gt_1154.txt  \n  inflating: vietnamese/labels/gt_1774.txt  \n  inflating: vietnamese/labels/gt_1335.txt  \n  inflating: vietnamese/labels/gt_978.txt  \n  inflating: vietnamese/labels/gt_209.txt  \n  inflating: vietnamese/labels/gt_81.txt  \n  inflating: vietnamese/labels/gt_724.txt  \n  inflating: vietnamese/labels/gt_1955.txt  \n  inflating: vietnamese/labels/gt_1816.txt  \n  inflating: vietnamese/labels/gt_1305.txt  \n  inflating: vietnamese/labels/gt_326.txt  \n  inflating: vietnamese/labels/gt_1492.txt  \n  inflating: vietnamese/labels/gt_24.txt  \n  inflating: vietnamese/labels/gt_907.txt  \n  inflating: vietnamese/labels/gt_529.txt  \n  inflating: vietnamese/labels/gt_740.txt  \n  inflating: vietnamese/labels/gt_1708.txt  \n  inflating: vietnamese/labels/gt_1080.txt  \n  inflating: vietnamese/labels/gt_755.txt  \n  inflating: vietnamese/labels/gt_822.txt  \n  inflating: vietnamese/labels/gt_1331.txt  \n  inflating: vietnamese/labels/gt_1936.txt  \n  inflating: vietnamese/labels/gt_223.txt  \n  inflating: vietnamese/labels/gt_235.txt  \n  inflating: vietnamese/labels/gt_1556.txt  \n  inflating: vietnamese/labels/gt_558.txt  \n  inflating: vietnamese/labels/gt_1471.txt  \n  inflating: vietnamese/labels/gt_906.txt  \n  inflating: vietnamese/labels/gt_1355.txt  \n  inflating: vietnamese/labels/gt_1108.txt  \n  inflating: vietnamese/labels/gt_1702.txt  \n  inflating: vietnamese/labels/gt_1930.txt  \n  inflating: vietnamese/labels/gt_1062.txt  \n  inflating: vietnamese/labels/gt_927.txt  \n  inflating: vietnamese/labels/gt_121.txt  \n  inflating: vietnamese/labels/gt_1373.txt  \n  inflating: vietnamese/labels/gt_983.txt  \n  inflating: vietnamese/labels/gt_133.txt  \n  inflating: vietnamese/labels/gt_1841.txt  \n  inflating: vietnamese/labels/gt_981.txt  \n  inflating: vietnamese/labels/gt_609.txt  \n  inflating: vietnamese/labels/gt_1520.txt  \n  inflating: vietnamese/labels/gt_117.txt  \n  inflating: vietnamese/labels/gt_373.txt  \n  inflating: vietnamese/labels/gt_90.txt  \n  inflating: vietnamese/labels/gt_1007.txt  \n  inflating: vietnamese/labels/gt_1697.txt  \n  inflating: vietnamese/labels/gt_1802.txt  \n  inflating: vietnamese/labels/gt_946.txt  \n  inflating: vietnamese/labels/gt_1256.txt  \n  inflating: vietnamese/labels/gt_1857.txt  \n  inflating: vietnamese/labels/gt_63.txt  \n  inflating: vietnamese/labels/gt_1093.txt  \n  inflating: vietnamese/labels/gt_1628.txt  \n  inflating: vietnamese/labels/gt_1830.txt  \n  inflating: vietnamese/labels/gt_1809.txt  \n  inflating: vietnamese/labels/gt_1757.txt  \n  inflating: vietnamese/labels/gt_548.txt  \n  inflating: vietnamese/labels/gt_1715.txt  \n  inflating: vietnamese/labels/gt_37.txt  \n  inflating: vietnamese/labels/gt_1365.txt  \n  inflating: vietnamese/labels/gt_141.txt  \n  inflating: vietnamese/labels/gt_1564.txt  \n  inflating: vietnamese/labels/gt_165.txt  \n  inflating: vietnamese/labels/gt_1660.txt  \n  inflating: vietnamese/labels/gt_429.txt  \n  inflating: vietnamese/labels/gt_555.txt  \n  inflating: vietnamese/labels/gt_171.txt  \n  inflating: vietnamese/labels/gt_73.txt  \n  inflating: vietnamese/labels/gt_1832.txt  \n  inflating: vietnamese/labels/gt_1958.txt  \n  inflating: vietnamese/labels/gt_620.txt  \n  inflating: vietnamese/labels/gt_274.txt  \n  inflating: vietnamese/labels/gt_1231.txt  \n  inflating: vietnamese/labels/gt_308.txt  \n  inflating: vietnamese/labels/gt_1250.txt  \n  inflating: vietnamese/labels/gt_1872.txt  \n  inflating: vietnamese/labels/gt_57.txt  \n  inflating: vietnamese/labels/gt_1138.txt  \n  inflating: vietnamese/labels/gt_1020.txt  \n  inflating: vietnamese/labels/gt_1764.txt  \n  inflating: vietnamese/labels/gt_590.txt  \n  inflating: vietnamese/labels/gt_1916.txt  \n  inflating: vietnamese/labels/gt_431.txt  \n  inflating: vietnamese/labels/gt_745.txt  \n  inflating: vietnamese/labels/gt_1917.txt  \n  inflating: vietnamese/labels/gt_244.txt  \n  inflating: vietnamese/labels/gt_968.txt  \n  inflating: vietnamese/labels/gt_1559.txt  \n  inflating: vietnamese/labels/gt_1518.txt  \n  inflating: vietnamese/labels/gt_108.txt  \n  inflating: vietnamese/labels/gt_1785.txt  \n/kaggle/working/units\n","output_type":"stream"}]},{"cell_type":"code","source":"%cd train_datasets\n!gdown 1Woe-dKj5QFI2E4t9X7k6-syEbWHNbn6h\n%cd ..","metadata":{"execution":{"iopub.status.busy":"2024-07-15T10:49:53.077206Z","iopub.execute_input":"2024-07-15T10:49:53.077902Z","iopub.status.idle":"2024-07-15T10:49:59.704075Z","shell.execute_reply.started":"2024-07-15T10:49:53.077854Z","shell.execute_reply":"2024-07-15T10:49:59.702966Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"/kaggle/working/units/train_datasets\nDownloading...\nFrom: https://drive.google.com/uc?id=1Woe-dKj5QFI2E4t9X7k6-syEbWHNbn6h\nTo: /kaggle/working/units/train_datasets/vintextfromtxttraining.json\n100%|███████████████████████████████████████| 13.9M/13.9M [00:00<00:00, 142MB/s]\n/kaggle/working/units\n","output_type":"stream"}]},{"cell_type":"code","source":"%cd train_datasets\n!gdown 1pDslnjbt09GTOYgV4xdmsXbRQcAiB46x\n%cd ..","metadata":{"execution":{"iopub.status.busy":"2024-07-15T10:49:59.706156Z","iopub.execute_input":"2024-07-15T10:49:59.706453Z","iopub.status.idle":"2024-07-15T10:50:04.599598Z","shell.execute_reply.started":"2024-07-15T10:49:59.706424Z","shell.execute_reply":"2024-07-15T10:50:04.598552Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"/kaggle/working/units/train_datasets\nDownloading...\nFrom: https://drive.google.com/uc?id=1pDslnjbt09GTOYgV4xdmsXbRQcAiB46x\nTo: /kaggle/working/units/train_datasets/vintextfromtxttest.json\n100%|███████████████████████████████████████| 3.46M/3.46M [00:00<00:00, 144MB/s]\n/kaggle/working/units\n","output_type":"stream"}]},{"cell_type":"code","source":"%cd train_datasets\n!gdown 1zsFu0s_2CLJpBBN1amTlhcLIwjVJmuj0\n# !gdown 1W-37YR0U-xU9bgb35SW7ZWYbBbMlBzIo\n%cd ..","metadata":{"execution":{"iopub.status.busy":"2024-07-15T10:50:04.601107Z","iopub.execute_input":"2024-07-15T10:50:04.601447Z","iopub.status.idle":"2024-07-15T10:50:09.357181Z","shell.execute_reply.started":"2024-07-15T10:50:04.601416Z","shell.execute_reply":"2024-07-15T10:50:09.356095Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"/kaggle/working/units/train_datasets\nDownloading...\nFrom: https://drive.google.com/uc?id=1zsFu0s_2CLJpBBN1amTlhcLIwjVJmuj0\nTo: /kaggle/working/units/train_datasets/vintextfromtxtunseen.json\n100%|███████████████████████████████████████| 4.88M/4.88M [00:00<00:00, 239MB/s]\n/kaggle/working/units\n","output_type":"stream"}]},{"cell_type":"code","source":"convertdata = open('./units/models/convert_data.py','w')\nconvertdata.write('''dictionary = \"aàáạảãâầấậẩẫăằắặẳẵAÀÁẠẢÃĂẰẮẶẲẴÂẦẤẬẨẪeèéẹẻẽêềếệểễEÈÉẸẺẼÊỀẾỆỂỄoòóọỏõôồốộổỗơờớợởỡOÒÓỌỎÕÔỒỐỘỔỖƠỜỚỢỞỠiìíịỉĩIÌÍỊỈĨuùúụủũưừứựửữƯỪỨỰỬỮUÙÚỤỦŨyỳýỵỷỹYỲÝỴỶỸ\"\n\n\ndef make_groups():\n    groups = []\n    i = 0\n    while i < len(dictionary) - 5:\n        group = [c for c in dictionary[i : i + 6]]\n        i += 6\n        groups.append(group)\n    return groups\n\n\ngroups = make_groups()\n\nTONES = [\"\", \"ˋ\", \"ˊ\", \"⸱\", \"ˀ\", \"˜\"]\nSOURCES = [\"ă\", \"â\", \"Ă\", \"Â\", \"ê\", \"Ê\", \"ô\", \"ơ\", \"Ô\", \"Ơ\", \"ư\", \"Ư\", \"Đ\", \"đ\"]\nTARGETS = [\"aˇ\", \"aˆ\", \"Aˇ\", \"Aˆ\", \"eˆ\", \"Eˆ\", \"oˆ\", \"o˒\", \"Oˆ\", \"O˒\", \"u˒\", \"U˒\", \"D^\", \"d^\"]\n\n\ndef parse_tone(word):\n    res = \"\"\n    tone = \"\"\n    for char in word:\n        if char in dictionary:\n            for group in groups:\n                if char in group:\n                    if tone == \"\":\n                        tone = TONES[group.index(char)]\n                    res += group[0]\n        else:\n            res += char\n    res += tone\n    return res\n\n\ndef full_parse(word):\n    word = parse_tone(word)\n    res = \"\"\n    for char in word:\n        if char in SOURCES:\n            res += TARGETS[SOURCES.index(char)]\n        else:\n            res += char\n    return res\n\n\ndef correct_tone_position(word):\n    word = word[:-1]\n    first_ord_char = \"\"\n    second_order_char = \"\"\n    for char in word:\n        for group in groups:\n            if char in group:\n                second_order_char = first_ord_char\n                first_ord_char = group[0]\n    if len(word) >= 1 and word[-1] == first_ord_char and second_order_char != \"\":\n        pair_chars = [\"qu\", \"Qu\", \"qU\", \"QU\", \"gi\", \"Gi\", \"gI\", \"GI\"]\n        for pair in pair_chars:\n            if pair in word and second_order_char in [\"u\", \"U\", \"i\", \"I\"]:\n                return first_ord_char\n        return second_order_char\n    return first_ord_char\n\n\ndef decoder(recognition):\n    for char in TARGETS:\n        recognition = recognition.replace(char, SOURCES[TARGETS.index(char)])\n    replace_char = correct_tone_position(recognition)\n    if recognition[-1] in TONES:\n        tone = recognition[-1]\n        recognition = recognition[:-1]\n        for group in groups:\n            if replace_char in group:\n                recognition = recognition.replace(replace_char, group[TONES.index(tone)])\n    return recognition\n''')\nconvertdata.close()","metadata":{"execution":{"iopub.status.busy":"2024-07-15T10:50:09.359672Z","iopub.execute_input":"2024-07-15T10:50:09.360008Z","iopub.status.idle":"2024-07-15T10:50:09.367679Z","shell.execute_reply.started":"2024-07-15T10:50:09.359976Z","shell.execute_reply":"2024-07-15T10:50:09.366772Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# @title make_lmdb.py\n\n# make_lmdb vintext\n\nmake_lmdb_vintext = open('./script/make_lmdb.py', 'w')\nmake_lmdb_vintext.write('''# python script/make_lmdb.py --split train/val/test\n\n\nfrom units.models.convert_data import *\n\n\nimport argparse\nimport multiprocessing\nimport os\nimport pickle\nfrom functools import partial\nfrom glob import glob\n\nimport lmdb\nimport numpy as np\nimport orjson\nfrom PIL import Image\nfrom pycocotools.coco import COCO\nfrom tqdm import tqdm\n\nannotation_path = \"train_datasets\"\nsynthtext_vocab = list(\n    \" !\\\"#$%&'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\\\]^_`abcdefghijklmnopqrstuvwxyz{|}~\"\n)\n\n# annotation, img_path pair list\ntrain_annotation_files = {\n    \"vintext\": [\n        \"vintextfromtxttraining.json\",\n        \"vietnamese/train_images\",\n    ],\n    \"icdar15\": [\n        \"annotations/icdar15/ICDAR2015_Incidental_train.json\",\n        \"images/icdar15/train\",\n    ],\n}\n\nval_annotation_files = {\n    \"vintext\": [\n        \"vintextfromtxttest.json\",\n        \"vietnamese/test_image\",\n    ],\n    \"icdar15\": [\n        \"annotations/icdar15/ICDAR2015_Incidental_test.json\",\n        \"images/icdar15/test\",\n    ],\n}\n\ntest_annotation_files = {\n    \"vintext\": [\n        \"vintextfromtxtunseen.json\",\n        \"vietnamese/unseen_test_images\",\n    ],\n    \"icdar15\": [\n        \"annotations/icdar15/ICDAR2015_Incidental_test.json\",\n        \"images/icdar15/test\",\n    ],\n}\n\nannotation_files = {\n    \"train\": train_annotation_files,\n    \"val\": val_annotation_files,\n    \"test\": test_annotation_files,\n}\n\n\ndef read_json(fname):\n    with open(fname) as f:\n        return orjson.loads(f.read())\n\n\ndef to_record(row, dataset):\n\n    image_id = row[\"image_id\"]\n    if dataset != \"hiertext\":\n        filename = row[\"filename\"]\n\n    dc, words = [], []\n    if dataset == \"hiertext\":\n        word_id = 0\n        for paragraph_id, paragraph in enumerate(row[\"paragraphs\"]):\n            for line_id, line in enumerate(paragraph[\"lines\"]):\n                for word in line[\"words\"]:\n                    vertices = word[\"vertices\"]\n                    text = word[\"text\"]\n                    legible = word[\"legible\"]\n                    # handwritten = word[\"handwritten\"]\n                    horizontal = not word[\"vertical\"]\n                    if text == \"\":\n                        legible = False\n                    if legible is False:\n                        dc.append(np.array(vertices, dtype=np.float32))\n                    else:\n                        words.append(\n                            (vertices, text, horizontal, word_id, line_id, paragraph_id)\n                        )\n                        word_id += 1\n        filename = str(image_id) + \".jpg\"\n    elif dataset in [\n        \"vintext\",\n        \"icdar13\",\n        \"icdar15\",\n        \"mlt19\",\n        \"textocr\",\n        \"textocr.poly\",\n        \"synthtext150k.poly.part1\",\n        \"synthtext150k.poly.part2\",\n        \"totaltext.poly\",\n        \"ctw1500.poly\",\n    ]:\n        for word_id, word in enumerate(row[\"words\"]):\n            vertices = [\n                (x, y) for x, y in zip(word[\"vertices\"][::2], word[\"vertices\"][1::2])\n            ]\n            text = word[\"text\"]\n            legible = word[\"legible\"]\n            paragraph_id = None\n            line_id = None\n            horizontal = None\n            if legible is False:\n                dc.append(np.array(vertices, dtype=np.float32))\n            else:\n                words.append(\n                    (vertices, text, horizontal, word_id, line_id, paragraph_id)\n                )\n\n    width = row[\"image_width\"]\n    height = row[\"image_height\"]\n\n    result = {\n        \"id\": image_id,\n        \"words\": words,\n        \"dcs\": dc,\n        \"filename\": filename,\n        \"orig_size\": (width, height),\n        \"dataset_name\": dataset,\n    }\n    return result\n\n\ndef worker(data, root, target, name, split, max_size):\n    id, row = data\n    record = to_record(row, name)\n    # record[\"img_size\"] = record[\"orig_size\"]\n    record[\"filename\"] = os.path.join(root, record[\"filename\"])\n    record_pkl = pickle.dumps(record)\n\n    return id, record_pkl\n\n\ndef process(annotation, root, name, split, target, max_size=2560, n_workers=8):\n    annot = read_json(annotation)\n    worker_fn = partial(\n        worker, root=root, target=target, name=name, split=split, max_size=max_size\n    )\n    \n    if name == \"mlt19\":\n        refined_annot = []\n        for r in annot[split]:\n            sample = dict()\n            sample[\"image_id\"] = r[\"id\"]\n            sample[\"filename\"] = r[\"file_name\"].split(\"/\")[-1]\n            img = Image.open(os.path.join(annotation_path, root, sample[\"filename\"]))\n            sample[\"image_width\"], sample[\"image_height\"] = img.width, img.height\n            words = []\n            for quad, text in zip(r[\"QUAD\"], r[\"TEXT\"]):\n                vertices = quad\n                legible = text != \"###\"\n                words.append({\"vertices\": vertices, \"text\": text, \"legible\": legible})\n            sample[\"words\"] = words\n            refined_annot.append(sample)\n\n        row = [(i, r) for i, r in enumerate(refined_annot)]\n\n    elif name in [\"vintext\"]:\n        coco = COCO(annotation)\n        refined_annot = []\n        for img_annot in annot[\"images\"]:\n            img_id = img_annot[\"id\"]\n            ann_ids = coco.getAnnIds(imgIds=img_id)\n            anns = coco.loadAnns(ann_ids)\n            sample = dict()\n            sample[\"image_width\"], sample[\"image_height\"] = (\n                img_annot[\"width\"],\n                img_annot[\"height\"],\n            )\n            sample[\"image_id\"] = img_annot[\"id\"]\n            sample[\"filename\"] = img_annot[\"file_name\"].split(\"/\")[-1]\n            words = []\n            for ann in anns:\n                assert len(ann[\"bezier_pts\"]) % 2 == 0\n                vertices = ann[\"bezier_pts\"]\n                text = ann[\"text\"]\n                text = full_parse(text)\n                # print(\"text ne \", text)\n                legible = text != \"###\"\n                words.append({\"vertices\": vertices, \"text\": text, \"legible\": legible})\n            sample[\"words\"] = words\n            refined_annot.append(sample)\n\n        row = [(i, r) for i, r in enumerate(refined_annot)]\n        \n    elif name in [\"icdar13\", \"icdar15\", \"icdar15_incidental\"]:\n        coco = COCO(annotation)\n        refined_annot = []\n        for img_annot in annot[\"images\"]:\n            img_id = img_annot[\"id\"]\n            ann_ids = coco.getAnnIds(imgIds=img_id)\n            anns = coco.loadAnns(ann_ids)\n            sample = dict()\n            sample[\"image_width\"], sample[\"image_height\"] = (\n                img_annot[\"width\"],\n                img_annot[\"height\"],\n            )\n            sample[\"image_id\"] = img_annot[\"id\"]\n            sample[\"filename\"] = img_annot[\"file_name\"].split(\"/\")[-1]\n            words = []\n            for ann in anns:\n                assert len(ann[\"bezier_pts\"]) % 2 == 0\n                vertices = ann[\"bezier_pts\"]\n                text = ann[\"text\"]\n                legible = text != \"###\"\n                words.append({\"vertices\": vertices, \"text\": text, \"legible\": legible})\n            sample[\"words\"] = words\n            refined_annot.append(sample)\n\n        row = [(i, r) for i, r in enumerate(refined_annot)]\n\n    elif name in [\n        \"synthtext150k.poly.part1\",\n        \"synthtext150k.poly.part2\",\n        \"totaltext.poly\",\n        \"ctw1500.poly\",\n    ]:\n        eos = len(synthtext_vocab)\n        coco = COCO(annotation)\n        refined_annot = []\n        for img_annot in annot[\"images\"]:\n            img_id = img_annot[\"id\"]\n            ann_ids = coco.getAnnIds(imgIds=img_id)\n            anns = coco.loadAnns(ann_ids)\n            sample = dict()\n            sample[\"image_width\"], sample[\"image_height\"] = (\n                img_annot[\"width\"],\n                img_annot[\"height\"],\n            )\n            sample[\"image_id\"] = img_annot[\"id\"]\n            sample[\"filename\"] = img_annot[\"file_name\"].split(\"/\")[-1]\n            words = []\n            for ann in anns:\n                vertices = ann[\"polys\"]\n                text = \"\"\n                for idx in ann[\"rec\"]:\n                    if idx >= eos:\n                        break\n                    text += synthtext_vocab[idx]\n                legible = text != \"###\" and text != \"\"\n                words.append({\"vertices\": vertices, \"text\": text, \"legible\": legible})\n            sample[\"words\"] = words\n            refined_annot.append(sample)\n\n        row = [(i, r) for i, r in enumerate(refined_annot)]\n\n    elif name == \"hiertext\":\n        row = [(i, r) for i, r in enumerate(annot[\"annotations\"])]\n\n    elif name in [\"textocr\", \"textocr.poly\"]:\n        refined_annot = []\n        for img_id, ann_ids in annot[\"imgToAnns\"].items():\n            img_annot = annot[\"imgs\"][img_id]\n            sample = dict()\n            sample[\"image_width\"], sample[\"image_height\"] = (\n                img_annot[\"width\"],\n                img_annot[\"height\"],\n            )\n            sample[\"image_id\"] = img_id\n            sample[\"filename\"] = img_annot[\"file_name\"].split(\"/\")[-1]\n            words = []\n            for ann_id in ann_ids:\n                vertices = annot[\"anns\"][ann_id][\"points\"]\n                text = annot[\"anns\"][ann_id][\"utf8_string\"]\n                legible = text != \".\"\n                words.append({\"vertices\": vertices, \"text\": text, \"legible\": legible})\n            sample[\"words\"] = words\n            refined_annot.append(sample)\n\n        row = [(i, r) for i, r in enumerate(refined_annot)]\n\n    with lmdb.open(\n        os.path.join(target, name + \"_\" + split + \".lmdb\"),\n        # './train_datasets/icdar15_train.lmdb',\n        # os.path.join(\"./train_datasets/\" + name + \"_\" + split + \".lmdb\"),\n        map_size=1024 ** 4,\n        readahead=False,\n    ) as env, multiprocessing.Pool(n_workers) as pool:\n        for i, record_pkl in tqdm(\n            pool.imap_unordered(worker_fn, row),\n            desc=os.path.basename(annotation),\n            total=len(row),\n            dynamic_ncols=True,\n        ):\n            with env.begin(write=True) as txn:\n                txn.put(str(i).encode(\"utf-8\"), record_pkl)\n\n        with env.begin(write=True) as txn:\n            txn.put(b\"length\", str(len(row)).encode(\"utf-8\"))\n\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--n_workers\", type=int, default=8)\n    parser.add_argument(\"--max_size\", type=int, default=2560)\n    parser.add_argument(\"--out\", type=str, default=\"./train_datasets\")\n    parser.add_argument(\"--split\", type=str, default=\"train\")\n\n    args = parser.parse_args()\n\n    for i, annot in enumerate(annotation_files[args.split].keys(), start=1):\n        print(f\"{i}. {annot}\")\n\n    for dataset, (annot, root) in annotation_files[args.split].items():\n        process(\n            \"./train_datasets/\"+annot, root, dataset, args.split, args.out, args.max_size, args.n_workers\n        )\n''')\nmake_lmdb_vintext.close()","metadata":{"id":"qjosxgw1KdVs","cellView":"form","execution":{"iopub.status.busy":"2024-07-15T10:50:09.369422Z","iopub.execute_input":"2024-07-15T10:50:09.369778Z","iopub.status.idle":"2024-07-15T10:50:09.580707Z","shell.execute_reply.started":"2024-07-15T10:50:09.369746Z","shell.execute_reply":"2024-07-15T10:50:09.579791Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"!PYTHONPATH=$PWD python script/make_lmdb.py --split train","metadata":{"id":"6TWNA_0zJQ_p","outputId":"a6b2641f-8e09-42f0-e17e-9c4518a99884","execution":{"iopub.status.busy":"2024-07-15T10:50:09.581996Z","iopub.execute_input":"2024-07-15T10:50:09.582600Z","iopub.status.idle":"2024-07-15T10:50:25.729464Z","shell.execute_reply.started":"2024-07-15T10:50:09.582569Z","shell.execute_reply":"2024-07-15T10:50:25.728352Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"1. vintext\n2. icdar15\nloading annotations into memory...\nDone (t=0.22s)\ncreating index...\nindex created!\nvintextfromtxttraining.json: 100%|█████████| 1200/1200 [00:05<00:00, 237.65it/s]\nloading annotations into memory...\nDone (t=0.06s)\ncreating index...\nindex created!\nICDAR2015_Incidental_train.json: 100%|█████| 1000/1000 [00:03<00:00, 264.33it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"!PYTHONPATH=$PWD python script/make_lmdb.py --split val","metadata":{"id":"bVhqNgRji8Pz","outputId":"dbc083e8-7eea-4d4d-bf5b-4b16387702b9","execution":{"iopub.status.busy":"2024-07-15T10:50:25.730868Z","iopub.execute_input":"2024-07-15T10:50:25.731193Z","iopub.status.idle":"2024-07-15T10:50:32.840864Z","shell.execute_reply.started":"2024-07-15T10:50:25.731160Z","shell.execute_reply":"2024-07-15T10:50:32.839638Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"1. vintext\n2. icdar15\nloading annotations into memory...\nDone (t=0.05s)\ncreating index...\nindex created!\nvintextfromtxttest.json: 100%|███████████████| 300/300 [00:01<00:00, 221.61it/s]\nloading annotations into memory...\nDone (t=0.09s)\ncreating index...\nindex created!\nICDAR2015_Incidental_test.json: 100%|████████| 500/500 [00:01<00:00, 265.45it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"!PYTHONPATH=$PWD python script/make_lmdb.py --split test","metadata":{"execution":{"iopub.status.busy":"2024-07-15T10:50:32.842503Z","iopub.execute_input":"2024-07-15T10:50:32.842878Z","iopub.status.idle":"2024-07-15T10:50:40.949729Z","shell.execute_reply.started":"2024-07-15T10:50:32.842840Z","shell.execute_reply":"2024-07-15T10:50:40.948598Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"1. vintext\n2. icdar15\nloading annotations into memory...\nDone (t=0.08s)\ncreating index...\nindex created!\nvintextfromtxtunseen.json: 100%|█████████████| 500/500 [00:02<00:00, 227.96it/s]\nloading annotations into memory...\nDone (t=0.03s)\ncreating index...\nindex created!\nICDAR2015_Incidental_test.json: 100%|████████| 500/500 [00:02<00:00, 248.83it/s]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Config, chỉnh code của người ta\n","metadata":{"id":"21icxJnuGipN"}},{"cell_type":"code","source":"transformerpy = open('./units/models/transformer.py', 'w')\ntransformerpy.write('''\"\"\" DropBlock, DropPath\n\nPyTorch implementations of DropBlock and DropPath (Stochastic Depth) regularization layers.\n\nPapers:\nDropBlock: A regularization method for convolutional networks (https://arxiv.org/abs/1810.12890)\n\nDeep Networks with Stochastic Depth (https://arxiv.org/abs/1603.09382)\n\nCode:\nDropBlock impl inspired by two Tensorflow impl that I liked:\n - https://github.com/tensorflow/tpu/blob/master/models/official/resnet/resnet_model.py#L74\n - https://github.com/clovaai/assembled-cnn/blob/master/nets/blocks.py\n\nHacked together by / Copyright 2020 Ross Wightman\n\"\"\"\nimport torch\nfrom torch import nn\n\n\ndef init_weights(module):\n    if isinstance(module, nn.Linear):\n        nn.init.normal_(module.weight, std=0.02)\n\n        if module.bias is not None:\n            nn.init.zeros_(module.bias)\n\n    elif isinstance(module, nn.LayerNorm):\n        nn.init.ones_(module.weight)\n        nn.init.zeros_(module.bias)\n\n\nclass MultiHeadAttention(nn.Module):\n    def __init__(self, d_in, n_head, d_head, dropout=0):\n        super().__init__()\n\n        self.n_head = n_head\n        self.d_head = d_head\n\n        d_proj = n_head * d_head\n\n        self.qkv = nn.Linear(d_in, d_proj * 3)\n        self.dropout = nn.Dropout(dropout)\n        self.out = nn.Linear(d_proj, d_in)\n\n        self.apply(init_weights)\n\n    def forward(self, input, mask=None, memory=None):\n        batch, length, dim = input.shape\n\n        qkv = self.qkv(input)\n        q, k, v = qkv.chunk(3, dim=-1)\n\n        # memory remember last layer's attention key and value\n        # These behaviour can be effective to remember long sequence.\n        with torch.no_grad():\n            if memory is not None and \"k\" in memory:\n                k = torch.cat((memory[\"k\"], k), 1)\n                v = torch.cat((memory[\"v\"], v), 1)\n            next_memory = {\"k\": k, \"v\": v}\n\n        q = q.reshape(batch, -1, self.n_head, self.d_head)\n        k = k.reshape(batch, -1, self.n_head, self.d_head)\n        v = v.reshape(batch, -1, self.n_head, self.d_head)\n\n        attn = (q.permute(0, 2, 1, 3) @ k.permute(0, 2, 3, 1)) / (self.d_head ** 0.5)\n\n        if mask is not None:\n            # TODO: use of different value to enable fp16\n            attn.masked_fill_(mask, float(\"-inf\"))\n\n        attn = torch.softmax(attn, -1)\n        attn = self.dropout(attn)\n\n        out = attn @ v.permute(0, 2, 1, 3)\n        out = out.transpose(1, 2).reshape(batch, length, dim)\n        out = self.out(out)\n\n        return out, next_memory\n\n\nclass MultiHeadCrossAttention(nn.Module):\n    def __init__(self, d_in, d_kv, n_head, d_head, dropout=0):\n        super().__init__()\n\n        self.n_head = n_head\n        self.d_head = d_head\n\n        d_proj = n_head * d_head\n\n        self.q = nn.Linear(d_in, d_proj)\n        self.kv = nn.Linear(d_kv, d_proj * 2)\n        self.dropout = nn.Dropout(dropout)\n        self.out = nn.Linear(d_proj, d_in)\n\n        self.apply(init_weights)\n\n    def forward(self, q, kv, mask=None, memory=None):\n        batch, length, dim = q.shape\n\n        q = self.q(q)\n\n        # memory remember last layer's attention key and value\n        # These behaviour can be effective to remember long sequence.\n        if memory is not None:\n            # print(\"memory is not none\")\n            with torch.no_grad():\n                k = memory[\"k\"]\n                v = memory[\"v\"]\n                # print(\"len v1: \", v.shape)\n                mask = memory[\"mask\"]\n\n                next_memory = memory\n\n        else:\n            # print(\"MEMORY IS NONEE\")\n            kv = self.kv(kv)\n            k, v = kv.chunk(2, dim=-1)\n            k = k.reshape(batch, -1, self.n_head, self.d_head)\n            v = v.reshape(batch, -1, self.n_head, self.d_head)\n            # print(\"len kv2: \", kv.shape)\n            # print(\"len v2: \", v.shape)\n\n            next_memory = {\"k\": k, \"v\": v, \"mask\": mask}\n\n        q = q.reshape(batch, -1, self.n_head, self.d_head)\n\n        attn = (q.permute(0, 2, 1, 3) @ k.permute(0, 2, 3, 1)) / (self.d_head ** 0.5)\n\n        if mask is not None:\n            # TODO: use of different value to enable fp16\n            attn.masked_fill_(mask, float(\"-inf\"))\n\n        attn = torch.softmax(attn, -1)\n        attn = self.dropout(attn)\n\n        out = attn @ v.permute(0, 2, 1, 3)\n        out = out.transpose(1, 2).reshape(batch, length, dim)\n        out = self.out(out)\n\n        return out, next_memory\n\n\ndef drop_path(\n    x, drop_prob: float = 0.0, training: bool = False, scale_by_keep: bool = True\n):\n    \"\"\"\n    Drop paths (Stochastic Depth) per sample (when applied in main path of residual blocks).\n    This is the same as the DropConnect impl I created for EfficientNet, etc networks, however,\n    the original name is misleading as 'Drop Connect' is a different form of dropout in a separate paper...\n    See discussion: https://github.com/tensorflow/tpu/issues/494#issuecomment-532968956 ... I've opted for\n    changing the layer and argument names to 'drop path' rather than mix DropConnect as a layer name and use\n    'survival rate' as the argument.\n    \"\"\"\n    if drop_prob == 0.0 or not training:\n        return x\n    keep_prob = 1 - drop_prob\n    shape = (x.shape[0],) + (1,) * (\n        x.ndim - 1\n    )  # work with diff dim tensors, not just 2D ConvNets\n    random_tensor = x.new_empty(shape).bernoulli_(keep_prob)\n    if keep_prob > 0.0 and scale_by_keep:\n        random_tensor.div_(keep_prob)\n    return x * random_tensor\n\n\nclass DropPath(nn.Module):\n    \"\"\"\n    Drop paths (Stochastic Depth) per sample  (when applied in main path of residual blocks).\n    \"\"\"\n\n    def __init__(self, drop_prob: float = 0.0, scale_by_keep: bool = True):\n        super(DropPath, self).__init__()\n        self.drop_prob = drop_prob\n        self.scale_by_keep = scale_by_keep\n\n    def forward(self, x):\n        return drop_path(x, self.drop_prob, self.training, self.scale_by_keep)\n\n\nclass FeedForwardLayer(nn.Module):\n    def __init__(self, dim, dim_mlp, act_layer=nn.GELU, drop_units=0.1):\n        super().__init__()\n        self.dense1 = nn.Linear(dim, dim_mlp)\n        self.act = act_layer()\n        self.dropout = nn.Dropout(drop_units)\n        self.dense2 = nn.Linear(dim_mlp, dim)\n\n        self.apply(init_weights)\n\n    def forward(self, x):\n        return self.dense2(self.dropout(self.act(self.dense1(x))))\n\n\nclass MLP(nn.Module):\n    def __init__(self, num_layers, dim, mlp_ratio, drop_path=0.1, drop_units=0.0):\n        super().__init__()\n\n        self.num_layers = num_layers\n        self.mlp_layers = nn.ModuleList(\n            [\n                FeedForwardLayer(dim, dim * mlp_ratio, drop_units=drop_units)\n                for _ in range(num_layers)\n            ]\n        )\n        self.layernorms = nn.ModuleList(\n            [nn.LayerNorm(dim, eps=1e-6) for _ in range(num_layers)]\n        )\n        self.droppath = DropPath(drop_path)\n\n        self.apply(init_weights)\n\n    def forward(self, x):\n        for i in range(self.num_layers):\n            x_residual = self.mlp_layers[i](self.layernorms[i](x))\n            x = x + self.droppath(x_residual)\n        return x\n\n\nclass MultiwayFeedForwardLayer(nn.Module):\n    def __init__(self, n_experts, dim, dim_mlp, act_layer=nn.GELU, drop_units=0.1):\n        super().__init__()\n\n        self.dim = dim\n        self.ff = nn.ModuleList(\n            [\n                FeedForwardLayer(dim, dim_mlp, act_layer, drop_units)\n                for _ in range(n_experts)\n            ]\n        )\n\n    def compute_expert_idx(self, expert_idx):\n        bs, seq_len = expert_idx.shape[:2]\n        feature_dim_idx = (\n            torch.arange(0, self.dim, device=expert_idx.device)\n            .unsqueeze(0)\n            .unsqueeze(0)\n        )\n        feature_dim_idx = feature_dim_idx.repeat(bs, seq_len, 1)  # bs x seq_len x dim\n        expert_idx = expert_idx.unsqueeze(2) * self.dim  # bs x seq_len x dim\n\n        return expert_idx + feature_dim_idx\n\n    def forward(self, x, expert_idx):\n        feat_all = torch.cat(\n            [ff(x) for ff in self.ff], dim=-1\n        )  # bs x seq_len x (dim * 2)\n        expert_idx = self.compute_expert_idx(expert_idx)  # bs x seq_len x dim\n        return torch.gather(feat_all, 2, expert_idx)\n\n\nclass MultiwayMLP(nn.Module):\n    def __init__(\n        self, num_experts, num_layers, dim, mlp_ratio, drop_path=0.1, drop_units=0.0\n    ):\n        super().__init__()\n\n        self.num_layers = num_layers\n        self.mlp_layers = nn.ModuleList(\n            [\n                MultiwayFeedForwardLayer(\n                    num_experts, dim, dim * mlp_ratio, drop_units=drop_units\n                )\n                for _ in range(num_layers)\n            ]\n        )\n        self.layernorms = nn.ModuleList(\n            [nn.LayerNorm(dim, eps=1e-6) for _ in range(num_layers)]\n        )\n        self.droppath = DropPath(drop_path)\n\n        self.apply(init_weights)\n\n    def forward(self, x, expert_idx):\n        for i in range(self.num_layers):\n            x_residual = self.mlp_layers[i](self.layernorms[i](x), expert_idx)\n            x = x + self.droppath(x_residual)\n        return x\n\n\nclass TransformerEncoderLayer(nn.Module):\n    def __init__(\n        self, dim, n_head, mlp_ratio=4, drop_path=0.1, drop_units=0.1, drop_attn=0.0\n    ):\n        \"\"\"\n        Args:\n            dim (int): hidden dimension\n            n_head (int): number of attention heads\n            mlp_ratio (int): hidden dim expansion in mlp\n            drop_path (float): droppath ratio for both attention and feedforward\n            drop_units (float): dropout ratio for feedforward\n            drop_attn (float): dropout ratio for attention\n        \"\"\"\n        super().__init__()\n\n        self.dim = dim\n\n        self.self_norm = nn.LayerNorm(dim, eps=1e-6)\n        self.self_attn = MultiHeadAttention(\n            dim, n_head, dim // n_head, dropout=drop_attn\n        )\n\n        self.droppath = DropPath(drop_path)  # drop path for attn\n\n        self.mlp = MLP(1, dim, mlp_ratio, drop_path=drop_path, drop_units=drop_units)\n\n    def forward(self, input, mask=None):\n        out = self.self_norm(input)\n        out, _ = self.self_attn(out, mask)\n        input = input + self.droppath(out)\n\n        out = self.mlp(input)\n        return out\n\n\nclass TransformerDecoderLayer(nn.Module):\n    def __init__(\n        self,\n        dim,\n        n_head,\n        n_experts=1,\n        mlp_ratio=4,\n        drop_path=0.1,\n        drop_units=0.1,\n        drop_attn=0.0,\n        self_attention=True,\n        cross_attention=True,\n    ):\n        \"\"\"\n        Args:\n            dim (int): hidden dimension\n            n_head (int): number of attention heads\n            mlp_ratio (int): hidden dim expansion in mlp\n            drop_path (float): droppath ratio for both attention and feedforward\n            drop_units (float): dropout ratio for feedforward\n            drop_attn (float): dropout ratio for attention\n        \"\"\"\n        super().__init__()\n\n        self.self_attention = self_attention\n        if self_attention:\n            self.self_norm = nn.LayerNorm(dim, eps=1e-6)\n            self.self_attn = MultiHeadAttention(\n                dim, n_head, dim // n_head, dropout=drop_attn\n            )\n\n        self.cross_attention = cross_attention\n        if cross_attention:\n            self.cross_norm = nn.LayerNorm(dim, eps=1e-6)\n            self.cross_attn = MultiHeadCrossAttention(\n                dim,\n                dim,\n                n_head,\n                dim // n_head,\n                dropout=drop_attn,\n            )\n\n        self.dim = dim\n        self.n_experts = n_experts\n        if n_experts > 1:\n            self.mlp = MultiwayMLP(\n                n_experts, 1, dim, mlp_ratio, drop_path=drop_path, drop_units=drop_units\n            )\n        else:\n            self.mlp = MLP(\n                1, dim, mlp_ratio, drop_path=drop_path, drop_units=drop_units\n            )\n        self.droppath = DropPath(drop_path)\n\n    def forward(\n        self,\n        input,\n        source,\n        source_mask,\n        memory=None,\n        mask=None,\n        expert_idx=None,\n    ):\n        \"\"\"\n        Args:\n            input (Tensor): Input query with shape (n_query, B, embed_dims)\n            source (Tensor): Encoder output. (8, ?, dim)\n            source_mask (Tensor[bool]): (B, ?)\n            memory (list[dict]): memory of attn \"key\" and \"value\"\n            mask (Tensor): mask tensor. Useful when we use\n                \"teacher forcing\" for training autoregressive model.\n\n        Returns:\n            out\n            next_memory\n        \"\"\"\n        if memory is None:\n            memory = (None, None)\n\n        if self.self_attention:\n            out = self.self_norm(input)\n            out, next_memory1 = self.self_attn(\n                out,\n                memory=memory[0],\n                mask=mask,\n            )\n            input = input + self.droppath(out)\n\n        if self.cross_attention:\n            out = self.cross_norm(input)\n            out, next_memory2 = self.cross_attn(\n                out,\n                source,\n                source_mask,\n                memory=memory[1],\n            )\n            input = input + self.droppath(out)\n\n        if self.n_experts > 1:\n            out = self.mlp(input, expert_idx)\n        else:\n            out = self.mlp(input)\n\n        return out, (next_memory1, next_memory2)\n\n\nclass TransformerEncoder(nn.Module):\n    def __init__(self, encoder_layers):\n        super().__init__()\n        self.encoder_layers = nn.ModuleList(encoder_layers)\n\n    def forward(self, x, mask=None):\n        for layer in self.encoder_layers:\n            x = layer(x, mask)\n\n        return x\n\n\ndef autoregressive_mask(query_size, memory_size, device):\n    mask = torch.triu(\n        torch.ones(\n            query_size, query_size + memory_size, device=device, dtype=torch.bool\n        ),\n        diagonal=memory_size + 1,\n    )\n\n    return mask\n\n\nclass TransformerDecoder(nn.Module):\n    def __init__(self, decoder_layers, autoregressive=True):\n        \"\"\"\n        Args:\n            decoder_layers (List[TransformerDecoderLayer]): decoder layers\n            autoregressive (bool): autoregressive or not\n        \"\"\"\n\n        super().__init__()\n\n        self.layers = nn.ModuleList(decoder_layers)\n        self.norm = nn.LayerNorm(self.layers[0].dim, eps=1e-6)\n\n        self.autoregressive = autoregressive\n\n    def forward(\n        self,\n        input,\n        pos,\n        source,\n        source_mask,\n        memory=None,\n        expert_idx=None,\n    ):\n        \"\"\"\n        Args:\n            input (Tensor): Input query with shape (n_query, B, embed_dims)\n            pos (Tensor): (B, n_query_pos, embed_dims)\n            source (Tensor): Encoder output. (8, ?, dim)\n            source_mask (Tensor[bool]): (B, ?)\n            memory (List[dict]): [Attention key,value] Memory from last decoder block.\n\n        Returns:\n            intermediate (List[Tensor]): list of intermediate tensors (B, n_query, dim)\n            memories (List[dict]): list of attention key-query memory\n        \"\"\"\n        out = input\n        # print(\"out shape: \", out.shape)\n        intermediate = []\n        memories = []\n        memory_size = 0 if memory is None else memory[0][0][\"k\"].shape[-2]\n\n        out = out if pos is None else out + pos\n\n        mask = None\n        if self.autoregressive:\n            mask = autoregressive_mask(input.shape[1], memory_size, device=input.device)\n\n        for i, layer in enumerate(self.layers):\n            cur_memory = None\n            if memory is not None:\n                cur_memory = memory[i]\n            # print(\"outx: \", i, \" \", out.shape)\n            out, next_memory = layer(\n                out,\n                source,\n                source_mask,\n                memory=cur_memory,\n                mask=mask,\n                expert_idx=expert_idx,\n            )\n            # print(\"next_memory len: \", next_memory[0]['k'])\n            # print(\"next_memory len 1: \", len(next_memory[0]['k'][0]))\n            # print(\"next_memory len 2: \", len(next_memory[0]['k'][0][0]))\n            memories.append(next_memory)\n            \n            out_norm = out\n            if i == len(self.layers) - 1:\n                out_norm = self.norm(out_norm)\n\n            intermediate.append(out_norm)\n\n        return intermediate, memories\n''')\ntransformerpy.close()","metadata":{"execution":{"iopub.status.busy":"2024-07-15T10:50:43.991254Z","iopub.execute_input":"2024-07-15T10:50:43.991667Z","iopub.status.idle":"2024-07-15T10:50:44.014730Z","shell.execute_reply.started":"2024-07-15T10:50:43.991627Z","shell.execute_reply":"2024-07-15T10:50:44.013810Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"decoder = open('./units/models/decoder.py', 'w')\ndecoder.write('''\"\"\"\nUNITS\nCopyright (c) 2023-present NAVER Cloud Corp.\nApache-2.0\n\"\"\"\n\nimport numpy as np\nimport torch\nimport torch.nn as nn\nfrom pydantic import StrictBool, StrictInt\n\n\n@torch.no_grad()\ndef greedy_decode(\n    batch_size,\n    device,\n    prev_outputs,\n    n_vocab,\n    max_length,\n    pix2seq_embed,\n    pix2seq_pos,\n    pix2seq_decoder,\n    pix2seq_head,\n    go=1,\n    eos=2,\n    noise=5,\n    text_eos=None,\n    prompt=None,\n    ignore_eos_noise=False,\n    detect_type=None,\n    text_length=25,\n    fixed_text_len=True,\n    multiple_experts=False,\n    **decoder_kwargs,\n):\n    \"\"\"\n    Args:\n        batch_size (int): batch size for decoding\n        device (Union[str, torch.device]): device for decoding\n        n_vocab (int): number of vocabulary for decoding\n        max_length (int): maximum length of sequences that decoded\n        pix2seq_embed (Callable): function that returns tensor given inputs\n        pix2seq_pos (Tensor[float]): positional encoding (max_length, dim)\n        pix2seq_decoder (Callable): transformer decoder\n        pix2seq_head (Callable): function that returns vocab id given decoder output\n        **decoder_kwargs: Rest of the input that should be given to the text decoder\n\n    Returns:\n        logits (Tensor[float]): logit before softmax (batch, max_length, n_vocab)\n        tokens (Tensor[int64]): decoded token ids (batch, max_length)\n    \"\"\"\n    start_token = prompt[0] if len(prompt) else go\n    dec = torch.zeros(batch_size, max_length, n_vocab, device=device)\n    out_texts = torch.ones(batch_size, max_length, dtype=torch.int64, device=device)\n    texts = torch.ones(batch_size, 1, dtype=torch.int64, device=device) * start_token\n    cache = None\n    eos_flag = torch.full((batch_size,), False, dtype=torch.bool, device=device)\n    expert_idx = torch.zeros(batch_size, 1, dtype=torch.int64, device=device)\n\n    detect_type, detect_type_token, num_pts = detect_type\n    span = 1 + num_pts * 2 + text_length\n    next_recog_start_idx = [-1] * batch_size\n\n    for i in range(max_length):\n        # print(\"i::: \", i)\n        # Enforce the beginning of the text to be the previous output.\n        if prev_outputs is not None and i < len(prev_outputs[0]):\n            for batch_i in range(len(prev_outputs)):\n                texts[batch_i, 0] = prev_outputs[batch_i][i]\n\n        # print(\"texts: \", texts)\n        embed = pix2seq_embed(texts)\n\n        pos = pix2seq_pos[i : i + 1].unsqueeze(0).expand(batch_size, -1, -1)\n\n        if multiple_experts:\n            expert_idx = refine_expert_idx(i, next_recog_start_idx, expert_idx)\n\n        # print(\"expert_idx: \", expert_idx)\n        decode_res = pix2seq_decoder(\n            embed,\n            pos,\n            memory=cache,\n            expert_idx=expert_idx if multiple_experts else None,\n            **decoder_kwargs,\n        )\n        decode = decode_res[0]\n        cache = decode_res[-1]\n        # print(\"cache: \", cache)\n\n        output_class = pix2seq_head(decode[-1])\n        next_step = output_class[:, -1]\n        # print(\"next_step: \", next_step)\n\n        if ignore_eos_noise:\n            next_step[:, eos] = -torch.tensor(float(\"inf\"))\n            next_step[:, noise] = -torch.tensor(float(\"inf\"))\n\n        next_token = next_step.argmax(1)\n\n        # Enforce the beginning of the text to be the prompt\n        if i < len(prompt):\n            if i == len(prompt) - 1:\n                next_token = (\n                    torch.ones(batch_size, dtype=torch.int64, device=device) * go\n                )\n            else:\n                next_token = (\n                    torch.ones(batch_size, dtype=torch.int64, device=device)\n                    * prompt[i + 1]\n                )\n\n        if fixed_text_len and (i - len(prompt)) % span == 0:\n            next_token = (\n                torch.ones(batch_size, dtype=torch.int64, device=device)\n                * detect_type_token\n            )\n            if multiple_experts:\n                expert_idx = torch.zeros(\n                    batch_size, 1, dtype=torch.int64, device=device\n                )\n                next_recog_start_idx = [i + num_pts * 2 + 1] * batch_size\n                # print(\"next_recog_start_idx: \", next_recog_start_idx)\n        elif fixed_text_len is False and i > 0:\n            for j in range(texts.shape[0]):\n                if texts[j, 0] in [text_eos, go]:\n                    next_token[j] = detect_type_token\n                    if multiple_experts:\n                        expert_idx[j] = 0\n                        next_recog_start_idx[j] = i + num_pts * 2 + 1\n\n        # print(\"next_token: \", next_token)\n        texts = next_token.unsqueeze(1)\n        out_texts[:, i] = next_token\n        dec[:, i, :] = next_step\n        eos_cond = next_token == eos\n        eos_flag = eos_flag | eos_cond\n\n        if eos_flag.all():\n            break\n\n    return torch.softmax(dec, dim=-1), out_texts\n\n\ndef refine_expert_idx(curr_step_i, next_recog_start_idx, expert_idx):\n    for batch_i, step_i in enumerate(next_recog_start_idx):\n        if step_i < 0:\n            continue\n        if curr_step_i == step_i:\n            expert_idx[batch_i] = 1\n\n    return expert_idx\n\n\nclass UnitsDecoder(nn.Module):\n    \"\"\"\n    Units Decoder\n    Args:\n        dim (int): hidden dimension\n        decoder_length (int): decoder max length\n    \"\"\"\n\n    def __init__(\n        self,\n        dim: StrictInt,\n        max_text_length: StrictInt,\n        pix2seq_dec: nn.Module,\n        loss_criterion: nn.Module,\n        n_object: StrictInt,\n        decoder_length: StrictInt,\n        tokenizer,\n        prompt,\n        detect_type,\n        fixed_text_len: StrictBool,\n        coord_order,\n        iterative_decoding=False,\n        max_iter=15,\n        n_overlap=4,\n    ):\n        super().__init__()\n\n        self.dim = dim\n        self.max_text_length = max_text_length\n\n        self.pix2seq_decoder = pix2seq_dec\n\n        self.tokenizer = tokenizer\n        \n        # print(\"n_vocab ne \", self.tokenizer.n_vocab)\n        \n        self.n_vocab = self.tokenizer.n_vocab\n\n        self.go = tokenizer.go\n        self.eos = tokenizer.eos\n        # special tokens index (noise, special prompts)\n        self.noise = tokenizer.vocab[\"[noise]\"]\n        self.roi = tokenizer.vocab[\"[roi]\"]\n        self.order = tokenizer.vocab[\"[order]\"]\n        self.point = tokenizer.vocab[\"[point]\"]\n        self.text_eos = tokenizer.vocab[\"[text_eos]\"]\n\n        self.bin_size = tokenizer.bin_size\n        self.coord_vocab_range = (\n            tokenizer.encode_coord(0),\n            tokenizer.encode_coord(self.bin_size - 1),\n        )\n\n        self.prompt = prompt\n        if prompt is not None:\n            assert prompt in [\"roi\", \"order\", \"point\"]\n\n        self.decoder_length = decoder_length\n        if self.prompt == \"order\":\n            self.order_vocab_range = (\n                tokenizer.encode_order(0),\n                tokenizer.encode_order(n_object - 1),\n            )\n\n        self.pix2seq_head = nn.Linear(dim, self.n_vocab)\n        self.pix2seq_embed = nn.Embedding(self.n_vocab, dim, padding_idx=None)\n        self.pix2seq_pos = nn.Parameter(torch.randn(decoder_length, dim) * 0.02)\n\n        self.loss_criterion = loss_criterion\n\n        num_pts_dict = {\n            \"single\": 1,\n            \"box\": 2,\n            \"quad\": 4,\n            \"polygon\": 16,\n        }\n        assert detect_type in num_pts_dict\n        self.num_pts_dict = num_pts_dict\n        self.detect_type = (\n            f\"[{detect_type}]\",\n            self.tokenizer.vocab[f\"[{detect_type}]\"],\n            num_pts_dict[detect_type],\n        )\n        self.token2npts = {\n            self.tokenizer.vocab[f\"[{dtype}]\"]: num_pts\n            for dtype, num_pts in num_pts_dict.items()\n        }\n\n        self.fixed_text_len = fixed_text_len\n        self.coord_order = coord_order\n        assert coord_order in [\"xy\", \"yx\"]\n\n        self.iterative_decoding = iterative_decoding\n        self.max_iter = max_iter if self.iterative_decoding else 1\n        self.n_overlap = n_overlap\n\n    def forward(\n        self,\n        batch,\n        source_feat,\n        mask,\n        detect_type=None,\n        threshold=0.0,\n    ):\n        \"\"\"\n        Args:\n            batch (Batch): instance of Batch with Pix2SeqBatch fields\n            source_feat (Tensor[float]): flattened and concatenated features (N, ?, dim)\n            mask (Tensor[bool]): True for non-image areas and False for image areas (N, H, W)\n            threshold (float): confidence threshold for filter out entities\n        \"\"\"\n\n        if self.training:\n            return self.forward_train(\n                batch,\n                source_feat,\n                mask,\n            )\n\n        else:\n            return self.forward_eval(\n                batch,\n                source_feat,\n                mask,\n                detect_type,\n                threshold,\n            )\n\n    def forward_train(\n        self,\n        batch,\n        feats,\n        mask,\n    ):\n        outputs = {}\n        pix2seq_in = batch.units.units_inputs\n        \n        # a = 0\n        # for i in pix2seq_in:\n        #     print(\"Hi\")\n        #     for j in i:\n        #         print(a, \" \", j)\n        #         a += 1\n        #     break\n        \n        # a = 0\n        # for i in batch.units.units_targets:\n        #     print(\"HELLO\")\n        #     for j in i:\n        #         print(a, \" \", j)\n        #         a += 1\n        #     break\n        \n        pix2seq_embed = self.pix2seq_embed(pix2seq_in)\n        pix2seq_pos = self.pix2seq_pos\n        pix2seq_pos = pix2seq_pos.unsqueeze(0).expand(pix2seq_in.shape[0], -1, -1)\n\n        source_mask = torch.unsqueeze(mask, 1).expand(-1, pix2seq_pos.shape[1], -1)\n        source_mask = source_mask.unsqueeze(1)\n        # source_mask = None\n\n        expert_idx = batch.units.tasks\n        pix2seq_out, _ = self.pix2seq_decoder(\n            pix2seq_embed, pix2seq_pos, feats, source_mask, expert_idx=expert_idx\n        )\n\n        output_logit = self.pix2seq_head(pix2seq_out[-1])\n\n        # print(batch.units.units_targets.reshape(-1))\n        # print(\"output_logit shape: \", output_logit.shape)\n        # print(\"output_logit argmax shape: \", output_logit[0].argmax(1).shape)\n        \n        # print(\"Hello\")\n        # for i in range(1024):\n        #     print(i, \"- target: \", batch.units.units_targets[0][i], \" input: \", pix2seq_in[0][i], \", output: \", output_logit[0].argmax(1)[i])\n\n        loss = self.loss_criterion(\n            output_logit.reshape(-1, output_logit.shape[-1]).contiguous(),\n            batch.units.units_targets.reshape(-1),\n        )\n\n        outputs.update(\n            {\n                \"total_loss\": loss,\n            }\n        )\n\n        return outputs\n\n    def forward_eval(\n        self,\n        batch,\n        feats,\n        mask,\n        detect_type,\n        threshold,\n    ):\n        if detect_type is not None:\n            assert detect_type in self.num_pts_dict\n            self.num_pts_dict = self.num_pts_dict\n            self.detect_type = (\n                f\"[{detect_type}]\",\n                self.tokenizer.vocab[f\"[{detect_type}]\"],\n                self.num_pts_dict[detect_type],\n            )\n            self.token2npts = {\n                self.tokenizer.vocab[f\"[{dtype}]\"]: num_pts\n                for dtype, num_pts in self.num_pts_dict.items()\n            }\n\n        outputs = {}\n\n        if self.prompt == \"roi\":\n            prompt_input = [\n                self.roi,\n                self.coord_vocab_range[0],\n                self.coord_vocab_range[0],\n                self.coord_vocab_range[1],\n                self.coord_vocab_range[1],\n            ]\n        elif self.prompt == \"order\":\n            prompt_input = [\n                self.order,\n                self.order_vocab_range[0],\n                self.order_vocab_range[1],\n            ]\n        elif self.prompt == \"point\":\n            prompt_input = [\n                self.point,\n                self.coord_vocab_range[0],\n                self.coord_vocab_range[0],\n            ]\n        else:\n            prompt_input = []\n\n        source_mask = torch.unsqueeze(torch.unsqueeze(mask, 1), 2)\n        # source_mask = None\n\n        prev_outputs = None\n\n        merged_output_logit, merged_output_ids = [], []\n        for _ in range(self.max_iter):\n            output_logit, output_ids = greedy_decode(\n                batch.images.shape[0],\n                feats.device,\n                prev_outputs,\n                self.n_vocab,\n                self.decoder_length,\n                self.pix2seq_embed,\n                self.pix2seq_pos,\n                self.pix2seq_decoder,\n                self.pix2seq_head,\n                go=self.go,\n                eos=self.eos,\n                noise=self.noise,\n                text_eos=self.text_eos,\n                prompt=prompt_input,\n                source=feats,\n                source_mask=source_mask,\n                detect_type=self.detect_type,\n                text_length=self.max_text_length,\n                fixed_text_len=self.fixed_text_len,\n                multiple_experts=self.pix2seq_decoder.layers[0].n_experts > 1,\n            )\n\n            merged_output_logit.append(output_logit)\n            merged_output_ids.append(output_ids)\n            # print(\"len(merged_output_ids)\", len(merged_output_ids))\n            if self.iterative_decoding:\n                prev_outputs = self.determine_last_objects(\n                    output_ids, detect_type=self.detect_type, n_overlap=self.n_overlap\n                )\n                # print(\"output_ids: \", output_ids)\n                # x = 1\n                # for i in output_ids[0]:\n                #     if i == 0 and x == 0:\n                #         continue\n                #     if i == 0:\n                #         print(\"HI\")\n                #         x = 0\n                #         continue\n                #     x = 1\n                #     print(i)\n                \n                prev_outputs = self.add_point_prompt(\n                    prev_outputs, detect_type=self.detect_type\n                )\n                # print(\"prev_outputs: \", prev_outputs)\n\n        vertices = []\n        scores = []\n        texts = []\n\n        eos_flags = [False] * output_ids.shape[0]\n\n        for i in range(len(merged_output_logit)):\n            # print(\"i: \", i)\n            output_ids = merged_output_ids[i]\n            output_logit = merged_output_logit[i]\n\n            for batch_i in range(output_ids.shape[0]):\n                # print(\"batch_i: \", batch_i)\n                if eos_flags[batch_i] == True:\n                    continue\n\n                if self.eos in output_ids[batch_i, len(prompt_input) :].tolist():\n                    eos_flags[batch_i] = True\n\n                h, w = batch.samples[batch_i].image_size\n\n                curr_vertices, curr_scores, curr_texts = self.convert_seq2ocr(\n                    output_logit[batch_i, len(prompt_input) :].tolist(),\n                    output_ids[batch_i, len(prompt_input) :].tolist(),\n                    h,\n                    w,\n                    threshold,\n                    self.fixed_text_len,\n                    self.text_eos,\n                    self.coord_order,\n                )\n                # print(\"curr_texts: \", curr_texts)\n                if i == 0:\n                    vertices.append(curr_vertices)\n                    scores.append(curr_scores)\n                    texts.append(curr_texts)\n                else:\n                    if (\n                        curr_vertices is not None\n                        and len(curr_vertices) > self.n_overlap\n                    ):\n                        # print(\"JJJ: \", vertices[batch_i])\n                        vertices[batch_i].extend(curr_vertices[self.n_overlap :])\n                        scores[batch_i].extend(curr_scores[self.n_overlap :])\n                        texts[batch_i].extend(curr_texts[self.n_overlap :])\n\n        outputs.update(\n            {\n                \"texts\": texts,\n                \"vertices\": vertices,\n                \"scores\": scores,\n            }\n        )\n\n        return outputs\n\n    def convert_seq2ocr(\n        self,\n        logit,\n        ids,\n        h,\n        w,\n        threshold=0.0,\n        fixed_text_len=True,\n        text_eos=0,\n        coord_order=\"xy\",\n    ):\n        \"\"\"\n        Convert sequence to OCR results.\n        \"\"\"\n        if self.tokenizer.eos in ids:\n            first_eos_ids = ids.index(self.tokenizer.eos)\n            ids = ids[:first_eos_ids]\n            logit = logit[:first_eos_ids]\n\n        min_idx_coord_vocab, max_idx_coord_vocab = self.coord_vocab_range\n\n        curr_vertices = []\n        curr_scores = []\n        curr_texts = []\n\n        # Split instances by detect type tokens.\n        start_ids, end_ids, num_pts_list = [], [], []\n        for i, idx in enumerate(ids):\n            if idx in self.token2npts:\n                start_ids.append(i)\n\n                num_pts = self.token2npts[idx]\n                num_pts_list.append(num_pts)\n\n                if fixed_text_len:\n                    span = 2 * num_pts + 1 + self.max_text_length\n                    if i + span - 1 < self.decoder_length:\n                        end_ids.append(i + span - 1)\n                elif idx == text_eos:\n                    end_ids.append(i)\n\n        # Convert tokens to vertices & text transcriptions.\n        for start_id, end_id, num_pts in zip(start_ids, end_ids, num_pts_list):\n            object = ids[start_id : end_id + 1]\n            if any(\n                [\n                    p < min_idx_coord_vocab or p > max_idx_coord_vocab\n                    for p in object[1 : 1 + 2 * num_pts]\n                ]\n            ):\n                continue\n\n            if len(object[1 : 1 + 2 * num_pts]) < 2 * num_pts:\n                continue\n\n            score = logit[start_id : end_id + 1]\n\n            mean_score = []\n            for i, p in enumerate(object[1 + 2 * num_pts :]):\n                if p == 0:\n                    break\n                mean_score.append(score[i + 1 + 2 * num_pts][p])\n            object_score = np.mean(mean_score)\n\n            vertices = list(\n                map(\n                    lambda x: self.tokenizer.decode_coord(x),\n                    object[1 : 1 + 2 * num_pts],\n                )\n            )\n\n            vertices = np.array(vertices, dtype=np.float32).reshape(num_pts, 2)\n            if coord_order == \"xy\":\n                vertices[:, 0], vertices[:, 1] = vertices[:, 0] * w / (\n                    self.bin_size - 1\n                ), vertices[:, 1] * h / (self.bin_size - 1)\n            else:\n                vertices[:, 0], vertices[:, 1] = vertices[:, 1] * h / (\n                    self.bin_size - 1\n                ), vertices[:, 0] * w / (self.bin_size - 1)\n\n            text = object[1 + 2 * num_pts :]\n            \n            # print(\"text: \", text)\n            # print(\"object_score: \", object_score)\n\n            if object_score >= threshold:\n                curr_vertices.append(vertices)\n                curr_scores.append(object_score)\n                curr_texts.append(text)\n\n        if curr_vertices == []:\n            curr_vertices = []\n            curr_scores = []\n            curr_texts = []\n            # curr_vertices = None\n            # curr_scores = None\n            # curr_texts = None\n\n        return curr_vertices, curr_scores, curr_texts\n\n    def determine_last_objects(\n        self, output_ids, detect_type, fixed_text_len=True, n_overlap=1\n    ):\n        \"\"\"\n        Determine last object tokens (n_overlap) for iterative decoding.\n        \"\"\"\n        detect_type, detect_type_token, num_pts = detect_type\n\n        # TODO: implement fixed_text_len=False\n        assert fixed_text_len == True\n        span = 2 * num_pts + self.max_text_length\n\n        last_object_tokens = []\n        for batch_i in range(output_ids.shape[0]):\n            batch_output_ids = output_ids[batch_i].tolist()\n            batch_last_object_tokens = []\n            if self.tokenizer.eos in batch_output_ids:\n                batch_last_object_tokens.append(detect_type_token)\n                batch_last_object_tokens.extend([self.tokenizer.eos] * span)\n\n                for _ in range(n_overlap - 1):\n                    batch_last_object_tokens.extend([self.tokenizer.eos])\n                    batch_last_object_tokens.extend([self.tokenizer.eos] * span)\n            else:\n                detect_type_ids = []\n                for token_i, token in enumerate(batch_output_ids):\n                    if token == detect_type_token:\n                        detect_type_ids.append(token_i)\n\n                # If last object is full\n                if detect_type_ids[-1] < self.decoder_length - span:\n                    for j in range(n_overlap - 1, -1, -1):\n                        batch_last_object_tokens.extend(\n                            batch_output_ids[\n                                detect_type_ids[-1 - j] : detect_type_ids[-1 - j]\n                                + span\n                                + 1\n                            ]\n                        )\n                else:\n                    for j in range(n_overlap - 1, -1, -1):\n                        batch_last_object_tokens.extend(\n                            batch_output_ids[\n                                detect_type_ids[-2 - j] : detect_type_ids[-2 - j]\n                                + span\n                                + 1\n                            ]\n                        )\n            last_object_tokens.append(batch_last_object_tokens)\n\n        return last_object_tokens\n\n    def add_point_prompt(self, prev_inputs, detect_type):\n        \"\"\"\n        Add starting-point prompt tokens to the beginning of the input tokens.\n        \"\"\"\n        detect_type, detect_type_token, num_pts = detect_type\n\n        for batch_i in range(len(prev_inputs)):\n            coords = prev_inputs[batch_i][1 : 2 * num_pts + 1]\n            if self.tokenizer.eos in coords:\n                # print(\"self.tokenizer.eos in coords XXXX\")\n                prev_inputs[batch_i] = [\n                    self.point,\n                    self.coord_vocab_range[0],\n                    self.coord_vocab_range[0],\n                    self.tokenizer.go,\n                ] + prev_inputs[batch_i]\n            else:\n                # print(\"self.tokenizer.eos NOT in coords XXXX\")\n                coords = [self.tokenizer.decode_coord(coord) for coord in coords]\n                prompt_x, prompt_y = self.tokenizer.encode_coord_xy(\n                    int(np.mean(coords[::2])), int(np.mean(coords[1::2]))\n                )\n                prev_inputs[batch_i] = [\n                    self.point,\n                    prompt_x,\n                    prompt_y,\n                    self.tokenizer.go,\n                ] + prev_inputs[batch_i]\n\n        return prev_inputs\n''')\ndecoder.close()","metadata":{"execution":{"iopub.status.busy":"2024-07-15T10:50:44.227835Z","iopub.execute_input":"2024-07-15T10:50:44.228132Z","iopub.status.idle":"2024-07-15T10:50:44.254948Z","shell.execute_reply.started":"2024-07-15T10:50:44.228108Z","shell.execute_reply":"2024-07-15T10:50:44.254047Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# decoder = open('./units/models/decoder.py', 'w')\n# decoder.write('''\"\"\"\n# UNITS\n# Copyright (c) 2023-present NAVER Cloud Corp.\n# Apache-2.0\n# \"\"\"\n\n# import numpy as np\n# import torch\n# import torch.nn as nn\n# from pydantic import StrictBool, StrictInt\n\n\n# @torch.no_grad()\n# def greedy_decode(\n#     batch_size,\n#     device,\n#     prev_outputs,\n#     n_vocab,\n#     max_length,\n#     pix2seq_embed,\n#     pix2seq_pos,\n#     pix2seq_decoder,\n#     pix2seq_head,\n#     go=1,\n#     eos=2,\n#     noise=5,\n#     text_eos=None,\n#     prompt=None,\n#     ignore_eos_noise=False,\n#     detect_type=None,\n#     text_length=25,\n#     fixed_text_len=True,\n#     multiple_experts=False,\n#     **decoder_kwargs,\n# ):\n#     \"\"\"\n#     Args:\n#         batch_size (int): batch size for decoding\n#         device (Union[str, torch.device]): device for decoding\n#         n_vocab (int): number of vocabulary for decoding\n#         max_length (int): maximum length of sequences that decoded\n#         pix2seq_embed (Callable): function that returns tensor given inputs\n#         pix2seq_pos (Tensor[float]): positional encoding (max_length, dim)\n#         pix2seq_decoder (Callable): transformer decoder\n#         pix2seq_head (Callable): function that returns vocab id given decoder output\n#         **decoder_kwargs: Rest of the input that should be given to the text decoder\n\n#     Returns:\n#         logits (Tensor[float]): logit before softmax (batch, max_length, n_vocab)\n#         tokens (Tensor[int64]): decoded token ids (batch, max_length)\n#     \"\"\"\n#     start_token = prompt[0] if len(prompt) else go\n#     dec = torch.zeros(batch_size, max_length, n_vocab, device=device)\n#     out_texts = torch.ones(batch_size, max_length, dtype=torch.int64, device=device)\n#     texts = torch.ones(batch_size, 1, dtype=torch.int64, device=device) * start_token\n#     cache = None\n#     eos_flag = torch.full((batch_size,), False, dtype=torch.bool, device=device)\n#     expert_idx = torch.zeros(batch_size, 1, dtype=torch.int64, device=device)\n\n#     detect_type, detect_type_token, num_pts = detect_type\n#     span = 1 + num_pts * 2 + text_length\n#     next_recog_start_idx = [-1] * batch_size\n\n#     for i in range(max_length):\n#         # print(\"i::: \", i)\n#         # Enforce the beginning of the text to be the previous output.\n#         if prev_outputs is not None and i < len(prev_outputs[0]):\n#             for batch_i in range(len(prev_outputs)):\n#                 texts[batch_i, 0] = prev_outputs[batch_i][i]\n\n#         # print(\"texts: \", texts)\n#         embed = pix2seq_embed(texts)\n\n#         pos = pix2seq_pos[i : i + 1].unsqueeze(0).expand(batch_size, -1, -1)\n\n#         if multiple_experts:\n#             expert_idx = refine_expert_idx(i, next_recog_start_idx, expert_idx)\n\n#         # print(\"expert_idx: \", expert_idx)\n#         decode_res = pix2seq_decoder(\n#             embed,\n#             pos,\n#             memory=cache,\n#             expert_idx=expert_idx if multiple_experts else None,\n#             **decoder_kwargs,\n#         )\n#         decode = decode_res[0]\n#         cache = decode_res[-1]\n#         # print(\"cache: \", cache)\n\n#         output_class = pix2seq_head(decode[-1])\n#         next_step = output_class[:, -1]\n#         # print(\"next_step: \", next_step)\n\n#         if ignore_eos_noise:\n#             next_step[:, eos] = -torch.tensor(float(\"inf\"))\n#             next_step[:, noise] = -torch.tensor(float(\"inf\"))\n\n#         next_token = next_step.argmax(1)\n\n#         # Enforce the beginning of the text to be the prompt\n#         if i < len(prompt):\n#             if i == len(prompt) - 1:\n#                 next_token = (\n#                     torch.ones(batch_size, dtype=torch.int64, device=device) * go\n#                 )\n#             else:\n#                 next_token = (\n#                     torch.ones(batch_size, dtype=torch.int64, device=device)\n#                     * prompt[i + 1]\n#                 )\n\n#         if fixed_text_len and (i - len(prompt)) % span == 0:\n#             next_token = (\n#                 torch.ones(batch_size, dtype=torch.int64, device=device)\n#                 * detect_type_token\n#             )\n#             if multiple_experts:\n#                 expert_idx = torch.zeros(\n#                     batch_size, 1, dtype=torch.int64, device=device\n#                 )\n#                 next_recog_start_idx = [i + num_pts * 2 + 1] * batch_size\n#                 # print(\"next_recog_start_idx: \", next_recog_start_idx)\n#         elif fixed_text_len is False and i > 0:\n#             for j in range(texts.shape[0]):\n#                 if texts[j, 0] in [text_eos, go]:\n#                     next_token[j] = detect_type_token\n#                     if multiple_experts:\n#                         expert_idx[j] = 0\n#                         next_recog_start_idx[j] = i + num_pts * 2 + 1\n\n#         # print(\"next_token: \", next_token)\n#         texts = next_token.unsqueeze(1)\n#         out_texts[:, i] = next_token\n#         dec[:, i, :] = next_step\n#         eos_cond = next_token == eos\n#         eos_flag = eos_flag | eos_cond\n\n#         if eos_flag.all():\n#             break\n\n#     return torch.softmax(dec, dim=-1), out_texts\n\n\n# def refine_expert_idx(curr_step_i, next_recog_start_idx, expert_idx):\n#     for batch_i, step_i in enumerate(next_recog_start_idx):\n#         if step_i < 0:\n#             continue\n#         if curr_step_i == step_i:\n#             expert_idx[batch_i] = 1\n\n#     return expert_idx\n\n\n# class UnitsDecoder(nn.Module):\n#     \"\"\"\n#     Units Decoder\n#     Args:\n#         dim (int): hidden dimension\n#         decoder_length (int): decoder max length\n#     \"\"\"\n\n#     def __init__(\n#         self,\n#         dim: StrictInt,\n#         max_text_length: StrictInt,\n#         pix2seq_dec: nn.Module,\n#         loss_criterion: nn.Module,\n#         n_object: StrictInt,\n#         decoder_length: StrictInt,\n#         tokenizer,\n#         prompt,\n#         detect_type,\n#         fixed_text_len: StrictBool,\n#         coord_order,\n#         iterative_decoding=False,\n#         max_iter=15,\n#         n_overlap=4,\n#     ):\n#         super().__init__()\n\n#         self.dim = dim\n#         self.max_text_length = max_text_length\n\n#         self.pix2seq_decoder = pix2seq_dec\n\n#         self.tokenizer = tokenizer\n        \n#         print(\"n_vocab ne \", self.tokenizer.n_vocab)\n        \n#         self.n_vocab = self.tokenizer.n_vocab\n\n#         self.go = tokenizer.go\n#         self.eos = tokenizer.eos\n#         # special tokens index (noise, special prompts)\n#         self.noise = tokenizer.vocab[\"[noise]\"]\n#         self.roi = tokenizer.vocab[\"[roi]\"]\n#         self.order = tokenizer.vocab[\"[order]\"]\n#         self.point = tokenizer.vocab[\"[point]\"]\n#         self.text_eos = tokenizer.vocab[\"[text_eos]\"]\n\n#         self.bin_size = tokenizer.bin_size\n#         self.coord_vocab_range = (\n#             tokenizer.encode_coord(0),\n#             tokenizer.encode_coord(self.bin_size - 1),\n#         )\n\n#         self.prompt = prompt\n#         if prompt is not None:\n#             assert prompt in [\"roi\", \"order\", \"point\"]\n\n#         self.decoder_length = decoder_length\n#         if self.prompt == \"order\":\n#             self.order_vocab_range = (\n#                 tokenizer.encode_order(0),\n#                 tokenizer.encode_order(n_object - 1),\n#             )\n\n#         self.pix2seq_head = nn.Linear(dim, self.n_vocab)\n#         self.pix2seq_embed = nn.Embedding(self.n_vocab, dim, padding_idx=None)\n#         self.pix2seq_pos = nn.Parameter(torch.randn(decoder_length, dim) * 0.02)\n\n#         self.loss_criterion = loss_criterion\n        \n#         self.numpts = {1111: 2, 1112: 4, 1113: 8, 1114: 32}\n\n#         num_pts_dict = {\n#             \"single\": 1,\n#             \"box\": 2,\n#             \"quad\": 4,\n#             \"polygon\": 16,\n#         }\n#         assert detect_type in num_pts_dict\n#         self.num_pts_dict = num_pts_dict\n#         self.detect_type = (\n#             f\"[{detect_type}]\",\n#             self.tokenizer.vocab[f\"[{detect_type}]\"],\n#             num_pts_dict[detect_type],\n#         )\n#         self.token2npts = {\n#             self.tokenizer.vocab[f\"[{dtype}]\"]: num_pts\n#             for dtype, num_pts in num_pts_dict.items()\n#         }\n\n#         self.fixed_text_len = fixed_text_len\n#         self.coord_order = coord_order\n#         assert coord_order in [\"xy\", \"yx\"]\n\n#         self.iterative_decoding = iterative_decoding\n#         self.max_iter = max_iter if self.iterative_decoding else 1\n#         self.n_overlap = n_overlap\n\n#     def forward(\n#         self,\n#         batch,\n#         source_feat,\n#         mask,\n#         detect_type=None,\n#         threshold=0.0,\n#     ):\n#         \"\"\"\n#         Args:\n#             batch (Batch): instance of Batch with Pix2SeqBatch fields\n#             source_feat (Tensor[float]): flattened and concatenated features (N, ?, dim)\n#             mask (Tensor[bool]): True for non-image areas and False for image areas (N, H, W)\n#             threshold (float): confidence threshold for filter out entities\n#         \"\"\"\n\n#         if self.training:\n#             return self.forward_train(\n#                 batch,\n#                 source_feat,\n#                 mask,\n#             )\n\n#         else:\n#             return self.forward_eval(\n#                 batch,\n#                 source_feat,\n#                 mask,\n#                 detect_type,\n#                 threshold,\n#             )\n\n#     def teacherforcing(self, input, batch, feats, mask):\n#         # pix2seq_in = batch.units.units_inputs\n#         pix2seq_in = input\n#         pix2seq_embed = self.pix2seq_embed(pix2seq_in)\n#         pix2seq_pos = self.pix2seq_pos\n#         pix2seq_pos = pix2seq_pos.unsqueeze(0).expand(pix2seq_in.shape[0], -1, -1)\n\n#         source_mask = torch.unsqueeze(mask, 1).expand(-1, pix2seq_pos.shape[1], -1)\n#         source_mask = source_mask.unsqueeze(1)\n#         # source_mask = None\n\n#         expert_idx = batch.units.tasks\n#         pix2seq_out, _ = self.pix2seq_decoder(\n#             pix2seq_embed, pix2seq_pos, feats, source_mask, expert_idx=expert_idx\n#         )\n\n#         output_logit = self.pix2seq_head(pix2seq_out[-1])\n        \n#         return output_logit\n    \n#     def mix(self, input, previous_output, sampling_probability):\n\n#         sample_mask = torch.rand(input.shape, device=input.device) < sampling_probability\n        \n#         sample_mask[:,:4] = False\n#         # sample_mask[:,:input.shape[1]//5] = False\n        \n#         # a = 0\n#         # for i in input[0]:\n#         #     print(a, \" \", i)\n#         #     a += 1\n        \n#         for batch_i in range(input.shape[0]):\n#             # print(\"batch_i: \", batch_i)\n#             i = 4\n#             while i < input.shape[1]:\n#                 # print(\"i: \", i)\n#                 detectoken = input[batch_i, i].item()\n#                 if detectoken == 2:\n#                     break\n#                 cur_numpts = self.numpts[detectoken]\n#                 sample_mask[batch_i, i] = False\n#                 i += (cur_numpts + 26)\n        \n#         intermedia_output = torch.zeros(input.shape, device=input.device, dtype=torch.long)\n#         for batch_i in range(input.shape[0]):\n#             # intermedia_output[batch_i] = [input[batch_i][i] if sample_mask[batch_i][i] \n#             #                     else previous_output[batch_i][i-1] \n#             #                     for i in range(input.shape[1])]\n#             for i in range(input.shape[1]):\n#                 if sample_mask[batch_i, i]:\n#                     intermedia_output[batch_i, i] = previous_output[batch_i, i - 1]\n#                 else:\n#                     intermedia_output[batch_i, i] = input[batch_i, i]\n                    \n#         return intermedia_output\n\n#     def forward_train(\n#         self,\n#         batch,\n#         feats,\n#         mask,\n#     ):\n#         outputs = {}\n#         pix2seq_in = batch.units.units_inputs\n#         # pix2seq_embed = self.pix2seq_embed(pix2seq_in)\n#         # pix2seq_pos = self.pix2seq_pos\n#         # pix2seq_pos = pix2seq_pos.unsqueeze(0).expand(pix2seq_in.shape[0], -1, -1)\n\n#         # source_mask = torch.unsqueeze(mask, 1).expand(-1, pix2seq_pos.shape[1], -1)\n#         # source_mask = source_mask.unsqueeze(1)\n#         # # source_mask = None\n\n#         # expert_idx = batch.units.tasks\n#         # pix2seq_out, _ = self.pix2seq_decoder(\n#         #     pix2seq_embed, pix2seq_pos, feats, source_mask, expert_idx=expert_idx\n#         # )\n\n#         # output_logit = self.pix2seq_head(pix2seq_out[-1])\n        \n#         with torch.no_grad():\n#             intermediate_logit = self.teacherforcing(pix2seq_in, batch, feats, mask)\n#             intermediate_output = torch.argmax(intermediate_logit, dim=-1)\n#             mixed_input = self.mix(pix2seq_in, intermediate_output, 0.9)\n            \n#         output_logit = self.teacherforcing(mixed_input, batch, feats, mask)\n        \n#         # print(\"output_logit shape: \", mixed_input.shape)\n#         # print(\"output_logit argmax shape: \", mixed_input[0].argmax(1).shape)\n        \n#         # print(\"Hello\")\n#         # for i in range(1024):\n#         #     print(i, \"- target: \", batch.units.units_targets[0][i], \" input: \", pix2seq_in[0][i], \", output: \", mixed_input[0][i])\n        \n\n#         loss = self.loss_criterion(\n#             output_logit.reshape(-1, output_logit.shape[-1]).contiguous(),\n#             batch.units.units_targets.reshape(-1),\n#         )\n\n#         outputs.update(\n#             {\n#                 \"total_loss\": loss,\n#             }\n#         )\n\n#         return outputs\n\n#     def forward_eval(\n#         self,\n#         batch,\n#         feats,\n#         mask,\n#         detect_type,\n#         threshold,\n#     ):\n#         if detect_type is not None:\n#             assert detect_type in self.num_pts_dict\n#             self.num_pts_dict = self.num_pts_dict\n#             self.detect_type = (\n#                 f\"[{detect_type}]\",\n#                 self.tokenizer.vocab[f\"[{detect_type}]\"],\n#                 self.num_pts_dict[detect_type],\n#             )\n#             self.token2npts = {\n#                 self.tokenizer.vocab[f\"[{dtype}]\"]: num_pts\n#                 for dtype, num_pts in self.num_pts_dict.items()\n#             }\n\n#         outputs = {}\n\n#         if self.prompt == \"roi\":\n#             prompt_input = [\n#                 self.roi,\n#                 self.coord_vocab_range[0],\n#                 self.coord_vocab_range[0],\n#                 self.coord_vocab_range[1],\n#                 self.coord_vocab_range[1],\n#             ]\n#         elif self.prompt == \"order\":\n#             prompt_input = [\n#                 self.order,\n#                 self.order_vocab_range[0],\n#                 self.order_vocab_range[1],\n#             ]\n#         elif self.prompt == \"point\":\n#             prompt_input = [\n#                 self.point,\n#                 self.coord_vocab_range[0],\n#                 self.coord_vocab_range[0],\n#             ]\n#         else:\n#             prompt_input = []\n\n#         source_mask = torch.unsqueeze(torch.unsqueeze(mask, 1), 2)\n#         # source_mask = None\n\n#         prev_outputs = None\n\n#         merged_output_logit, merged_output_ids = [], []\n#         for _ in range(self.max_iter):\n#             output_logit, output_ids = greedy_decode(\n#                 batch.images.shape[0],\n#                 feats.device,\n#                 prev_outputs,\n#                 self.n_vocab,\n#                 self.decoder_length,\n#                 self.pix2seq_embed,\n#                 self.pix2seq_pos,\n#                 self.pix2seq_decoder,\n#                 self.pix2seq_head,\n#                 go=self.go,\n#                 eos=self.eos,\n#                 noise=self.noise,\n#                 text_eos=self.text_eos,\n#                 prompt=prompt_input,\n#                 source=feats,\n#                 source_mask=source_mask,\n#                 detect_type=self.detect_type,\n#                 text_length=self.max_text_length,\n#                 fixed_text_len=self.fixed_text_len,\n#                 multiple_experts=self.pix2seq_decoder.layers[0].n_experts > 1,\n#             )\n\n#             merged_output_logit.append(output_logit)\n#             merged_output_ids.append(output_ids)\n#             # print(\"len(merged_output_ids)\", len(merged_output_ids))\n#             if self.iterative_decoding:\n#                 prev_outputs = self.determine_last_objects(\n#                     output_ids, detect_type=self.detect_type, n_overlap=self.n_overlap\n#                 )\n#                 # print(\"output_ids: \", output_ids)\n#                 # x = 1\n#                 # for i in output_ids[0]:\n#                 #     if i == 0 and x == 0:\n#                 #         continue\n#                 #     if i == 0:\n#                 #         print(\"HI\")\n#                 #         x = 0\n#                 #         continue\n#                 #     x = 1\n#                 #     print(i)\n                \n#                 prev_outputs = self.add_point_prompt(\n#                     prev_outputs, detect_type=self.detect_type\n#                 )\n#                 # print(\"prev_outputs: \", prev_outputs)\n\n#         vertices = []\n#         scores = []\n#         texts = []\n\n#         eos_flags = [False] * output_ids.shape[0]\n\n#         for i in range(len(merged_output_logit)):\n#             # print(\"i: \", i)\n#             output_ids = merged_output_ids[i]\n#             output_logit = merged_output_logit[i]\n\n#             for batch_i in range(output_ids.shape[0]):\n#                 # print(\"batch_i: \", batch_i)\n#                 if eos_flags[batch_i] == True:\n#                     continue\n\n#                 if self.eos in output_ids[batch_i, len(prompt_input) :].tolist():\n#                     eos_flags[batch_i] = True\n\n#                 h, w = batch.samples[batch_i].image_size\n\n#                 curr_vertices, curr_scores, curr_texts = self.convert_seq2ocr(\n#                     output_logit[batch_i, len(prompt_input) :].tolist(),\n#                     output_ids[batch_i, len(prompt_input) :].tolist(),\n#                     h,\n#                     w,\n#                     threshold,\n#                     self.fixed_text_len,\n#                     self.text_eos,\n#                     self.coord_order,\n#                 )\n#                 # print(\"curr_texts: \", curr_texts)\n#                 if i == 0:\n#                     vertices.append(curr_vertices)\n#                     scores.append(curr_scores)\n#                     texts.append(curr_texts)\n#                 else:\n#                     if (\n#                         curr_vertices is not None\n#                         and len(curr_vertices) > self.n_overlap\n#                     ):\n#                         # print(\"JJJ: \", vertices[batch_i])\n#                         vertices[batch_i].extend(curr_vertices[self.n_overlap :])\n#                         scores[batch_i].extend(curr_scores[self.n_overlap :])\n#                         texts[batch_i].extend(curr_texts[self.n_overlap :])\n\n#         outputs.update(\n#             {\n#                 \"texts\": texts,\n#                 \"vertices\": vertices,\n#                 \"scores\": scores,\n#             }\n#         )\n\n#         return outputs\n\n#     def convert_seq2ocr(\n#         self,\n#         logit,\n#         ids,\n#         h,\n#         w,\n#         threshold=0.0,\n#         fixed_text_len=True,\n#         text_eos=0,\n#         coord_order=\"xy\",\n#     ):\n#         \"\"\"\n#         Convert sequence to OCR results.\n#         \"\"\"\n#         if self.tokenizer.eos in ids:\n#             first_eos_ids = ids.index(self.tokenizer.eos)\n#             ids = ids[:first_eos_ids]\n#             logit = logit[:first_eos_ids]\n\n#         min_idx_coord_vocab, max_idx_coord_vocab = self.coord_vocab_range\n\n#         curr_vertices = []\n#         curr_scores = []\n#         curr_texts = []\n\n#         # Split instances by detect type tokens.\n#         start_ids, end_ids, num_pts_list = [], [], []\n#         for i, idx in enumerate(ids):\n#             if idx in self.token2npts:\n#                 start_ids.append(i)\n\n#                 num_pts = self.token2npts[idx]\n#                 num_pts_list.append(num_pts)\n\n#                 if fixed_text_len:\n#                     span = 2 * num_pts + 1 + self.max_text_length\n#                     if i + span - 1 < self.decoder_length:\n#                         end_ids.append(i + span - 1)\n#                 elif idx == text_eos:\n#                     end_ids.append(i)\n\n#         # Convert tokens to vertices & text transcriptions.\n#         for start_id, end_id, num_pts in zip(start_ids, end_ids, num_pts_list):\n#             object = ids[start_id : end_id + 1]\n#             if any(\n#                 [\n#                     p < min_idx_coord_vocab or p > max_idx_coord_vocab\n#                     for p in object[1 : 1 + 2 * num_pts]\n#                 ]\n#             ):\n#                 continue\n\n#             if len(object[1 : 1 + 2 * num_pts]) < 2 * num_pts:\n#                 continue\n\n#             score = logit[start_id : end_id + 1]\n\n#             mean_score = []\n#             for i, p in enumerate(object[1 + 2 * num_pts :]):\n#                 if p == 0:\n#                     break\n#                 mean_score.append(score[i + 1 + 2 * num_pts][p])\n#             object_score = np.mean(mean_score)\n\n#             vertices = list(\n#                 map(\n#                     lambda x: self.tokenizer.decode_coord(x),\n#                     object[1 : 1 + 2 * num_pts],\n#                 )\n#             )\n\n#             vertices = np.array(vertices, dtype=np.float32).reshape(num_pts, 2)\n#             if coord_order == \"xy\":\n#                 vertices[:, 0], vertices[:, 1] = vertices[:, 0] * w / (\n#                     self.bin_size - 1\n#                 ), vertices[:, 1] * h / (self.bin_size - 1)\n#             else:\n#                 vertices[:, 0], vertices[:, 1] = vertices[:, 1] * h / (\n#                     self.bin_size - 1\n#                 ), vertices[:, 0] * w / (self.bin_size - 1)\n\n#             text = object[1 + 2 * num_pts :]\n            \n#             # print(\"text: \", text)\n#             # print(\"object_score: \", object_score)\n\n#             if object_score >= threshold:\n#                 curr_vertices.append(vertices)\n#                 curr_scores.append(object_score)\n#                 curr_texts.append(text)\n\n#         if curr_vertices == []:\n#             curr_vertices = []\n#             curr_scores = []\n#             curr_texts = []\n#             # curr_vertices = None\n#             # curr_scores = None\n#             # curr_texts = None\n\n#         return curr_vertices, curr_scores, curr_texts\n\n#     def determine_last_objects(\n#         self, output_ids, detect_type, fixed_text_len=True, n_overlap=1\n#     ):\n#         \"\"\"\n#         Determine last object tokens (n_overlap) for iterative decoding.\n#         \"\"\"\n#         detect_type, detect_type_token, num_pts = detect_type\n\n#         # TODO: implement fixed_text_len=False\n#         assert fixed_text_len == True\n#         span = 2 * num_pts + self.max_text_length\n\n#         last_object_tokens = []\n#         for batch_i in range(output_ids.shape[0]):\n#             batch_output_ids = output_ids[batch_i].tolist()\n#             batch_last_object_tokens = []\n#             if self.tokenizer.eos in batch_output_ids:\n#                 batch_last_object_tokens.append(detect_type_token)\n#                 batch_last_object_tokens.extend([self.tokenizer.eos] * span)\n\n#                 for _ in range(n_overlap - 1):\n#                     batch_last_object_tokens.extend([self.tokenizer.eos])\n#                     batch_last_object_tokens.extend([self.tokenizer.eos] * span)\n#             else:\n#                 detect_type_ids = []\n#                 for token_i, token in enumerate(batch_output_ids):\n#                     if token == detect_type_token:\n#                         detect_type_ids.append(token_i)\n\n#                 # If last object is full\n#                 if detect_type_ids[-1] < self.decoder_length - span:\n#                     for j in range(n_overlap - 1, -1, -1):\n#                         batch_last_object_tokens.extend(\n#                             batch_output_ids[\n#                                 detect_type_ids[-1 - j] : detect_type_ids[-1 - j]\n#                                 + span\n#                                 + 1\n#                             ]\n#                         )\n#                 else:\n#                     for j in range(n_overlap - 1, -1, -1):\n#                         batch_last_object_tokens.extend(\n#                             batch_output_ids[\n#                                 detect_type_ids[-2 - j] : detect_type_ids[-2 - j]\n#                                 + span\n#                                 + 1\n#                             ]\n#                         )\n#             last_object_tokens.append(batch_last_object_tokens)\n\n#         return last_object_tokens\n\n#     def add_point_prompt(self, prev_inputs, detect_type):\n#         \"\"\"\n#         Add starting-point prompt tokens to the beginning of the input tokens.\n#         \"\"\"\n#         detect_type, detect_type_token, num_pts = detect_type\n\n#         for batch_i in range(len(prev_inputs)):\n#             coords = prev_inputs[batch_i][1 : 2 * num_pts + 1]\n#             if self.tokenizer.eos in coords:\n#                 # print(\"self.tokenizer.eos in coords XXXX\")\n#                 prev_inputs[batch_i] = [\n#                     self.point,\n#                     self.coord_vocab_range[0],\n#                     self.coord_vocab_range[0],\n#                     self.tokenizer.go,\n#                 ] + prev_inputs[batch_i]\n#             else:\n#                 # print(\"self.tokenizer.eos NOT in coords XXXX\")\n#                 coords = [self.tokenizer.decode_coord(coord) for coord in coords]\n#                 prompt_x, prompt_y = self.tokenizer.encode_coord_xy(\n#                     int(np.mean(coords[::2])), int(np.mean(coords[1::2]))\n#                 )\n#                 prev_inputs[batch_i] = [\n#                     self.point,\n#                     prompt_x,\n#                     prompt_y,\n#                     self.tokenizer.go,\n#                 ] + prev_inputs[batch_i]\n\n#         return prev_inputs\n# ''')\n# decoder.close()","metadata":{"execution":{"iopub.status.busy":"2024-07-15T10:50:44.384642Z","iopub.execute_input":"2024-07-15T10:50:44.384976Z","iopub.status.idle":"2024-07-15T10:50:44.417246Z","shell.execute_reply.started":"2024-07-15T10:50:44.384948Z","shell.execute_reply":"2024-07-15T10:50:44.416278Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# mixer = open('./units/models/decoder.py', 'w')\n# mixer.write('''\n# import torch\n\n# ''')\n# mixer.close()","metadata":{"execution":{"iopub.status.busy":"2024-07-15T10:50:44.484091Z","iopub.execute_input":"2024-07-15T10:50:44.484724Z","iopub.status.idle":"2024-07-15T10:50:44.488671Z","shell.execute_reply.started":"2024-07-15T10:50:44.484694Z","shell.execute_reply":"2024-07-15T10:50:44.487617Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"decoder = open('./units/models/decoder.py', 'w')\ndecoder.write('''\"\"\"\nUNITS\nCopyright (c) 2023-present NAVER Cloud Corp.\nApache-2.0\n\"\"\"\n\nimport numpy as np\nimport torch\nimport torch.nn as nn\nfrom pydantic import StrictBool, StrictInt\n\n\n@torch.no_grad()\ndef greedy_decode(\n    batch_size,\n    device,\n    prev_outputs,\n    n_vocab,\n    max_length,\n    pix2seq_embed,\n    pix2seq_pos,\n    pix2seq_decoder,\n    pix2seq_head,\n    go=1,\n    eos=2,\n    noise=5,\n    text_eos=None,\n    prompt=None,\n    ignore_eos_noise=False,\n    detect_type=None,\n    text_length=25,\n    fixed_text_len=True,\n    multiple_experts=False,\n    **decoder_kwargs,\n):\n    \"\"\"\n    Args:\n        batch_size (int): batch size for decoding\n        device (Union[str, torch.device]): device for decoding\n        n_vocab (int): number of vocabulary for decoding\n        max_length (int): maximum length of sequences that decoded\n        pix2seq_embed (Callable): function that returns tensor given inputs\n        pix2seq_pos (Tensor[float]): positional encoding (max_length, dim)\n        pix2seq_decoder (Callable): transformer decoder\n        pix2seq_head (Callable): function that returns vocab id given decoder output\n        **decoder_kwargs: Rest of the input that should be given to the text decoder\n\n    Returns:\n        logits (Tensor[float]): logit before softmax (batch, max_length, n_vocab)\n        tokens (Tensor[int64]): decoded token ids (batch, max_length)\n    \"\"\"\n    start_token = prompt[0] if len(prompt) else go\n    dec = torch.zeros(batch_size, max_length, n_vocab, device=device)\n    out_texts = torch.ones(batch_size, max_length, dtype=torch.int64, device=device)\n    texts = torch.ones(batch_size, 1, dtype=torch.int64, device=device) * start_token\n    cache = None\n    eos_flag = torch.full((batch_size,), False, dtype=torch.bool, device=device)\n    expert_idx = torch.zeros(batch_size, 1, dtype=torch.int64, device=device)\n\n    detect_type, detect_type_token, num_pts = detect_type\n    span = 1 + num_pts * 2 + text_length\n    next_recog_start_idx = [-1] * batch_size\n\n    for i in range(max_length):\n        # print(\"i::: \", i)\n        # Enforce the beginning of the text to be the previous output.\n        if prev_outputs is not None and i < len(prev_outputs[0]):\n            for batch_i in range(len(prev_outputs)):\n                texts[batch_i, 0] = prev_outputs[batch_i][i]\n\n        # print(\"texts: \", texts)\n        embed = pix2seq_embed(texts)\n\n        pos = pix2seq_pos[i : i + 1].unsqueeze(0).expand(batch_size, -1, -1)\n\n        if multiple_experts:\n            expert_idx = refine_expert_idx(i, next_recog_start_idx, expert_idx)\n\n        # print(\"expert_idx: \", expert_idx)\n        decode_res = pix2seq_decoder(\n            embed,\n            pos,\n            memory=cache,\n            expert_idx=expert_idx if multiple_experts else None,\n            **decoder_kwargs,\n        )\n        decode = decode_res[0]\n        cache = decode_res[-1]\n        # print(\"cache: \", cache)\n\n        output_class = pix2seq_head(decode[-1])\n        next_step = output_class[:, -1]\n        # print(\"next_step: \", next_step)\n\n        if ignore_eos_noise:\n            next_step[:, eos] = -torch.tensor(float(\"inf\"))\n            next_step[:, noise] = -torch.tensor(float(\"inf\"))\n\n        next_token = next_step.argmax(1)\n\n        # Enforce the beginning of the text to be the prompt\n        if i < len(prompt):\n            if i == len(prompt) - 1:\n                next_token = (\n                    torch.ones(batch_size, dtype=torch.int64, device=device) * go\n                )\n            else:\n                next_token = (\n                    torch.ones(batch_size, dtype=torch.int64, device=device)\n                    * prompt[i + 1]\n                )\n\n        if fixed_text_len and (i - len(prompt)) % span == 0:\n            next_token = (\n                torch.ones(batch_size, dtype=torch.int64, device=device)\n                * detect_type_token\n            )\n            if multiple_experts:\n                expert_idx = torch.zeros(\n                    batch_size, 1, dtype=torch.int64, device=device\n                )\n                next_recog_start_idx = [i + num_pts * 2 + 1] * batch_size\n                # print(\"next_recog_start_idx: \", next_recog_start_idx)\n        elif fixed_text_len is False and i > 0:\n            for j in range(texts.shape[0]):\n                if texts[j, 0] in [text_eos, go]:\n                    next_token[j] = detect_type_token\n                    if multiple_experts:\n                        expert_idx[j] = 0\n                        next_recog_start_idx[j] = i + num_pts * 2 + 1\n\n        # print(\"next_token: \", next_token)\n        texts = next_token.unsqueeze(1)\n        out_texts[:, i] = next_token\n        dec[:, i, :] = next_step\n        eos_cond = next_token == eos\n        eos_flag = eos_flag | eos_cond\n\n        if eos_flag.all():\n            break\n\n    return torch.softmax(dec, dim=-1), out_texts\n\n\ndef refine_expert_idx(curr_step_i, next_recog_start_idx, expert_idx):\n    for batch_i, step_i in enumerate(next_recog_start_idx):\n        if step_i < 0:\n            continue\n        if curr_step_i == step_i:\n            expert_idx[batch_i] = 1\n\n    return expert_idx\n\n\nclass UnitsDecoder(nn.Module):\n    \"\"\"\n    Units Decoder\n    Args:\n        dim (int): hidden dimension\n        decoder_length (int): decoder max length\n    \"\"\"\n\n    def __init__(\n        self,\n        dim: StrictInt,\n        max_text_length: StrictInt,\n        pix2seq_dec: nn.Module,\n        loss_criterion: nn.Module,\n        n_object: StrictInt,\n        decoder_length: StrictInt,\n        tokenizer,\n        prompt,\n        detect_type,\n        fixed_text_len: StrictBool,\n        coord_order,\n        iterative_decoding=False,\n        max_iter=15,\n        n_overlap=4,\n    ):\n        super().__init__()\n\n        self.dim = dim\n        self.max_text_length = max_text_length\n\n        self.pix2seq_decoder = pix2seq_dec\n\n        self.tokenizer = tokenizer\n        \n        print(\"n_vocab ne \", self.tokenizer.n_vocab)\n        \n        self.n_vocab = self.tokenizer.n_vocab\n\n        self.go = tokenizer.go\n        self.eos = tokenizer.eos\n        # special tokens index (noise, special prompts)\n        self.noise = tokenizer.vocab[\"[noise]\"]\n        self.roi = tokenizer.vocab[\"[roi]\"]\n        self.order = tokenizer.vocab[\"[order]\"]\n        self.point = tokenizer.vocab[\"[point]\"]\n        self.text_eos = tokenizer.vocab[\"[text_eos]\"]\n\n        self.bin_size = tokenizer.bin_size\n        self.coord_vocab_range = (\n            tokenizer.encode_coord(0),\n            tokenizer.encode_coord(self.bin_size - 1),\n        )\n\n        self.prompt = prompt\n        if prompt is not None:\n            assert prompt in [\"roi\", \"order\", \"point\"]\n\n        self.decoder_length = decoder_length\n        if self.prompt == \"order\":\n            self.order_vocab_range = (\n                tokenizer.encode_order(0),\n                tokenizer.encode_order(n_object - 1),\n            )\n\n        self.pix2seq_head = nn.Linear(dim, self.n_vocab)\n        self.pix2seq_embed = nn.Embedding(self.n_vocab, dim, padding_idx=None)\n        self.pix2seq_pos = nn.Parameter(torch.randn(decoder_length, dim) * 0.02)\n\n        self.loss_criterion = loss_criterion\n        \n        self.numpts = {self.tokenizer.vocab[\"[single]\"]: 2,\n                       self.tokenizer.vocab[\"[box]\"]: 4, \n                       self.tokenizer.vocab[\"[quad]\"]: 8,\n                       self.tokenizer.vocab[\"[polygon]\"]: 32\n        }\n\n        num_pts_dict = {\n            \"single\": 1,\n            \"box\": 2,\n            \"quad\": 4,\n            \"polygon\": 16,\n        }\n        assert detect_type in num_pts_dict\n        self.num_pts_dict = num_pts_dict\n        self.detect_type = (\n            f\"[{detect_type}]\",\n            self.tokenizer.vocab[f\"[{detect_type}]\"],\n            num_pts_dict[detect_type],\n        )\n        self.token2npts = {\n            self.tokenizer.vocab[f\"[{dtype}]\"]: num_pts\n            for dtype, num_pts in num_pts_dict.items()\n        }\n\n        self.fixed_text_len = fixed_text_len\n        self.coord_order = coord_order\n        assert coord_order in [\"xy\", \"yx\"]\n\n        self.iterative_decoding = iterative_decoding\n        self.max_iter = max_iter if self.iterative_decoding else 1\n        self.n_overlap = n_overlap\n\n    def forward(\n        self,\n        batch,\n        source_feat,\n        mask,\n        detect_type=None,\n        threshold=0.0,\n    ):\n        \"\"\"\n        Args:\n            batch (Batch): instance of Batch with Pix2SeqBatch fields\n            source_feat (Tensor[float]): flattened and concatenated features (N, ?, dim)\n            mask (Tensor[bool]): True for non-image areas and False for image areas (N, H, W)\n            threshold (float): confidence threshold for filter out entities\n        \"\"\"\n\n        if self.training:\n            return self.forward_train(\n                batch,\n                source_feat,\n                mask,\n            )\n\n        else:\n            return self.forward_eval(\n                batch,\n                source_feat,\n                mask,\n                detect_type,\n                threshold,\n            )\n\n    def teacherforcing(self, input, batch, feats, mask):\n        # pix2seq_in = batch.units.units_inputs\n        pix2seq_in = input\n        pix2seq_embed = self.pix2seq_embed(pix2seq_in)\n        pix2seq_pos = self.pix2seq_pos\n        pix2seq_pos = pix2seq_pos.unsqueeze(0).expand(pix2seq_in.shape[0], -1, -1)\n\n        source_mask = torch.unsqueeze(mask, 1).expand(-1, pix2seq_pos.shape[1], -1)\n        source_mask = source_mask.unsqueeze(1)\n        # source_mask = None\n\n        expert_idx = batch.units.tasks\n        pix2seq_out, _ = self.pix2seq_decoder(\n            pix2seq_embed, pix2seq_pos, feats, source_mask, expert_idx=expert_idx\n        )\n\n        output_logit = self.pix2seq_head(pix2seq_out[-1])\n        \n        return output_logit\n    \n    def mix(self, input, previous_output, k):\n        sample_mask = torch.ones(input.shape, device=input.device, dtype=torch.bool)\n        \n        sample_mask[:,:4] = False\n        \n        for batch_i in range(input.shape[0]):\n            i = 4\n            while i + 12 + 4 < input.shape[1]:\n                # print(\"i: \", i)\n                detectoken = input[batch_i, i].item()\n                if detectoken == 2:\n                    break\n                cur_numpts = self.numpts[detectoken]\n                ee = 0\n                if k == 0:\n                    ee = -4\n                sample_mask[batch_i, i: i + cur_numpts + ee + (k-1)*4 + 1] = False\n                sample_mask[batch_i, i] = False\n                i += (cur_numpts + 26)\n        \n        intermedia_output = torch.zeros(input.shape, device=input.device, dtype=torch.long)\n        for batch_i in range(input.shape[0]):\n            for i in range(input.shape[1]):\n                if sample_mask[batch_i, i]:\n                    intermedia_output[batch_i, i] = previous_output[batch_i, i - 1]\n                else:\n                    intermedia_output[batch_i, i] = input[batch_i, i]\n                    \n        return intermedia_output\n\n    def forward_train(\n        self,\n        batch,\n        feats,\n        mask,\n    ):\n        outputs = {}\n        pix2seq_in = batch.units.units_inputs\n        \n        with torch.no_grad():\n            for i in range(3):\n                intermediate_logit = self.teacherforcing(pix2seq_in, batch, feats, mask)\n                intermediate_output = torch.argmax(intermediate_logit, dim=-1)\n                pix2seq_in = self.mix(pix2seq_in, intermediate_output, i)\n            \n        output_logit = self.teacherforcing(pix2seq_in, batch, feats, mask)\n        \n        # print(\"output_logit shape: \", mixed_input.shape)\n        # print(\"output_logit argmax shape: \", mixed_input[0].argmax(1).shape)\n        \n        # print(\"Hello\")\n        # for i in range(1024):\n        #     print(i, \"- target: \", batch.units.units_targets[0][i], \" input: \", batch.units.units_inputs[0][i], \", output: \", pix2seq_in[0][i])\n        \n\n        loss = self.loss_criterion(\n            output_logit.reshape(-1, output_logit.shape[-1]).contiguous(),\n            batch.units.units_targets.reshape(-1),\n        )\n\n        outputs.update(\n            {\n                \"total_loss\": loss,\n            }\n        )\n\n        return outputs\n\n    def forward_eval(\n        self,\n        batch,\n        feats,\n        mask,\n        detect_type,\n        threshold,\n    ):\n        if detect_type is not None:\n            assert detect_type in self.num_pts_dict\n            self.num_pts_dict = self.num_pts_dict\n            self.detect_type = (\n                f\"[{detect_type}]\",\n                self.tokenizer.vocab[f\"[{detect_type}]\"],\n                self.num_pts_dict[detect_type],\n            )\n            self.token2npts = {\n                self.tokenizer.vocab[f\"[{dtype}]\"]: num_pts\n                for dtype, num_pts in self.num_pts_dict.items()\n            }\n\n        outputs = {}\n\n        if self.prompt == \"roi\":\n            prompt_input = [\n                self.roi,\n                self.coord_vocab_range[0],\n                self.coord_vocab_range[0],\n                self.coord_vocab_range[1],\n                self.coord_vocab_range[1],\n            ]\n        elif self.prompt == \"order\":\n            prompt_input = [\n                self.order,\n                self.order_vocab_range[0],\n                self.order_vocab_range[1],\n            ]\n        elif self.prompt == \"point\":\n            prompt_input = [\n                self.point,\n                self.coord_vocab_range[0],\n                self.coord_vocab_range[0],\n            ]\n        else:\n            prompt_input = []\n\n        source_mask = torch.unsqueeze(torch.unsqueeze(mask, 1), 2)\n        # source_mask = None\n\n        prev_outputs = None\n\n        merged_output_logit, merged_output_ids = [], []\n        for _ in range(self.max_iter):\n            output_logit, output_ids = greedy_decode(\n                batch.images.shape[0],\n                feats.device,\n                prev_outputs,\n                self.n_vocab,\n                self.decoder_length,\n                self.pix2seq_embed,\n                self.pix2seq_pos,\n                self.pix2seq_decoder,\n                self.pix2seq_head,\n                go=self.go,\n                eos=self.eos,\n                noise=self.noise,\n                text_eos=self.text_eos,\n                prompt=prompt_input,\n                source=feats,\n                source_mask=source_mask,\n                detect_type=self.detect_type,\n                text_length=self.max_text_length,\n                fixed_text_len=self.fixed_text_len,\n                multiple_experts=self.pix2seq_decoder.layers[0].n_experts > 1,\n            )\n\n            merged_output_logit.append(output_logit)\n            merged_output_ids.append(output_ids)\n            # print(\"len(merged_output_ids)\", len(merged_output_ids))\n            if self.iterative_decoding:\n                prev_outputs = self.determine_last_objects(\n                    output_ids, detect_type=self.detect_type, n_overlap=self.n_overlap\n                )\n                \n                prev_outputs = self.add_point_prompt(\n                    prev_outputs, detect_type=self.detect_type\n                )\n\n        vertices = []\n        scores = []\n        texts = []\n\n        eos_flags = [False] * output_ids.shape[0]\n\n        for i in range(len(merged_output_logit)):\n            # print(\"i: \", i)\n            output_ids = merged_output_ids[i]\n            output_logit = merged_output_logit[i]\n\n            for batch_i in range(output_ids.shape[0]):\n                # print(\"batch_i: \", batch_i)\n                if eos_flags[batch_i] == True:\n                    continue\n\n                if self.eos in output_ids[batch_i, len(prompt_input) :].tolist():\n                    eos_flags[batch_i] = True\n\n                h, w = batch.samples[batch_i].image_size\n\n                curr_vertices, curr_scores, curr_texts = self.convert_seq2ocr(\n                    output_logit[batch_i, len(prompt_input) :].tolist(),\n                    output_ids[batch_i, len(prompt_input) :].tolist(),\n                    h,\n                    w,\n                    threshold,\n                    self.fixed_text_len,\n                    self.text_eos,\n                    self.coord_order,\n                )\n                # print(\"curr_texts: \", curr_texts)\n                if i == 0:\n                    vertices.append(curr_vertices)\n                    scores.append(curr_scores)\n                    texts.append(curr_texts)\n                else:\n                    if (\n                        curr_vertices is not None\n                        and len(curr_vertices) > self.n_overlap\n                    ):\n                        # print(\"JJJ: \", vertices[batch_i])\n                        vertices[batch_i].extend(curr_vertices[self.n_overlap :])\n                        scores[batch_i].extend(curr_scores[self.n_overlap :])\n                        texts[batch_i].extend(curr_texts[self.n_overlap :])\n\n        outputs.update(\n            {\n                \"texts\": texts,\n                \"vertices\": vertices,\n                \"scores\": scores,\n            }\n        )\n\n        return outputs\n\n    def convert_seq2ocr(\n        self,\n        logit,\n        ids,\n        h,\n        w,\n        threshold=0.0,\n        fixed_text_len=True,\n        text_eos=0,\n        coord_order=\"xy\",\n    ):\n        \"\"\"\n        Convert sequence to OCR results.\n        \"\"\"\n        if self.tokenizer.eos in ids:\n            first_eos_ids = ids.index(self.tokenizer.eos)\n            ids = ids[:first_eos_ids]\n            logit = logit[:first_eos_ids]\n\n        min_idx_coord_vocab, max_idx_coord_vocab = self.coord_vocab_range\n\n        curr_vertices = []\n        curr_scores = []\n        curr_texts = []\n\n        # Split instances by detect type tokens.\n        start_ids, end_ids, num_pts_list = [], [], []\n        for i, idx in enumerate(ids):\n            if idx in self.token2npts:\n                start_ids.append(i)\n\n                num_pts = self.token2npts[idx]\n                num_pts_list.append(num_pts)\n\n                if fixed_text_len:\n                    span = 2 * num_pts + 1 + self.max_text_length\n                    if i + span - 1 < self.decoder_length:\n                        end_ids.append(i + span - 1)\n                elif idx == text_eos:\n                    end_ids.append(i)\n\n        # Convert tokens to vertices & text transcriptions.\n        for start_id, end_id, num_pts in zip(start_ids, end_ids, num_pts_list):\n            object = ids[start_id : end_id + 1]\n            if any(\n                [\n                    p < min_idx_coord_vocab or p > max_idx_coord_vocab\n                    for p in object[1 : 1 + 2 * num_pts]\n                ]\n            ):\n                continue\n\n            if len(object[1 : 1 + 2 * num_pts]) < 2 * num_pts:\n                continue\n\n            score = logit[start_id : end_id + 1]\n\n            mean_score = []\n            for i, p in enumerate(object[1 + 2 * num_pts :]):\n                if p == 0:\n                    break\n                mean_score.append(score[i + 1 + 2 * num_pts][p])\n            object_score = np.mean(mean_score)\n\n            vertices = list(\n                map(\n                    lambda x: self.tokenizer.decode_coord(x),\n                    object[1 : 1 + 2 * num_pts],\n                )\n            )\n\n            vertices = np.array(vertices, dtype=np.float32).reshape(num_pts, 2)\n            if coord_order == \"xy\":\n                vertices[:, 0], vertices[:, 1] = vertices[:, 0] * w / (\n                    self.bin_size - 1\n                ), vertices[:, 1] * h / (self.bin_size - 1)\n            else:\n                vertices[:, 0], vertices[:, 1] = vertices[:, 1] * h / (\n                    self.bin_size - 1\n                ), vertices[:, 0] * w / (self.bin_size - 1)\n\n            text = object[1 + 2 * num_pts :]\n            \n            # print(\"text: \", text)\n            # print(\"object_score: \", object_score)\n\n            if object_score >= threshold:\n                curr_vertices.append(vertices)\n                curr_scores.append(object_score)\n                curr_texts.append(text)\n\n        if curr_vertices == []:\n            curr_vertices = []\n            curr_scores = []\n            curr_texts = []\n            # curr_vertices = None\n            # curr_scores = None\n            # curr_texts = None\n\n        return curr_vertices, curr_scores, curr_texts\n\n    def determine_last_objects(\n        self, output_ids, detect_type, fixed_text_len=True, n_overlap=1\n    ):\n        \"\"\"\n        Determine last object tokens (n_overlap) for iterative decoding.\n        \"\"\"\n        detect_type, detect_type_token, num_pts = detect_type\n\n        # TODO: implement fixed_text_len=False\n        assert fixed_text_len == True\n        span = 2 * num_pts + self.max_text_length\n\n        last_object_tokens = []\n        for batch_i in range(output_ids.shape[0]):\n            batch_output_ids = output_ids[batch_i].tolist()\n            batch_last_object_tokens = []\n            if self.tokenizer.eos in batch_output_ids:\n                batch_last_object_tokens.append(detect_type_token)\n                batch_last_object_tokens.extend([self.tokenizer.eos] * span)\n\n                for _ in range(n_overlap - 1):\n                    batch_last_object_tokens.extend([self.tokenizer.eos])\n                    batch_last_object_tokens.extend([self.tokenizer.eos] * span)\n            else:\n                detect_type_ids = []\n                for token_i, token in enumerate(batch_output_ids):\n                    if token == detect_type_token:\n                        detect_type_ids.append(token_i)\n\n                # If last object is full\n                if detect_type_ids[-1] < self.decoder_length - span:\n                    for j in range(n_overlap - 1, -1, -1):\n                        batch_last_object_tokens.extend(\n                            batch_output_ids[\n                                detect_type_ids[-1 - j] : detect_type_ids[-1 - j]\n                                + span\n                                + 1\n                            ]\n                        )\n                else:\n                    for j in range(n_overlap - 1, -1, -1):\n                        batch_last_object_tokens.extend(\n                            batch_output_ids[\n                                detect_type_ids[-2 - j] : detect_type_ids[-2 - j]\n                                + span\n                                + 1\n                            ]\n                        )\n            last_object_tokens.append(batch_last_object_tokens)\n\n        return last_object_tokens\n\n    def add_point_prompt(self, prev_inputs, detect_type):\n        \"\"\"\n        Add starting-point prompt tokens to the beginning of the input tokens.\n        \"\"\"\n        detect_type, detect_type_token, num_pts = detect_type\n\n        for batch_i in range(len(prev_inputs)):\n            coords = prev_inputs[batch_i][1 : 2 * num_pts + 1]\n            if self.tokenizer.eos in coords:\n                # print(\"self.tokenizer.eos in coords XXXX\")\n                prev_inputs[batch_i] = [\n                    self.point,\n                    self.coord_vocab_range[0],\n                    self.coord_vocab_range[0],\n                    self.tokenizer.go,\n                ] + prev_inputs[batch_i]\n            else:\n                # print(\"self.tokenizer.eos NOT in coords XXXX\")\n                coords = [self.tokenizer.decode_coord(coord) for coord in coords]\n                prompt_x, prompt_y = self.tokenizer.encode_coord_xy(\n                    int(np.mean(coords[::2])), int(np.mean(coords[1::2]))\n                )\n                prev_inputs[batch_i] = [\n                    self.point,\n                    prompt_x,\n                    prompt_y,\n                    self.tokenizer.go,\n                ] + prev_inputs[batch_i]\n\n        return prev_inputs\n''')\ndecoder.close()","metadata":{"execution":{"iopub.status.busy":"2024-07-15T10:50:44.698783Z","iopub.execute_input":"2024-07-15T10:50:44.699110Z","iopub.status.idle":"2024-07-15T10:50:44.727216Z","shell.execute_reply.started":"2024-07-15T10:50:44.699083Z","shell.execute_reply":"2024-07-15T10:50:44.726192Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# decoder = open('./units/models/decoder.py', 'w')\n# decoder.write('''\"\"\"\n# UNITS\n# Copyright (c) 2023-present NAVER Cloud Corp.\n# Apache-2.0\n# \"\"\"\n\n# import numpy as np\n# import torch\n# import torch.nn as nn\n# from pydantic import StrictBool, StrictInt\n\n\n# @torch.no_grad()\n# def greedy_decode(\n#     batch_size,\n#     device,\n#     prev_outputs,\n#     n_vocab,\n#     max_length,\n#     pix2seq_embed,\n#     pix2seq_pos,\n#     pix2seq_decoder,\n#     pix2seq_head,\n#     go=1,\n#     eos=2,\n#     noise=5,\n#     text_eos=None,\n#     prompt=None,\n#     ignore_eos_noise=False,\n#     detect_type=None,\n#     text_length=25,\n#     fixed_text_len=True,\n#     multiple_experts=False,\n#     **decoder_kwargs,\n# ):\n#     \"\"\"\n#     Args:\n#         batch_size (int): batch size for decoding\n#         device (Union[str, torch.device]): device for decoding\n#         n_vocab (int): number of vocabulary for decoding\n#         max_length (int): maximum length of sequences that decoded\n#         pix2seq_embed (Callable): function that returns tensor given inputs\n#         pix2seq_pos (Tensor[float]): positional encoding (max_length, dim)\n#         pix2seq_decoder (Callable): transformer decoder\n#         pix2seq_head (Callable): function that returns vocab id given decoder output\n#         **decoder_kwargs: Rest of the input that should be given to the text decoder\n\n#     Returns:\n#         logits (Tensor[float]): logit before softmax (batch, max_length, n_vocab)\n#         tokens (Tensor[int64]): decoded token ids (batch, max_length)\n#     \"\"\"\n#     start_token = prompt[0] if len(prompt) else go\n#     dec = torch.zeros(batch_size, max_length, n_vocab, device=device)\n#     out_texts = torch.ones(batch_size, max_length, dtype=torch.int64, device=device)\n#     texts = torch.ones(batch_size, 1, dtype=torch.int64, device=device) * start_token\n#     cache = None\n#     eos_flag = torch.full((batch_size,), False, dtype=torch.bool, device=device)\n#     expert_idx = torch.zeros(batch_size, 1, dtype=torch.int64, device=device)\n\n#     detect_type, detect_type_token, num_pts = detect_type\n#     span = 1 + num_pts * 2 + text_length\n#     next_recog_start_idx = [-1] * batch_size\n\n#     for i in range(max_length):\n#         # print(\"i::: \", i)\n#         # Enforce the beginning of the text to be the previous output.\n#         if prev_outputs is not None and i < len(prev_outputs[0]):\n#             for batch_i in range(len(prev_outputs)):\n#                 texts[batch_i, 0] = prev_outputs[batch_i][i]\n\n#         # print(\"texts: \", texts)\n#         embed = pix2seq_embed(texts)\n\n#         pos = pix2seq_pos[i : i + 1].unsqueeze(0).expand(batch_size, -1, -1)\n\n#         if multiple_experts:\n#             expert_idx = refine_expert_idx(i, next_recog_start_idx, expert_idx)\n\n#         # print(\"expert_idx: \", expert_idx)\n#         decode_res = pix2seq_decoder(\n#             embed,\n#             pos,\n#             memory=cache,\n#             expert_idx=expert_idx if multiple_experts else None,\n#             **decoder_kwargs,\n#         )\n#         decode = decode_res[0]\n#         cache = decode_res[-1]\n#         # print(\"cache: \", cache)\n\n#         output_class = pix2seq_head(decode[-1])\n#         next_step = output_class[:, -1]\n#         # print(\"next_step: \", next_step)\n\n#         if ignore_eos_noise:\n#             next_step[:, eos] = -torch.tensor(float(\"inf\"))\n#             next_step[:, noise] = -torch.tensor(float(\"inf\"))\n\n#         next_token = next_step.argmax(1)\n\n#         # Enforce the beginning of the text to be the prompt\n#         if i < len(prompt):\n#             if i == len(prompt) - 1:\n#                 next_token = (\n#                     torch.ones(batch_size, dtype=torch.int64, device=device) * go\n#                 )\n#             else:\n#                 next_token = (\n#                     torch.ones(batch_size, dtype=torch.int64, device=device)\n#                     * prompt[i + 1]\n#                 )\n\n#         if fixed_text_len and (i - len(prompt)) % span == 0:\n#             next_token = (\n#                 torch.ones(batch_size, dtype=torch.int64, device=device)\n#                 * detect_type_token\n#             )\n#             if multiple_experts:\n#                 expert_idx = torch.zeros(\n#                     batch_size, 1, dtype=torch.int64, device=device\n#                 )\n#                 next_recog_start_idx = [i + num_pts * 2 + 1] * batch_size\n#                 # print(\"next_recog_start_idx: \", next_recog_start_idx)\n#         elif fixed_text_len is False and i > 0:\n#             for j in range(texts.shape[0]):\n#                 if texts[j, 0] in [text_eos, go]:\n#                     next_token[j] = detect_type_token\n#                     if multiple_experts:\n#                         expert_idx[j] = 0\n#                         next_recog_start_idx[j] = i + num_pts * 2 + 1\n\n#         # print(\"next_token: \", next_token)\n#         texts = next_token.unsqueeze(1)\n#         out_texts[:, i] = next_token\n#         dec[:, i, :] = next_step\n#         eos_cond = next_token == eos\n#         eos_flag = eos_flag | eos_cond\n\n#         if eos_flag.all():\n#             break\n\n#     return torch.softmax(dec, dim=-1), out_texts\n\n\n# def refine_expert_idx(curr_step_i, next_recog_start_idx, expert_idx):\n#     for batch_i, step_i in enumerate(next_recog_start_idx):\n#         if step_i < 0:\n#             continue\n#         if curr_step_i == step_i:\n#             expert_idx[batch_i] = 1\n\n#     return expert_idx\n\n\n# class UnitsDecoder(nn.Module):\n#     \"\"\"\n#     Units Decoder\n#     Args:\n#         dim (int): hidden dimension\n#         decoder_length (int): decoder max length\n#     \"\"\"\n\n#     def __init__(\n#         self,\n#         dim: StrictInt,\n#         max_text_length: StrictInt,\n#         pix2seq_dec: nn.Module,\n#         loss_criterion: nn.Module,\n#         n_object: StrictInt,\n#         decoder_length: StrictInt,\n#         tokenizer,\n#         prompt,\n#         detect_type,\n#         fixed_text_len: StrictBool,\n#         coord_order,\n#         iterative_decoding=False,\n#         max_iter=15,\n#         n_overlap=4,\n#     ):\n#         super().__init__()\n\n#         self.dim = dim\n#         self.max_text_length = max_text_length\n\n#         self.pix2seq_decoder = pix2seq_dec\n\n#         self.tokenizer = tokenizer\n        \n#         print(\"n_vocab ne \", self.tokenizer.n_vocab)\n#         self.step = 0\n        \n#         self.n_vocab = self.tokenizer.n_vocab\n\n#         self.go = tokenizer.go\n#         self.eos = tokenizer.eos\n#         # special tokens index (noise, special prompts)\n#         self.noise = tokenizer.vocab[\"[noise]\"]\n#         self.roi = tokenizer.vocab[\"[roi]\"]\n#         self.order = tokenizer.vocab[\"[order]\"]\n#         self.point = tokenizer.vocab[\"[point]\"]\n#         self.text_eos = tokenizer.vocab[\"[text_eos]\"]\n\n#         self.bin_size = tokenizer.bin_size\n#         self.coord_vocab_range = (\n#             tokenizer.encode_coord(0),\n#             tokenizer.encode_coord(self.bin_size - 1),\n#         )\n\n#         self.prompt = prompt\n#         if prompt is not None:\n#             assert prompt in [\"roi\", \"order\", \"point\"]\n\n#         self.decoder_length = decoder_length\n#         if self.prompt == \"order\":\n#             self.order_vocab_range = (\n#                 tokenizer.encode_order(0),\n#                 tokenizer.encode_order(n_object - 1),\n#             )\n\n#         self.pix2seq_head = nn.Linear(dim, self.n_vocab)\n#         self.pix2seq_embed = nn.Embedding(self.n_vocab, dim, padding_idx=None)\n#         self.pix2seq_pos = nn.Parameter(torch.randn(decoder_length, dim) * 0.02)\n\n#         self.loss_criterion = loss_criterion\n        \n#         self.numpts = {self.tokenizer.vocab[\"[single]\"]: 2,\n#                        self.tokenizer.vocab[\"[box]\"]: 4, \n#                        self.tokenizer.vocab[\"[quad]\"]: 8,\n#                        self.tokenizer.vocab[\"[polygon]\"]: 32\n#         }\n\n#         num_pts_dict = {\n#             \"single\": 1,\n#             \"box\": 2,\n#             \"quad\": 4,\n#             \"polygon\": 16,\n#         }\n#         assert detect_type in num_pts_dict\n#         self.num_pts_dict = num_pts_dict\n#         self.detect_type = (\n#             f\"[{detect_type}]\",\n#             self.tokenizer.vocab[f\"[{detect_type}]\"],\n#             num_pts_dict[detect_type],\n#         )\n#         self.token2npts = {\n#             self.tokenizer.vocab[f\"[{dtype}]\"]: num_pts\n#             for dtype, num_pts in num_pts_dict.items()\n#         }\n\n#         self.fixed_text_len = fixed_text_len\n#         self.coord_order = coord_order\n#         assert coord_order in [\"xy\", \"yx\"]\n\n#         self.iterative_decoding = iterative_decoding\n#         self.max_iter = max_iter if self.iterative_decoding else 1\n#         self.n_overlap = n_overlap\n\n#     def forward(\n#         self,\n#         batch,\n#         source_feat,\n#         mask,\n#         detect_type=None,\n#         threshold=0.0,\n#     ):\n#         \"\"\"\n#         Args:\n#             batch (Batch): instance of Batch with Pix2SeqBatch fields\n#             source_feat (Tensor[float]): flattened and concatenated features (N, ?, dim)\n#             mask (Tensor[bool]): True for non-image areas and False for image areas (N, H, W)\n#             threshold (float): confidence threshold for filter out entities\n#         \"\"\"\n\n#         if self.training:\n#             return self.forward_train(\n#                 batch,\n#                 source_feat,\n#                 mask,\n#             )\n\n#         else:\n#             return self.forward_eval(\n#                 batch,\n#                 source_feat,\n#                 mask,\n#                 detect_type,\n#                 threshold,\n#             )\n\n#     def teacherforcing(self, input, batch, feats, mask):\n#         # pix2seq_in = batch.units.units_inputs\n#         pix2seq_in = input\n#         pix2seq_embed = self.pix2seq_embed(pix2seq_in)\n#         pix2seq_pos = self.pix2seq_pos\n#         pix2seq_pos = pix2seq_pos.unsqueeze(0).expand(pix2seq_in.shape[0], -1, -1)\n\n#         source_mask = torch.unsqueeze(mask, 1).expand(-1, pix2seq_pos.shape[1], -1)\n#         source_mask = source_mask.unsqueeze(1)\n#         # source_mask = None\n\n#         expert_idx = batch.units.tasks\n#         pix2seq_out, _ = self.pix2seq_decoder(\n#             pix2seq_embed, pix2seq_pos, feats, source_mask, expert_idx=expert_idx\n#         )\n\n#         output_logit = self.pix2seq_head(pix2seq_out[-1])\n        \n#         return output_logit\n    \n#     def mix(self, input, previous_output, sampling_probability):\n\n#         sample_mask = torch.rand(input.shape, device=input.device) < sampling_probability\n        \n#         sample_mask[:,:4] = False\n#         # sample_mask[:,:input.shape[1]//5] = False\n        \n#         # a = 0\n#         # for i in input[0]:\n#         #     print(a, \" \", i)\n#         #     a += 1\n        \n#         for batch_i in range(input.shape[0]):\n#             # print(\"batch_i: \", batch_i)\n#             i = 4\n#             while i < input.shape[1]:\n#                 # print(\"i: \", i)\n#                 detectoken = input[batch_i, i].item()\n#                 if detectoken == 2:\n#                     break\n#                 cur_numpts = self.numpts[detectoken]\n#                 sample_mask[batch_i, i] = False\n#                 i += (cur_numpts + 26)\n        \n#         intermedia_output = torch.zeros(input.shape, device=input.device, dtype=torch.long)\n#         for batch_i in range(input.shape[0]):\n#             # intermedia_output[batch_i] = [input[batch_i][i] if sample_mask[batch_i][i] \n#             #                     else previous_output[batch_i][i-1] \n#             #                     for i in range(input.shape[1])]\n#             for i in range(input.shape[1]):\n#                 if sample_mask[batch_i, i]:\n#                     intermedia_output[batch_i, i] = previous_output[batch_i, i - 1]\n#                 else:\n#                     intermedia_output[batch_i, i] = input[batch_i, i]\n                    \n#         return intermedia_output\n\n#     def forward_train(\n#         self,\n#         batch,\n#         feats,\n#         mask,\n#     ):\n        \n#         self.step += 1\n#         # print(\"step: \", self.step)\n#         outputs = {}\n#         pix2seq_in = batch.units.units_inputs\n#         # pix2seq_embed = self.pix2seq_embed(pix2seq_in)\n#         # pix2seq_pos = self.pix2seq_pos\n#         # pix2seq_pos = pix2seq_pos.unsqueeze(0).expand(pix2seq_in.shape[0], -1, -1)\n\n#         # source_mask = torch.unsqueeze(mask, 1).expand(-1, pix2seq_pos.shape[1], -1)\n#         # source_mask = source_mask.unsqueeze(1)\n#         # # source_mask = None\n\n#         # expert_idx = batch.units.tasks\n#         # pix2seq_out, _ = self.pix2seq_decoder(\n#         #     pix2seq_embed, pix2seq_pos, feats, source_mask, expert_idx=expert_idx\n#         # )\n\n#         # output_logit = self.pix2seq_head(pix2seq_out[-1])\n        \n#         with torch.no_grad():\n#             intermediate_logit = self.teacherforcing(pix2seq_in, batch, feats, mask)\n#             intermediate_output = torch.argmax(intermediate_logit, dim=-1)\n#             mixed_input = self.mix(pix2seq_in, intermediate_output, self.step/4400)\n            \n#         output_logit = self.teacherforcing(mixed_input, batch, feats, mask)\n        \n#         # print(\"output_logit shape: \", mixed_input.shape)\n#         # print(\"output_logit argmax shape: \", mixed_input[0].argmax(1).shape)\n        \n#         # print(\"Hello\")\n#         # for i in range(1024):\n#         #     print(i, \"- target: \", batch.units.units_targets[0][i], \" input: \", pix2seq_in[0][i], \", output: \", mixed_input[0][i])\n        \n\n#         loss = self.loss_criterion(\n#             output_logit.reshape(-1, output_logit.shape[-1]).contiguous(),\n#             batch.units.units_targets.reshape(-1),\n#         )\n\n#         outputs.update(\n#             {\n#                 \"total_loss\": loss,\n#             }\n#         )\n\n#         return outputs\n\n#     def forward_eval(\n#         self,\n#         batch,\n#         feats,\n#         mask,\n#         detect_type,\n#         threshold,\n#     ):\n#         if detect_type is not None:\n#             assert detect_type in self.num_pts_dict\n#             self.num_pts_dict = self.num_pts_dict\n#             self.detect_type = (\n#                 f\"[{detect_type}]\",\n#                 self.tokenizer.vocab[f\"[{detect_type}]\"],\n#                 self.num_pts_dict[detect_type],\n#             )\n#             self.token2npts = {\n#                 self.tokenizer.vocab[f\"[{dtype}]\"]: num_pts\n#                 for dtype, num_pts in self.num_pts_dict.items()\n#             }\n\n#         outputs = {}\n\n#         if self.prompt == \"roi\":\n#             prompt_input = [\n#                 self.roi,\n#                 self.coord_vocab_range[0],\n#                 self.coord_vocab_range[0],\n#                 self.coord_vocab_range[1],\n#                 self.coord_vocab_range[1],\n#             ]\n#         elif self.prompt == \"order\":\n#             prompt_input = [\n#                 self.order,\n#                 self.order_vocab_range[0],\n#                 self.order_vocab_range[1],\n#             ]\n#         elif self.prompt == \"point\":\n#             prompt_input = [\n#                 self.point,\n#                 self.coord_vocab_range[0],\n#                 self.coord_vocab_range[0],\n#             ]\n#         else:\n#             prompt_input = []\n\n#         source_mask = torch.unsqueeze(torch.unsqueeze(mask, 1), 2)\n#         # source_mask = None\n\n#         prev_outputs = None\n\n#         merged_output_logit, merged_output_ids = [], []\n#         for _ in range(self.max_iter):\n#             output_logit, output_ids = greedy_decode(\n#                 batch.images.shape[0],\n#                 feats.device,\n#                 prev_outputs,\n#                 self.n_vocab,\n#                 self.decoder_length,\n#                 self.pix2seq_embed,\n#                 self.pix2seq_pos,\n#                 self.pix2seq_decoder,\n#                 self.pix2seq_head,\n#                 go=self.go,\n#                 eos=self.eos,\n#                 noise=self.noise,\n#                 text_eos=self.text_eos,\n#                 prompt=prompt_input,\n#                 source=feats,\n#                 source_mask=source_mask,\n#                 detect_type=self.detect_type,\n#                 text_length=self.max_text_length,\n#                 fixed_text_len=self.fixed_text_len,\n#                 multiple_experts=self.pix2seq_decoder.layers[0].n_experts > 1,\n#             )\n\n#             merged_output_logit.append(output_logit)\n#             merged_output_ids.append(output_ids)\n#             # print(\"len(merged_output_ids)\", len(merged_output_ids))\n#             if self.iterative_decoding:\n#                 prev_outputs = self.determine_last_objects(\n#                     output_ids, detect_type=self.detect_type, n_overlap=self.n_overlap\n#                 )\n#                 # print(\"output_ids: \", output_ids)\n#                 # x = 1\n#                 # for i in output_ids[0]:\n#                 #     if i == 0 and x == 0:\n#                 #         continue\n#                 #     if i == 0:\n#                 #         print(\"HI\")\n#                 #         x = 0\n#                 #         continue\n#                 #     x = 1\n#                 #     print(i)\n                \n#                 prev_outputs = self.add_point_prompt(\n#                     prev_outputs, detect_type=self.detect_type\n#                 )\n#                 # print(\"prev_outputs: \", prev_outputs)\n\n#         vertices = []\n#         scores = []\n#         texts = []\n\n#         eos_flags = [False] * output_ids.shape[0]\n\n#         for i in range(len(merged_output_logit)):\n#             # print(\"i: \", i)\n#             output_ids = merged_output_ids[i]\n#             output_logit = merged_output_logit[i]\n\n#             for batch_i in range(output_ids.shape[0]):\n#                 # print(\"batch_i: \", batch_i)\n#                 if eos_flags[batch_i] == True:\n#                     continue\n\n#                 if self.eos in output_ids[batch_i, len(prompt_input) :].tolist():\n#                     eos_flags[batch_i] = True\n\n#                 h, w = batch.samples[batch_i].image_size\n\n#                 curr_vertices, curr_scores, curr_texts = self.convert_seq2ocr(\n#                     output_logit[batch_i, len(prompt_input) :].tolist(),\n#                     output_ids[batch_i, len(prompt_input) :].tolist(),\n#                     h,\n#                     w,\n#                     threshold,\n#                     self.fixed_text_len,\n#                     self.text_eos,\n#                     self.coord_order,\n#                 )\n#                 # print(\"curr_texts: \", curr_texts)\n#                 if i == 0:\n#                     vertices.append(curr_vertices)\n#                     scores.append(curr_scores)\n#                     texts.append(curr_texts)\n#                 else:\n#                     if (\n#                         curr_vertices is not None\n#                         and len(curr_vertices) > self.n_overlap\n#                     ):\n#                         # print(\"JJJ: \", vertices[batch_i])\n#                         vertices[batch_i].extend(curr_vertices[self.n_overlap :])\n#                         scores[batch_i].extend(curr_scores[self.n_overlap :])\n#                         texts[batch_i].extend(curr_texts[self.n_overlap :])\n\n#         outputs.update(\n#             {\n#                 \"texts\": texts,\n#                 \"vertices\": vertices,\n#                 \"scores\": scores,\n#             }\n#         )\n\n#         return outputs\n\n#     def convert_seq2ocr(\n#         self,\n#         logit,\n#         ids,\n#         h,\n#         w,\n#         threshold=0.0,\n#         fixed_text_len=True,\n#         text_eos=0,\n#         coord_order=\"xy\",\n#     ):\n#         \"\"\"\n#         Convert sequence to OCR results.\n#         \"\"\"\n#         if self.tokenizer.eos in ids:\n#             first_eos_ids = ids.index(self.tokenizer.eos)\n#             ids = ids[:first_eos_ids]\n#             logit = logit[:first_eos_ids]\n\n#         min_idx_coord_vocab, max_idx_coord_vocab = self.coord_vocab_range\n\n#         curr_vertices = []\n#         curr_scores = []\n#         curr_texts = []\n\n#         # Split instances by detect type tokens.\n#         start_ids, end_ids, num_pts_list = [], [], []\n#         for i, idx in enumerate(ids):\n#             if idx in self.token2npts:\n#                 start_ids.append(i)\n\n#                 num_pts = self.token2npts[idx]\n#                 num_pts_list.append(num_pts)\n\n#                 if fixed_text_len:\n#                     span = 2 * num_pts + 1 + self.max_text_length\n#                     if i + span - 1 < self.decoder_length:\n#                         end_ids.append(i + span - 1)\n#                 elif idx == text_eos:\n#                     end_ids.append(i)\n\n#         # Convert tokens to vertices & text transcriptions.\n#         for start_id, end_id, num_pts in zip(start_ids, end_ids, num_pts_list):\n#             object = ids[start_id : end_id + 1]\n#             if any(\n#                 [\n#                     p < min_idx_coord_vocab or p > max_idx_coord_vocab\n#                     for p in object[1 : 1 + 2 * num_pts]\n#                 ]\n#             ):\n#                 continue\n\n#             if len(object[1 : 1 + 2 * num_pts]) < 2 * num_pts:\n#                 continue\n\n#             score = logit[start_id : end_id + 1]\n\n#             mean_score = []\n#             for i, p in enumerate(object[1 + 2 * num_pts :]):\n#                 if p == 0:\n#                     break\n#                 mean_score.append(score[i + 1 + 2 * num_pts][p])\n#             object_score = np.mean(mean_score)\n\n#             vertices = list(\n#                 map(\n#                     lambda x: self.tokenizer.decode_coord(x),\n#                     object[1 : 1 + 2 * num_pts],\n#                 )\n#             )\n\n#             vertices = np.array(vertices, dtype=np.float32).reshape(num_pts, 2)\n#             if coord_order == \"xy\":\n#                 vertices[:, 0], vertices[:, 1] = vertices[:, 0] * w / (\n#                     self.bin_size - 1\n#                 ), vertices[:, 1] * h / (self.bin_size - 1)\n#             else:\n#                 vertices[:, 0], vertices[:, 1] = vertices[:, 1] * h / (\n#                     self.bin_size - 1\n#                 ), vertices[:, 0] * w / (self.bin_size - 1)\n\n#             text = object[1 + 2 * num_pts :]\n            \n#             # print(\"text: \", text)\n#             # print(\"object_score: \", object_score)\n\n#             if object_score >= threshold:\n#                 curr_vertices.append(vertices)\n#                 curr_scores.append(object_score)\n#                 curr_texts.append(text)\n\n#         if curr_vertices == []:\n#             curr_vertices = []\n#             curr_scores = []\n#             curr_texts = []\n#             # curr_vertices = None\n#             # curr_scores = None\n#             # curr_texts = None\n\n#         return curr_vertices, curr_scores, curr_texts\n\n#     def determine_last_objects(\n#         self, output_ids, detect_type, fixed_text_len=True, n_overlap=1\n#     ):\n#         \"\"\"\n#         Determine last object tokens (n_overlap) for iterative decoding.\n#         \"\"\"\n#         detect_type, detect_type_token, num_pts = detect_type\n\n#         # TODO: implement fixed_text_len=False\n#         assert fixed_text_len == True\n#         span = 2 * num_pts + self.max_text_length\n\n#         last_object_tokens = []\n#         for batch_i in range(output_ids.shape[0]):\n#             batch_output_ids = output_ids[batch_i].tolist()\n#             batch_last_object_tokens = []\n#             if self.tokenizer.eos in batch_output_ids:\n#                 batch_last_object_tokens.append(detect_type_token)\n#                 batch_last_object_tokens.extend([self.tokenizer.eos] * span)\n\n#                 for _ in range(n_overlap - 1):\n#                     batch_last_object_tokens.extend([self.tokenizer.eos])\n#                     batch_last_object_tokens.extend([self.tokenizer.eos] * span)\n#             else:\n#                 detect_type_ids = []\n#                 for token_i, token in enumerate(batch_output_ids):\n#                     if token == detect_type_token:\n#                         detect_type_ids.append(token_i)\n\n#                 # If last object is full\n#                 if detect_type_ids[-1] < self.decoder_length - span:\n#                     for j in range(n_overlap - 1, -1, -1):\n#                         batch_last_object_tokens.extend(\n#                             batch_output_ids[\n#                                 detect_type_ids[-1 - j] : detect_type_ids[-1 - j]\n#                                 + span\n#                                 + 1\n#                             ]\n#                         )\n#                 else:\n#                     for j in range(n_overlap - 1, -1, -1):\n#                         batch_last_object_tokens.extend(\n#                             batch_output_ids[\n#                                 detect_type_ids[-2 - j] : detect_type_ids[-2 - j]\n#                                 + span\n#                                 + 1\n#                             ]\n#                         )\n#             last_object_tokens.append(batch_last_object_tokens)\n\n#         return last_object_tokens\n\n#     def add_point_prompt(self, prev_inputs, detect_type):\n#         \"\"\"\n#         Add starting-point prompt tokens to the beginning of the input tokens.\n#         \"\"\"\n#         detect_type, detect_type_token, num_pts = detect_type\n\n#         for batch_i in range(len(prev_inputs)):\n#             coords = prev_inputs[batch_i][1 : 2 * num_pts + 1]\n#             if self.tokenizer.eos in coords:\n#                 # print(\"self.tokenizer.eos in coords XXXX\")\n#                 prev_inputs[batch_i] = [\n#                     self.point,\n#                     self.coord_vocab_range[0],\n#                     self.coord_vocab_range[0],\n#                     self.tokenizer.go,\n#                 ] + prev_inputs[batch_i]\n#             else:\n#                 # print(\"self.tokenizer.eos NOT in coords XXXX\")\n#                 coords = [self.tokenizer.decode_coord(coord) for coord in coords]\n#                 prompt_x, prompt_y = self.tokenizer.encode_coord_xy(\n#                     int(np.mean(coords[::2])), int(np.mean(coords[1::2]))\n#                 )\n#                 prev_inputs[batch_i] = [\n#                     self.point,\n#                     prompt_x,\n#                     prompt_y,\n#                     self.tokenizer.go,\n#                 ] + prev_inputs[batch_i]\n\n#         return prev_inputs''')\n# decoder.close()","metadata":{"execution":{"iopub.status.busy":"2024-07-15T10:50:44.881190Z","iopub.execute_input":"2024-07-15T10:50:44.881512Z","iopub.status.idle":"2024-07-15T10:50:44.916218Z","shell.execute_reply.started":"2024-07-15T10:50:44.881485Z","shell.execute_reply":"2024-07-15T10:50:44.915165Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# decoder = open('./units/models/decoder.py', 'w')\n# decoder.write('''\"\"\"\n# UNITS\n# Copyright (c) 2023-present NAVER Cloud Corp.\n# Apache-2.0\n# \"\"\"\n\n# # k = 5\n\n# # print(\"HELLO\")\n\n# import numpy as np\n# import torch\n# import torch.nn as nn\n# from pydantic import StrictBool, StrictInt\n\n\n# @torch.no_grad()\n# def greedy_decode(\n#     batch_size,\n#     device,\n#     prev_outputs,\n#     n_vocab,\n#     max_length,\n#     pix2seq_embed,\n#     pix2seq_pos,\n#     pix2seq_decoder,\n#     pix2seq_head,\n#     go=1,\n#     eos=2,\n#     noise=5,\n#     text_eos=None,\n#     prompt=None,\n#     ignore_eos_noise=False,\n#     detect_type=None,\n#     text_length=25,\n#     fixed_text_len=True,\n#     multiple_experts=False,\n#     **decoder_kwargs,\n# ):\n#     \"\"\"\n#     Args:\n#         batch_size (int): batch size for decoding\n#         device (Union[str, torch.device]): device for decoding\n#         n_vocab (int): number of vocabulary for decoding\n#         max_length (int): maximum length of sequences that decoded\n#         pix2seq_embed (Callable): function that returns tensor given inputs\n#         pix2seq_pos (Tensor[float]): positional encoding (max_length, dim)\n#         pix2seq_decoder (Callable): transformer decoder\n#         pix2seq_head (Callable): function that returns vocab id given decoder output\n#         **decoder_kwargs: Rest of the input that should be given to the text decoder\n\n#     Returns:\n#         logits (Tensor[float]): logit before softmax (batch, max_length, n_vocab)\n#         tokens (Tensor[int64]): decoded token ids (batch, max_length)\n#     \"\"\"\n#     start_token = prompt[0] if len(prompt) else go\n#     dec = torch.zeros(batch_size, max_length, n_vocab, device=device)\n#     out_texts = torch.ones(batch_size, max_length, dtype=torch.int64, device=device)\n#     texts = torch.ones(batch_size, 1, dtype=torch.int64, device=device) * start_token\n#     cache = None\n#     eos_flag = torch.full((batch_size,), False, dtype=torch.bool, device=device)\n#     expert_idx = torch.zeros(batch_size, 1, dtype=torch.int64, device=device)\n\n#     detect_type, detect_type_token, num_pts = detect_type\n#     span = 1 + num_pts * 2 + text_length\n#     next_recog_start_idx = [-1] * batch_size\n\n#     for i in range(max_length):\n#         # print(\"i::: \", i)\n#         # Enforce the beginning of the text to be the previous output.\n#         if prev_outputs is not None and i < len(prev_outputs[0]):\n#             for batch_i in range(len(prev_outputs)):\n#                 texts[batch_i, 0] = prev_outputs[batch_i][i]\n\n#         # print(\"texts: \", texts)\n#         embed = pix2seq_embed(texts)\n\n#         pos = pix2seq_pos[i : i + 1].unsqueeze(0).expand(batch_size, -1, -1)\n\n#         if multiple_experts:\n#             expert_idx = refine_expert_idx(i, next_recog_start_idx, expert_idx)\n\n#         # print(\"expert_idx: \", expert_idx)\n#         decode_res = pix2seq_decoder(\n#             embed,\n#             pos,\n#             memory=cache,\n#             expert_idx=expert_idx if multiple_experts else None,\n#             **decoder_kwargs,\n#         )\n#         decode = decode_res[0]\n#         cache = decode_res[-1]\n#         # print(\"cache: \", cache)\n\n#         output_class = pix2seq_head(decode[-1])\n#         next_step = output_class[:, -1]\n#         # print(\"next_step: \", next_step)\n\n#         if ignore_eos_noise:\n#             next_step[:, eos] = -torch.tensor(float(\"inf\"))\n#             next_step[:, noise] = -torch.tensor(float(\"inf\"))\n\n#         next_token = next_step.argmax(1)\n\n#         # Enforce the beginning of the text to be the prompt\n#         if i < len(prompt):\n#             if i == len(prompt) - 1:\n#                 next_token = (\n#                     torch.ones(batch_size, dtype=torch.int64, device=device) * go\n#                 )\n#             else:\n#                 next_token = (\n#                     torch.ones(batch_size, dtype=torch.int64, device=device)\n#                     * prompt[i + 1]\n#                 )\n\n#         if fixed_text_len and (i - len(prompt)) % span == 0:\n#             next_token = (\n#                 torch.ones(batch_size, dtype=torch.int64, device=device)\n#                 * detect_type_token\n#             )\n#             if multiple_experts:\n#                 expert_idx = torch.zeros(\n#                     batch_size, 1, dtype=torch.int64, device=device\n#                 )\n#                 next_recog_start_idx = [i + num_pts * 2 + 1] * batch_size\n#                 # print(\"next_recog_start_idx: \", next_recog_start_idx)\n#         elif fixed_text_len is False and i > 0:\n#             for j in range(texts.shape[0]):\n#                 if texts[j, 0] in [text_eos, go]:\n#                     next_token[j] = detect_type_token\n#                     if multiple_experts:\n#                         expert_idx[j] = 0\n#                         next_recog_start_idx[j] = i + num_pts * 2 + 1\n\n#         # print(\"next_token: \", next_token)\n#         texts = next_token.unsqueeze(1)\n#         out_texts[:, i] = next_token\n#         dec[:, i, :] = next_step\n#         eos_cond = next_token == eos\n#         eos_flag = eos_flag | eos_cond\n\n#         if eos_flag.all():\n#             break\n\n#     return torch.softmax(dec, dim=-1), out_texts\n\n\n# def refine_expert_idx(curr_step_i, next_recog_start_idx, expert_idx):\n#     for batch_i, step_i in enumerate(next_recog_start_idx):\n#         if step_i < 0:\n#             continue\n#         if curr_step_i == step_i:\n#             expert_idx[batch_i] = 1\n\n#     return expert_idx\n\n\n# class UnitsDecoder(nn.Module):\n#     \"\"\"\n#     Units Decoder\n#     Args:\n#         dim (int): hidden dimension\n#         decoder_length (int): decoder max length\n#     \"\"\"\n\n#     def __init__(\n#         self,\n#         dim: StrictInt,\n#         max_text_length: StrictInt,\n#         pix2seq_dec: nn.Module,\n#         loss_criterion: nn.Module,\n#         n_object: StrictInt,\n#         decoder_length: StrictInt,\n#         tokenizer,\n#         prompt,\n#         detect_type,\n#         fixed_text_len: StrictBool,\n#         coord_order,\n#         iterative_decoding=False,\n#         max_iter=15,\n#         n_overlap=4,\n#     ):\n#         super().__init__()\n\n#         self.dim = dim\n#         self.max_text_length = max_text_length\n\n#         self.pix2seq_decoder = pix2seq_dec\n\n#         self.tokenizer = tokenizer\n        \n#         print(\"n_vocab ne \", self.tokenizer.n_vocab)\n        \n#         self.n_vocab = self.tokenizer.n_vocab\n\n#         self.go = tokenizer.go\n#         self.eos = tokenizer.eos\n#         # special tokens index (noise, special prompts)\n#         self.noise = tokenizer.vocab[\"[noise]\"]\n#         self.roi = tokenizer.vocab[\"[roi]\"]\n#         self.order = tokenizer.vocab[\"[order]\"]\n#         self.point = tokenizer.vocab[\"[point]\"]\n#         self.text_eos = tokenizer.vocab[\"[text_eos]\"]\n\n#         self.bin_size = tokenizer.bin_size\n#         self.coord_vocab_range = (\n#             tokenizer.encode_coord(0),\n#             tokenizer.encode_coord(self.bin_size - 1),\n#         )\n\n#         self.prompt = prompt\n#         if prompt is not None:\n#             assert prompt in [\"roi\", \"order\", \"point\"]\n\n#         self.decoder_length = decoder_length\n#         if self.prompt == \"order\":\n#             self.order_vocab_range = (\n#                 tokenizer.encode_order(0),\n#                 tokenizer.encode_order(n_object - 1),\n#             )\n\n#         self.pix2seq_head = nn.Linear(dim, self.n_vocab)\n#         self.pix2seq_embed = nn.Embedding(self.n_vocab, dim, padding_idx=None)\n#         self.pix2seq_pos = nn.Parameter(torch.randn(decoder_length, dim) * 0.02)\n\n#         self.loss_criterion = loss_criterion\n        \n#         self.step = 0\n        \n#         self.numpts = {self.tokenizer.vocab[\"[single]\"]: 2,\n#                        self.tokenizer.vocab[\"[box]\"]: 4, \n#                        self.tokenizer.vocab[\"[quad]\"]: 8,\n#                        self.tokenizer.vocab[\"[polygon]\"]: 32\n#         }\n\n#         num_pts_dict = {\n#             \"single\": 1,\n#             \"box\": 2,\n#             \"quad\": 4,\n#             \"polygon\": 16,\n#         }\n#         assert detect_type in num_pts_dict\n#         self.num_pts_dict = num_pts_dict\n#         self.detect_type = (\n#             f\"[{detect_type}]\",\n#             self.tokenizer.vocab[f\"[{detect_type}]\"],\n#             num_pts_dict[detect_type],\n#         )\n#         self.token2npts = {\n#             self.tokenizer.vocab[f\"[{dtype}]\"]: num_pts\n#             for dtype, num_pts in num_pts_dict.items()\n#         }\n\n#         self.fixed_text_len = fixed_text_len\n#         self.coord_order = coord_order\n#         assert coord_order in [\"xy\", \"yx\"]\n\n#         self.iterative_decoding = iterative_decoding\n#         self.max_iter = max_iter if self.iterative_decoding else 1\n#         self.n_overlap = n_overlap\n\n#     def forward(\n#         self,\n#         batch,\n#         source_feat,\n#         mask,\n#         detect_type=None,\n#         threshold=0.0,\n#     ):\n#         \"\"\"\n#         Args:\n#             batch (Batch): instance of Batch with Pix2SeqBatch fields\n#             source_feat (Tensor[float]): flattened and concatenated features (N, ?, dim)\n#             mask (Tensor[bool]): True for non-image areas and False for image areas (N, H, W)\n#             threshold (float): confidence threshold for filter out entities\n#         \"\"\"\n\n#         if self.training:\n#             return self.forward_train(\n#                 batch,\n#                 source_feat,\n#                 mask,\n#             )\n\n#         else:\n#             return self.forward_eval(\n#                 batch,\n#                 source_feat,\n#                 mask,\n#                 detect_type,\n#                 threshold,\n#             )\n\n#     def teacherforcing(self, input, batch, feats, mask):\n#         # pix2seq_in = batch.units.units_inputs\n#         pix2seq_in = input\n#         pix2seq_embed = self.pix2seq_embed(pix2seq_in)\n#         pix2seq_pos = self.pix2seq_pos\n#         pix2seq_pos = pix2seq_pos.unsqueeze(0).expand(pix2seq_in.shape[0], -1, -1)\n\n#         source_mask = torch.unsqueeze(mask, 1).expand(-1, pix2seq_pos.shape[1], -1)\n#         source_mask = source_mask.unsqueeze(1)\n#         # source_mask = None\n\n#         expert_idx = batch.units.tasks\n#         pix2seq_out, _ = self.pix2seq_decoder(\n#             pix2seq_embed, pix2seq_pos, feats, source_mask, expert_idx=expert_idx\n#         )\n\n#         output_logit = self.pix2seq_head(pix2seq_out[-1])\n        \n#         return output_logit\n    \n#     def mix(self, gold_tg, input, previous_output, k, sampling_probability):\n\n#         sample_mask = (torch.rand(input.shape, device=input.device) < sampling_probability).int()\n#         # sample_mask = torch.ones(input.shape, device=input.device, dtype=torch.bool)\n        \n#         sample_mask[:,:4] = False\n        \n#         # sample_mask[:,:input.shape[1]//5] = False\n        \n#         # a = 0\n#         # for i in input[0]:\n#         #     print(a, \" \", i)\n#         #     a += 1\n        \n#         for batch_i in range(input.shape[0]):\n#             # print(\"batch_i: \", batch_i)\n#             i = 4\n#             while i + 8 + 4 < input.shape[1]:\n#                 # print(\"i: \", i)\n#                 detectoken = input[batch_i, i].item()\n#                 if detectoken == 2:\n#                     break\n#                 cur_numpts = self.numpts[detectoken]\n#                 # sample_mask[batch_i, i] = False\n#                 sample_mask[batch_i, i: i + cur_numpts + (k-1)*4 + 1] = 2\n#                 i += (cur_numpts + 26)\n        \n#         intermedia_output = torch.zeros(input.shape, device=input.device, dtype=torch.long)\n#         for batch_i in range(input.shape[0]):\n#             for i in range(input.shape[1]):\n#                 if sample_mask[batch_i, i] == 2:\n#                     intermedia_output[batch_i, i] = input[batch_i, i]\n#                 elif sample_mask[batch_i, i] == 1:\n#                     intermedia_output[batch_i, i] = previous_output[batch_i, i - 1]\n#                 else:\n#                     intermedia_output[batch_i, i] = gold_tg[batch_i, i]\n                    \n#         return intermedia_output\n\n#     def forward_train(\n#         self,\n#         batch,\n#         feats,\n#         mask,\n#     ):\n#         self.step += 1\n        \n#         outputs = {}\n#         pix2seq_in = batch.units.units_inputs.clone()\n#         gold_tg = batch.units.units_inputs\n        \n#         with torch.no_grad():\n#             for i in range(3):\n#                 intermediate_logit = self.teacherforcing(pix2seq_in, batch, feats, mask)\n#                 intermediate_output = torch.argmax(intermediate_logit, dim=-1)\n#                 pix2seq_in = self.mix(gold_tg, pix2seq_in, intermediate_output, i, self.step/4400)\n            \n#         output_logit = self.teacherforcing(pix2seq_in, batch, feats, mask)\n        \n#         # print(\"output_logit shape: \", mixed_input.shape)\n#         # print(\"output_logit argmax shape: \", mixed_input[0].argmax(1).shape)\n        \n#         # print(\"Hello\")\n#         # for i in range(1024):\n#         #     print(i, \"- target: \", batch.units.units_targets[0][i], \" input: \", batch.units.units_inputs[0][i], \", output: \", pix2seq_in[0][i])\n        \n\n#         loss = self.loss_criterion(\n#             output_logit.reshape(-1, output_logit.shape[-1]).contiguous(),\n#             batch.units.units_targets.reshape(-1),\n#         )\n\n#         outputs.update(\n#             {\n#                 \"total_loss\": loss,\n#             }\n#         )\n\n#         return outputs\n\n#     def forward_eval(\n#         self,\n#         batch,\n#         feats,\n#         mask,\n#         detect_type,\n#         threshold,\n#     ):\n#         if detect_type is not None:\n#             assert detect_type in self.num_pts_dict\n#             self.num_pts_dict = self.num_pts_dict\n#             self.detect_type = (\n#                 f\"[{detect_type}]\",\n#                 self.tokenizer.vocab[f\"[{detect_type}]\"],\n#                 self.num_pts_dict[detect_type],\n#             )\n#             self.token2npts = {\n#                 self.tokenizer.vocab[f\"[{dtype}]\"]: num_pts\n#                 for dtype, num_pts in self.num_pts_dict.items()\n#             }\n\n#         outputs = {}\n\n#         if self.prompt == \"roi\":\n#             prompt_input = [\n#                 self.roi,\n#                 self.coord_vocab_range[0],\n#                 self.coord_vocab_range[0],\n#                 self.coord_vocab_range[1],\n#                 self.coord_vocab_range[1],\n#             ]\n#         elif self.prompt == \"order\":\n#             prompt_input = [\n#                 self.order,\n#                 self.order_vocab_range[0],\n#                 self.order_vocab_range[1],\n#             ]\n#         elif self.prompt == \"point\":\n#             prompt_input = [\n#                 self.point,\n#                 self.coord_vocab_range[0],\n#                 self.coord_vocab_range[0],\n#             ]\n#         else:\n#             prompt_input = []\n\n#         source_mask = torch.unsqueeze(torch.unsqueeze(mask, 1), 2)\n#         # source_mask = None\n\n#         prev_outputs = None\n\n#         merged_output_logit, merged_output_ids = [], []\n#         for _ in range(self.max_iter):\n#             output_logit, output_ids = greedy_decode(\n#                 batch.images.shape[0],\n#                 feats.device,\n#                 prev_outputs,\n#                 self.n_vocab,\n#                 self.decoder_length,\n#                 self.pix2seq_embed,\n#                 self.pix2seq_pos,\n#                 self.pix2seq_decoder,\n#                 self.pix2seq_head,\n#                 go=self.go,\n#                 eos=self.eos,\n#                 noise=self.noise,\n#                 text_eos=self.text_eos,\n#                 prompt=prompt_input,\n#                 source=feats,\n#                 source_mask=source_mask,\n#                 detect_type=self.detect_type,\n#                 text_length=self.max_text_length,\n#                 fixed_text_len=self.fixed_text_len,\n#                 multiple_experts=self.pix2seq_decoder.layers[0].n_experts > 1,\n#             )\n\n#             merged_output_logit.append(output_logit)\n#             merged_output_ids.append(output_ids)\n#             # print(\"len(merged_output_ids)\", len(merged_output_ids))\n#             if self.iterative_decoding:\n#                 prev_outputs = self.determine_last_objects(\n#                     output_ids, detect_type=self.detect_type, n_overlap=self.n_overlap\n#                 )\n#                 # print(\"output_ids: \", output_ids)\n#                 # x = 1\n#                 # for i in output_ids[0]:\n#                 #     if i == 0 and x == 0:\n#                 #         continue\n#                 #     if i == 0:\n#                 #         print(\"HI\")\n#                 #         x = 0\n#                 #         continue\n#                 #     x = 1\n#                 #     print(i)\n                \n#                 prev_outputs = self.add_point_prompt(\n#                     prev_outputs, detect_type=self.detect_type\n#                 )\n#                 # print(\"prev_outputs: \", prev_outputs)\n\n#         vertices = []\n#         scores = []\n#         texts = []\n\n#         eos_flags = [False] * output_ids.shape[0]\n\n#         for i in range(len(merged_output_logit)):\n#             # print(\"i: \", i)\n#             output_ids = merged_output_ids[i]\n#             output_logit = merged_output_logit[i]\n\n#             for batch_i in range(output_ids.shape[0]):\n#                 # print(\"batch_i: \", batch_i)\n#                 if eos_flags[batch_i] == True:\n#                     continue\n\n#                 if self.eos in output_ids[batch_i, len(prompt_input) :].tolist():\n#                     eos_flags[batch_i] = True\n\n#                 h, w = batch.samples[batch_i].image_size\n\n#                 curr_vertices, curr_scores, curr_texts = self.convert_seq2ocr(\n#                     output_logit[batch_i, len(prompt_input) :].tolist(),\n#                     output_ids[batch_i, len(prompt_input) :].tolist(),\n#                     h,\n#                     w,\n#                     threshold,\n#                     self.fixed_text_len,\n#                     self.text_eos,\n#                     self.coord_order,\n#                 )\n#                 # print(\"curr_texts: \", curr_texts)\n#                 if i == 0:\n#                     vertices.append(curr_vertices)\n#                     scores.append(curr_scores)\n#                     texts.append(curr_texts)\n#                 else:\n#                     if (\n#                         curr_vertices is not None\n#                         and len(curr_vertices) > self.n_overlap\n#                     ):\n#                         # print(\"JJJ: \", vertices[batch_i])\n#                         vertices[batch_i].extend(curr_vertices[self.n_overlap :])\n#                         scores[batch_i].extend(curr_scores[self.n_overlap :])\n#                         texts[batch_i].extend(curr_texts[self.n_overlap :])\n\n#         outputs.update(\n#             {\n#                 \"texts\": texts,\n#                 \"vertices\": vertices,\n#                 \"scores\": scores,\n#             }\n#         )\n\n#         return outputs\n\n#     def convert_seq2ocr(\n#         self,\n#         logit,\n#         ids,\n#         h,\n#         w,\n#         threshold=0.0,\n#         fixed_text_len=True,\n#         text_eos=0,\n#         coord_order=\"xy\",\n#     ):\n#         \"\"\"\n#         Convert sequence to OCR results.\n#         \"\"\"\n#         if self.tokenizer.eos in ids:\n#             first_eos_ids = ids.index(self.tokenizer.eos)\n#             ids = ids[:first_eos_ids]\n#             logit = logit[:first_eos_ids]\n\n#         min_idx_coord_vocab, max_idx_coord_vocab = self.coord_vocab_range\n\n#         curr_vertices = []\n#         curr_scores = []\n#         curr_texts = []\n\n#         # Split instances by detect type tokens.\n#         start_ids, end_ids, num_pts_list = [], [], []\n#         for i, idx in enumerate(ids):\n#             if idx in self.token2npts:\n#                 start_ids.append(i)\n\n#                 num_pts = self.token2npts[idx]\n#                 num_pts_list.append(num_pts)\n\n#                 if fixed_text_len:\n#                     span = 2 * num_pts + 1 + self.max_text_length\n#                     if i + span - 1 < self.decoder_length:\n#                         end_ids.append(i + span - 1)\n#                 elif idx == text_eos:\n#                     end_ids.append(i)\n\n#         # Convert tokens to vertices & text transcriptions.\n#         for start_id, end_id, num_pts in zip(start_ids, end_ids, num_pts_list):\n#             object = ids[start_id : end_id + 1]\n#             if any(\n#                 [\n#                     p < min_idx_coord_vocab or p > max_idx_coord_vocab\n#                     for p in object[1 : 1 + 2 * num_pts]\n#                 ]\n#             ):\n#                 continue\n\n#             if len(object[1 : 1 + 2 * num_pts]) < 2 * num_pts:\n#                 continue\n\n#             score = logit[start_id : end_id + 1]\n\n#             mean_score = []\n#             for i, p in enumerate(object[1 + 2 * num_pts :]):\n#                 if p == 0:\n#                     break\n#                 mean_score.append(score[i + 1 + 2 * num_pts][p])\n#             object_score = np.mean(mean_score)\n\n#             vertices = list(\n#                 map(\n#                     lambda x: self.tokenizer.decode_coord(x),\n#                     object[1 : 1 + 2 * num_pts],\n#                 )\n#             )\n\n#             vertices = np.array(vertices, dtype=np.float32).reshape(num_pts, 2)\n#             if coord_order == \"xy\":\n#                 vertices[:, 0], vertices[:, 1] = vertices[:, 0] * w / (\n#                     self.bin_size - 1\n#                 ), vertices[:, 1] * h / (self.bin_size - 1)\n#             else:\n#                 vertices[:, 0], vertices[:, 1] = vertices[:, 1] * h / (\n#                     self.bin_size - 1\n#                 ), vertices[:, 0] * w / (self.bin_size - 1)\n\n#             text = object[1 + 2 * num_pts :]\n            \n#             # print(\"text: \", text)\n#             # print(\"object_score: \", object_score)\n\n#             if object_score >= threshold:\n#                 curr_vertices.append(vertices)\n#                 curr_scores.append(object_score)\n#                 curr_texts.append(text)\n\n#         if curr_vertices == []:\n#             curr_vertices = []\n#             curr_scores = []\n#             curr_texts = []\n#             # curr_vertices = None\n#             # curr_scores = None\n#             # curr_texts = None\n\n#         return curr_vertices, curr_scores, curr_texts\n\n#     def determine_last_objects(\n#         self, output_ids, detect_type, fixed_text_len=True, n_overlap=1\n#     ):\n#         \"\"\"\n#         Determine last object tokens (n_overlap) for iterative decoding.\n#         \"\"\"\n#         detect_type, detect_type_token, num_pts = detect_type\n\n#         # TODO: implement fixed_text_len=False\n#         assert fixed_text_len == True\n#         span = 2 * num_pts + self.max_text_length\n\n#         last_object_tokens = []\n#         for batch_i in range(output_ids.shape[0]):\n#             batch_output_ids = output_ids[batch_i].tolist()\n#             batch_last_object_tokens = []\n#             if self.tokenizer.eos in batch_output_ids:\n#                 batch_last_object_tokens.append(detect_type_token)\n#                 batch_last_object_tokens.extend([self.tokenizer.eos] * span)\n\n#                 for _ in range(n_overlap - 1):\n#                     batch_last_object_tokens.extend([self.tokenizer.eos])\n#                     batch_last_object_tokens.extend([self.tokenizer.eos] * span)\n#             else:\n#                 detect_type_ids = []\n#                 for token_i, token in enumerate(batch_output_ids):\n#                     if token == detect_type_token:\n#                         detect_type_ids.append(token_i)\n\n#                 # If last object is full\n#                 if detect_type_ids[-1] < self.decoder_length - span:\n#                     for j in range(n_overlap - 1, -1, -1):\n#                         batch_last_object_tokens.extend(\n#                             batch_output_ids[\n#                                 detect_type_ids[-1 - j] : detect_type_ids[-1 - j]\n#                                 + span\n#                                 + 1\n#                             ]\n#                         )\n#                 else:\n#                     for j in range(n_overlap - 1, -1, -1):\n#                         batch_last_object_tokens.extend(\n#                             batch_output_ids[\n#                                 detect_type_ids[-2 - j] : detect_type_ids[-2 - j]\n#                                 + span\n#                                 + 1\n#                             ]\n#                         )\n#             last_object_tokens.append(batch_last_object_tokens)\n\n#         return last_object_tokens\n\n#     def add_point_prompt(self, prev_inputs, detect_type):\n#         \"\"\"\n#         Add starting-point prompt tokens to the beginning of the input tokens.\n#         \"\"\"\n#         detect_type, detect_type_token, num_pts = detect_type\n\n#         for batch_i in range(len(prev_inputs)):\n#             coords = prev_inputs[batch_i][1 : 2 * num_pts + 1]\n#             if self.tokenizer.eos in coords:\n#                 # print(\"self.tokenizer.eos in coords XXXX\")\n#                 prev_inputs[batch_i] = [\n#                     self.point,\n#                     self.coord_vocab_range[0],\n#                     self.coord_vocab_range[0],\n#                     self.tokenizer.go,\n#                 ] + prev_inputs[batch_i]\n#             else:\n#                 # print(\"self.tokenizer.eos NOT in coords XXXX\")\n#                 coords = [self.tokenizer.decode_coord(coord) for coord in coords]\n#                 prompt_x, prompt_y = self.tokenizer.encode_coord_xy(\n#                     int(np.mean(coords[::2])), int(np.mean(coords[1::2]))\n#                 )\n#                 prev_inputs[batch_i] = [\n#                     self.point,\n#                     prompt_x,\n#                     prompt_y,\n#                     self.tokenizer.go,\n#                 ] + prev_inputs[batch_i]\n\n#         return prev_inputs\n# ''')\n# decoder.close()","metadata":{"execution":{"iopub.status.busy":"2024-07-15T10:50:45.101384Z","iopub.execute_input":"2024-07-15T10:50:45.101685Z","iopub.status.idle":"2024-07-15T10:50:45.131490Z","shell.execute_reply.started":"2024-07-15T10:50:45.101661Z","shell.execute_reply":"2024-07-15T10:50:45.130565Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"tokenizer = open('./units/tokenizer.py', 'w')\ntokenizer.write('''import re\nimport unicodedata\n\nclass Tokenizer:\n    def __init__(self, key, version=None, go=1, eos=2, unk=3, pad=0, special_tokens=()):\n        self.go = go\n        self.eos = eos\n        self.unk = unk\n        self.pad = pad\n        self._key = key\n        self._version = version\n        self.special_tokens = special_tokens\n\n        vocab = list(\" !~#$%&'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[]^_`abcdefghijklmnopqrstuvwxyz|ˋˊ⸱ˀ˜ˇˆ˒\")\n        \n        print(\"vocab \", vocab)\n        \n        self.vocab = {\n            \"[go]\": self.go,\n            \"[eos]\": self.eos,\n            \"[unk]\": self.unk,\n            \"[pad]\": self.pad,\n        }\n\n        for id, token in enumerate(special_tokens, start=self.n_vocab):\n            self.vocab[token] = id\n\n        for id, ch in enumerate(vocab, start=self.n_vocab):\n            self.vocab[ch] = id\n\n        self.inv_vocab = {v: k for k, v in self.vocab.items()}\n\n    @property\n    def n_vocab(self):\n        return max(self.vocab.values()) + 1\n\n    def normalize(self, text):\n        text = text.strip()\n        text = re.sub(r\"\\s+\", \" \", text)\n\n        chars = []\n\n        for char in text:\n            target = unicodedata.normalize(\"NFC\", char)\n            if not (char != \" \" and target[0] == \" \"):\n                char = target\n\n            chars.append(char)\n        text = \"\".join(chars)\n        return text\n\n    def __call__(self, text, add_go_eos=True, normalize=True):\n        return self.encode(text, add_go_eos, normalize)\n\n    def encode(self, text, add_go_eos=True, normalize=True):\n        print(\"text ne \", text)\n        if normalize:\n            text = normalize(text)\n\n        codes = []\n        for ch in text:\n            try:\n                codes.append(self.vocab[ch])\n\n            except KeyError:\n                codes.append(self.unk)\n\n        if add_go_eos:\n            return [self.go] + codes + [self.eos]\n\n        return codes\n\n    def decode(self, codes):\n        text = []\n\n        for code in codes:\n            if code == self.eos:\n                break\n\n            text.append(self.inv_vocab[code])\n\n        return \"\".join(text)\n\n\nclass UnitsTokenizer(Tokenizer):\n    def __init__(\n        self,\n        key=None,\n        version=None,\n        go=1,\n        eos=2,\n        unk=3,\n        pad=0,\n        special_tokens=(\n            \"[mask]\",\n            \"[noise]\",\n            \"[text]\",\n            \"[roi]\",\n            \"[order]\",\n            \"[point]\",\n            \"[text_eos]\",\n        ),\n    ):\n        super().__init__(key, version, go, eos, unk, pad, special_tokens)\n\n        char_vocab = list(\" !~#$%&'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[]^_`abcdefghijklmnopqrstuvwxyz|ˋˊ⸱ˀ˜ˇˆ˒\")\n        \n        print(\"char vocab \", char_vocab)\n\n        self.char_vocab_range = [self.vocab[char_vocab[0]], self.vocab[char_vocab[-1]]]\n\n    def add_unify_annotation_vocab(\n        self,\n        special_tokens=(\n            \"[single]\",\n            \"[box]\",\n            \"[quad]\",\n            \"[polygon]\",\n            \"[case-sensitive]\",\n            \"[case-insensitive]\",\n        ),\n    ):\n        for coord_key in special_tokens:\n            coord_value = self.n_vocab\n            self.vocab[coord_key] = coord_value\n            self.inv_vocab[coord_value] = coord_key\n\n    def add_detection_vocab(\n        self,\n        bin_size,\n    ):\n        self.bin_size = bin_size\n\n        # coord tokens\n        for i in range(bin_size):\n            coord_key = f\"[coord-{i}]\"\n            coord_value = self.n_vocab\n            self.vocab[coord_key] = coord_value\n            self.inv_vocab[coord_value] = coord_key\n\n        # special coord tokens\n        special_coord_tokens = [\"[coord-out]\"]\n        for coord_key in special_coord_tokens:\n            coord_value = self.n_vocab\n            self.vocab[coord_key] = coord_value\n            self.inv_vocab[coord_value] = coord_key\n\n    def add_order_vocab(\n        self,\n        max_order,\n    ):\n        self.max_order = max_order\n\n        # order tokens\n        if max_order is not None:\n            for i in range(self.max_order):\n                order_key = f\"[order-{i}]\"\n                order_value = self.n_vocab\n                self.vocab[order_key] = order_value\n                self.inv_vocab[order_value] = order_key\n\n    def __call__(self, text, normalize=True):\n        return self.encode(text, normalize)\n\n    def encode(self, text, normalize=True):\n        if normalize:\n            text = self.normalize(text)\n\n        codes = []\n        for ch in text:\n            try:\n                codes.append(self.vocab[ch])\n\n            except KeyError:\n                codes.append(self.unk)\n\n        return codes\n\n    def decode(self, codes):\n        text = []\n        text_eos = self.vocab[\"[text_eos]\"]\n\n        for code in codes:\n            if code in [self.pad, text_eos]:\n                break\n\n            text.append(self.inv_vocab[code])\n\n        return \"\".join(text)\n\n    def encode_coord(self, quantized_coord):\n        # assert 0 <= quantized_coord <= self.bin_size - 1\n\n        if quantized_coord < 0 or quantized_coord >= self.bin_size:\n            return self.vocab[\"[coord-out]\"]\n\n        return self.vocab[f\"[coord-{quantized_coord}]\"]\n\n    def encode_coord_xy(self, quantized_coord_x, quantized_coord_y):\n        if (\n            quantized_coord_x < 0\n            or quantized_coord_x >= self.bin_size\n            or quantized_coord_y < 0\n            or quantized_coord_y >= self.bin_size\n        ):\n            return self.vocab[\"[coord-out]\"], self.vocab[\"[coord-out]\"]\n\n        return (\n            self.vocab[f\"[coord-{quantized_coord_x}]\"],\n            self.vocab[f\"[coord-{quantized_coord_y}]\"],\n        )\n\n    def decode_coord(self, coord_vocab):\n        min_coord_id, max_coord_id = 0, self.bin_size - 1\n                \n        # print(\"gia tri Min \", self.vocab[f\"[coord-{min_coord_id}]\"])\n        # print(\"gia tri hien tai \", coord_vocab)\n        \n        assert (\n            self.vocab[f\"[coord-{min_coord_id}]\"]\n            <= coord_vocab\n            <= self.vocab[f\"[coord-{max_coord_id}]\"]\n        )\n        return int(self.inv_vocab[coord_vocab][7:-1])\n\n    def encode_order(self, order):\n        assert 0 <= order <= self.max_order - 1\n        return self.vocab[f\"[order-{order}]\"]\n\n''')\ntokenizer.close()","metadata":{"execution":{"iopub.status.busy":"2024-07-15T10:50:45.422417Z","iopub.execute_input":"2024-07-15T10:50:45.422745Z","iopub.status.idle":"2024-07-15T10:50:45.434162Z","shell.execute_reply.started":"2024-07-15T10:50:45.422717Z","shell.execute_reply":"2024-07-15T10:50:45.433250Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"datasetpy = open('./units/dataset.py', 'w')\ndatasetpy.write('''import bisect\nimport math\nimport random\nimport warnings\n\nimport numpy as np\nimport torch\nfrom torch.utils import data\n\nfrom units.structures import Batch\n\n# import matplotlib.pyplot as plt\n# import matplotlib.image as mpimg\n\n\nDETECT_TYPE = \"quad\"  # 'single', 'box', 'quad', 'polygon'\nfrom PIL import Image, ImageDraw, ImageFont, ImageOps\nfont = ImageFont.truetype(\"TC/Arial.ttf\", size=24)\ndef resize_instance(polygon, image_size, orig_size):\n    \"\"\"\n    During training, the images were resized while maintaining the aspect ratio, and padding was added to fill the empty space.\n    Thus, perform the inverse transformation.\n    \"\"\"\n    ratio = max(orig_size) / max(image_size)\n\n    return polygon * ratio\n\n\ndef draw_ocr(img, coords, texts, detect_type=\"quad\", draw_width=5):\n    ocr_img = img.copy()\n    draw = ImageDraw.Draw(ocr_img)\n\n    for coord in coords:\n        if detect_type in [\"quad\", \"polygon\"]:\n            coord = np.array(coord)\n            draw.polygon(\n                coord.reshape(-1).astype(np.int64).tolist(),\n                outline=\"red\",\n                width=draw_width,\n            )\n        elif detect_type in [\"single\"]:\n            x, y = coord[0]\n            draw.ellipse([x - 4, y - 4, x + 4, y + 4], fill=\"red\", width=draw_width)\n        else:  # ['box']\n            c1, c2 = coord\n            x1, y1 = c1\n            x2, y2 = c2\n            draw.rectangle([x1, y1, x2, y2], outline=\"red\", width=draw_width)\n\n    for coord, text in zip(coords, texts):\n        size = font.getsize(text)\n\n        pos = coord[0].copy()\n        pos[1] -= size[1]\n        draw.rectangle(\n            (pos[0] - 1, pos[1] - 1, pos[0] + size[0] + 1, pos[1] + size[1] + 1),\n            fill=(0, 0, 0),\n        )\n        draw.text(pos, full_parse(text), font=font, fill=(255, 255, 255, 255))\n        print(\"tieng viet ne \", full_parse(text))\n\n    return ocr_img\n\n\nclass SampleError(Exception):\n    \"\"\"Raised when sample is malformed\"\"\"\n\n\nclass MultitaskDataset(data.Dataset):\n    \"\"\"General Multi-task Dataset\n    Args:\n        datasource: Datasource class form datasource.py\n        mappers: List of mappers that generates the input for the model\n        transform: dataset-wise transform object.\n            Image Tensorize operation should be contained.\n    \"\"\"\n\n    def __init__(self, datasource, mappers, transform):\n        super().__init__()\n        self.datasource = datasource\n        self.mappers = mappers\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.datasource)\n\n    def __getitem__(self, index):\n        \"\"\"\n        Args:\n            index (int): data index\n\n        Returns:\n            image (Tensor[float32]): tensorized image (C, H, W)\n            sample (structures.Sample): container that has the input for the model\n        \"\"\"\n        img, sample = self.datasource[index]\n\n        if self.transform is not None:\n            img, sample = self.transform(img, sample)\n\n        _, height, width = img.shape\n        sample.image_size = (height, width)\n\n        # We expect complaints about the samples only occurs in the mapper\n        # But maybe it is better to capture entire __getitem__?\n        try:\n            for mapper in self.mappers:\n                input = mapper(sample)\n                sample.set(mapper.name, input)\n\n        except SampleError:\n            try:\n                warnings.warn(\n                    f\"Failed to use {index} of {self.datasource}; try {index + 1}\"\n                )\n\n                return self.__getitem__(index + 1)\n\n            except IndexError:\n                rand_index = random.randrange(len(self))\n\n                warnings.warn(\n                    f\"Failed to use {index + 1} of {self.datasource}; try {rand_index}\"\n                )\n\n                return self.__getitem__(rand_index)\n                \n                \n                \n        # img = Image.open('./train_datasets/'+sample.img_path)\n        # img = ImageOps.exif_transpose(img)\n        # img_np = img.numpy().transpose((1, 2, 0))\n        # img_out = draw_ocr(img_np, sample.ocr.coords, sample.ocr.texts, 'quad')\n        \n        # img_np = img.mul(255).byte().numpy().transpose((1, 2, 0))  # Assuming the tensor is in [0, 1] range\n        # ocr_img = Image.fromarray(img_np)\n        # draw = ImageDraw.Draw(ocr_img)\n        # coords_numpy = np.array(sample.ocr.coords)\n        # img_out = draw_ocr(ocr_img, coords_numpy, sample.ocr.texts, 'quad')\n        # print(sample.img_path)\n        # numbers = re.findall(r'\\d+', sample.img_path)\n        # img_out.save(\"result_\"+ numbers[-1] + \".jpg\")        \n\n        return img, sample\n\n\nclass MultitaskCollator:\n    \"\"\"General Multi-task Collator\n    1. Get (max_h, max_w) from batch.\n    2. Use img_multiple to get canvas which has multiply of img_multiple.\n        (i.e. canvas % 32 == 0)\n\n    This collate funtion maintains aspect ratio of images with padding.\n    img_multiple is useful when you concat multiple features using FPN.\n\n    Args:\n        mappers: List of mappers that generates the input for the model\n        img_multiple (Union[int, float]): img-size multiplication\n\n    Returns:\n        batch (structures.Batch): container that contains:\n            images (Tensor[float32]): (B, C, H, W)\n            masks (Tensor[bool]): (B, H, W)\n            and additional inputs that mapper produces for the model\n    \"\"\"\n\n    def __init__(self, mappers, evaluate=False, img_multiple=32):\n        self.mappers = mappers\n        self.evaluate = evaluate\n        self.img_multiple = img_multiple\n\n    def __call__(self, batch):\n        img_shapes = [img.shape for img, _ in batch]\n        max_h = max([s[1] for s in img_shapes])\n        max_w = max([s[2] for s in img_shapes])\n\n        height = math.ceil(max_h / self.img_multiple) * self.img_multiple\n        width = math.ceil(max_w / self.img_multiple) * self.img_multiple\n        b_size = len(batch)\n\n        images = torch.zeros(\n            b_size, batch[0][0].shape[0], height, width, dtype=torch.float32\n        )\n        masks = torch.ones(b_size, height, width, dtype=torch.bool)\n\n        for i, (img, _) in enumerate(batch):\n            _, height, width = img.shape\n            images[i, :, :height, :width] = img\n            masks[i, :height, :width] = False\n\n        return_batch = Batch(images=images, masks=masks)\n        samples = [sample for _, sample in batch]\n\n        for mapper in self.mappers:\n            input = mapper.collate_fn(samples)\n            return_batch.set(mapper.name, input)\n\n        if self.evaluate:\n            return_batch.set(\"samples\", samples)\n\n        return return_batch\n\n\nclass WeightedDataset(data.Dataset):\n    def __init__(self, datasets, ratios, names=None):\n        super().__init__()\n        self.ratios = ratios\n        sizes = np.array([len(d) for d in datasets])\n        ratios = np.asarray(ratios)\n        self.names = names\n        n_sample = sizes.sum() * ratios\n        target_sample = n_sample / np.min(n_sample / sizes)\n        self.datasets = datasets\n        self.target_sample = np.round(target_sample).astype(int)\n        self.points = np.cumsum(self.target_sample).tolist()\n\n    def summary(self):\n        for i, (dset, ratio, sample) in enumerate(\n            zip(self.datasets, self.ratios, self.target_sample.tolist())\n        ):\n            if self.names is not None:\n                print(\n                    f\"#{i} {self.names[i]} total: {len(dset)} ratio: {ratio} sample: {sample}\"\n                )\n\n            else:\n                print(f\"#{i} total: {len(dset)} ratio: {ratio} sample: {sample}\")\n\n    def __len__(self):\n        return self.points[-1]\n\n    def __getitem__(self, index):\n        point = bisect.bisect(self.points, index)\n        dataset = self.datasets[point]\n\n        if point == 0:\n            diff = index\n\n        else:\n            diff = index - self.points[point - 1]\n\n        return dataset[diff % len(dataset)]\n''')\ndatasetpy.close()","metadata":{"execution":{"iopub.status.busy":"2024-07-15T10:50:45.875132Z","iopub.execute_input":"2024-07-15T10:50:45.875457Z","iopub.status.idle":"2024-07-15T10:50:45.888769Z","shell.execute_reply.started":"2024-07-15T10:50:45.875430Z","shell.execute_reply":"2024-07-15T10:50:45.887796Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"swin_transformerdotpy = open(\"./units/models/backbones/swin_transformer.py\", \"w\")\nswin_transformerdotpy.write('''# --------------------------------------------------------\n# Swin Transformer\n# Copyright (c) 2021 Microsoft\n# Licensed under The MIT License [see LICENSE for details]\n# Written by Ze Liu, Yutong Lin, Yixuan Wei\n# --------------------------------------------------------\nimport collections.abc\nimport math\nimport warnings\nfrom itertools import repeat\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.utils.checkpoint as checkpoint\nfrom torch.hub import load_state_dict_from_url\n\nmodel_urls = {\n    \"swin_small_patch4_window7_224_22k\": \"https://github.com/SwinTransformer/storage/releases/download/v1.0.8/swin_small_patch4_window7_224_22k.pth\",\n    \"swin_base_patch4_window7_224_22k\": \"https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_base_patch4_window7_224_22k.pth\",\n}\n\n\ndef drop_path(x, drop_prob: float = 0.0, training: bool = False):\n    \"\"\"Drop paths per sample.\n    Drop Stochastic Depth when applied in main path of residual blocks.\n    This is the same as the DropConnect impl I created for EfficientNet, etc networks,\n    however, the original name is misleading as 'Drop Connect' is a different form of\n    dropout in a separate paper...\n\n    See discussion: https://github.com/tensorflow/tpu/issues/494#issuecomment-532968956\n    ... I've opted for changing the layer and argument names to 'drop path' rather than\n    mix DropConnect as a layer name and use 'survival rate' as the argument.\n    \"\"\"\n    if drop_prob == 0.0 or not training:\n        return x\n    keep_prob = 1 - drop_prob\n    shape = (x.shape[0],) + (1,) * (\n        x.ndim - 1\n    )  # work with diff dim tensors, not just 2D ConvNets\n    random_tensor = keep_prob + torch.rand(shape, dtype=x.dtype, device=x.device)\n    random_tensor.floor_()  # binarize\n    output = x.div(keep_prob) * random_tensor\n    return output\n\n\nclass DropPath(nn.Module):\n    \"\"\"Drop paths per sample.\n    Drop Stochastic Depth when applied in main path of residual blocks.\n    \"\"\"\n\n    def __init__(self, drop_prob=None):\n        super().__init__()\n        self.drop_prob = drop_prob\n\n    def forward(self, x):\n        return drop_path(x, self.drop_prob, self.training)\n\n\ndef _ntuple(n):\n    def parse(x):\n        if isinstance(x, collections.abc.Iterable):\n            return x\n        return tuple(repeat(x, n))\n\n    return parse\n\n\nto_2tuple = _ntuple(2)\n\n\n@torch.no_grad()\ndef _no_grad_trunc_normal_(tensor, mean, std, a, b):\n    # Cut & paste from PyTorch official master until it's in a few official releases\n    # Method based on\n    # https://people.sc.fsu.edu/~jburkardt/presentations/truncated_normal.pdf\n    def norm_cdf(x):\n        # Computes standard normal cumulative distribution function\n        return (1.0 + math.erf(x / math.sqrt(2.0))) / 2.0\n\n    if (mean < a - 2 * std) or (mean > b + 2 * std):\n        warnings.warn(\n            \"mean is more than 2 std from [a, b] in nn.init.trunc_normal_. \"\n            \"The distribution of values may be incorrect.\",\n            stacklevel=2,\n        )\n\n    # Values are generated by using a truncated uniform distribution and\n    # then using the inverse CDF for the normal distribution.\n    # Get upper and lower cdf values\n    l = norm_cdf((a - mean) / std)\n    u = norm_cdf((b - mean) / std)\n    # Uniformly fill tensor with values from [l, u], then translate to\n    # [2l-1, 2u-1].\n    tensor.uniform_(2 * l - 1, 2 * u - 1)\n    # Use inverse cdf transform for normal distribution to get truncated\n    # standard normal\n    tensor.erfinv_()\n    # Transform to proper mean, std\n    tensor.mul_(std * math.sqrt(2.0))\n    tensor.add_(mean)\n    # Clamp to ensure it's in the proper range\n    tensor.clamp_(min=a, max=b)\n\n    return tensor\n\n\ndef trunc_normal_(tensor, mean=0.0, std=1.0, a=-2.0, b=2.0):\n    # type: (Tensor, float, float, float, float) -> Tensor\n    r\"\"\"Fills the input Tensor with values drawn from a truncated\n    normal distribution. The values are effectively drawn from the\n    normal distribution :math:`\\mathcal{N}(\\text{mean}, \\text{std}^2)`\n    with values outside :math:`[a, b]` redrawn until they are within\n    the bounds. The method used for generating the random values works\n    best when :math:`a \\leq \\text{mean} \\leq b`.\n    Args:\n        tensor: an n-dimensional `torch.Tensor`\n        mean: the mean of the normal distribution\n        std: the standard deviation of the normal distribution\n        a: the minimum cutoff value\n        b: the maximum cutoff value\n    Examples:\n        >>> w = torch.empty(3, 5)\n        >>> nn.init.trunc_normal_(w)\n    \"\"\"\n    return _no_grad_trunc_normal_(tensor, mean, std, a, b)\n\n\nclass Mlp(nn.Module):\n    \"\"\"Multilayer perceptron.\"\"\"\n\n    def __init__(\n        self,\n        in_features,\n        hidden_features=None,\n        out_features=None,\n        act_layer=nn.GELU,\n        drop=0.0,\n    ):\n        super().__init__()\n        out_features = out_features or in_features\n        hidden_features = hidden_features or in_features\n        self.fc1 = nn.Linear(in_features, hidden_features)\n        self.act = act_layer()\n        self.fc2 = nn.Linear(hidden_features, out_features)\n        self.drop = nn.Dropout(drop)\n\n    def forward(self, x):\n        x = self.fc1(x)\n        x = self.act(x)\n        x = self.drop(x)\n        x = self.fc2(x)\n        x = self.drop(x)\n        return x\n\n\ndef window_partition(x, window_size):\n    \"\"\"\n    Args:\n        x: (B, H, W, C)\n        window_size (int): window size\n    Returns:\n        windows: (num_windows*B, window_size, window_size, C)\n    \"\"\"\n    B, H, W, C = x.shape\n    x = x.view(B, H // window_size, window_size, W // window_size, window_size, C)\n    windows = (\n        x.permute(0, 1, 3, 2, 4, 5).contiguous().view(-1, window_size, window_size, C)\n    )\n    return windows\n\n\ndef window_reverse(windows, window_size, H, W):\n    \"\"\"\n    Args:\n        windows: (num_windows*B, window_size, window_size, C)\n        window_size (int): Window size\n        H (int): Height of image\n        W (int): Width of image\n    Returns:\n        x: (B, H, W, C)\n    \"\"\"\n    B = int(windows.shape[0] / (H * W / window_size / window_size))\n    x = windows.view(\n        B, H // window_size, W // window_size, window_size, window_size, -1\n    )\n    x = x.permute(0, 1, 3, 2, 4, 5).contiguous().view(B, H, W, -1)\n    return x\n\n\nclass WindowAttention(nn.Module):\n    \"\"\"Window based multi-head self attention (W-MSA) module with relative pos bias.\n    It supports both of shifted and non-shifted window.\n    Args:\n        dim (int): Number of input channels.\n        window_size (tuple[int]): The height and width of the window.\n        num_heads (int): Number of attention heads.\n        qkv_bias (bool, optional):\n            If True, add a learnable bias to query, key, value. Default: True\n        qk_scale (float | None, optional): Override default qk scale if set\n        attn_drop (float, optional): Dropout ratio of attention weight. Default: 0.0\n        proj_drop (float, optional): Dropout ratio of output. Default: 0.0\n    \"\"\"\n\n    def __init__(\n        self,\n        dim,\n        window_size,\n        num_heads,\n        qkv_bias=True,\n        qk_scale=None,\n        attn_drop=0.0,\n        proj_drop=0.0,\n    ):\n        super().__init__()\n        self.dim = dim\n        self.window_size = window_size  # Wh, Ww\n        self.num_heads = num_heads\n        head_dim = dim // num_heads\n        self.scale = qk_scale or head_dim ** -0.5\n        # define a parameter table of relative position bias\n        self.relative_position_bias_table = nn.Parameter(\n            torch.zeros((2 * window_size[0] - 1) * (2 * window_size[1] - 1), num_heads)\n        )  # 2*Wh-1 * 2*Ww-1, nH\n        # get pair-wise relative position index for each token inside the window\n        coords_h = torch.arange(self.window_size[0])\n        coords_w = torch.arange(self.window_size[1])\n        coords = torch.stack(torch.meshgrid([coords_h, coords_w]))  # 2, Wh, Ww\n        coords_flatten = torch.flatten(coords, 1)  # 2, Wh*Ww\n        relative_coords = (\n            coords_flatten[:, :, None] - coords_flatten[:, None, :]\n        )  # 2, Wh*Ww, Wh*Ww\n        relative_coords = relative_coords.permute(\n            1, 2, 0\n        ).contiguous()  # Wh*Ww, Wh*Ww, 2\n        relative_coords[:, :, 0] += self.window_size[0] - 1  # shift to start from 0\n        relative_coords[:, :, 1] += self.window_size[1] - 1\n        relative_coords[:, :, 0] *= 2 * self.window_size[1] - 1\n        relative_position_index = relative_coords.sum(-1)  # Wh*Ww, Wh*Ww\n        self.register_buffer(\"relative_position_index\", relative_position_index)\n        self.qkv = nn.Linear(dim, dim * 3, bias=qkv_bias)\n        self.attn_drop = nn.Dropout(attn_drop)\n        self.proj = nn.Linear(dim, dim)\n        self.proj_drop = nn.Dropout(proj_drop)\n        trunc_normal_(self.relative_position_bias_table, std=0.02)\n        self.softmax = nn.Softmax(dim=-1)\n\n    def forward(self, x, mask=None):\n        \"\"\"Forward function.\n        Args:\n            x: input features with shape of (num_windows*B, N, C)\n            mask: (0/-inf) mask with shape of (num_windows, Wh*Ww, Wh*Ww) or None\n        \"\"\"\n        B_, N, C = x.shape\n        qkv = (\n            self.qkv(x)\n            .reshape(B_, N, 3, self.num_heads, C // self.num_heads)\n            .permute(2, 0, 3, 1, 4)\n        )\n        q, k, v = (\n            qkv[0],\n            qkv[1],\n            qkv[2],\n        )  # make torchscript happy (cannot use tensor as tuple)\n        q = q * self.scale\n        attn = q @ k.transpose(-2, -1)\n        relative_position_bias = self.relative_position_bias_table[\n            self.relative_position_index.view(-1)\n        ].view(\n            self.window_size[0] * self.window_size[1],\n            self.window_size[0] * self.window_size[1],\n            -1,\n        )  # Wh*Ww,Wh*Ww,nH\n        relative_position_bias = relative_position_bias.permute(\n            2, 0, 1\n        ).contiguous()  # nH, Wh*Ww, Wh*Ww\n        attn = attn + relative_position_bias.unsqueeze(0)\n        if mask is not None:\n            nW = mask.shape[0]\n            attn = attn.view(B_ // nW, nW, self.num_heads, N, N) + mask.unsqueeze(\n                1\n            ).unsqueeze(0)\n            attn = attn.view(-1, self.num_heads, N, N)\n            attn = self.softmax(attn)\n        else:\n            attn = self.softmax(attn)\n        attn = self.attn_drop(attn)\n        x = (attn @ v).transpose(1, 2).reshape(B_, N, C)\n        x = self.proj(x)\n        x = self.proj_drop(x)\n        return x\n\n\nclass SwinTransformerBlock(nn.Module):\n    \"\"\"Swin Transformer Block.\n    Args:\n        dim (int): Number of input channels.\n        num_heads (int): Number of attention heads.\n        window_size (int): Window size.\n        shift_size (int): Shift size for SW-MSA.\n        mlp_ratio (float): Ratio of mlp hidden dim to embedding dim.\n        qkv_bias (bool, optional):\n            If True, add a learnable bias to query, key, value. Default: True\n        qk_scale (float | None, optional): Override default qk scale if set.\n        drop (float, optional): Dropout rate. Default: 0.0\n        attn_drop (float, optional): Attention dropout rate. Default: 0.0\n        drop_path (float, optional): Stochastic depth rate. Default: 0.0\n        act_layer (nn.Module, optional): Activation layer. Default: nn.GELU\n        norm_layer (nn.Module, optional): Normalization layer.  Default: nn.LayerNorm\n    \"\"\"\n\n    def __init__(\n        self,\n        dim,\n        num_heads,\n        window_size=7,\n        shift_size=0,\n        mlp_ratio=4.0,\n        qkv_bias=True,\n        qk_scale=None,\n        drop=0.0,\n        attn_drop=0.0,\n        drop_path=0.0,\n        act_layer=nn.GELU,\n        norm_layer=nn.LayerNorm,\n    ):\n        super().__init__()\n        self.dim = dim\n        self.num_heads = num_heads\n        self.window_size = window_size\n        self.shift_size = shift_size\n        self.mlp_ratio = mlp_ratio\n        assert (\n            0 <= self.shift_size < self.window_size\n        ), \"shift_size must in 0-window_size\"\n        self.norm1 = norm_layer(dim)\n        self.attn = WindowAttention(\n            dim,\n            window_size=to_2tuple(self.window_size),\n            num_heads=num_heads,\n            qkv_bias=qkv_bias,\n            qk_scale=qk_scale,\n            attn_drop=attn_drop,\n            proj_drop=drop,\n        )\n        self.drop_path = DropPath(drop_path) if drop_path > 0.0 else nn.Identity()\n        self.norm2 = norm_layer(dim)\n        mlp_hidden_dim = int(dim * mlp_ratio)\n        self.mlp = Mlp(\n            in_features=dim,\n            hidden_features=mlp_hidden_dim,\n            act_layer=act_layer,\n            drop=drop,\n        )\n        self.H = None\n        self.W = None\n\n    def forward(self, x, mask_matrix):\n        \"\"\"Forward function.\n        Args:\n            x: Input feature, tensor size (B, H*W, C).\n            H, W: Spatial resolution of the input feature.\n            mask_matrix: Attention mask for cyclic shift.\n        \"\"\"\n        B, L, C = x.shape\n        H, W = self.H, self.W\n        assert L == H * W, \"input feature has wrong size\"\n        shortcut = x\n        x = self.norm1(x)\n        x = x.view(B, H, W, C)\n        # pad feature maps to multiples of window size\n        pad_l = pad_t = 0\n        pad_r = (self.window_size - W % self.window_size) % self.window_size\n        pad_b = (self.window_size - H % self.window_size) % self.window_size\n        x = F.pad(x, (0, 0, pad_l, pad_r, pad_t, pad_b))\n        _, Hp, Wp, _ = x.shape\n        # cyclic shift\n        if self.shift_size > 0:\n            shifted_x = torch.roll(\n                x, shifts=(-self.shift_size, -self.shift_size), dims=(1, 2)\n            )\n            attn_mask = mask_matrix\n        else:\n            shifted_x = x\n            attn_mask = None\n        # partition windows\n        x_windows = window_partition(\n            shifted_x, self.window_size\n        )  # nW*B, window_size, window_size, C\n        x_windows = x_windows.view(\n            -1, self.window_size * self.window_size, C\n        )  # nW*B, window_size*window_size, C\n        # W-MSA/SW-MSA\n        attn_windows = self.attn(\n            x_windows, mask=attn_mask\n        )  # nW*B, window_size*window_size, C\n        # merge windows\n        attn_windows = attn_windows.view(-1, self.window_size, self.window_size, C)\n        shifted_x = window_reverse(attn_windows, self.window_size, Hp, Wp)  # B H' W' C\n        # reverse cyclic shift\n        if self.shift_size > 0:\n            x = torch.roll(\n                shifted_x, shifts=(self.shift_size, self.shift_size), dims=(1, 2)\n            )\n        else:\n            x = shifted_x\n        if pad_r > 0 or pad_b > 0:\n            x = x[:, :H, :W, :].contiguous()\n        x = x.view(B, H * W, C)\n        # FFN\n        x = shortcut + self.drop_path(x)\n        x = x + self.drop_path(self.mlp(self.norm2(x)))\n        return x\n\n\nclass PatchMerging(nn.Module):\n    \"\"\"Patch Merging Layer\n    Args:\n        dim (int): Number of input channels.\n        norm_layer (nn.Module, optional): Normalization layer.  Default: nn.LayerNorm\n    \"\"\"\n\n    def __init__(self, dim, norm_layer=nn.LayerNorm):\n        super().__init__()\n        self.dim = dim\n        self.reduction = nn.Linear(4 * dim, 2 * dim, bias=False)\n        self.norm = norm_layer(4 * dim)\n\n    def forward(self, x, H, W):\n        \"\"\"Forward function.\n        Args:\n            x: Input feature, tensor size (B, H*W, C).\n            H, W: Spatial resolution of the input feature.\n        \"\"\"\n        B, L, C = x.shape\n        assert L == H * W, \"input feature has wrong size\"\n        x = x.view(B, H, W, C)\n        # padding\n        pad_input = (H % 2 == 1) or (W % 2 == 1)\n        if pad_input:\n            x = F.pad(x, (0, 0, 0, W % 2, 0, H % 2))\n        x0 = x[:, 0::2, 0::2, :]  # B H/2 W/2 C\n        x1 = x[:, 1::2, 0::2, :]  # B H/2 W/2 C\n        x2 = x[:, 0::2, 1::2, :]  # B H/2 W/2 C\n        x3 = x[:, 1::2, 1::2, :]  # B H/2 W/2 C\n        x = torch.cat([x0, x1, x2, x3], -1)  # B H/2 W/2 4*C\n        x = x.view(B, -1, 4 * C)  # B H/2*W/2 4*C\n        x = self.norm(x)\n        x = self.reduction(x)\n        return x\n\n\nclass BasicLayer(nn.Module):\n    \"\"\"A basic Swin Transformer layer for one stage.\n    Args:\n        dim (int): Number of feature channels\n        depth (int): Depths of this stage.\n        num_heads (int): Number of attention head.\n        window_size (int): Local window size. Default: 7.\n        mlp_ratio (float): Ratio of mlp hidden dim to embedding dim. Default: 4.\n        qkv_bias (bool, optional):\n            If True, add a learnable bias to query, key, value. Default: True\n        qk_scale (float | None, optional): Override default qk scale if set.\n        drop (float, optional): Dropout rate. Default: 0.0\n        attn_drop (float, optional): Attention dropout rate. Default: 0.0\n        drop_path (float | tuple[float], optional): Stochastic depth rate. Default: 0.0\n        norm_layer (nn.Module, optional): Normalization layer. Default: nn.LayerNorm\n        downsample (nn.Module | None, optional):\n            Downsample layer at the end of the layer. Default: None\n        use_checkpoint (bool):\n            Whether to use checkpointing to save memory. Default: False.\n    \"\"\"\n\n    def __init__(\n        self,\n        dim,\n        depth,\n        num_heads,\n        window_size=7,\n        mlp_ratio=4.0,\n        qkv_bias=True,\n        qk_scale=None,\n        drop=0.0,\n        attn_drop=0.0,\n        drop_path=0.0,\n        norm_layer=nn.LayerNorm,\n        downsample=None,\n        use_checkpoint=False,\n    ):\n        super().__init__()\n        self.window_size = window_size\n        self.shift_size = window_size // 2\n        self.depth = depth\n        self.use_checkpoint = use_checkpoint\n        # build blocks\n        self.blocks = nn.ModuleList(\n            [\n                SwinTransformerBlock(\n                    dim=dim,\n                    num_heads=num_heads,\n                    window_size=window_size,\n                    shift_size=0 if (i % 2 == 0) else window_size // 2,\n                    mlp_ratio=mlp_ratio,\n                    qkv_bias=qkv_bias,\n                    qk_scale=qk_scale,\n                    drop=drop,\n                    attn_drop=attn_drop,\n                    drop_path=drop_path[i]\n                    if isinstance(drop_path, list)\n                    else drop_path,\n                    norm_layer=norm_layer,\n                )\n                for i in range(depth)\n            ]\n        )\n        # patch merging layer\n        if downsample is not None:\n            self.downsample = downsample(dim=dim, norm_layer=norm_layer)\n        else:\n            self.downsample = None\n\n    def forward(self, x, H, W):\n        \"\"\"Forward function.\n        Args:\n            x: Input feature, tensor size (B, H*W, C).\n            H, W: Spatial resolution of the input feature.\n        \"\"\"\n        # calculate attention mask for SW-MSA\n        Hp = int(math.ceil(H / self.window_size)) * self.window_size\n        Wp = int(math.ceil(W / self.window_size)) * self.window_size\n        img_mask = torch.zeros((1, Hp, Wp, 1), device=x.device)  # 1 Hp Wp 1\n        h_slices = (\n            slice(0, -self.window_size),\n            slice(-self.window_size, -self.shift_size),\n            slice(-self.shift_size, None),\n        )\n        w_slices = (\n            slice(0, -self.window_size),\n            slice(-self.window_size, -self.shift_size),\n            slice(-self.shift_size, None),\n        )\n        cnt = 0\n        for h in h_slices:\n            for w in w_slices:\n                img_mask[:, h, w, :] = cnt\n                cnt += 1\n        mask_windows = window_partition(\n            img_mask, self.window_size\n        )  # nW, window_size, window_size, 1\n        mask_windows = mask_windows.view(-1, self.window_size * self.window_size)\n        attn_mask = mask_windows.unsqueeze(1) - mask_windows.unsqueeze(2)\n        attn_mask = attn_mask.masked_fill(attn_mask != 0, float(-100.0)).masked_fill(\n            attn_mask == 0, float(0.0)\n        )\n        for blk in self.blocks:\n            blk.H, blk.W = H, W\n            if self.use_checkpoint:\n                x = checkpoint.checkpoint(blk, x, attn_mask, use_reentrant=False) # NP added use_reentrant=False\n            else:\n                x = blk(x, attn_mask)\n        if self.downsample is not None:\n            x_down = self.downsample(x, H, W)\n            Wh, Ww = (H + 1) // 2, (W + 1) // 2\n            return x, H, W, x_down, Wh, Ww\n        else:\n            return x, H, W, x, H, W\n\n\nclass PatchEmbed(nn.Module):\n    \"\"\"Image to Patch Embedding\n    Args:\n        patch_size (int): Patch token size. Default: 4.\n        in_chans (int): Number of input image channels. Default: 3.\n        embed_dim (int): Number of linear projection output channels. Default: 96.\n        norm_layer (nn.Module, optional): Normalization layer. Default: None\n    \"\"\"\n\n    def __init__(self, patch_size=4, in_chans=3, embed_dim=96, norm_layer=None):\n        super().__init__()\n        patch_size = to_2tuple(patch_size)\n        self.patch_size = patch_size\n        self.in_chans = in_chans\n        self.embed_dim = embed_dim\n        self.proj = nn.Conv2d(\n            in_chans, embed_dim, kernel_size=patch_size, stride=patch_size\n        )\n        if norm_layer is not None:\n            self.norm = norm_layer(embed_dim)\n        else:\n            self.norm = None\n\n    def forward(self, x):\n        \"\"\"Forward function.\"\"\"\n        # padding\n        _, _, H, W = x.size()\n        if W % self.patch_size[1] != 0:\n            x = F.pad(x, (0, self.patch_size[1] - W % self.patch_size[1]))\n        if H % self.patch_size[0] != 0:\n            x = F.pad(x, (0, 0, 0, self.patch_size[0] - H % self.patch_size[0]))\n        x = self.proj(x)  # B C Wh Ww\n        if self.norm is not None:\n            Wh, Ww = x.size(2), x.size(3)\n            x = x.flatten(2).transpose(1, 2)\n            x = self.norm(x)\n            x = x.transpose(1, 2).view(-1, self.embed_dim, Wh, Ww)\n        return x\n\n\nclass SwinTransformer(nn.Module):\n    \"\"\"Swin Transformer backbone.\n        A PyTorch impl of:\n            `Swin Transformer: Hierarchical Vision Transformer using Shifted Windows`\n            https://arxiv.org/pdf/2103.14030\n    Args:\n        pretrain_img_size (int): Input image size for training the pretrained model,\n            used in absolute postion embedding. Default 224.\n        patch_size (int | tuple(int)): Patch size. Default: 4.\n        in_chans (int): Number of input image channels. Default: 3.\n        embed_dim (int): Number of linear projection output channels. Default: 96.\n        depths (tuple[int]): Depths of each Swin Transformer stage.\n        num_heads (tuple[int]): Number of attention head of each stage.\n        window_size (int): Window size. Default: 7.\n        mlp_ratio (float): Ratio of mlp hidden dim to embedding dim. Default: 4.\n        qkv_bias (bool):\n            If True, add a learnable bias to query, key, value. Default: True\n        qk_scale (float): Override default qk scale of head_dim ** -0.5 if set.\n        drop_rate (float): Dropout rate.\n        attn_drop_rate (float): Attention dropout rate. Default: 0.\n        drop_path_rate (float): Stochastic depth rate. Default: 0.2.\n        norm_layer (nn.Module): Normalization layer. Default: nn.LayerNorm.\n        ape (bool): If True, add absolute position embedding to the patch embedding.\n            Default: False.\n        patch_norm (bool): If True, add normalization after patch embedding.\n            Default: True.\n        out_indices (Sequence[int]): Output from which stages.\n        frozen_stages (int): Stages to be frozen (stop grad and set eval mode).\n            -1 means not freezing any parameters.\n        use_checkpoint (bool): Whether to use checkpointing to save memory.\n            Default: False.\n    \"\"\"\n\n    def __init__(\n        self,\n        pretrain_img_size=224,\n        patch_size=4,\n        in_chans=3,\n        embed_dim=96,\n        depths=[2, 2, 6, 2],\n        num_heads=[3, 6, 12, 24],\n        window_size=7,\n        mlp_ratio=4.0,\n        qkv_bias=True,\n        qk_scale=None,\n        drop_rate=0.0,\n        attn_drop_rate=0.0,\n        drop_path_rate=0.2,\n        norm_layer=nn.LayerNorm,\n        ape=False,\n        patch_norm=True,\n        out_indices=(0, 1, 2, 3),\n        frozen_stages=-1,\n        use_checkpoint=False,\n    ):\n        super().__init__()\n        self.pretrain_img_size = pretrain_img_size\n        self.num_layers = len(depths)\n        self.embed_dim = embed_dim\n        self.ape = ape\n        self.patch_norm = patch_norm\n        self.out_indices = out_indices\n        self.frozen_stages = frozen_stages\n        # split image into non-overlapping patches\n        self.patch_embed = PatchEmbed(\n            patch_size=patch_size,\n            in_chans=in_chans,\n            embed_dim=embed_dim,\n            norm_layer=norm_layer if self.patch_norm else None,\n        )\n        # absolute position embedding\n        if self.ape:\n            pretrain_img_size = to_2tuple(pretrain_img_size)\n            patch_size = to_2tuple(patch_size)\n            patches_resolution = [\n                pretrain_img_size[0] // patch_size[0],\n                pretrain_img_size[1] // patch_size[1],\n            ]\n            self.absolute_pos_embed = nn.Parameter(\n                torch.zeros(1, embed_dim, patches_resolution[0], patches_resolution[1])\n            )\n            trunc_normal_(self.absolute_pos_embed, std=0.02)\n        self.pos_drop = nn.Dropout(p=drop_rate)\n        # stochastic depth\n        dpr = [\n            x.item() for x in torch.linspace(0, drop_path_rate, sum(depths))\n        ]  # stochastic depth decay rule\n        # build layers\n        self.layers = nn.ModuleList()\n        for i_layer in range(self.num_layers):\n            layer = BasicLayer(\n                dim=int(embed_dim * 2 ** i_layer),\n                depth=depths[i_layer],\n                num_heads=num_heads[i_layer],\n                window_size=window_size,\n                mlp_ratio=mlp_ratio,\n                qkv_bias=qkv_bias,\n                qk_scale=qk_scale,\n                drop=drop_rate,\n                attn_drop=attn_drop_rate,\n                drop_path=dpr[sum(depths[:i_layer]) : sum(depths[: i_layer + 1])],\n                norm_layer=norm_layer,\n                downsample=PatchMerging if (i_layer < self.num_layers - 1) else None,\n                use_checkpoint=use_checkpoint,\n            )\n            self.layers.append(layer)\n        num_features = [int(embed_dim * 2 ** i) for i in range(self.num_layers)]\n        self.num_features = num_features\n        # add a norm layer for each output\n        for i_layer in out_indices:\n            layer = norm_layer(num_features[i_layer])\n            layer_name = f\"norm{i_layer}\"\n            self.add_module(layer_name, layer)\n        self._freeze_stages()\n\n    def _freeze_stages(self):\n        print(\"frozen ne \", self.frozen_stages)\n        if self.frozen_stages >= 0:\n            self.patch_embed.eval()\n            for param in self.patch_embed.parameters():\n                param.requires_grad = False\n        if self.frozen_stages >= 1 and self.ape:\n            self.absolute_pos_embed.requires_grad = False\n            \n        if self.frozen_stages == 9:\n            print(\"MTPPPPP\")\n            self.pos_drop.eval()\n            for i in range(0, 2):\n                m = self.layers[i]\n                m.eval()\n                for param in m.parameters():\n                    param.requires_grad = False\n                    \n            third_stage = self.layers[2]\n            for block in third_stage.blocks[0:5]:\n                block.eval()\n                for param in block.parameters():\n                    param.requires_grad = False\n            \n            return\n            \n        if self.frozen_stages >= 2:\n            self.pos_drop.eval()\n            for i in range(0, self.frozen_stages - 1):\n                m = self.layers[i]\n                m.eval()\n                for param in m.parameters():\n                    param.requires_grad = False\n\n    def init_weights(self, pretrained=None):\n        \"\"\"Initialize the weights in backbone.\n        Args:\n            pretrained (str, optional): Path to pre-trained weights.\n                Defaults to None.\n        \"\"\"\n\n        def _init_weights(m):\n            if isinstance(m, nn.Linear):\n                trunc_normal_(m.weight, std=0.02)\n                if isinstance(m, nn.Linear) and m.bias is not None:\n                    nn.init.constant_(m.bias, 0)\n            elif isinstance(m, nn.LayerNorm):\n                nn.init.constant_(m.bias, 0)\n                nn.init.constant_(m.weight, 1.0)\n\n        if isinstance(pretrained, str):\n            self.apply(_init_weights)\n        elif pretrained is None:\n            self.apply(_init_weights)\n        else:\n            raise TypeError(\"pretrained must be a str or None\")\n\n    def forward(self, x, input_pos=None):\n        \"\"\"Forward function.\"\"\"\n        x = self.patch_embed(x)\n        if input_pos is not None:\n            x = x + input_pos\n        Wh, Ww = x.size(2), x.size(3)\n        if self.ape:\n            # interpolate the position embedding to the corresponding size\n            absolute_pos_embed = F.interpolate(\n                self.absolute_pos_embed, size=(Wh, Ww), mode=\"bicubic\"\n            )\n            x = (x + absolute_pos_embed).flatten(2).transpose(1, 2)  # B Wh*Ww C\n        else:\n            x = x.flatten(2).transpose(1, 2)\n        x = self.pos_drop(x)\n        outs = []\n        for i in range(self.num_layers):\n            layer = self.layers[i]\n            x_out, H, W, x, Wh, Ww = layer(x, Wh, Ww)\n            if i in self.out_indices:\n                norm_layer = getattr(self, f\"norm{i}\")\n                x_out = norm_layer(x_out)\n                out = (\n                    x_out.view(-1, H, W, self.num_features[i])\n                    .permute(0, 3, 1, 2)\n                    .contiguous()\n                )\n                outs.append(out)\n        return tuple([None] + outs)\n\n    def train(self, mode=True):\n        \"\"\"Convert the model into training mode while keep layers freezed.\"\"\"\n        super(SwinTransformer, self).train(mode)\n        self._freeze_stages()\n\n\ndef swin_transformer_s(frozen_stages=-1, pretrained: bool = False, use_checkpoint=False):\n    model = SwinTransformer(\n        embed_dim=96,\n        depths=(2, 2, 18, 2),\n        num_heads=[3, 6, 12, 24],\n        window_size=7,\n        ape=False,\n        drop_path_rate=0.2,\n        patch_norm=True,\n        use_checkpoint=use_checkpoint,\n        qkv_bias=True,\n        frozen_stages=frozen_stages\n    )\n    if pretrained:\n        state_dict = load_state_dict_from_url(\n            model_urls[\"swin_small_patch4_window7_224_22k\"],\n            progress=True,\n            map_location=lambda storage, loc: storage,\n        )\n        print(model.load_state_dict(state_dict[\"model\"], strict=False))\n\n    return model, (None, 96, 192, 384, 768)\n\n\ndef swin_transformer_b(frozen_stages=-1, pretrained: bool = False, use_checkpoint=False):\n    model = SwinTransformer(\n        embed_dim=128,\n        depths=(2, 2, 18, 2),\n        num_heads=[4, 8, 16, 32],\n        window_size=7,\n        ape=False,\n        drop_path_rate=0.2,\n        patch_norm=True,\n        use_checkpoint=use_checkpoint,\n        qkv_bias=True,\n        frozen_stages=frozen_stages\n    )\n    print(\"Day la pretrained \", pretrained)\n    if pretrained:\n        state_dict = load_state_dict_from_url(\n            model_urls[\"swin_base_patch4_window7_224_22k\"],\n            progress=True,\n            map_location=lambda storage, loc: storage,\n        )\n        print(\"DUNG LAM TRAI TIM ANH DAU\")\n        print(model.load_state_dict(state_dict[\"model\"], strict=False))\n\n    return model, (None, 128, 256, 512, 1024)\n''')\nswin_transformerdotpy.close()","metadata":{"execution":{"iopub.status.busy":"2024-07-15T10:50:46.165001Z","iopub.execute_input":"2024-07-15T10:50:46.165344Z","iopub.status.idle":"2024-07-15T10:50:46.202482Z","shell.execute_reply.started":"2024-07-15T10:50:46.165318Z","shell.execute_reply":"2024-07-15T10:50:46.201401Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"# @title train.py\ntrainpy = open('./script/train.py', 'w')\ntrainpy.write('''import warnings\n\nfrom collections import OrderedDict\n\nwarnings.filterwarnings(\"ignore\")\n\nimport torch\nfrom tensorfn import distributed as dist\nfrom tensorfn import get_logger, load_arg_config\nfrom tensorfn.config import instantiate\nfrom torch import nn\nfrom torch.cuda.amp import GradScaler, autocast\nfrom torch.utils.data import ConcatDataset, DataLoader\n\nfrom units.config import E2EConfig\nfrom units.dataset import MultitaskCollator, MultitaskDataset, WeightedDataset\nfrom units.train_fn import add_weight_decay, sample_data, wd_skip_fn\nfrom units.transform import Compose\n\ndef make_dataset(datasources, weighted=True):\n    if not isinstance(datasources, (list, tuple)):\n        datasources = [datasources]\n\n    sources = []\n    ratios = []\n    names = []\n\n    for datasource in datasources:\n        source_fn = instantiate(datasource.datasource)\n\n        for name in datasource.sources:\n            if isinstance(name, str):\n                ratio = 1\n\n            else:\n                name, ratio = name\n\n            sources.append(source_fn(datasource.path, name))\n            ratios.append(ratio)\n            names.append(name)\n\n    if weighted:\n        source = WeightedDataset(sources, ratios, names=names)\n\n        if dist.is_primary():\n            source.summary()\n\n    else:\n        source = ConcatDataset(sources)\n\n        if dist.is_primary():\n            for i, (name, s) in enumerate(zip(names, sources)):\n                print(f\"#{i} {name} total: {len(s)} \")\n\n    return source\n\n@torch.no_grad()\ndef evaluate(conf, mappers, loader, model, device, logger):\n    is_train = model.training\n    model.eval()\n\n    # metrics = Metrics(\n    #     conf.evaluate.eval_metrics, mappers, device, conf.evaluate.eval_metrics_option\n    # )\n    total = len(loader)\n\n    for i, batch in enumerate(loader):\n        out = model(batch.to(device))\n        # metrics(batch, out)\n\n        if dist.is_primary() and i % conf.log_freq == 0:\n            logger.info(f\"evaluation [{i}/{total}]\")\n\n    # res = metrics.compute()\n    report = {}\n\n    if is_train:\n        model.train()\n\n    return report\n\ndef main(conf):\n    \n    device = \"cuda\"\n    \n    conf.distributed = conf.n_gpu > 1\n    \n    logger = get_logger(mode=conf.logger)\n\n    logger.info(conf.dict())\n    model = instantiate(conf.model).to(device)\n    \n    # encoder = model.encoder\n    # encoder.eval()\n    # for param in encoder.parameters():\n    #     param.requires_grad = False\n    \n    # BBencoder = model.encoder.backbone\n    # for layer in BBencoder.layers[0:3]:\n    #     layer.eval()\n    #     for param in layer.parameters():\n    #         param.requires_grad = False\n        \n    # connector = model.connector\n    # connector.eval()\n    # for param in connector.parameters():\n    #    param.requires_grad = False\n        \n    # proj_mlp = model.proj_mlp\n    # proj_mlp.eval()\n    # for param in proj_mlp.parameters():\n    #     param.requires_grad = False\n    \n    \n    # n_layers_to_train = 2\n    # Đóng băng các lớp đầu của decoder\n    # decoder = model.decoder\n    # decoder.pix2seq_decoder.eval()\n    # for layer in decoder.pix2seq_decoder.layers[:-n_layers_to_train]:\n    # for layer in decoder.pix2seq_decoder.layers:\n    #     for param in layer.parameters():\n    #         param.requires_grad = False\n\n    # Cho phép huấn luyện n_layers_to_train lớp cuối của decoder\n    # for layer in decoder.pix2seq_decoder.layers[-n_layers_to_train:]:\n    #     layer.train()\n    #     for param in layer.parameters():\n    #         param.requires_grad = True\n\n    # Cho phép huấn luyện các tầng khác của decoder\n    # decoder.pix2seq_head.train()\n    # for param in decoder.pix2seq_head.parameters():\n    #     param.requires_grad = True\n        \n    # decoder.pix2seq_embed.eval()\n    # for param in decoder.pix2seq_embed.parameters():\n    #     param.requires_grad = False\n  \n    \n    model.train()\n\n    if conf.distributed:\n        model = nn.parallel.DistributedDataParallel(\n            model,\n            device_ids=[dist.get_local_rank()],\n            output_device=dist.get_local_rank(),\n            find_unused_parameters=True,\n        )\n        \n        model._set_static_graph()\n    \n    source = make_dataset(conf.training.datasources)\n    mappers = instantiate(conf.training.mappers)\n    train_set = MultitaskDataset(\n        source, mappers, transform=Compose(instantiate(conf.training.transform))\n    )\n    train_collator = MultitaskCollator(mappers)\n    batch_size = conf.training.loader.batch_size // dist.get_world_size()\n    \n    train_loader = DataLoader(\n        train_set,\n        batch_size,\n        num_workers=conf.training.loader.num_workers,\n        sampler=dist.data_sampler(\n            train_set, shuffle=True, distributed=conf.distributed\n        ),\n        collate_fn=train_collator,\n    )\n\n    source = make_dataset(conf.evaluate.datasources, weighted=False)\n    valid_set = MultitaskDataset(\n        source, mappers, transform=Compose(instantiate(conf.evaluate.transform))\n    )\n    valid_collator = MultitaskCollator(mappers, evaluate=True)\n    val_batch_size = conf.training.val_loader.batch_size // dist.get_world_size()\n    \n    valid_loader = DataLoader(\n        valid_set,\n        val_batch_size,\n        num_workers=conf.training.val_loader.num_workers,\n        sampler=dist.data_sampler(\n            valid_set, shuffle=False, distributed=conf.distributed\n        ),\n        collate_fn=valid_collator,\n    )\n    \n    parameters, _ = add_weight_decay(\n        model.named_parameters(),\n        conf.training.weight_decay,\n        wd_skip_fn(conf.training.wd_skip_fn),\n    )\n    optimizer = instantiate(conf.training.optimizer, parameters)\n    scheduler = instantiate(conf.training.scheduler, optimizer)\n    checker = instantiate(conf.checker)\n    checker.catalog(conf)\n\n    start_i = 0\n\n    if conf.ckpt is not None:\n        ckpt = torch.load(conf.ckpt, map_location=lambda storage, loc: storage)\n\n        ckpt_model = dict()\n        for key, value in ckpt[\"model\"].items():\n            if conf.n_gpu > 1:\n                ckpt_model[key] = value\n            else:\n                ckpt_model[key.replace(\"module.\", \"\", 1)] = value\n                \n        # new_ckpt_model = OrderedDict()\n        # for key, value in ckpt_model.items():\n        #     if key.startswith('module.decoder.pix2seq_head') or key.startswith('module.decoder.pix2seq_embed'):\n        #         continue\n        #     new_ckpt_model[key] = value\n        \n        if conf.finetune:\n            logger.info(model.load_state_dict(ckpt_model, strict=False))\n\n            # if len(missing_keys) > 0:\n            #     logger.info(f\"Missing keys: {missing_keys}\")\n            # if len(unexpected_keys) > 0:\n            #     logger.info(f\"Unexpected keys: {unexpected_keys}\")\n                \n            # logger.info(model.load_state_dict(ckpt_model,strict=False))\n\n        else:\n            # model.load_state_dict(new_ckpt_model)\n            logger.info(model.load_state_dict(ckpt_model, strict=False))\n            start_i = ckpt[\"step\"]\n\n            if \"scheduler\" in ckpt and ckpt[\"scheduler\"] is not None:\n                print(\"MTP\")\n                scheduler.load_state_dict(ckpt[\"scheduler\"])\n\n            if \"optimizer\" in ckpt and ckpt[\"optimizer\"] is not None:\n                print(\"Hai Tu\")\n                optimizer.load_state_dict(ckpt[\"optimizer\"])\n          \n        # Khởi tạo ngẫu nhiên trọng số cho lớp này\n        # for layer in decoder.pix2seq_decoder.layers[-n_layers_to_train:]:\n        #     for name, param in layer.named_parameters():\n        #         if param.requires_grad:\n        #             param.data.normal_(0, 0.01)\n        \n        # Nếu muốn khởi tạo ngẫu nhiên trọng số cho decoder.pix2seq_head\n        # for name, param in decoder.pix2seq_head.named_parameters():\n        #     if param.requires_grad:\n        #         param.data.normal_(0, 0.02)\n        \n        # Nếu muốn khởi tạo ngẫu nhiên trọng số cho decoder.pix2seq_embed\n        # for name, param in decoder.pix2seq_embed.named_parameters():\n        #     if param.requires_grad:\n        #         param.data.normal_(0, 0.02)\n        \n        # nn.init.xavier_uniform_(decoder.pix2seq_head.weight)\n        # nn.init.constant_(decoder.pix2seq_head.bias, 0)\n        # nn.init.xavier_uniform_(decoder.pix2seq_embed.weight)\n        \n        # model = model.to(device) # moi them vao not necessary\n    \n    loader = sample_data(train_loader)\n    grad_scaler = GradScaler(enabled=conf.training.mixed_precision)\n\n    for i in range(start_i, conf.training.n_iter + 1):\n    \n        # if i == start_i:\n        if 0:\n            checker.checkpoint(\n                {\n                    \"model\": model.state_dict(),\n                    \"conf\": conf.dict(),\n                    \"optimizer\": optimizer.state_dict()\n                    if hasattr(optimizer, \"state_dict\")\n                    else None,\n                    \"scheduler\": scheduler.state_dict()\n                    if hasattr(scheduler, \"state_dict\")\n                    else None,\n                    \"step\": i,\n                },\n                f\"ckpt-{str(i).zfill(6)}.pt\",\n            )\n            \n        batch = next(loader).to(device)\n        optimizer.zero_grad()\n\n        with autocast(enabled=conf.training.mixed_precision):\n            out = model(batch)\n\n        grad_scaler.scale(out[\"total_loss\"]).backward()\n        grad_scaler.unscale_(optimizer)\n        nn.utils.clip_grad_norm_(model.parameters(), conf.training.clip_grad)\n        scheduler.step()\n        parameters[-1][\"lr\"] *= 0.1\n        grad_scaler.step(optimizer)\n        grad_scaler.update()\n\n        if dist.is_primary():\n            if i % conf.log_freq == 0:\n                lr = optimizer.param_groups[0][\"lr\"]\n                losses = {\"lr\": lr}\n                for k, v in out.items():\n                    if not k.endswith(\"_loss\"):\n                        continue\n\n                    losses[k.replace(\"_loss\", \"\", 1)] = v.item()\n\n                checker.log(**losses, step=i)\n\n        if i % conf.evaluate.eval_freq == 0:\n            checker.checkpoint(\n                {\n                    \"model\": model.state_dict(),\n                    \"conf\": conf.dict(),\n                    \"optimizer\": optimizer.state_dict()\n                    if hasattr(optimizer, \"state_dict\")\n                    else None,\n                    \"scheduler\": scheduler.state_dict()\n                    if hasattr(scheduler, \"state_dict\")\n                    else None,\n                    \"step\": i,\n                },\n                f\"ckpt-{str(i).zfill(6)}.pt\",\n            )\n\n        if (\n            i > 0\n            and i % conf.evaluate.eval_freq == 0\n            and not conf.evaluate.skip_evaluate\n        ):\n\n            report = evaluate(conf, mappers, valid_loader, model, device, logger)\n     \n            if dist.is_primary():\n                checker.log(**report, step=i)\n\n\nif __name__ == \"__main__\":\n    conf = load_arg_config(E2EConfig, elastic=True)\n    dist.run(conf, main, args=(conf,))\n''')\ntrainpy.close()","metadata":{"execution":{"iopub.status.busy":"2024-07-15T10:50:46.350124Z","iopub.execute_input":"2024-07-15T10:50:46.350432Z","iopub.status.idle":"2024-07-15T10:50:46.367161Z","shell.execute_reply.started":"2024-07-15T10:50:46.350407Z","shell.execute_reply":"2024-07-15T10:50:46.366286Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"# @title data.py\n\ndatadotpy = open('./units/models/data.py', 'w')\ndatadotpy.write('''\"\"\"\nUNITS\nCopyright (c) 2023-present NAVER Cloud Corp.\nApache-2.0\n\"\"\"\n\nimport math\nimport random\nfrom dataclasses import dataclass\nfrom typing import List\n\nimport numpy as np\nimport torch\n\nfrom units.dataset import SampleError\nfrom units.models.utils import (\n    make_duplicate_coord,\n    make_random_coord,\n    make_random_tokens,\n    make_shift_coord,\n    poly_center,\n)\nfrom units.structures import FieldsMixin, OCRInstances\n\nfrom .convert_data import *\n\n\nclass DetectFormat:\n    def __init__(self, num_pts, detect_type, token):\n        self.num_pts = num_pts\n        self.detect_type = detect_type\n        self.token = token\n\n\n@dataclass\nclass UnitsSample:\n    class_ids: torch.Tensor  # 0: noise, 1: text, -1: dcs\n    texts: torch.Tensor\n    coords: List[torch.Tensor]\n    detect_types: List[int]  # 0: single, 1: box, 2: quad, 3: polygon\n    # recogn_types: torch.Tensor # 0: case-sensitive, 1: case-insensitive\n    width: int\n    height: int\n    prompt_input: List[int]\n    \"\"\"\n    roi: [tlx, tly, brx, bry]\n    order: [start_idx, end_idx]\n    point: [x, y]\n    \"\"\"\n\n\n@dataclass\nclass UnitsBatch(FieldsMixin):\n    units_inputs: torch.Tensor\n    units_targets: torch.Tensor\n    tasks: torch.Tensor  # detect -> 0, recognition -> 1\n    w: torch.Tensor\n    h: torch.Tensor\n\n\nclass UnitsMapper:\n    name: str = \"units\"\n    task: str = \"ocr\"\n\n    def __init__(\n        self,\n        tokenizer,\n        max_text_length,\n        n_object=100,\n        decoder_length=1024,\n        img_multiple=32,\n        ignore_idx=-100,\n        drop_token_prob=0.0,\n        eos_only_end=False,\n        dcs_inputs=True,\n        iou_filtering=True,\n        boundary_clipping=True,\n        all_unks_remove=True,\n        w_noise_augmentation=False,\n        coord_order=\"xy\",\n        fixed_text_len=True,\n        text_order_type=\"serialization\",\n        permutation=False,\n        input_perturbation=False,\n        prompt=None,\n        mixed_annot_change_prob=0.0,\n        all_annot_change_prob=0.0,\n        skip_invalid_sample=True,\n    ):\n        \"\"\"\n        Args:\n            tokenizer: tokenizer for units\n            max_text_length (int): maximum length of text (word transcription)\n            n_object (int): the maximum number of objects (including augmented noise)\n            decoder_length (int): decoder max length\n            ignore_idx (float): ignore index of targets\n            drop_token_prob (float): drop token ratio for input (text transcription masking)\n            eos_only_end (bool): eos appears only at the end or several times on the augmentation noise\n                                 if True => noise target is [na, na, na, na, noise] (pix2seq official code version)\n                                 False => noise target is [eos, na, na, na, noise] (pix2seq official paper version)\n            dcs_inputs (bool): whether input sequence includes dcs or not\n            iou_filtering (bool): cropped instance filtering by box iou threshold\n            boundary_clipping: boundary region clipping\n            all_unks_remove: remove all unks samples\n            w_noise_augmentation (bool): whether augment noise in object sequence or not\n            coord_order (string): 'xy' or 'yx'\n            fixed_text_len (bool): fixed transcription length (including [pad]) or not\n            text_order_type: text ordering method\n                            None => using raw data\n                            serialization (string) => sorting by topleft serialization method\n                            random (string) => random shuffling\n            permutation (bool): whether apply permutation into the order of objects or not\n            input_perturbation (bool): whether insert input coordinate noise\n            prompt: decoder input prompt type (roi or order)\n                    None => without prompt\n                    roi (string) => using roi prompt\n                    order (string) => using order span prompt\n            skip_invalid_sample: whether skip invalid sample or not\n        \"\"\"\n        self.tokenizer = tokenizer\n        self.max_text_length = max_text_length\n        self.n_object = n_object\n        self.decoder_length = decoder_length\n        self.img_multiple = img_multiple\n        self.ignore_idx = ignore_idx\n\n        self.drop_token_prob = drop_token_prob\n\n        self.eos_only_end = eos_only_end\n        self.dcs_inputs = dcs_inputs\n        self.iou_filtering = iou_filtering\n        self.boundary_clipping = boundary_clipping\n        self.all_unks_remove = all_unks_remove\n        self.w_noise_augmentation = w_noise_augmentation\n        self.fixed_text_len = fixed_text_len\n\n        self.coord_order = coord_order\n        assert coord_order in [\"xy\", \"yx\"]\n\n        if text_order_type is not None:\n            assert text_order_type in [\"serialization\", \"random\"]\n        self.text_order_type = text_order_type\n        self.permutation = permutation\n        self.input_perturbation = input_perturbation\n\n        # special tokens index (input mask, noise, special prompts, coord outside image)\n        self.mask_token = self.tokenizer.vocab[\"[mask]\"]\n        self.noise_token = self.tokenizer.vocab[\"[noise]\"]\n        # self.text_token = self.tokenizer.vocab[\"[text]\"] # for detect only\n        self.roi_token = self.tokenizer.vocab[\"[roi]\"]\n        self.order_token = self.tokenizer.vocab[\"[order]\"]\n        self.point_token = self.tokenizer.vocab[\"[point]\"]\n        self.coord_out_token = self.tokenizer.vocab[\"[coord-out]\"]\n\n        self.prompt = prompt\n        if prompt in [\"order\", \"point\"]:\n            assert self.w_noise_augmentation == False\n\n        self.mixed_annot_change_prob = mixed_annot_change_prob\n        self.all_annot_change_prob = all_annot_change_prob\n\n        self.single_format = DetectFormat(num_pts=1, detect_type=0, token=\"[single]\")\n        self.box_format = DetectFormat(num_pts=2, detect_type=1, token=\"[box]\")\n        self.quad_format = DetectFormat(num_pts=4, detect_type=2, token=\"[quad]\")\n        self.polygon_format = DetectFormat(num_pts=16, detect_type=3, token=\"[polygon]\")\n\n        self.detect_formats = [\n            self.single_format,\n            self.box_format,\n            self.quad_format,\n            self.polygon_format,\n        ]\n\n        self.detect_task_id = 0\n        self.recog_task_id = 1\n\n        self.skip_invalid_sample = skip_invalid_sample\n\n    def __call__(self, sample):\n        img_h, img_w = sample.image_size\n\n        ocr = sample.ocr.filter_dont_care(img_w, img_h)\n        # print(\"bat dau texts\")\n        # print(ocr.texts)\n        coords = [coord.numpy() for coord in ocr.coords]\n        texts = [text for text in ocr.texts]\n        # print(\"----------------\")\n        # print(texts)\n        # print(\"ket thuc texts\")\n\n        # print(texts[0])\n\n        # Filtering\n        if self.iou_filtering:\n            coords, texts = self._iou_filtering(coords, texts, img_w, img_h)\n        # print(\"coords1.5 \", coords)\n        if self.boundary_clipping:\n            coords = self._boundary_clipping(coords, img_w, img_h)\n        # print(\"coords1.9 \", coords)\n        coords = self._refine_coords(coords)\n        # print(\"coords2 \", coords)\n        # Serialization & permutation\n        instance_ids = self._serialize_text(coords, self.text_order_type)\n\n        if self.permutation:\n            instance_ids = self._apply_permutation(instance_ids)\n\n        texts = [texts[i] for i in instance_ids]\n        coords = [coords[i] for i in instance_ids]\n        \n        # print(\"instance_ids \", instance_ids)\n        # print(\"coords 3 \", coords)\n        \n\n        detect_types = self._determine_detect_types(coords)\n\n        # print('loai anoot ', detect_types)\n\n        # Change detection formats\n        if np.random.random() <= self.mixed_annot_change_prob:\n            # Change each instances to randomly selected detection format\n            coords, detect_types = self._convert_random_detect_types(\n                coords, detect_types, annot_change_prob=0.5\n            )\n        else:\n            # Change all instances to same detection format\n            if np.random.random() <= self.all_annot_change_prob:\n                if np.random.random() <= 0.5:\n                    coords, detect_types = self._convert_only_single_type(\n                        coords, detect_types\n                    )\n                else:\n                    coords, detect_types = self._convert_only_box_type(\n                        coords, detect_types\n                    )\n\n        if self.all_unks_remove:\n            coords, texts, detect_types = self._remove_all_unks(\n                coords, texts, detect_types\n            )\n\n        # Select prompt input & extract instances corresponding to prompt input\n        if self.prompt == \"roi\":\n            (\n                prompt_input,\n                coords,\n                texts,\n                detect_types,\n                is_valid_sample,\n            ) = self._sampling_roi(\n                coords,\n                texts,\n                detect_types,\n                img_w,\n                img_h,\n            )\n        elif self.prompt == \"order\":\n            prompt_input, coords, texts, detect_types = self._sampling_orders(\n                coords,\n                texts,\n                detect_types,\n                self.tokenizer.max_order,\n                self.dcs_inputs,\n                self.n_object,\n            )\n        elif self.prompt == \"point\":\n            (\n                prompt_input,\n                coords,\n                texts,\n                detect_types,\n                is_valid_sample,\n            ) = self._sampling_starting_point(\n                coords,\n                texts,\n                detect_types,\n                img_w,\n                img_h,\n            )\n        else:\n            prompt_input = None\n\n        ignores = []\n        for i in range(len(coords)):\n            string = texts[i]\n\n            if string == \"\":\n                # Ignore empty text (Don't care, ###, invisible text)\n                ignores.append(True)\n            else:\n                ignores.append(False)\n\n        candid_texts = []\n        candid_coords = []\n        candid_detect_types = []\n        candid_dcs = []\n\n        for coord, text, detect_type, ignore in zip(\n            coords, texts, detect_types, ignores\n        ):\n            if not self.dcs_inputs and ignore:\n                continue\n\n            tokens = self.tokenizer(text)\n\n            candid_texts.append(tokens)\n            candid_coords.append(coord.copy())\n            candid_detect_types.append(detect_type)\n            candid_dcs.append(ignore)\n\n        if self.skip_invalid_sample:\n            if self.prompt == None and len(candid_texts) < 1:\n                raise SampleError(\"No valid text instance found\")\n            elif self.prompt in [\"roi\", \"point\"] and not is_valid_sample:\n                raise SampleError(f\"No valid {self.prompt}\")\n\n        (\n            selected_texts,\n            selected_coords,\n            selected_categories,\n            selected_detect_types,\n        ) = self._make_sequence_for_ocr(\n            candid_texts,\n            candid_coords,\n            candid_detect_types,\n            candid_dcs,\n            img_h,\n            img_w,\n            prompt_input,\n        )\n\n        selected_categories = torch.tensor(selected_categories)\n        selected_texts = [torch.tensor(text) for text in selected_texts]\n        selected_coords = [torch.tensor(coords) for coords in selected_coords]\n\n        # print('ket thuc mapper')\n        return UnitsSample(\n            selected_categories,\n            selected_texts,\n            selected_coords,\n            selected_detect_types,\n            img_w,\n            img_h,\n            prompt_input,\n        )\n\n    def postprocess(self, batch_samples, outputs):\n        batched_vertices = outputs[\"vertices\"]\n        batched_texts = outputs[\"texts\"]\n        batched_scores = outputs[\"scores\"]\n        instances = []\n\n        for batch_vertice, batch_text, batch_score in zip(\n            batched_vertices, batched_texts, batched_scores\n        ):\n            if batch_vertice is None:\n                instances.append(OCRInstances([], []))\n                continue\n\n            texts = [self.tokenizer.decode(text) for text in batch_text]\n\n            output_vertices, output_texts, output_scores = [], [], []\n            for i, text in enumerate(texts):\n                if \"[mask]\" not in text:\n                    output_vertices.append(batch_vertice[i].tolist())\n                    output_texts.append(text)\n                    output_scores.append(batch_score[i])\n            ocr_instances = OCRInstances(output_vertices, output_texts, output_scores)\n            instances.append(ocr_instances)\n\n        return instances\n\n    def _get_batch_shape(self, batch):\n        max_height = 0\n        max_width = 0\n        max_text_len = 0\n\n        for b in batch:\n            max_height = max(max_height, b.units.height)\n            max_width = max(max_width, b.units.width)\n\n            for s in b.units.texts:\n                max_text_len = max(max_text_len, len(s))\n\n        return max_height, max_width, max_text_len\n\n    def collate_fn(self, batch):\n        batch_size = len(batch)\n        height, width, _ = self._get_batch_shape(batch)\n\n        height = math.ceil(height / self.img_multiple) * self.img_multiple\n        width = math.ceil(width / self.img_multiple) * self.img_multiple\n\n        h = torch.zeros(batch_size, dtype=torch.float32)\n        w = torch.zeros(batch_size, dtype=torch.float32)\n\n        sequence_length = self.decoder_length\n        batched_sequence_inputs = torch.zeros(\n            batch_size, sequence_length, dtype=torch.int64\n        )\n        batched_sequence_targets = torch.zeros(\n            batch_size, sequence_length, dtype=torch.int64\n        )\n        batched_sequence_tasks = torch.zeros(\n            batch_size, sequence_length, dtype=torch.int64\n        )\n\n        for i, sample_i in enumerate(batch):\n            sample_i = sample_i.units\n            n_object = sample_i.class_ids.shape[0]\n            class_ids = sample_i.class_ids.tolist()\n            h[i], w[i] = sample_i.height, sample_i.width\n\n            sample_i_sequence_inputs = []\n            sample_i_seqeunce_targets = []\n            sample_i_sequence_tasks = []\n\n            # Convert coordinate to bin (quantization)\n            for j in range(n_object):\n                object_category = class_ids[j]\n                object_coord = sample_i.coords[j].numpy()\n                object_text = sample_i.texts[j].tolist()\n                \n                # print(\"object_text: \", object_text)\n\n                (\n                    object_j_inputs,\n                    object_j_targets,\n                    object_j_tasks,\n                ) = self._make_object_sequence(\n                    object_category,\n                    object_coord,\n                    sample_i.width,\n                    sample_i.height,\n                    object_text,\n                    sample_i.detect_types[j],\n                )\n                \n                # print(\"sample_i.detect_types[j]: \", sample_i.detect_types[j],)\n                \n                # print(\"object_j_inputs: \", object_j_inputs)\n                # print(\"object_j_targets: \", object_j_targets)\n                \n                sample_i_sequence_inputs.extend(object_j_inputs)\n                sample_i_seqeunce_targets.extend(object_j_targets)\n                sample_i_sequence_tasks.extend(object_j_tasks)\n\n            last_detect_type = self._determine_last_detect_type(\n                sample_i_sequence_inputs\n            )\n            last_detect_token = self._determine_detect_token(last_detect_type)\n\n            # print(\"sample_i_sequence_inputs 1: \", sample_i_sequence_inputs)\n            sample_i_sequence_inputs.append(last_detect_token)\n            # print(\"sample_i_sequence_inputs 2: \", sample_i_sequence_inputs)\n            \n            sample_i_seqeunce_targets.append(self.ignore_idx)\n            sample_i_sequence_tasks.append(self.detect_task_id)\n\n            sample_i_sequence_inputs.insert(0, self.tokenizer.go)\n            sample_i_seqeunce_targets.append(self.tokenizer.eos)\n            sample_i_sequence_tasks.append(self.detect_task_id)\n\n            if self.prompt == \"roi\":\n                (\n                    sample_i_sequence_inputs,\n                    sample_i_seqeunce_targets,\n                    sample_i_sequence_tasks,\n                ) = self._add_roi_point_prompt(\n                    sample_i_sequence_inputs,\n                    sample_i_seqeunce_targets,\n                    sample_i_sequence_tasks,\n                    sample_i.prompt_input,\n                )\n            elif self.prompt == \"order\":\n                (\n                    sample_i_sequence_inputs,\n                    sample_i_seqeunce_targets,\n                    sample_i_sequence_tasks,\n                ) = self._add_order_prompt(\n                    sample_i_sequence_inputs,\n                    sample_i_seqeunce_targets,\n                    sample_i_sequence_tasks,\n                    sample_i.prompt_input,\n                )\n            elif self.prompt == \"point\":\n                (\n                    sample_i_sequence_inputs,\n                    sample_i_seqeunce_targets,\n                    sample_i_sequence_tasks,\n                ) = self._add_point_prompt(\n                    sample_i_sequence_inputs,\n                    sample_i_seqeunce_targets,\n                    sample_i_sequence_tasks,\n                    sample_i.prompt_input,\n                )\n\n            if len(sample_i_sequence_inputs) < sequence_length:\n                sample_i_sequence_inputs += (\n                    sequence_length - len(sample_i_sequence_inputs)\n                ) * [self.tokenizer.eos]\n\n            if len(sample_i_seqeunce_targets) < sequence_length:\n                sample_i_seqeunce_targets += (\n                    sequence_length - len(sample_i_seqeunce_targets)\n                ) * [\n                    self.tokenizer.eos\n                ]  # [self.ignore_idx]\n\n            sample_i_sequence_inputs = sample_i_sequence_inputs[:sequence_length]\n            sample_i_seqeunce_targets = sample_i_seqeunce_targets[:sequence_length]\n            sample_i_sequence_tasks = sample_i_sequence_tasks[:sequence_length]\n\n            sample_i_sequence_inputs = torch.Tensor(sample_i_sequence_inputs)\n            sample_i_seqeunce_targets = torch.Tensor(sample_i_seqeunce_targets)\n            sample_i_sequence_tasks = torch.Tensor(sample_i_sequence_tasks)\n            \n            # print(\"sequence_length, \", sequence_length)\n            # print(\"sample_i_sequence_inputs.shape[0] \", sample_i_sequence_inputs.shape[0])\n\n            batched_sequence_inputs[\n                i, : sample_i_sequence_inputs.shape[0]\n            ] = sample_i_sequence_inputs\n            batched_sequence_targets[\n                i, : sample_i_seqeunce_targets.shape[0]\n            ] = sample_i_seqeunce_targets\n            batched_sequence_tasks[\n                i, : sample_i_sequence_tasks.shape[0]\n            ] = sample_i_sequence_tasks\n\n        return UnitsBatch(\n            batched_sequence_inputs,\n            batched_sequence_targets,\n            batched_sequence_tasks,\n            w,\n            h,\n        )\n\n    def _iou_filtering(self, coords, texts, img_w, img_h, threshold=0.6):\n        \"\"\"\n        Remove invalid instances whose overlap region is small.\n        \"\"\"\n        refined_coords, refined_texts = [], []\n        img_box = (0, 0, img_w, img_h)\n\n        for coord, text in zip(coords, texts):\n            text_box = np.min(coord, axis=0).tolist() + np.max(coord, axis=0).tolist()\n            if (\n                text_box[0] < 0\n                or text_box[1] < 0\n                or text_box[2] > img_w\n                or text_box[3] > img_h\n            ):\n                text_box_area = (text_box[2] - text_box[0]) * (\n                    text_box[3] - text_box[1]\n                )\n\n                x1 = max(text_box[0], img_box[0])\n                y1 = max(text_box[1], img_box[1])\n                x2 = min(text_box[2], img_box[2])\n                y2 = min(text_box[3], img_box[3])\n\n                intersect_w = max(0, x2 - x1)\n                intersect_h = max(0, y2 - y1)\n\n                inter = intersect_w * intersect_h\n                iou = inter / text_box_area\n\n                if iou < threshold:\n                    continue\n\n            refined_coords.append(coord)\n            refined_texts.append(text)\n\n        return refined_coords, refined_texts\n\n    def _boundary_clipping(self, coords, img_w, img_h):\n        \"\"\"\n        Clip text region cropped from image boundary, and convert to bounding box.\n        \"\"\"\n        for i, coord in enumerate(coords):\n            tlx, tly = np.min(coord, axis=0)\n            brx, bry = np.max(coord, axis=0)\n            if tlx < 0 or tly < 0 or brx >= img_w or bry >= img_h:\n                tlx = np.clip(tlx, 0, img_w - 1)\n                tly = np.clip(tly, 0, img_h - 1)\n                brx = np.clip(brx, 0, img_w - 1)\n                bry = np.clip(bry, 0, img_h - 1)\n                coords[i] = np.array([[tlx, tly], [brx, bry]], dtype=np.float32)\n        return coords\n\n    def _refine_coords(self, coords, prob_box=0.5):\n        \"\"\"\n        Convert to bounding box or single point for invalid annotation.\n        \"\"\"\n        for i, coord in enumerate(coords):\n            if coord.shape[0] not in [\n                detection_format.num_pts for detection_format in self.detect_formats\n            ]:\n                if np.random.random() <= prob_box:\n                    tlx, tly = np.min(coord, axis=0)\n                    brx, bry = np.max(coord, axis=0)\n                    coords[i] = np.array([[tlx, tly], [brx, bry]], dtype=np.float32)\n                else:\n                    coords[i] = poly_center(coord)\n        return coords\n\n    def _serialize_text(self, coords, text_order_type):\n        \"\"\"\n        Serialize text instances.\n        \"\"\"\n        instance_ids = list(range(len(coords)))\n        if text_order_type == \"serialization\":\n            instance_ids.sort(key=lambda x: poly_center(coords[x])[0].tolist()[::-1])\n        elif self.text_order_type == \"random\":\n            random.shuffle(instance_ids)\n        return instance_ids\n\n    def _remove_all_unks(self, coords, texts, detect_types):\n        \"\"\"\n        Remove text with all unks.\n        \"\"\"\n        refined_coords, refined_texts, refined_detect_types = [], [], []\n        for coord, text, detect_type in zip(coords, texts, detect_types):\n            tokens = self.tokenizer(text)\n            if set(tokens) == {self.tokenizer.unk}:\n                continue\n\n            refined_coords.append(coord)\n            refined_texts.append(text)\n            refined_detect_types.append(detect_type)\n        return refined_coords, refined_texts, refined_detect_types\n\n    def _apply_permutation(self, inputs, shuffle_ratio=0.1, neighbor_span=1):\n        \"\"\"\n        Permute sequence order.\n        \"\"\"\n        for idx in range(len(inputs) - neighbor_span):\n            if np.random.random() < shuffle_ratio:\n                inputs[idx : idx + neighbor_span + 1] = (\n                    inputs[idx + neighbor_span : idx - 1 : -1]\n                    if idx > 0\n                    else inputs[idx + neighbor_span :: -1]\n                )\n\n        return inputs\n\n    def _determine_detect_types(self, coords):\n        \"\"\"\n        Determine detection annotation type.\n        \"\"\"\n        detect_types = []\n        for coord in coords:\n            assert coord.shape[1] == 2\n            # print('coord.shape[0 va 1] ', coord.shape[0], coord.shape[1])\n            # print(coord)\n            detect_type = self._num_pts_to_detect_type(coord.shape[0])\n            # print(\"shape \", coord)\n            # print(\"detect type: \", detect_type)\n            detect_types.append(detect_type)\n\n        return detect_types\n\n    def _convert_random_detect_types(\n        self, coords, detect_types, annot_change_prob=0.15\n    ):\n        \"\"\"\n        Convert quad, polygon to single, box randomly.\n        \"\"\"\n\n        for i, coord in enumerate(coords):\n            if np.random.random() <= annot_change_prob:\n                if np.random.random() <= 0.5:\n                    # box\n                    detect_types[i] = self.box_format.detect_type\n                    coords[i] = np.reshape(\n                        np.concatenate(\n                            (np.min(coord, axis=0), np.max(coord, axis=0)),\n                            0,\n                        ),\n                        (2, 2),\n                    )\n                else:\n                    # single\n                    detect_types[i] = self.single_format.detect_type\n                    coords[i] = poly_center(coord)\n\n        return coords, detect_types\n\n    def _convert_only_single_type(self, coords, detect_types):\n        \"\"\"\n        Convert all annotations to single.\n        \"\"\"\n        for i, coord in enumerate(coords):\n            coords[i] = poly_center(coord)\n            detect_types[i] = self.single_format.detect_type\n\n        return coords, detect_types\n\n    def _convert_only_box_type(self, coords, detect_types):\n        \"\"\"\n        Convert all annotations to box.\n        \"\"\"\n        for i, coord in enumerate(coords):\n            if coord.shape[0] <= 2:\n                # In the case of single, it is impossible to convert to box.\n                continue\n            tlx, tly = np.min(coord, axis=0)\n            brx, bry = np.max(coord, axis=0)\n            coords[i] = np.array([[tlx, tly], [brx, bry]], dtype=np.float32)\n\n            detect_types[i] = self.box_format.detect_type\n\n        return coords, detect_types\n\n    def _determine_last_detect_type(self, inputs):\n        \"\"\"\n        Determine detect token for a last (fake) object.\n        \"\"\"\n        nums = []\n        for detect_token_type in [0, 1, 2, 3]:\n            num = inputs.count(self._determine_detect_token(detect_token_type))\n            nums.append((num, detect_token_type))\n\n        return max(nums)[1]\n\n    def _num_pts_to_detect_type(self, num_pts):\n        \"\"\"\n        Determine detection annotation type.\n        \"\"\"\n        assert num_pts in [\n            detect_format.num_pts for detect_format in self.detect_formats\n        ]\n\n        for detect_format in self.detect_formats:\n            if num_pts == detect_format.num_pts:\n                return detect_format.detect_type\n\n    def _detect_type_to_num_pts(self, detect_type):\n        \"\"\"\n        Determine the number of points by using detection annotation.\n        \"\"\"\n        assert detect_type in [\n            detect_format.detect_type for detect_format in self.detect_formats\n        ]\n\n        for detect_format in self.detect_formats:\n            if detect_type == detect_format.detect_type:\n                return detect_format.num_pts\n\n    def _determine_detect_token(self, detect_type):\n        \"\"\"\n        Determine token idx of detection annotation type.\n        \"\"\"\n        assert detect_type in [\n            detect_format.detect_type for detect_format in self.detect_formats\n        ]\n        for detect_format in self.detect_formats:\n            if detect_type == detect_format.detect_type:\n                return self.tokenizer.vocab[detect_format.token]\n\n    def _make_object_sequence(\n        self,\n        category,\n        coords,\n        width,\n        height,\n        text=None,\n        detect_type=0,\n        input_perturb_prob=0.2,\n    ):\n        \"\"\"\n        Compute sequence corresponding to the object.\n        \"\"\"\n        if not self.w_noise_augmentation:\n            assert category != 0\n\n        bin_size = self.tokenizer.bin_size\n        inputs, targets = [], []\n        tasks = []\n\n        detect_token = self._determine_detect_token(detect_type)\n        \n        # print(\"detect_token: \", detect_token)\n        \n        inputs.append(detect_token)\n        targets.append(self.ignore_idx)\n        tasks.append(self.detect_task_id)\n\n        for k in range(coords.shape[0]):\n            # print(print(\"inputs \", k,\" 1: \",inputs))\n            x, y = coords[k, :]\n\n            x_bin = np.floor(x / width * (bin_size - 1)).astype(np.int32)\n            y_bin = np.floor(y / height * (bin_size - 1)).astype(np.int32)\n\n            # x_idx = self.tokenizer.encode_coord(x_bin)\n            # y_idx = self.tokenizer.encode_coord(y_bin)\n            x_idx, y_idx = self.tokenizer.encode_coord_xy(x_bin, y_bin)\n\n            if (\n                self.input_perturbation\n                and self.coord_out_token not in [x_idx, y_idx]\n                and np.random.random() < input_perturb_prob\n            ):\n                input_x_idx, input_y_idx = self._apply_coord_perturbation(\n                    x_bin, y_bin, bin_size\n                )\n            else:\n                input_x_idx, input_y_idx = x_idx, y_idx\n\n            if self.coord_order == \"xy\":\n                inputs.extend([input_x_idx, input_y_idx])\n            else:\n                inputs.extend([input_y_idx, input_x_idx])\n                \n            # print(print(\"inputs \", k,\" 2: \",inputs))\n\n            if category == 1:\n                # text\n                target_x_idx, target_y_idx = x_idx, y_idx\n            elif category == -1 or self.eos_only_end or k > 0:\n                # DC or noise's the other pts\n                target_x_idx, target_y_idx = self.ignore_idx, self.ignore_idx\n            else:\n                # noise's first pts\n                target_x_idx, target_y_idx = self.tokenizer.eos, self.ignore_idx\n\n            if self.coord_order == \"xy\":\n                targets.extend([target_x_idx, target_y_idx])\n            else:\n                targets.extend([target_y_idx, target_x_idx])\n\n            tasks.extend([0, 0])\n            \n        # print(\"inputs 3: \",inputs)\n\n        input_tokens, target_tokens = self._make_transcriptions_tokens(\n            self.drop_token_prob, category, text, self.max_text_length\n        )\n        \n        inputs.extend(input_tokens)        \n        targets.extend(target_tokens)\n        tasks.extend([self.recog_task_id] * len(target_tokens))\n\n        return inputs, targets, tasks\n\n    def _apply_coord_perturbation(\n        self, x_bin, y_bin, bin_size, input_perturb_span_ratio=0.005\n    ):\n        \"\"\"\n        Coordinate perturbation.\n        \"\"\"\n        input_perturb_span = int(bin_size * input_perturb_span_ratio)\n        perturb_x_bin = np.random.randint(-input_perturb_span, input_perturb_span + 1)\n        perturb_y_bin = np.random.randint(-input_perturb_span, input_perturb_span + 1)\n\n        perturb_x_bin = np.clip(x_bin + perturb_x_bin, 0, bin_size - 1)\n        perturb_y_bin = np.clip(y_bin + perturb_y_bin, 0, bin_size - 1)\n        return self.tokenizer.encode_coord_xy(perturb_x_bin, perturb_y_bin)\n\n    def _make_transcriptions_tokens(\n        self, drop_token_prob, category, text, max_text_length\n    ):\n        \"\"\"\n        Determine tokens for recognition transcription.\n        \"\"\"\n        text = text[:max_text_length]\n        is_input_mask = False\n        if category == -1 or np.random.random() < drop_token_prob:\n            input_tokens = [self.mask_token] + (\n                [self.tokenizer.pad] * (max_text_length - 1)\n                if self.fixed_text_len\n                else [self.tokenizer.vocab[\"[text_eos]\"]]\n            )\n            is_input_mask = True\n        else:\n            input_tokens = text + (\n                [self.tokenizer.pad] * (max_text_length - len(text))\n                if self.fixed_text_len\n                else [self.tokenizer.vocab[\"[text_eos]\"]]\n            )\n\n        if category == -1 or is_input_mask:\n            # DC\n            target_tokens = [self.ignore_idx] * len(input_tokens)\n        elif category == 1:\n            # text\n            target_tokens = text + (\n                [self.tokenizer.pad] * (max_text_length - len(text))\n                if self.fixed_text_len\n                else [self.tokenizer.vocab[\"[text_eos]\"]]\n            )\n        else:\n            # noise\n            target_tokens = [self.noise_token] + (\n                [self.tokenizer.pad] * (max_text_length - 1)\n                if self.fixed_text_len\n                else [self.tokenizer.vocab[\"[text_eos]\"]]\n            )\n\n        return input_tokens, target_tokens\n\n    def _add_roi_point_prompt(self, inputs, targets, tasks, roi_bin):\n        \"\"\"\n        Add roi prompt in sequence.\n        \"\"\"\n        assert len(roi_bin) == 4\n        roi_prompt = [self.roi_token] + [\n            self.tokenizer.encode_coord(coord_bin) for coord_bin in roi_bin\n        ]\n\n        if self.coord_order == \"yx\":\n            roi_prompt[1], roi_prompt[2] = roi_prompt[2], roi_prompt[1]\n            roi_prompt[3], roi_prompt[4] = roi_prompt[4], roi_prompt[3]\n\n        inputs = roi_prompt + inputs\n        targets = [self.ignore_idx] * len(roi_prompt) + targets\n        tasks = [self.detect_task_id] * len(roi_prompt) + tasks\n\n        return inputs, targets, tasks\n\n    def _add_order_prompt(self, inputs, targets, tasks, order_span):\n        \"\"\"\n        Add order prompt in sequence.\n        \"\"\"\n        assert len(order_span) == 2\n        order_start_idx, order_end_idx = order_span\n        order_start_idx = self.tokenizer.encode_order(order_start_idx)\n        order_end_idx = self.tokenizer.encode_order(order_end_idx)\n\n        inputs = [\n            self.order_token,\n            order_start_idx,\n            order_end_idx,\n        ] + inputs\n        targets = [self.ignore_idx] * 3 + targets\n        tasks = [self.detect_task_id] * 3 + tasks\n\n        return inputs, targets, tasks\n\n    def _add_point_prompt(self, inputs, targets, tasks, point_bin):\n        \"\"\"\n        Add point prompt in sequence.\n        \"\"\"\n        assert len(point_bin) == 2\n        point_prompt = [self.point_token] + [\n            self.tokenizer.encode_coord(coord_bin) for coord_bin in point_bin\n        ]\n\n        if self.coord_order == \"yx\":\n            point_prompt[1], point_prompt[2] = point_prompt[2], point_prompt[1]\n\n        inputs = point_prompt + inputs\n        targets = [self.ignore_idx] * len(point_prompt) + targets\n        tasks = [self.detect_task_id] * len(point_prompt) + tasks\n\n        return inputs, targets, tasks\n\n    def _make_sequence_for_ocr(\n        self,\n        candid_texts,\n        candid_coords,\n        candid_detect_types,\n        candid_dcs,\n        img_h,\n        img_w,\n        prompt_input=None,\n        prob_duplicate_noise=0.5,\n        prob_shift_noise=0.5,\n    ):\n        \"\"\"\n        Make input and target sequence.\n        Args:\n            prob_duplicate_noise: duplicated noise ratio out of the whole noise (duplicated noise + random noise)\n            prob_shift_noise: center shifted noise ratio out of the random noise (center shifted noise + randomly generated noise)\n        \"\"\"\n        selected_texts = []\n        selected_coords = []\n        selected_categories = []\n        selected_detect_types = []\n\n        if self.prompt == \"roi\":\n            bin_size = self.tokenizer.bin_size\n            tlx_bin, tly_bin, brx_bin, bry_bin = prompt_input\n            tlx = tlx_bin / (bin_size - 1) * img_w\n            tly = tly_bin / (bin_size - 1) * img_h\n            brx = brx_bin / (bin_size - 1) * img_w\n            bry = bry_bin / (bin_size - 1) * img_h\n            roi = tlx, tly, brx, bry\n        else:\n            roi = None\n\n        if self.n_object <= len(candid_texts):\n            ids = list(range(self.n_object))\n        else:\n            ids = list(range(len(candid_texts)))\n            if self.w_noise_augmentation:\n                ids = ids + [-1] * (self.n_object - len(candid_texts))\n\n        for id in ids:\n            if id == -1:\n                if len(candid_coords) > 0:\n                    if np.random.random() <= prob_duplicate_noise:\n                        noise_coord, noise_coord_id = make_duplicate_coord(\n                            candid_coords, img_w, img_h, roi\n                        )\n                        noise_detect_type = candid_detect_types[noise_coord_id]\n                    else:\n                        if np.random.random() <= prob_shift_noise:\n                            noise_coord, noise_coord_id = make_shift_coord(\n                                candid_coords, img_w, img_h, roi\n                            )\n                            noise_detect_type = candid_detect_types[noise_coord_id]\n                        else:\n                            noise_detect_type = random.randint(\n                                0, len(self.detect_formats) - 1\n                            )\n                            noise_num_pts = self._detect_type_to_num_pts(\n                                noise_detect_type\n                            )\n                            noise_coord = make_random_coord(\n                                img_w, img_h, noise_num_pts, roi\n                            )\n                else:\n                    noise_detect_type = random.randint(0, 3)\n                    noise_num_pts = self._detect_type_to_num_pts(noise_detect_type)\n                    noise_coord = make_random_coord(img_w, img_h, noise_num_pts, roi)\n\n                noise_text = make_random_tokens(\n                    self.max_text_length, self.tokenizer.char_vocab_range\n                )\n\n                category = 0  # noise\n                selected_texts.append(noise_text)\n                selected_coords.append(noise_coord)\n                selected_categories.append(category)\n                selected_detect_types.append(noise_detect_type)\n            else:\n                category = -1 if candid_dcs[id] else 1  # valid text or dc\n                selected_texts.append(candid_texts[id])\n                selected_coords.append(candid_coords[id])\n                selected_categories.append(category)\n                selected_detect_types.append(candid_detect_types[id])\n\n        return (\n            selected_texts,\n            selected_coords,\n            selected_categories,\n            selected_detect_types,\n        )\n\n    def _sampling_roi(\n        self,\n        coords,\n        texts,\n        detect_types,\n        img_w,\n        img_h,\n        prob_at_least_one=0.8,\n        coord_bin_margin=0.005,\n        max_tries=50,\n    ):\n        \"\"\"\n        Generate RoI and refine instances.\n        \"\"\"\n        bin_size = self.tokenizer.bin_size\n        min_n_object = 1 if np.random.random() <= prob_at_least_one else 0\n        coord_bin_margin = int(bin_size * coord_bin_margin)\n\n        for _ in range(max_tries):\n            roi_tlx = np.random.randint(bin_size)\n            roi_tly = np.random.randint(bin_size)\n            roi_brx = np.random.randint(roi_tlx + 1, bin_size)\n            roi_bry = np.random.randint(roi_tly + 1, bin_size)\n\n            refined_coords, refined_texts, refined_detect_types = [], [], []\n\n            for coord, text, detect_type in zip(coords, texts, detect_types):\n                instance_x, instance_y = poly_center(coord)[0].tolist()\n\n                instance_x = np.floor(instance_x / img_w * (bin_size - 1)).astype(\n                    np.int32\n                )\n                instance_y = np.floor(instance_y / img_h * (bin_size - 1)).astype(\n                    np.int32\n                )\n                if (\n                    instance_x >= roi_tlx - coord_bin_margin\n                    and instance_x <= roi_brx + coord_bin_margin\n                    and instance_y >= roi_tly - coord_bin_margin\n                    and instance_y <= roi_bry + coord_bin_margin\n                ):\n                    refined_coords.append(coord)\n                    refined_texts.append(text)\n                    refined_detect_types.append(detect_type)\n\n            n_valid_object = len([text for text in refined_texts if text != \"\"])\n            if n_valid_object >= min_n_object:\n                return (\n                    [roi_tlx, roi_tly, roi_brx, roi_bry],\n                    refined_coords,\n                    refined_texts,\n                    refined_detect_types,\n                    True,\n                )\n\n        return (\n            [0, 0, bin_size - 1, bin_size - 1],\n            coords,\n            texts,\n            detect_types,\n            False,\n        )\n\n    def _sampling_orders(\n        self,\n        coords,\n        texts,\n        detect_types,\n        max_order,\n        dcs_inputs=False,\n        max_n_object=100,\n        zero_start_prob=0.2,\n        max_end_idx_prob=0.5,\n        prob_at_least_one=0.8,\n        span_margin=5,\n    ):\n        \"\"\"\n        Generate start/end idx and refine instances.\n        \"\"\"\n        valid_coords, valid_texts, valid_detect_types = [], [], []\n        for coord, text, detect_type in zip(coords, texts, detect_types):\n            if not dcs_inputs and text == \"\":\n                continue\n            valid_coords.append(coord)\n            valid_texts.append(text)\n            valid_detect_types.append(detect_type)\n\n        if np.random.random() <= zero_start_prob:\n            start_idx = 0\n        else:\n            if np.random.random() <= prob_at_least_one:\n                start_idx = (\n                    min(max_order, np.random.randint(len(valid_coords)))\n                    if len(valid_coords)\n                    else 0\n                )\n            else:\n                start_idx = np.random.randint(\n                    min(max_order, len(valid_coords) + span_margin)\n                )\n\n        if np.random.random() <= max_end_idx_prob:\n            end_idx = start_idx + max_n_object - 1\n        else:\n            end_idx = start_idx + np.random.randint(max_n_object)\n\n        start_idx = min(start_idx, max_order - 1)\n        end_idx = min(end_idx, max_order - 1)\n\n        sampled_coords, sampled_texts, sampled_detect_types = [], [], []\n\n        for i in range(start_idx, min(end_idx + 1, len(valid_coords))):\n            sampled_coords.append(valid_coords[i])\n            sampled_texts.append(valid_texts[i])\n            sampled_detect_types.append(valid_detect_types[i])\n\n        return [start_idx, end_idx], sampled_coords, sampled_texts, sampled_detect_types\n\n    def _sampling_starting_point(\n        self,\n        coords,\n        texts,\n        detect_types,\n        img_w,\n        img_h,\n        prob_at_start=0.5,\n        prob_at_random=0.5,\n        prob_at_least_one=0.8,\n        coord_bin_margin=0.005,\n        max_tries=50,\n    ):\n        \"\"\"\n        Generate point and refine instances.\n        \"\"\"\n        bin_size = self.tokenizer.bin_size\n        min_n_object = 1 if np.random.random() <= prob_at_least_one else 0\n        coord_bin_margin = int(bin_size * coord_bin_margin)\n\n        for _ in range(max_tries):\n            if np.random.random() <= prob_at_start:\n                start_x, start_y = 0, 0\n            else:\n                if len(coords) == 0 or np.random.random() <= prob_at_random:\n                    start_x = np.random.randint(bin_size)\n                    start_y = np.random.randint(bin_size)\n                else:\n                    sampled_idx = np.random.randint(len(coords))\n                    start_x, start_y = np.mean(coords[sampled_idx], axis=0)\n                    start_x = np.floor(start_x / img_w * (bin_size - 1)).astype(\n                        np.int32\n                    )\n                    start_y = np.floor(start_y / img_h * (bin_size - 1)).astype(\n                        np.int32\n                    )\n\n            refined_coords, refined_texts, refined_detect_types = [], [], []\n\n            for coord, text, detect_type in zip(coords, texts, detect_types):\n                instance_x, instance_y = poly_center(coord)[0].tolist()\n\n                instance_x = np.floor(instance_x / img_w * (bin_size - 1)).astype(\n                    np.int32\n                )\n                instance_y = np.floor(instance_y / img_h * (bin_size - 1)).astype(\n                    np.int32\n                )\n                if instance_y > start_y or (\n                    start_y - instance_y <= coord_bin_margin\n                    and start_x - instance_x <= coord_bin_margin\n                ):\n                    refined_coords.append(coord)\n                    refined_texts.append(text)\n                    refined_detect_types.append(detect_type)\n\n            n_valid_object = len([text for text in refined_texts if text != \"\"])\n            if n_valid_object >= min_n_object:\n                return (\n                    [start_x, start_y],\n                    refined_coords,\n                    refined_texts,\n                    refined_detect_types,\n                    True,\n                )\n\n        return (\n            [0, 0],\n            coords,\n            texts,\n            detect_types,\n            False,\n        )\n''')\ndatadotpy.close()","metadata":{"id":"qoIYJ2gE2Brp","cellView":"form","execution":{"iopub.status.busy":"2024-07-15T10:50:46.555557Z","iopub.execute_input":"2024-07-15T10:50:46.555849Z","iopub.status.idle":"2024-07-15T10:50:46.604080Z","shell.execute_reply.started":"2024-07-15T10:50:46.555826Z","shell.execute_reply":"2024-07-15T10:50:46.603163Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"datasource = open('./units/datasource.py', 'w')\ndatasource.write('''import os\n\nfrom PIL import Image\nfrom tensorfn.data import LMDBReader\n\nfrom units.structures import OCRInstances, Sample\n\n\nclass LMDBSource:\n    task_key = \"ocr\"\n\n    def __init__(self, root, annotation):\n        \"\"\"\n        Args:\n            root (str): Root path indicates the directory contains image and lmdb\n            annotation (str): Path to the annotation lmdb relative to root\n        \"\"\"\n        self.root = root\n        self.annots = LMDBReader(os.path.join(root, annotation), reader=\"pickle\")\n        self.key = os.path.splitext(annotation)[0]\n\n    def __len__(self):\n        return len(self.annots)\n\n    def read_image(self, path):\n        img = Image.open(os.path.join(self.root, path))\n        if img.mode != \"RGB\":\n            img = img.convert(\"RGB\")\n        return img\n\n    def __getitem__(self, index):\n        \"\"\"\n        Returns:\n            img (Image): Raw pillow image of the record\n            sample (Sample): Sample with ocr fields, which contains:\n                coords (List[List[Tuple[float, float]]]):\n                    (x, y) coordinate of bounding polygon of each entries\n                texts (List[str]): Text content of each entries\n\n        !Important! text with length 0 ('') indicates don't care area!\n        \"\"\"\n\n        annot = self.annots[index]\n\n        words = annot[\"words\"]\n        dcs = annot[\"dcs\"]\n        img_path = annot[\"filename\"]\n        orig_size = annot[\"orig_size\"]\n\n        img = self.read_image(img_path)\n\n        coords = []\n        texts = []\n\n        for word in words:\n            points = word[0]\n            letters = word[1]\n\n            coords.append(points)\n            texts.append(letters)\n\n        for dc in dcs:\n            coords.append(dc)\n            texts.append(\"\")\n\n        # print(\"text trong datasource \", texts)\n        return img, Sample(\n            image_size=img.size[::-1],\n            # orig_size=orig_size[::-1],\n            orig_size=img.size[::-1],\n            img_path=img_path,\n            key=self.key,\n            ocr=OCRInstances(\n                coords,\n                texts,\n            ),\n        )\n''')\ndatasource.close()","metadata":{"execution":{"iopub.status.busy":"2024-07-15T10:50:46.743211Z","iopub.execute_input":"2024-07-15T10:50:46.743504Z","iopub.status.idle":"2024-07-15T10:50:46.750176Z","shell.execute_reply.started":"2024-07-15T10:50:46.743482Z","shell.execute_reply":"2024-07-15T10:50:46.749252Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"test = open(\"./script/test.py\", \"w\")\ntest.write('''# PYTHONPATH=$PWD python script/test.py --conf configs/finetune.py --ckpt weights/shared.pt\n\n\nfrom units.models.convert_data import *\n\n\nimport warnings\n\nwarnings.filterwarnings(\"ignore\")\nimport os\nimport re\n\nimport torch\nfrom PIL import Image, ImageDraw, ImageFont\nfrom tensorfn import distributed as dist\nfrom tensorfn import get_logger, load_arg_config\nfrom tensorfn.config import instantiate\nfrom torch import nn\nfrom torch.utils.data import ConcatDataset, DataLoader\n\nfrom units.config import E2EConfig\nfrom units.dataset import MultitaskCollator, MultitaskDataset, WeightedDataset\nfrom units.transform import Compose\n\n# config\nPRED_PATH = \"res_output\"\n# DETECT_TYPE = \"quad\"  # 'single', 'box', 'quad', 'polygon'\n# font = ImageFont.truetype(\"TC/Georgia.ttf\", size=24)\n\n\n# def resize_instance(polygon, image_size, orig_size):\n#     \"\"\"\n#     During training, the images were resized while maintaining the aspect ratio, and padding was added to fill the empty space.\n#     Thus, perform the inverse transformation.\n#     \"\"\"\n#     ratio = max(orig_size) / max(image_size)\n\n#     polygon = torch.stack(polygon, 0).numpy()\n#     polygon = polygon * ratio\n#     polygon = polygon.round().astype(np.int64).tolist()\n\n#     return polygon\n\ndef make_dataset(datasources, weighted=True):\n    if not isinstance(datasources, (list, tuple)):\n        datasources = [datasources]\n\n    sources = []\n    ratios = []\n    names = []\n\n    for datasource in datasources:\n        source_fn = instantiate(datasource.datasource)\n\n        for name in datasource.sources:\n            if isinstance(name, str):\n                ratio = 1\n\n            else:\n                name, ratio = name\n\n            sources.append(source_fn(datasource.path, name))\n            ratios.append(ratio)\n            names.append(name)\n\n    if weighted:\n        source = WeightedDataset(sources, ratios, names=names)\n\n        if dist.is_primary():\n            source.summary()\n\n    else:\n        source = ConcatDataset(sources)\n\n        if dist.is_primary():\n            for i, (name, s) in enumerate(zip(names, sources)):\n                print(f\"#{i} {name} total: {len(s)} \")\n\n    return source\n\n\n@torch.no_grad()\ndef predict(conf, mappers, loader, model, device, logger):\n    is_train = model.training\n    model.eval()\n\n    # metrics = Metrics(\n    #     conf.evaluate.eval_metrics, mappers, device, conf.evaluate.eval_metrics_option\n    # )\n    total = len(loader)\n\n    if os.path.isdir(PRED_PATH):\n        os.system(\"rm -r {}\".format(PRED_PATH))\n    os.system(\"mkdir {}\".format(PRED_PATH))\n\n    for i, batch in enumerate(loader):\n        # out = model(batch.to(device), DETECT_TYPE)\n        # The DETECT_TYPE can also be adjusted in the configuration file.\n        out = model(batch.to(device))\n        # metrics(batch, out)\n        pred_instances = mappers[0].postprocess(batch, out)\n\n        for batch_i in range(len(batch.samples)):\n            filename = batch.samples[batch_i].img_path.split(\"/\")[-1].split(\".\")[0]\n\n            pred = pred_instances[batch_i]\n            coords = [coord.cpu().numpy() for coord in pred.coords]\n            texts = [text for text in pred.texts]\n            scores = pred.confidences\n\n            # normalization\n            # ratio = max(batch.samples[batch_i].orig_size) / max(\n            #     batch.samples[batch_i].image_size\n            # )\n            # coords = [coord * ratio for coord in coords]\n            \n            # o_w, o_h = batch.samples[batch_i].image_size\n            # _, n_h, n_w = batch.images[batch_i].shape\n            \n            # ratio = max(o_w, o_h) / max(n_h, n_w)\n            ratio = max(batch.samples[batch_i].orig_size) / max(\n                batch.samples[batch_i].image_size\n            )\n            # print(\"ratio \", ratio)\n            coords = [coord * ratio for coord in coords]\n            # coords = resize_instance(coords, (n_h, n_w), (o_h, o_w))\n            \n            coords = [\n                list(map(str, map(int, coord.reshape(-1).tolist()))) for coord in coords\n            ]\n\n\n            numbers = re.findall(r'\\d+', filename)\n            print(os.path.join(PRED_PATH, (7-len(numbers[0]))*'0' + numbers[0] + \".txt\"))\n            with open(os.path.join(PRED_PATH, (7-len(numbers[0]))*'0' + numbers[0] + \".txt\"), \"w\") as file:\n                for coord, text, score in zip(coords, texts, scores):\n                    # coord = ['%.2f' % elem for elem in coord]\n                    # message = \",\".join(coord) + \",****\" + f\"{score}\" + \",####\" + f\"{(text)}\"\n                    # message = \",\".join(coord) + f\",{score},{decoder(text)}\"\n                    message = \",\".join(coord) + f\",{score},{text}\"\n                    # print(filename)\n                    # print(message)\n                    file.write(message + \"\\\\n\")\n\n        if dist.is_primary() and i % conf.log_freq == 0:\n            logger.info(f\"evaluation [{i}/{total}]\")\n\n    # res = metrics.compute()\n    report = {}\n\n    if is_train:\n        model.train()\n\n    return report\n\n\ndef main(conf):\n    device = \"cuda\"\n    conf.distributed = conf.n_gpu > 1\n\n    logger = get_logger(mode=conf.logger)\n    logger.info(conf.dict())\n\n    model = instantiate(conf.model).to(device)\n\n    if conf.distributed:\n        model = nn.parallel.DistributedDataParallel(\n            model,\n            device_ids=[dist.get_local_rank()],\n            output_device=dist.get_local_rank(),\n            find_unused_parameters=True,\n        )\n\n    mappers = instantiate(conf.training.mappers)\n\n    # when evaluate, we don't want to skip invalid sample.\n    for mapper in mappers:\n        mapper.skip_invalid_sample = False\n\n    source = make_dataset(conf.evaluate.datasources, weighted=False)\n    valid_set = MultitaskDataset(\n        source, mappers, transform=Compose(instantiate(conf.evaluate.transform))\n    )\n    valid_collator = MultitaskCollator(mappers, evaluate=True)\n    val_batch_size = conf.training.val_loader.batch_size // dist.get_world_size()\n\n    valid_loader = DataLoader(\n        valid_set,\n        val_batch_size,\n        num_workers=conf.training.val_loader.num_workers,\n        sampler=dist.data_sampler(\n            valid_set, shuffle=False, distributed=conf.distributed\n        ),\n        collate_fn=valid_collator,\n    )\n\n    checker = instantiate(conf.checker)\n    checker.catalog(conf)\n\n    ckpt = torch.load(conf.ckpt, map_location=lambda storage, loc: storage)\n    ckpt_model = dict()\n    for key, value in ckpt[\"model\"].items():\n        if conf.n_gpu > 1:\n            ckpt_model[key] = value\n        else:\n            ckpt_model[key.replace(\"module.\", \"\", 1)] = value\n\n    model.load_state_dict(ckpt_model)\n    predict(conf, mappers, valid_loader, model, device, logger)\n\n\nif __name__ == \"__main__\":\n    conf = load_arg_config(E2EConfig, elastic=True)\n    dist.run(conf, main, args=(conf,))\n''')\ntest.close()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# @title configtrain.py\n\nconfigtrain = open('./units/config.py', 'w')\nconfigtrain.write('''from typing import Dict, List, Optional, Tuple, Union\n\nfrom pydantic import StrictBool, StrictInt, StrictStr\nfrom tensorfn.config import (\n    Checker,\n    Config,\n    DataLoader,\n    Instance,\n    MainConfig,\n    Optimizer,\n    Scheduler,\n)\n\n\nclass DataSources(Config):\n    datasource: Instance\n    path: StrictStr\n    sources: List[Union[StrictStr, Tuple[StrictStr, float]]]\n\n\nclass Training(Config):\n    n_iter: int\n\n    datasources: Union[DataSources, List[DataSources]]\n    mappers: List[Instance]\n    transform: List[Instance]\n    img_multiple: int = 32\n\n    optimizer: Optimizer\n    weight_decay: float = 1e-4\n    wd_skip_fn: StrictStr = \"vit\"\n    clip_grad: float = 0.1\n    scheduler: Scheduler\n    loader: DataLoader\n    val_loader: DataLoader\n\n    resume_ckpt_freq: StrictInt = 100\n    mixed_precision: bool = False\n\n\nclass Evaluate(Config):\n    eval_freq: StrictInt = 10000\n    eval_metrics: List[StrictStr]\n    eval_metrics_option: Optional[Dict] = None\n\n    datasources: DataSources\n    transform: List[Instance]\n\n    skip_evaluate: StrictBool = True\n\n\nclass E2EConfig(MainConfig):\n    model: Instance\n    training: Training\n    evaluate: Evaluate\n    finetune: StrictBool = False\n\n    log_freq: StrictInt = 100\n    checker: Checker = Checker()\n    logger: StrictStr = \"rich\"\n''')\nconfigtrain.close()","metadata":{"id":"F1KQjymnJio0","cellView":"form","execution":{"iopub.status.busy":"2024-07-15T10:50:46.977290Z","iopub.execute_input":"2024-07-15T10:50:46.977603Z","iopub.status.idle":"2024-07-15T10:50:46.983687Z","shell.execute_reply.started":"2024-07-15T10:50:46.977577Z","shell.execute_reply":"2024-07-15T10:50:46.982799Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"# @title config_vintext.py CHỈNH THÔNG TIN NHƯ BATCH SIZE, SỐ STEP\nconfig_vintext = open('./configs/vintext.py', 'w')\nconfig_vintext.write('''# sudo -H PYTHONPATH=$PWD python script/train.py --conf configs/finetune.py --ckpt weights/pretrain.pt\nfrom tensorfn.config.builder import F, L, field\nfrom tensorfn.nn import repeat\nfrom torch import nn\n\nfrom units.augment import (\n    ColorJitter,\n    ExpandPAD,\n    MultiScaleCrop,\n    RandomApply,\n    RandomCrop,\n    RandomGaussianBlur,\n    RandomResizeScale,\n    RandomRotate,\n    RandomSelect,\n    RandomTranspose,\n    RandomUnsharpMask,\n)\nfrom units.datasource import LMDBSource\nfrom units.models.backbones.swin_transformer import (\n    swin_transformer_b,\n    # swin_transformer_s,\n)\nfrom units.models.data import UnitsMapper\nfrom units.models.decoder import UnitsDecoder\nfrom units.models.model import HybridTransformer, Units, VisionTransformer\nfrom units.models.transformer import TransformerDecoder, TransformerDecoderLayer\nfrom units.tokenizer import UnitsTokenizer\nfrom units.transform import Compose, EdgeEnhance, Grayscale, Normalize, Resize, ToTensor\n\nconf = field()\nconf.finetune = True\n\n# Common\n\nexp_name = \"unitsonvintextbynp\"\ndata_path = \"train_datasets\"\nprompt_type = \"point\"  # None, \"roi\", \"order\", \"point\"\ntokenizer = UnitsTokenizer()\n# print(\"n_vocab 1 \", tokenizer.n_vocab)\ntokenizer.add_detection_vocab(bin_size=1000)\n\n# print(\"n_vocab 2 \", tokenizer.vocab)\n\n# tokenizer.add_order_vocab(max_order=150)\ntokenizer.add_unify_annotation_vocab()\nignore_idx = -100\nwo_source_pos_encod = True\nstride16_feat = False\ncoord_order = \"xy\"\n\n\n# Model\n\ndim_enc = 512 if stride16_feat else 1024\ndim_dec = 256\nn_head_enc = 8\nn_head_dec = 8\nmlp_ratio_enc = 4\nmlp_ratio_dec = 4\nn_enc = 6\nn_dec = 8\nmax_text_length = 25\nn_object = 100\ndecoder_length = 1024\n\ncriterion = L[nn.CrossEntropyLoss](ignore_index=ignore_idx)\n\nbackbone = L[swin_transformer_b](frozen_stages=-1, pretrained=False, use_checkpoint=True)\n\nencoder = L[VisionTransformer](\n    backbone,\n    (16,) if stride16_feat else (32,),\n    wo_source_pos_encod,\n)\n\ntrm_decoder = L[TransformerDecoder](\n    repeat(L[TransformerDecoderLayer](dim_dec, n_head_dec, n_experts=2), n_dec),\n    autoregressive=True,\n)\n\ndecoder = L[UnitsDecoder](\n    dim_dec,\n    max_text_length,\n    trm_decoder,\n    criterion,\n    n_object,\n    decoder_length,\n    tokenizer,\n    prompt=prompt_type,\n    detect_type=\"quad\",\n    fixed_text_len=True,\n    coord_order=coord_order,\n    iterative_decoding=True,\n)\n\nconf.model = L[Units](\n    dim_enc, dim_dec, encoder, decoder, wo_source_pos_encod=wo_source_pos_encod\n)\n\n# Training & Evaluate\n\nmappers = [\n    L[UnitsMapper](\n        tokenizer,\n        max_text_length,\n        n_object=n_object,\n        decoder_length=decoder_length,\n        ignore_idx=ignore_idx,\n        dcs_inputs=True,\n        iou_filtering=False,\n        all_unks_remove=False,\n        coord_order=coord_order,\n        fixed_text_len=True,\n        prompt=prompt_type,\n        # mixed_annot_change_prob=0.1, # nhờ 2 dòng này mà\n        # all_annot_change_prob=0.3,   # trong phần demo mình có thể chọn các kiểu annotation khau như point, box, 4 điểm...\n    )\n]\n\n# Training\n\nangle = 45\ntrain_size = 1920\nvalid_size = 1920\n# n_iter = 32010\nn_iter = 5001\n\ntrain_transform = [\n    L[RandomSelect](\n        [\n            (L[RandomRotate](-angle, angle), 0.333),\n        ],\n    ),\n    L[RandomResizeScale](1.0, 1.0, (train_size, train_size)),\n    L[ExpandPAD]((train_size, train_size)),\n    L[RandomApply](L[ColorJitter](0.4, 0.4, 0.2, 0.1), 0.8),\n    L[RandomApply](L[Grayscale](), 0.3),\n    L[RandomSelect](\n        [\n            (L[RandomGaussianBlur](), 0.3),\n            (L[RandomUnsharpMask](), 0.1),\n            (L[EdgeEnhance](), 0.1),\n            (L[Compose]([L[RandomUnsharpMask](), L[EdgeEnhance]()]), 0.1),\n        ],\n    ),\n    L[ToTensor](),\n    L[Normalize](),\n]\n\n# mixed finetune\ntrain_sets = [\n    # (\"icdar15_train.lmdb\", 10.0),\n    # (\"icdar15_val.lmdb\", 5.0),\n    (\"vintext_train.lmdb\", 12.0),\n    # (\"vintext_val.lmdb\", 3.0),\n    # (\"vintext_test.lmdb\", 5.0),\n]\n\ndatasources = field(datasource=F[LMDBSource](), path=data_path, sources=train_sets)\n\nlr = 3e-5\n# lr = 1e-6\nweight_decay = 1e-4\nwd_skip_fn = \"vit\"\nbatch_size = 5\nnum_workers = 2\nval_batch_size = 12\nval_num_workers = 6\nclip_grad = 0.1\n\noptimizer = field(type=\"adamw\", lr=lr)\n\n# scheduler = field(\n#     type=\"cycle\",\n#     lr=lr,\n#     n_iter=n_iter + 1,\n#     initial_multiplier=1e-5,\n#     warmup=700,\n#     decay=(\"linear\", \"cos\"),\n# )\n\nscheduler = field(\n    type=\"constant\",\n)\n\nloader = field(\n    batch_size=batch_size,\n    shuffle=True,\n    num_workers=num_workers,\n)\nval_loader = field(\n    batch_size=val_batch_size,\n    shuffle=False,\n    num_workers=val_num_workers,\n)\nconf.training = field(\n    n_iter=n_iter,\n    datasources=datasources,\n    transform=train_transform,\n    mappers=mappers,\n    optimizer=optimizer,\n    scheduler=scheduler,\n    loader=loader,\n    val_loader=val_loader,\n    weight_decay=weight_decay,\n    wd_skip_fn=wd_skip_fn,\n    clip_grad=clip_grad,\n)\n\n# Evaluate\n\nvalid_transform = [\n    # L[RandomResizeScale](1.0, 1.0, (valid_size, valid_size)),\n    L[Resize](valid_size),\n    L[ExpandPAD]((valid_size, valid_size)),\n    L[ToTensor](),\n    L[Normalize](),\n]\n\nvalid_sets = [\n    \"vintext_test.lmdb\",\n    # \"icdar15_val.lmdb\",\n]\n\ndatasources = field(datasource=F[LMDBSource](), path=data_path, sources=valid_sets)\n\n# skip evaluation\nconf.evaluate = field(\n    eval_metrics=[],\n    eval_metrics_option=None,\n    datasources=datasources,\n    transform=valid_transform,\n    eval_freq=1000,\n    # eval_freq=1,\n    skip_evaluate=True,\n)\n\nconf.checker = field(\n    storage=[field(type=\"local\", path=\"checkpoints\")],\n    reporter=[\n        field(type=\"logger\"),\n        field(\n            type=\"wandb\",\n            project=\"units\",\n            name=exp_name,\n        ),\n    ],\n)\n''')\nconfig_vintext.close()","metadata":{"id":"q7K9NQxMcqjs","cellView":"form","execution":{"iopub.status.busy":"2024-07-15T10:50:47.290464Z","iopub.execute_input":"2024-07-15T10:50:47.290828Z","iopub.status.idle":"2024-07-15T10:50:47.303425Z","shell.execute_reply.started":"2024-07-15T10:50:47.290801Z","shell.execute_reply":"2024-07-15T10:50:47.302387Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":"# chạy cell này, đăng kí, đăng nhập và vô trang web của wandb để xem loss (ko hiểu sao ngta đặt tên loss là total, sau này dùng sẽ thấy)","metadata":{"id":"Mx9ztsAyHq3R"}},{"cell_type":"code","source":"# !wandb off\nimport wandb\n# 4add229440b47ccc15cbf6940e32ca8663089213\n# tu tao cai khac chu dung dung cai nay\n\n# 84a1cd9d1cb99256694ab784dd9dea9fc25bdd50\n\nwandb.login(key='4add229440b47ccc15cbf6940e32ca8663089213')","metadata":{"id":"fgw7oAOFJio2","outputId":"d2c9e790-f000-4f61-b939-0d310d42ffbb","execution":{"iopub.status.busy":"2024-07-15T10:50:48.049362Z","iopub.execute_input":"2024-07-15T10:50:48.049717Z","iopub.status.idle":"2024-07-15T10:50:50.637600Z","shell.execute_reply.started":"2024-07-15T10:50:48.049689Z","shell.execute_reply":"2024-07-15T10:50:50.636731Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"markdown","source":"# Train thôi nào, colab ko hiện ra train tới bước nào, muốn thì chuyển sang kaggle","metadata":{"id":"fEkZqS7DIjzx"}},{"cell_type":"code","source":"### ic15 finetune\n!PYTHONPATH=$PWD python script/train.py --conf configs/vintext.py --ckpt ./checkpoints/final6000.pt --n_proc 2\n# !PYTHONPATH=$PWD python script/train.py --conf configs/ic15.py --ckpt checkpoints/2024-05-19T15.18.18.114157+00.00/ckpt-000002.pt --n_proc 1","metadata":{"id":"KL4l56lEIfAg","outputId":"2c354906-43d4-4b16-fcce-94797e3a941e","execution":{"iopub.status.busy":"2024-07-15T10:52:29.308543Z","iopub.execute_input":"2024-07-15T10:52:29.309588Z","iopub.status.idle":"2024-07-15T10:53:26.383569Z","shell.execute_reply.started":"2024-07-15T10:52:29.309544Z","shell.execute_reply":"2024-07-15T10:53:26.382070Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"vocab  [' ', '!', '~', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '<', '=', '>', '?', '@', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', ']', '^', '_', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '|', 'ˋ', 'ˊ', '⸱', 'ˀ', '˜', 'ˇ', 'ˆ', '˒']\nchar vocab  [' ', '!', '~', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '<', '=', '>', '?', '@', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', ']', '^', '_', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '|', 'ˋ', 'ˊ', '⸱', 'ˀ', '˜', 'ˇ', 'ˆ', '˒']\n\u001b[2;36m07/15 10:52:37\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[1m{\u001b[0m\u001b[32m'checker'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'reporter'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1m{\u001b[0m\u001b[32m'type'\u001b[0m:           \u001b]8;id=997013;file:///kaggle/working/units/script/train.py\u001b\\\u001b[2mtrain.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=641612;file:///kaggle/working/units/script/train.py#90\u001b\\\u001b[2m90\u001b[0m\u001b]8;;\u001b\\\n\u001b[2;36m               \u001b[0m         \u001b[32m'logger'\u001b[0m\u001b[1m}\u001b[0m,                                   \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                   \u001b[1m{\u001b[0m\u001b[32m'group'\u001b[0m: \u001b[3;35mNone\u001b[0m,    \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                    \u001b[32m'id'\u001b[0m: \u001b[3;35mNone\u001b[0m,       \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                    \u001b[32m'name'\u001b[0m:           \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[32m'unitsonvintextbynp'\u001b[0m,                        \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                    \u001b[32m'notes'\u001b[0m: \u001b[3;35mNone\u001b[0m,    \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                    \u001b[32m'project'\u001b[0m:        \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[32m'units'\u001b[0m,                                     \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                    \u001b[32m'resume'\u001b[0m: \u001b[3;35mNone\u001b[0m,   \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                    \u001b[32m'tags'\u001b[0m: \u001b[3;35mNone\u001b[0m,     \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                    \u001b[32m'type'\u001b[0m:           \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[32m'wandb'\u001b[0m\u001b[1m}\u001b[0m\u001b[1m]\u001b[0m,                                   \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                      \u001b[32m'storage'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1m{\u001b[0m\u001b[32m'keep'\u001b[0m: \u001b[1;36m-1\u001b[0m,        \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[32m'path'\u001b[0m: \u001b[32m'checkpoints'\u001b[0m, \u001b[32m'type'\u001b[0m: \u001b[32m'local'\u001b[0m\u001b[1m}\u001b[0m\u001b[1m]\u001b[0m\u001b[1m}\u001b[0m,   \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m          \u001b[32m'ckpt'\u001b[0m: \u001b[32m'./checkpoints/final6000.pt'\u001b[0m,       \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m          \u001b[32m'dist_url'\u001b[0m: \u001b[32m'127.0.0.1:49152'\u001b[0m,              \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m          \u001b[32m'distributed'\u001b[0m: \u001b[3;92mTrue\u001b[0m,                        \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m          \u001b[32m'evaluate'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'datasources'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'datasource'\u001b[0m:  \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[1m{\u001b[0m\u001b[32m'__fn'\u001b[0m: \u001b[32m'units.datasource.LMDBSource'\u001b[0m\u001b[1m}\u001b[0m,     \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                       \u001b[32m'path'\u001b[0m:        \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[32m'train_datasets'\u001b[0m,                            \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                       \u001b[32m'sources'\u001b[0m:     \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[1m[\u001b[0m\u001b[32m'vintext_test.lmdb'\u001b[0m\u001b[1m]\u001b[0m\u001b[1m}\u001b[0m,                      \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                       \u001b[32m'eval_freq'\u001b[0m: \u001b[1;36m1000\u001b[0m,             \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                       \u001b[32m'eval_metrics'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,            \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                       \u001b[32m'eval_metrics_option'\u001b[0m: \u001b[3;35mNone\u001b[0m,   \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                       \u001b[32m'skip_evaluate'\u001b[0m: \u001b[3;92mTrue\u001b[0m,         \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                       \u001b[32m'transform'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1m{\u001b[0m\u001b[32m'__args'\u001b[0m:       \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[1m[\u001b[0m\u001b[1;36m1920\u001b[0m\u001b[1m]\u001b[0m,                                      \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                      \u001b[32m'__init'\u001b[0m:       \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[32m'units.transform.Resize'\u001b[0m\u001b[1m}\u001b[0m,                   \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                     \u001b[1m{\u001b[0m\u001b[32m'__args'\u001b[0m:       \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1920\u001b[0m, \u001b[1;36m1920\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m,                              \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                      \u001b[32m'__init'\u001b[0m:       \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[32m'units.augment.ExpandPAD'\u001b[0m\u001b[1m}\u001b[0m,                  \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                     \u001b[1m{\u001b[0m\u001b[32m'__init'\u001b[0m:       \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[32m'units.transform.ToTensor'\u001b[0m\u001b[1m}\u001b[0m,                 \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                     \u001b[1m{\u001b[0m\u001b[32m'__init'\u001b[0m:       \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[32m'units.transform.Normalize'\u001b[0m\u001b[1m}\u001b[0m\u001b[1m]\u001b[0m\u001b[1m}\u001b[0m,              \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m          \u001b[32m'finetune'\u001b[0m: \u001b[3;92mTrue\u001b[0m,                           \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m          \u001b[32m'launch_config'\u001b[0m: \u001b[1;35mLaunchConfig\u001b[0m\u001b[1m(\u001b[0m\u001b[33mmin_nodes\u001b[0m=\u001b[1;36m1\u001b[0m,  \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                        \u001b[33mmax_nodes\u001b[0m=\u001b[1;36m1\u001b[0m,  \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                        \u001b[33mnproc_per_nod\u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[33me\u001b[0m=\u001b[1;36m2\u001b[0m,                                         \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                        \u001b[33mrun_id\u001b[0m=\u001b[32m'none'\u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         ,                                            \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                        \u001b[33mrole\u001b[0m=\u001b[32m'default\u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[32m'\u001b[0m,                                           \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                        \u001b[33mrdzv_endpoint\u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         =\u001b[32m'127.0.0.1:49152'\u001b[0m,                          \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                        \u001b[33mrdzv_backend\u001b[0m= \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[32m'static'\u001b[0m,                                    \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                        \u001b[33mrdzv_configs\u001b[0m= \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[1m{\u001b[0m\u001b[32m'rank'\u001b[0m: \u001b[1;36m0\u001b[0m, \u001b[32m'timeout'\u001b[0m: \u001b[1;36m900\u001b[0m\u001b[1m}\u001b[0m,                 \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                        \u001b[33mrdzv_timeout\u001b[0m= \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[1;36m-1\u001b[0m,                                          \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                        \u001b[33mmax_restarts\u001b[0m= \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[1;36m0\u001b[0m,                                           \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                        \u001b[33mmonitor_inter\u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[33mval\u001b[0m=\u001b[1;36m5\u001b[0m,                                       \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                        \u001b[33mstart_method\u001b[0m= \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[32m'spawn'\u001b[0m,                                     \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                        \u001b[33mlog_dir\u001b[0m=\u001b[3;35mNone\u001b[0m, \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                        \u001b[33mredirects\u001b[0m=\u001b[1m<\u001b[0m\u001b[1;95mSt\u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[1;95md.NONE:\u001b[0m\u001b[39m \u001b[0m\u001b[1;36m0\u001b[0m\u001b[39m>,\u001b[0m                                  \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m                               \u001b[0m\u001b[33mtee\u001b[0m\u001b[39m=<Std.NONE\u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m: \u001b[0m\u001b[1;36m0\u001b[0m\u001b[39m>,\u001b[0m                                        \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m                               \u001b[0m\u001b[33mmetrics_cfg\u001b[0m\u001b[39m=\u001b[0m\u001b[1;39m{\u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[1;39m}\u001b[0m\u001b[39m,\u001b[0m                                           \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m                               \u001b[0m\u001b[33mlocal_addr\u001b[0m\u001b[39m=\u001b[0m\u001b[3;35mNo\u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[3;35mne\u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m,\u001b[0m                                         \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m \u001b[0m\u001b[32m'log_freq'\u001b[0m\u001b[39m: \u001b[0m\u001b[1;36m100\u001b[0m\u001b[39m,\u001b[0m                            \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m \u001b[0m\u001b[32m'logger'\u001b[0m\u001b[39m: \u001b[0m\u001b[32m'rich'\u001b[0m\u001b[39m,\u001b[0m                           \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m \u001b[0m\u001b[32m'machine_rank'\u001b[0m\u001b[39m: \u001b[0m\u001b[1;36m0\u001b[0m\u001b[39m,\u001b[0m                          \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m \u001b[0m\u001b[32m'model'\u001b[0m\u001b[39m: \u001b[0m\u001b[1;39m{\u001b[0m\u001b[32m'__args'\u001b[0m\u001b[39m: \u001b[0m\u001b[1;39m[\u001b[0m\u001b[1;36m1024\u001b[0m\u001b[39m,\u001b[0m                  \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m                      \u001b[0m\u001b[1;36m256\u001b[0m\u001b[39m,\u001b[0m                   \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m                      \u001b[0m\u001b[1;39m{\u001b[0m\u001b[32m'__args'\u001b[0m\u001b[39m: \u001b[0m\u001b[1;39m[\u001b[0m\u001b[1;39m{\u001b[0m\u001b[32m'__init'\u001b[0m\u001b[39m:\u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[32m'units.models.backbones.swin_transformer_b'\u001b[0m\u001b[39m,\u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m                                   \u001b[0m\u001b[32m'frozen_s\u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[32mtages'\u001b[0m\u001b[39m: \u001b[0m\u001b[1;36m-1\u001b[0m\u001b[39m,\u001b[0m                                  \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m                                   \u001b[0m\u001b[32m'pretrain\u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[32med'\u001b[0m\u001b[39m: \u001b[0m\u001b[3;91mFalse\u001b[0m\u001b[39m,\u001b[0m                                  \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m                                   \u001b[0m\u001b[32m'use_chec\u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[32mkpoint'\u001b[0m\u001b[39m: \u001b[0m\u001b[3;92mTrue\u001b[0m\u001b[1;39m}\u001b[0m\u001b[39m,\u001b[0m                              \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m                                  \u001b[0m\u001b[1;39m[\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;39m]\u001b[0m\u001b[39m,\u001b[0m      \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m                                  \u001b[0m\u001b[3;92mTrue\u001b[0m\u001b[1;39m]\u001b[0m\u001b[39m,\u001b[0m     \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m                       \u001b[0m\u001b[32m'__init'\u001b[0m\u001b[39m: \u001b[0m            \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[32m'units.models.VisionTransformer'\u001b[0m\u001b[1;39m}\u001b[0m\u001b[39m,\u001b[0m           \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m                      \u001b[0m\u001b[1;39m{\u001b[0m\u001b[32m'__args'\u001b[0m\u001b[39m: \u001b[0m\u001b[1;39m[\u001b[0m\u001b[1;36m256\u001b[0m\u001b[39m,\u001b[0m       \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m                                  \u001b[0m\u001b[1;36m25\u001b[0m\u001b[39m,\u001b[0m        \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m                                  \u001b[0m\u001b[1;39m{\u001b[0m\u001b[32m'__args'\u001b[0m\u001b[39m:\u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[1;39m[\u001b[0m\u001b[1;39m[\u001b[0m\u001b[1;39m{\u001b[0m\u001b[32m'__args'\u001b[0m\u001b[39m: \u001b[0m\u001b[1;39m[\u001b[0m\u001b[1;36m256\u001b[0m\u001b[39m, \u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;39m]\u001b[0m\u001b[39m,\u001b[0m                       \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m                                            \u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m    \u001b[0m\u001b[32m'__init'\u001b[0m\u001b[39m: \u001b[0m                               \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[32m'units.models.transformer.TransformerDecoder\u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[32mLayer'\u001b[0m\u001b[39m,\u001b[0m                                      \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m                                            \u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m    \u001b[0m\u001b[32m'n_experts'\u001b[0m\u001b[39m: \u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;39m}\u001b[0m\u001b[39m,\u001b[0m                         \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m                                            \u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m   \u001b[0m\u001b[1;39m{\u001b[0m\u001b[32m'__args'\u001b[0m\u001b[39m: \u001b[0m\u001b[1;39m[\u001b[0m\u001b[1;36m256\u001b[0m\u001b[39m, \u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;39m]\u001b[0m\u001b[39m,\u001b[0m                      \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m                                            \u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m    \u001b[0m\u001b[32m'__init'\u001b[0m\u001b[39m: \u001b[0m                               \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[32m'units.models.transformer.TransformerDecoder\u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[32mLayer'\u001b[0m\u001b[39m,\u001b[0m                                      \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m                                            \u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m    \u001b[0m\u001b[32m'n_experts'\u001b[0m\u001b[39m: \u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;39m}\u001b[0m\u001b[39m,\u001b[0m                         \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m                                            \u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m   \u001b[0m\u001b[1;39m{\u001b[0m\u001b[32m'__args'\u001b[0m\u001b[39m: \u001b[0m\u001b[1;39m[\u001b[0m\u001b[1;36m256\u001b[0m\u001b[39m, \u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;39m]\u001b[0m\u001b[39m,\u001b[0m                      \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m                                            \u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m    \u001b[0m\u001b[32m'__init'\u001b[0m\u001b[39m: \u001b[0m                               \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[32m'units.models.transformer.TransformerDecoder\u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[32mLayer'\u001b[0m\u001b[39m,\u001b[0m                                      \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m                                            \u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m    \u001b[0m\u001b[32m'n_experts'\u001b[0m\u001b[39m: \u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;39m}\u001b[0m\u001b[39m,\u001b[0m                         \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m                                            \u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m   \u001b[0m\u001b[1;39m{\u001b[0m\u001b[32m'__args'\u001b[0m\u001b[39m: \u001b[0m\u001b[1;39m[\u001b[0m\u001b[1;36m256\u001b[0m\u001b[39m, \u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;39m]\u001b[0m\u001b[39m,\u001b[0m                      \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m                                            \u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m    \u001b[0m\u001b[32m'__init'\u001b[0m\u001b[39m: \u001b[0m                               \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[32m'units.models.transformer.TransformerDecoder\u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[32mLayer'\u001b[0m\u001b[39m,\u001b[0m                                      \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m                                            \u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m    \u001b[0m\u001b[32m'n_experts'\u001b[0m\u001b[39m: \u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;39m}\u001b[0m\u001b[39m,\u001b[0m                         \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m                                            \u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m   \u001b[0m\u001b[1;39m{\u001b[0m\u001b[32m'__args'\u001b[0m\u001b[39m: \u001b[0m\u001b[1;39m[\u001b[0m\u001b[1;36m256\u001b[0m\u001b[39m, \u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;39m]\u001b[0m\u001b[39m,\u001b[0m                      \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m                                            \u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m    \u001b[0m\u001b[32m'__init'\u001b[0m\u001b[39m: \u001b[0m                               \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[32m'units.models.transformer.TransformerDecoder\u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[32mLayer'\u001b[0m\u001b[39m,\u001b[0m                                      \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m                                            \u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m    \u001b[0m\u001b[32m'n_experts'\u001b[0m\u001b[39m: \u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;39m}\u001b[0m\u001b[39m,\u001b[0m                         \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m                                            \u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m   \u001b[0m\u001b[1;39m{\u001b[0m\u001b[32m'__args'\u001b[0m\u001b[39m: \u001b[0m\u001b[1;39m[\u001b[0m\u001b[1;36m256\u001b[0m\u001b[39m, \u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;39m]\u001b[0m\u001b[39m,\u001b[0m                      \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m                                            \u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m    \u001b[0m\u001b[32m'__init'\u001b[0m\u001b[39m: \u001b[0m                               \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[32m'units.models.transformer.TransformerDecoder\u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[32mLayer'\u001b[0m\u001b[39m,\u001b[0m                                      \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m                                            \u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m    \u001b[0m\u001b[32m'n_experts'\u001b[0m\u001b[39m: \u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;39m}\u001b[0m\u001b[39m,\u001b[0m                         \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m                                            \u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m   \u001b[0m\u001b[1;39m{\u001b[0m\u001b[32m'__args'\u001b[0m\u001b[39m: \u001b[0m\u001b[1;39m[\u001b[0m\u001b[1;36m256\u001b[0m\u001b[39m, \u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;39m]\u001b[0m\u001b[39m,\u001b[0m                      \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m                                            \u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m    \u001b[0m\u001b[32m'__init'\u001b[0m\u001b[39m: \u001b[0m                               \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[32m'units.models.transformer.TransformerDecoder\u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[32mLayer'\u001b[0m\u001b[39m,\u001b[0m                                      \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m                                            \u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m    \u001b[0m\u001b[32m'n_experts'\u001b[0m\u001b[39m: \u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;39m}\u001b[0m\u001b[39m,\u001b[0m                         \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m                                            \u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m   \u001b[0m\u001b[1;39m{\u001b[0m\u001b[32m'__args'\u001b[0m\u001b[39m: \u001b[0m\u001b[1;39m[\u001b[0m\u001b[1;36m256\u001b[0m\u001b[39m, \u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;39m]\u001b[0m\u001b[39m,\u001b[0m                      \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m                                            \u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m    \u001b[0m\u001b[32m'__init'\u001b[0m\u001b[39m: \u001b[0m                               \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[32m'units.models.transformer.TransformerDecoder\u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[32mLayer'\u001b[0m\u001b[39m,\u001b[0m                                      \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m                                            \u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m    \u001b[0m\u001b[32m'n_experts'\u001b[0m\u001b[39m: \u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;39m}\u001b[0m\u001b[1;39m]\u001b[0m\u001b[1;39m]\u001b[0m\u001b[39m,\u001b[0m                       \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m                                   \u001b[0m\u001b[32m'__init'\u001b[0m\u001b[39m:\u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[32m'units.models.transformer.TransformerDecoder\u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[32m'\u001b[0m\u001b[39m,\u001b[0m                                           \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m                                   \u001b[0m\u001b[32m'autoregr\u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[32messive'\u001b[0m\u001b[39m: \u001b[0m\u001b[3;92mTrue\u001b[0m\u001b[1;39m}\u001b[0m\u001b[39m,\u001b[0m                              \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m                                  \u001b[0m\u001b[1;39m{\u001b[0m\u001b[32m'__init'\u001b[0m\u001b[39m:\u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[32m'torch.nn.CrossEntropyLoss'\u001b[0m\u001b[39m,\u001b[0m                 \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m                                   \u001b[0m\u001b[32m'ignore_i\u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[32mndex'\u001b[0m\u001b[39m: \u001b[0m\u001b[1;36m-100\u001b[0m\u001b[1;39m}\u001b[0m\u001b[39m,\u001b[0m                                \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m                                  \u001b[0m\u001b[1;36m100\u001b[0m\u001b[39m,\u001b[0m       \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m                                  \u001b[0m\u001b[1;36m1024\u001b[0m\u001b[39m,\u001b[0m      \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m                                  <units.tok\u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39menizer.UnitsTokenizer object at \u001b[0m             \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[1;36m0x7f6f04c6efb0\u001b[0m\u001b[39m>\u001b[0m\u001b[1;39m]\u001b[0m\u001b[39m,\u001b[0m                            \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m                       \u001b[0m\u001b[32m'__init'\u001b[0m\u001b[39m: \u001b[0m            \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[32m'units.models.UnitsDecoder'\u001b[0m\u001b[39m,\u001b[0m                 \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m                       \u001b[0m\u001b[32m'coord_order'\u001b[0m\u001b[39m: \u001b[0m\u001b[32m'xy'\u001b[0m\u001b[39m,\u001b[0m  \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m                       \u001b[0m\u001b[32m'detect_type'\u001b[0m\u001b[39m: \u001b[0m       \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[32m'quad'\u001b[0m\u001b[39m,\u001b[0m                                      \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m                       \u001b[0m\u001b[32m'fixed_text_len'\u001b[0m\u001b[39m: \u001b[0m    \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[3;92mTrue\u001b[0m\u001b[39m,\u001b[0m                                        \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m                       \u001b[0m\u001b[32m'iterative_decoding'\u001b[0m\u001b[39m:\u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[3;92mTrue\u001b[0m\u001b[39m,\u001b[0m                                        \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m                       \u001b[0m\u001b[32m'prompt'\u001b[0m\u001b[39m: \u001b[0m\u001b[32m'point'\u001b[0m\u001b[1;39m}\u001b[0m\u001b[1;39m]\u001b[0m\u001b[39m,\u001b[0m  \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m           \u001b[0m\u001b[32m'__init'\u001b[0m\u001b[39m: \u001b[0m\u001b[32m'units.models.Units'\u001b[0m\u001b[39m,\u001b[0m   \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m           \u001b[0m\u001b[32m'wo_source_pos_encod'\u001b[0m\u001b[39m: \u001b[0m\u001b[3;92mTrue\u001b[0m\u001b[1;39m}\u001b[0m\u001b[39m,\u001b[0m     \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m \u001b[0m\u001b[32m'n_gpu'\u001b[0m\u001b[39m: \u001b[0m\u001b[1;36m2\u001b[0m\u001b[39m,\u001b[0m                                 \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m \u001b[0m\u001b[32m'n_machine'\u001b[0m\u001b[39m: \u001b[0m\u001b[1;36m1\u001b[0m\u001b[39m,\u001b[0m                             \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m \u001b[0m\u001b[32m'training'\u001b[0m\u001b[39m: \u001b[0m\u001b[1;39m{\u001b[0m\u001b[32m'clip_grad'\u001b[0m\u001b[39m: \u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[39m,\u001b[0m              \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m              \u001b[0m\u001b[32m'datasources'\u001b[0m\u001b[39m: \u001b[0m\u001b[1;39m{\u001b[0m\u001b[32m'datasource'\u001b[0m\u001b[39m: \u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[1;39m{\u001b[0m\u001b[32m'__fn'\u001b[0m\u001b[39m: \u001b[0m\u001b[32m'units.datasource.LMDBSource'\u001b[0m\u001b[1;39m}\u001b[0m\u001b[39m,\u001b[0m     \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m                              \u001b[0m\u001b[32m'path'\u001b[0m\u001b[39m: \u001b[0m       \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[32m'train_datasets'\u001b[0m\u001b[39m,\u001b[0m                            \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m                              \u001b[0m\u001b[32m'sources'\u001b[0m\u001b[39m: \u001b[0m    \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[1;39m[\u001b[0m\u001b[1;39m(\u001b[0m\u001b[32m'vintext_train.lmdb'\u001b[0m\u001b[39m, \u001b[0m\u001b[1;36m12.0\u001b[0m\u001b[1;39m)\u001b[0m\u001b[1;39m]\u001b[0m\u001b[1;39m}\u001b[0m\u001b[39m,\u001b[0m             \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m              \u001b[0m\u001b[32m'img_multiple'\u001b[0m\u001b[39m: \u001b[0m\u001b[1;36m32\u001b[0m\u001b[39m,\u001b[0m            \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m              \u001b[0m\u001b[32m'loader'\u001b[0m\u001b[39m: \u001b[0m\u001b[1;39m{\u001b[0m\u001b[32m'batch_size'\u001b[0m\u001b[39m: \u001b[0m\u001b[1;36m5\u001b[0m\u001b[39m,\u001b[0m    \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m                         \u001b[0m\u001b[32m'drop_last'\u001b[0m\u001b[39m: \u001b[0m\u001b[3;91mFalse\u001b[0m\u001b[39m,\u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m                         \u001b[0m\u001b[32m'num_workers'\u001b[0m\u001b[39m: \u001b[0m\u001b[1;36m2\u001b[0m\u001b[39m,\u001b[0m   \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m                         \u001b[0m\u001b[32m'pin_memory'\u001b[0m\u001b[39m: \u001b[0m      \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[3;91mFalse\u001b[0m\u001b[39m,\u001b[0m                                       \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m                         \u001b[0m\u001b[32m'shuffle'\u001b[0m\u001b[39m: \u001b[0m\u001b[3;92mTrue\u001b[0m\u001b[39m,\u001b[0m    \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m                         \u001b[0m\u001b[32m'timeout'\u001b[0m\u001b[39m: \u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;39m}\u001b[0m\u001b[39m,\u001b[0m      \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m              \u001b[0m\u001b[32m'mappers'\u001b[0m\u001b[39m: \u001b[0m\u001b[1;39m[\u001b[0m\u001b[1;39m{\u001b[0m\u001b[32m'__args'\u001b[0m\u001b[39m: \u001b[0m        \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[1;39m[\u001b[0m\u001b[39m<units.tokenizer.UnitsTokenizer object at \u001b[0m  \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[1;36m0x7f6f04c6efb0\u001b[0m\u001b[1m>\u001b[0m,                             \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                               \u001b[1;36m25\u001b[0m\u001b[1m]\u001b[0m,   \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                    \u001b[32m'__init'\u001b[0m:         \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[32m'units.models.UnitsMapper'\u001b[0m,                  \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                    \u001b[32m'all_unks_remove'\u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         : \u001b[3;91mFalse\u001b[0m,                                     \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                    \u001b[32m'coord_order'\u001b[0m:    \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[32m'xy'\u001b[0m,                                        \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                    \u001b[32m'dcs_inputs'\u001b[0m:     \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[3;92mTrue\u001b[0m,                                        \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                    \u001b[32m'decoder_length'\u001b[0m: \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[1;36m1024\u001b[0m,                                        \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                    \u001b[32m'fixed_text_len'\u001b[0m: \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[3;92mTrue\u001b[0m,                                        \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                    \u001b[32m'ignore_idx'\u001b[0m:     \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[1;36m-100\u001b[0m,                                        \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                    \u001b[32m'iou_filtering'\u001b[0m:  \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[3;91mFalse\u001b[0m,                                       \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                    \u001b[32m'n_object'\u001b[0m: \u001b[1;36m100\u001b[0m,  \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                    \u001b[32m'prompt'\u001b[0m:         \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[32m'point'\u001b[0m\u001b[1m}\u001b[0m\u001b[1m]\u001b[0m,                                   \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                       \u001b[32m'mixed_precision'\u001b[0m: \u001b[3;91mFalse\u001b[0m,      \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                       \u001b[32m'n_iter'\u001b[0m: \u001b[1;36m5001\u001b[0m,                \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                       \u001b[32m'optimizer'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'amsgrad'\u001b[0m:       \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[3;91mFalse\u001b[0m,                                       \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                     \u001b[32m'betas'\u001b[0m: \u001b[1m(\u001b[0m\u001b[1;36m0.9\u001b[0m,   \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[1;36m0.999\u001b[0m\u001b[1m)\u001b[0m,                                      \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                     \u001b[32m'eps'\u001b[0m: \u001b[1;36m1e-08\u001b[0m,    \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                     \u001b[32m'lr'\u001b[0m: \u001b[1;36m3e-05\u001b[0m,     \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                     \u001b[32m'type'\u001b[0m: \u001b[32m'adamw'\u001b[0m, \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                     \u001b[32m'weight_decay'\u001b[0m:  \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[1;36m0\u001b[0m\u001b[1m}\u001b[0m,                                          \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                       \u001b[32m'resume_ckpt_freq'\u001b[0m: \u001b[1;36m100\u001b[0m,       \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                       \u001b[32m'scheduler'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'type'\u001b[0m:          \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[32m'constant'\u001b[0m\u001b[1m}\u001b[0m,                                 \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                       \u001b[32m'transform'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1m{\u001b[0m\u001b[32m'__args'\u001b[0m:       \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1m{\u001b[0m\u001b[32m'__args'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1;36m-45\u001b[0m, \u001b[1;36m45\u001b[0m\u001b[1m]\u001b[0m,                     \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                                    \u001b[32m'\u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[32m__init'\u001b[0m: \u001b[32m'units.augment.RandomRotate'\u001b[0m\u001b[1m}\u001b[0m,      \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                                   \u001b[1;36m0.\u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[1;36m333\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m,                                      \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                      \u001b[32m'__init'\u001b[0m:       \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[32m'units.augment.RandomSelect'\u001b[0m\u001b[1m}\u001b[0m,               \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                     \u001b[1m{\u001b[0m\u001b[32m'__args'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1;36m1.0\u001b[0m, \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[1;36m1.0\u001b[0m, \u001b[1m[\u001b[0m\u001b[1;36m1920\u001b[0m, \u001b[1;36m1920\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m,                          \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                      \u001b[32m'__init'\u001b[0m:       \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[32m'units.augment.RandomResizeScale'\u001b[0m\u001b[1m}\u001b[0m,          \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                     \u001b[1m{\u001b[0m\u001b[32m'__args'\u001b[0m:       \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1920\u001b[0m, \u001b[1;36m1920\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m,                              \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                      \u001b[32m'__init'\u001b[0m:       \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[32m'units.augment.ExpandPAD'\u001b[0m\u001b[1m}\u001b[0m,                  \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                     \u001b[1m{\u001b[0m\u001b[32m'__args'\u001b[0m:       \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[1m[\u001b[0m\u001b[1m{\u001b[0m\u001b[32m'__args'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1;36m0.4\u001b[0m, \u001b[1;36m0.4\u001b[0m, \u001b[1;36m0.2\u001b[0m, \u001b[1;36m0.1\u001b[0m\u001b[1m]\u001b[0m,            \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                                  \u001b[32m'__\u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[32minit'\u001b[0m: \u001b[32m'units.augment.ColorJitter'\u001b[0m\u001b[1m}\u001b[0m,         \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                                 \u001b[1;36m0.8\u001b[0m\u001b[1m]\u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         ,                                            \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                      \u001b[32m'__init'\u001b[0m:       \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[32m'units.augment.RandomApply'\u001b[0m\u001b[1m}\u001b[0m,                \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                     \u001b[1m{\u001b[0m\u001b[32m'__args'\u001b[0m:       \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[1m[\u001b[0m\u001b[1m{\u001b[0m\u001b[32m'__init'\u001b[0m: \u001b[32m'units.transform.Grayscale'\u001b[0m\u001b[1m}\u001b[0m,    \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                                 \u001b[1;36m0.3\u001b[0m\u001b[1m]\u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         ,                                            \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                      \u001b[32m'__init'\u001b[0m:       \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[32m'units.augment.RandomApply'\u001b[0m\u001b[1m}\u001b[0m,                \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                     \u001b[1m{\u001b[0m\u001b[32m'__args'\u001b[0m:       \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1m{\u001b[0m\u001b[32m'__init'\u001b[0m:                                \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[32m'units.augment.RandomGaussianBlur'\u001b[0m\u001b[1m}\u001b[0m,         \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                                   \u001b[1;36m0.\u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[1;36m3\u001b[0m\u001b[1m]\u001b[0m,                                          \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                                  \u001b[1m[\u001b[0m\u001b[1m{\u001b[0m\u001b[32m'\u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[32m__init'\u001b[0m: \u001b[32m'units.augment.RandomUnsharpMask'\u001b[0m\u001b[1m}\u001b[0m, \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                                   \u001b[1;36m0.\u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[1;36m1\u001b[0m\u001b[1m]\u001b[0m,                                          \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                                  \u001b[1m[\u001b[0m\u001b[1m{\u001b[0m\u001b[32m'\u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[32m__init'\u001b[0m: \u001b[32m'units.transform.EdgeEnhance'\u001b[0m\u001b[1m}\u001b[0m,     \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                                   \u001b[1;36m0.\u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[1;36m1\u001b[0m\u001b[1m]\u001b[0m,                                          \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                                  \u001b[1m[\u001b[0m\u001b[1m{\u001b[0m\u001b[32m'\u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[32m__args'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1m{\u001b[0m\u001b[32m'__init'\u001b[0m:                        \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[32m'units.augment.RandomUnsharpMask'\u001b[0m\u001b[1m}\u001b[0m,          \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                                      \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                    \u001b[1m{\u001b[0m\u001b[32m'__init'\u001b[0m:                        \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[32m'units.transform.EdgeEnhance'\u001b[0m\u001b[1m}\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m,            \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                                    \u001b[32m'\u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[32m__init'\u001b[0m: \u001b[32m'units.transform.Compose'\u001b[0m\u001b[1m}\u001b[0m,         \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                                   \u001b[1;36m0.\u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[1;36m1\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m,                                        \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                      \u001b[32m'__init'\u001b[0m:       \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[32m'units.augment.RandomSelect'\u001b[0m\u001b[1m}\u001b[0m,               \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                     \u001b[1m{\u001b[0m\u001b[32m'__init'\u001b[0m:       \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[32m'units.transform.ToTensor'\u001b[0m\u001b[1m}\u001b[0m,                 \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                     \u001b[1m{\u001b[0m\u001b[32m'__init'\u001b[0m:       \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[32m'units.transform.Normalize'\u001b[0m\u001b[1m}\u001b[0m\u001b[1m]\u001b[0m,               \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                       \u001b[32m'val_loader'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'batch_size'\u001b[0m:   \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[1;36m12\u001b[0m,                                          \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                      \u001b[32m'drop_last'\u001b[0m:    \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[3;91mFalse\u001b[0m,                                       \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                      \u001b[32m'num_workers'\u001b[0m:  \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[1;36m6\u001b[0m,                                           \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                      \u001b[32m'pin_memory'\u001b[0m:   \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[3;91mFalse\u001b[0m,                                       \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                      \u001b[32m'shuffle'\u001b[0m:      \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[3;91mFalse\u001b[0m,                                       \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                      \u001b[32m'timeout'\u001b[0m: \u001b[1;36m0\u001b[0m\u001b[1m}\u001b[0m,  \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                       \u001b[32m'wd_skip_fn'\u001b[0m: \u001b[32m'vit'\u001b[0m,           \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                       \u001b[32m'weight_decay'\u001b[0m: \u001b[1;36m0.0001\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m       \u001b[2m           \u001b[0m\nfrozen ne  -1\nDay la pretrained  False\nfrozen ne  -1\nDay la pretrained  False\nn_vocab ne  1117\nfrozen ne  -1\nn_vocab ne  1117\nfrozen ne  -1\n#0 vintext_train.lmdb total: 1200 ratio: 12.0 sample: 1200\n#0 vintext_test.lmdb total: 500 \n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcolabnguyen082\u001b[0m (\u001b[33mphuc-honor-hcmus\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.17.4 is available!  To upgrade, please run:\n\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.17.0\n\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/units/wandb/run-20240715_105240-rqfnr9lm\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33munitsonvintextbynp\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/phuc-honor-hcmus/units\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/phuc-honor-hcmus/units/runs/rqfnr9lm\u001b[0m\n\u001b[2;36m07/15 10:52:57\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[1m<\u001b[0m\u001b[1;95mAll\u001b[0m\u001b[39m keys matched successfully\u001b[0m\u001b[1m>\u001b[0m             \u001b]8;id=117793;file:///kaggle/working/units/script/train.py\u001b\\\u001b[2mtrain.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=49972;file:///kaggle/working/units/script/train.py#216\u001b\\\u001b[2m216\u001b[0m\u001b]8;;\u001b\\\n\u001b[2;36m07/15 10:53:12\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m step: \u001b[1;36m0\u001b[0m; lr: \u001b[1;36m3e-05\u001b[0m; total: \u001b[1;36m0.164\u001b[0m          \u001b]8;id=373111;file:///opt/conda/lib/python3.10/site-packages/tensorfn/checker/backend.py\u001b\\\u001b[2mbackend.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=76578;file:///opt/conda/lib/python3.10/site-packages/tensorfn/checker/backend.py#353\u001b\\\u001b[2m353\u001b[0m\u001b]8;;\u001b\\\n^C\n[2024-07-15 10:53:25,672] torch.distributed.elastic.agent.server.api: [WARNING] Received Signals.SIGINT death signal, shutting down workers\n[2024-07-15 10:53:25,682] torch.distributed.elastic.multiprocessing.api: [WARNING] Closing process 342 via signal SIGINT\n[2024-07-15 10:53:25,682] torch.distributed.elastic.multiprocessing.api: [WARNING] Closing process 343 via signal SIGINT\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# STOP","metadata":{}},{"cell_type":"code","source":"# Change directory to 'checkpoints'\n%cd checkpoints\n\n# Get the current path\ncurrent_path = !pwd\ncurrent_path = current_path[0].strip()\n\n# Get the list of subdirectories\nfolders = !ls -d */\nfolders = [f.strip() for f in folders]\n\nfull_path = None\nif len(folders) == 1:\n    # Create the full path\n    full_path = os.path.join(current_path, folders[0], 'ckpt-005000.pt')\n    print(full_path)\nelse:\n    print(\"Multiple or no folders found.\")\n\n# Change back to the parent directory\n%cd ..\n\nif full_path:\n    # Format the command string\n    command = f\"PYTHONPATH=$PWD python script/test.py --conf configs/vintext.py --ckpt {full_path} --n_proc 2\"\n    # Execute the command\n    !{command}\nelse:\n    print(\"Checkpoint path not set.\")","metadata":{"execution":{"iopub.status.busy":"2024-07-15T11:18:55.873546Z","iopub.execute_input":"2024-07-15T11:18:55.874622Z","iopub.status.idle":"2024-07-15T11:19:29.818505Z","shell.execute_reply.started":"2024-07-15T11:18:55.874572Z","shell.execute_reply":"2024-07-15T11:19:29.816869Z"},"trusted":true},"execution_count":77,"outputs":[{"name":"stdout","text":"/kaggle/working/units/checkpoints\n/kaggle/working/units/checkpoints/2024-07-15T10.52.39.722116+00.00/ckpt-000000.pt\n/kaggle/working/units\nvocab  [' ', '!', '~', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '<', '=', '>', '?', '@', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', ']', '^', '_', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '|', 'ˋ', 'ˊ', '⸱', 'ˀ', '˜', 'ˇ', 'ˆ', '˒']\nchar vocab  [' ', '!', '~', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '<', '=', '>', '?', '@', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', ']', '^', '_', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '|', 'ˋ', 'ˊ', '⸱', 'ˀ', '˜', 'ˇ', 'ˆ', '˒']\n\u001b[2;36m07/15 11:19:04\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[1m{\u001b[0m\u001b[32m'checker'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'reporter'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1m{\u001b[0m\u001b[32m'type'\u001b[0m:           \u001b]8;id=948698;file:///kaggle/working/units/script/test.py\u001b\\\u001b[2mtest.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=782090;file:///kaggle/working/units/script/test.py#127\u001b\\\u001b[2m127\u001b[0m\u001b]8;;\u001b\\\n\u001b[2;36m               \u001b[0m         \u001b[32m'logger'\u001b[0m\u001b[1m}\u001b[0m,                                   \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                   \u001b[1m{\u001b[0m\u001b[32m'group'\u001b[0m: \u001b[3;35mNone\u001b[0m,    \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                    \u001b[32m'id'\u001b[0m: \u001b[3;35mNone\u001b[0m,       \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                    \u001b[32m'name'\u001b[0m:           \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[32m'unitsonvintextbynp'\u001b[0m,                        \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                    \u001b[32m'notes'\u001b[0m: \u001b[3;35mNone\u001b[0m,    \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                    \u001b[32m'project'\u001b[0m:        \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[32m'units'\u001b[0m,                                     \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                    \u001b[32m'resume'\u001b[0m: \u001b[3;35mNone\u001b[0m,   \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                    \u001b[32m'tags'\u001b[0m: \u001b[3;35mNone\u001b[0m,     \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                    \u001b[32m'type'\u001b[0m:           \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[32m'wandb'\u001b[0m\u001b[1m}\u001b[0m\u001b[1m]\u001b[0m,                                   \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                      \u001b[32m'storage'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1m{\u001b[0m\u001b[32m'keep'\u001b[0m: \u001b[1;36m-1\u001b[0m,        \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[32m'path'\u001b[0m: \u001b[32m'checkpoints'\u001b[0m, \u001b[32m'type'\u001b[0m: \u001b[32m'local'\u001b[0m\u001b[1m}\u001b[0m\u001b[1m]\u001b[0m\u001b[1m}\u001b[0m,   \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m          \u001b[32m'ckpt'\u001b[0m:                                     \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[32m'/kaggle/working/units/checkpoints/2024-07-1\u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[32m5T10.52.39.722116+00.00/ckpt-000000.pt'\u001b[0m,     \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m          \u001b[32m'dist_url'\u001b[0m: \u001b[32m'127.0.0.1:49152'\u001b[0m,              \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m          \u001b[32m'distributed'\u001b[0m: \u001b[3;92mTrue\u001b[0m,                        \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m          \u001b[32m'evaluate'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'datasources'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'datasource'\u001b[0m:  \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[1m{\u001b[0m\u001b[32m'__fn'\u001b[0m: \u001b[32m'units.datasource.LMDBSource'\u001b[0m\u001b[1m}\u001b[0m,     \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                       \u001b[32m'path'\u001b[0m:        \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[32m'train_datasets'\u001b[0m,                            \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                       \u001b[32m'sources'\u001b[0m:     \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[1m[\u001b[0m\u001b[32m'vintext_test.lmdb'\u001b[0m\u001b[1m]\u001b[0m\u001b[1m}\u001b[0m,                      \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                       \u001b[32m'eval_freq'\u001b[0m: \u001b[1;36m1000\u001b[0m,             \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                       \u001b[32m'eval_metrics'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,            \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                       \u001b[32m'eval_metrics_option'\u001b[0m: \u001b[3;35mNone\u001b[0m,   \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                       \u001b[32m'skip_evaluate'\u001b[0m: \u001b[3;92mTrue\u001b[0m,         \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                       \u001b[32m'transform'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1m{\u001b[0m\u001b[32m'__args'\u001b[0m:       \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[1m[\u001b[0m\u001b[1;36m1920\u001b[0m\u001b[1m]\u001b[0m,                                      \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                      \u001b[32m'__init'\u001b[0m:       \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[32m'units.transform.Resize'\u001b[0m\u001b[1m}\u001b[0m,                   \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                     \u001b[1m{\u001b[0m\u001b[32m'__args'\u001b[0m:       \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1920\u001b[0m, \u001b[1;36m1920\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m,                              \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                      \u001b[32m'__init'\u001b[0m:       \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[32m'units.augment.ExpandPAD'\u001b[0m\u001b[1m}\u001b[0m,                  \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                     \u001b[1m{\u001b[0m\u001b[32m'__init'\u001b[0m:       \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[32m'units.transform.ToTensor'\u001b[0m\u001b[1m}\u001b[0m,                 \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                     \u001b[1m{\u001b[0m\u001b[32m'__init'\u001b[0m:       \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[32m'units.transform.Normalize'\u001b[0m\u001b[1m}\u001b[0m\u001b[1m]\u001b[0m\u001b[1m}\u001b[0m,              \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m          \u001b[32m'finetune'\u001b[0m: \u001b[3;92mTrue\u001b[0m,                           \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m          \u001b[32m'launch_config'\u001b[0m: \u001b[1;35mLaunchConfig\u001b[0m\u001b[1m(\u001b[0m\u001b[33mmin_nodes\u001b[0m=\u001b[1;36m1\u001b[0m,  \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                        \u001b[33mmax_nodes\u001b[0m=\u001b[1;36m1\u001b[0m,  \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                        \u001b[33mnproc_per_nod\u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[33me\u001b[0m=\u001b[1;36m2\u001b[0m,                                         \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                        \u001b[33mrun_id\u001b[0m=\u001b[32m'none'\u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         ,                                            \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                        \u001b[33mrole\u001b[0m=\u001b[32m'default\u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[32m'\u001b[0m,                                           \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                        \u001b[33mrdzv_endpoint\u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         =\u001b[32m'127.0.0.1:49152'\u001b[0m,                          \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                        \u001b[33mrdzv_backend\u001b[0m= \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[32m'static'\u001b[0m,                                    \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                        \u001b[33mrdzv_configs\u001b[0m= \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[1m{\u001b[0m\u001b[32m'rank'\u001b[0m: \u001b[1;36m0\u001b[0m, \u001b[32m'timeout'\u001b[0m: \u001b[1;36m900\u001b[0m\u001b[1m}\u001b[0m,                 \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                        \u001b[33mrdzv_timeout\u001b[0m= \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[1;36m-1\u001b[0m,                                          \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                        \u001b[33mmax_restarts\u001b[0m= \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[1;36m0\u001b[0m,                                           \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                        \u001b[33mmonitor_inter\u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[33mval\u001b[0m=\u001b[1;36m5\u001b[0m,                                       \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                        \u001b[33mstart_method\u001b[0m= \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[32m'spawn'\u001b[0m,                                     \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                        \u001b[33mlog_dir\u001b[0m=\u001b[3;35mNone\u001b[0m, \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                        \u001b[33mredirects\u001b[0m=\u001b[1m<\u001b[0m\u001b[1;95mSt\u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[1;95md.NONE:\u001b[0m\u001b[39m \u001b[0m\u001b[1;36m0\u001b[0m\u001b[39m>,\u001b[0m                                  \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m                               \u001b[0m\u001b[33mtee\u001b[0m\u001b[39m=<Std.NONE\u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m: \u001b[0m\u001b[1;36m0\u001b[0m\u001b[39m>,\u001b[0m                                        \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m                               \u001b[0m\u001b[33mmetrics_cfg\u001b[0m\u001b[39m=\u001b[0m\u001b[1;39m{\u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[1;39m}\u001b[0m\u001b[39m,\u001b[0m                                           \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m                               \u001b[0m\u001b[33mlocal_addr\u001b[0m\u001b[39m=\u001b[0m\u001b[3;35mNo\u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[3;35mne\u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m,\u001b[0m                                         \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m \u001b[0m\u001b[32m'log_freq'\u001b[0m\u001b[39m: \u001b[0m\u001b[1;36m100\u001b[0m\u001b[39m,\u001b[0m                            \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m \u001b[0m\u001b[32m'logger'\u001b[0m\u001b[39m: \u001b[0m\u001b[32m'rich'\u001b[0m\u001b[39m,\u001b[0m                           \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m \u001b[0m\u001b[32m'machine_rank'\u001b[0m\u001b[39m: \u001b[0m\u001b[1;36m0\u001b[0m\u001b[39m,\u001b[0m                          \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m \u001b[0m\u001b[32m'model'\u001b[0m\u001b[39m: \u001b[0m\u001b[1;39m{\u001b[0m\u001b[32m'__args'\u001b[0m\u001b[39m: \u001b[0m\u001b[1;39m[\u001b[0m\u001b[1;36m1024\u001b[0m\u001b[39m,\u001b[0m                  \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m                      \u001b[0m\u001b[1;36m256\u001b[0m\u001b[39m,\u001b[0m                   \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m                      \u001b[0m\u001b[1;39m{\u001b[0m\u001b[32m'__args'\u001b[0m\u001b[39m: \u001b[0m\u001b[1;39m[\u001b[0m\u001b[1;39m{\u001b[0m\u001b[32m'__init'\u001b[0m\u001b[39m:\u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[32m'units.models.backbones.swin_transformer_b'\u001b[0m\u001b[39m,\u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m                                   \u001b[0m\u001b[32m'frozen_s\u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[32mtages'\u001b[0m\u001b[39m: \u001b[0m\u001b[1;36m-1\u001b[0m\u001b[39m,\u001b[0m                                  \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m                                   \u001b[0m\u001b[32m'pretrain\u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[32med'\u001b[0m\u001b[39m: \u001b[0m\u001b[3;91mFalse\u001b[0m\u001b[39m,\u001b[0m                                  \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m                                   \u001b[0m\u001b[32m'use_chec\u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[32mkpoint'\u001b[0m\u001b[39m: \u001b[0m\u001b[3;92mTrue\u001b[0m\u001b[1;39m}\u001b[0m\u001b[39m,\u001b[0m                              \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m                                  \u001b[0m\u001b[1;39m[\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;39m]\u001b[0m\u001b[39m,\u001b[0m      \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m                                  \u001b[0m\u001b[3;92mTrue\u001b[0m\u001b[1;39m]\u001b[0m\u001b[39m,\u001b[0m     \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m                       \u001b[0m\u001b[32m'__init'\u001b[0m\u001b[39m: \u001b[0m            \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[32m'units.models.VisionTransformer'\u001b[0m\u001b[1;39m}\u001b[0m\u001b[39m,\u001b[0m           \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m                      \u001b[0m\u001b[1;39m{\u001b[0m\u001b[32m'__args'\u001b[0m\u001b[39m: \u001b[0m\u001b[1;39m[\u001b[0m\u001b[1;36m256\u001b[0m\u001b[39m,\u001b[0m       \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m                                  \u001b[0m\u001b[1;36m25\u001b[0m\u001b[39m,\u001b[0m        \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m                                  \u001b[0m\u001b[1;39m{\u001b[0m\u001b[32m'__args'\u001b[0m\u001b[39m:\u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[1;39m[\u001b[0m\u001b[1;39m[\u001b[0m\u001b[1;39m{\u001b[0m\u001b[32m'__args'\u001b[0m\u001b[39m: \u001b[0m\u001b[1;39m[\u001b[0m\u001b[1;36m256\u001b[0m\u001b[39m, \u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;39m]\u001b[0m\u001b[39m,\u001b[0m                       \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m                                            \u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m    \u001b[0m\u001b[32m'__init'\u001b[0m\u001b[39m: \u001b[0m                               \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[32m'units.models.transformer.TransformerDecoder\u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[32mLayer'\u001b[0m\u001b[39m,\u001b[0m                                      \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m                                            \u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m    \u001b[0m\u001b[32m'n_experts'\u001b[0m\u001b[39m: \u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;39m}\u001b[0m\u001b[39m,\u001b[0m                         \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m                                            \u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m   \u001b[0m\u001b[1;39m{\u001b[0m\u001b[32m'__args'\u001b[0m\u001b[39m: \u001b[0m\u001b[1;39m[\u001b[0m\u001b[1;36m256\u001b[0m\u001b[39m, \u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;39m]\u001b[0m\u001b[39m,\u001b[0m                      \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m                                            \u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m    \u001b[0m\u001b[32m'__init'\u001b[0m\u001b[39m: \u001b[0m                               \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[32m'units.models.transformer.TransformerDecoder\u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[32mLayer'\u001b[0m\u001b[39m,\u001b[0m                                      \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m                                            \u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m    \u001b[0m\u001b[32m'n_experts'\u001b[0m\u001b[39m: \u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;39m}\u001b[0m\u001b[39m,\u001b[0m                         \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m                                            \u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m   \u001b[0m\u001b[1;39m{\u001b[0m\u001b[32m'__args'\u001b[0m\u001b[39m: \u001b[0m\u001b[1;39m[\u001b[0m\u001b[1;36m256\u001b[0m\u001b[39m, \u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;39m]\u001b[0m\u001b[39m,\u001b[0m                      \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m                                            \u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m    \u001b[0m\u001b[32m'__init'\u001b[0m\u001b[39m: \u001b[0m                               \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[32m'units.models.transformer.TransformerDecoder\u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[32mLayer'\u001b[0m\u001b[39m,\u001b[0m                                      \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m                                            \u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m    \u001b[0m\u001b[32m'n_experts'\u001b[0m\u001b[39m: \u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;39m}\u001b[0m\u001b[39m,\u001b[0m                         \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m                                            \u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m   \u001b[0m\u001b[1;39m{\u001b[0m\u001b[32m'__args'\u001b[0m\u001b[39m: \u001b[0m\u001b[1;39m[\u001b[0m\u001b[1;36m256\u001b[0m\u001b[39m, \u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;39m]\u001b[0m\u001b[39m,\u001b[0m                      \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m                                            \u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m    \u001b[0m\u001b[32m'__init'\u001b[0m\u001b[39m: \u001b[0m                               \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[32m'units.models.transformer.TransformerDecoder\u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[32mLayer'\u001b[0m\u001b[39m,\u001b[0m                                      \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m                                            \u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m    \u001b[0m\u001b[32m'n_experts'\u001b[0m\u001b[39m: \u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;39m}\u001b[0m\u001b[39m,\u001b[0m                         \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m                                            \u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m   \u001b[0m\u001b[1;39m{\u001b[0m\u001b[32m'__args'\u001b[0m\u001b[39m: \u001b[0m\u001b[1;39m[\u001b[0m\u001b[1;36m256\u001b[0m\u001b[39m, \u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;39m]\u001b[0m\u001b[39m,\u001b[0m                      \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m                                            \u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m    \u001b[0m\u001b[32m'__init'\u001b[0m\u001b[39m: \u001b[0m                               \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[32m'units.models.transformer.TransformerDecoder\u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[32mLayer'\u001b[0m\u001b[39m,\u001b[0m                                      \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m                                            \u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m    \u001b[0m\u001b[32m'n_experts'\u001b[0m\u001b[39m: \u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;39m}\u001b[0m\u001b[39m,\u001b[0m                         \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m                                            \u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m   \u001b[0m\u001b[1;39m{\u001b[0m\u001b[32m'__args'\u001b[0m\u001b[39m: \u001b[0m\u001b[1;39m[\u001b[0m\u001b[1;36m256\u001b[0m\u001b[39m, \u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;39m]\u001b[0m\u001b[39m,\u001b[0m                      \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m                                            \u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m    \u001b[0m\u001b[32m'__init'\u001b[0m\u001b[39m: \u001b[0m                               \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[32m'units.models.transformer.TransformerDecoder\u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[32mLayer'\u001b[0m\u001b[39m,\u001b[0m                                      \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m                                            \u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m    \u001b[0m\u001b[32m'n_experts'\u001b[0m\u001b[39m: \u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;39m}\u001b[0m\u001b[39m,\u001b[0m                         \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m                                            \u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m   \u001b[0m\u001b[1;39m{\u001b[0m\u001b[32m'__args'\u001b[0m\u001b[39m: \u001b[0m\u001b[1;39m[\u001b[0m\u001b[1;36m256\u001b[0m\u001b[39m, \u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;39m]\u001b[0m\u001b[39m,\u001b[0m                      \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m                                            \u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m    \u001b[0m\u001b[32m'__init'\u001b[0m\u001b[39m: \u001b[0m                               \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[32m'units.models.transformer.TransformerDecoder\u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[32mLayer'\u001b[0m\u001b[39m,\u001b[0m                                      \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m                                            \u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m    \u001b[0m\u001b[32m'n_experts'\u001b[0m\u001b[39m: \u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;39m}\u001b[0m\u001b[39m,\u001b[0m                         \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m                                            \u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m   \u001b[0m\u001b[1;39m{\u001b[0m\u001b[32m'__args'\u001b[0m\u001b[39m: \u001b[0m\u001b[1;39m[\u001b[0m\u001b[1;36m256\u001b[0m\u001b[39m, \u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;39m]\u001b[0m\u001b[39m,\u001b[0m                      \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m                                            \u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m    \u001b[0m\u001b[32m'__init'\u001b[0m\u001b[39m: \u001b[0m                               \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[32m'units.models.transformer.TransformerDecoder\u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[32mLayer'\u001b[0m\u001b[39m,\u001b[0m                                      \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m                                            \u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m    \u001b[0m\u001b[32m'n_experts'\u001b[0m\u001b[39m: \u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;39m}\u001b[0m\u001b[1;39m]\u001b[0m\u001b[1;39m]\u001b[0m\u001b[39m,\u001b[0m                       \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m                                   \u001b[0m\u001b[32m'__init'\u001b[0m\u001b[39m:\u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[32m'units.models.transformer.TransformerDecoder\u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[32m'\u001b[0m\u001b[39m,\u001b[0m                                           \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m                                   \u001b[0m\u001b[32m'autoregr\u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[32messive'\u001b[0m\u001b[39m: \u001b[0m\u001b[3;92mTrue\u001b[0m\u001b[1;39m}\u001b[0m\u001b[39m,\u001b[0m                              \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m                                  \u001b[0m\u001b[1;39m{\u001b[0m\u001b[32m'__init'\u001b[0m\u001b[39m:\u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[32m'torch.nn.CrossEntropyLoss'\u001b[0m\u001b[39m,\u001b[0m                 \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m                                   \u001b[0m\u001b[32m'ignore_i\u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[32mndex'\u001b[0m\u001b[39m: \u001b[0m\u001b[1;36m-100\u001b[0m\u001b[1;39m}\u001b[0m\u001b[39m,\u001b[0m                                \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m                                  \u001b[0m\u001b[1;36m100\u001b[0m\u001b[39m,\u001b[0m       \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m                                  \u001b[0m\u001b[1;36m1024\u001b[0m\u001b[39m,\u001b[0m      \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m                                  <units.tok\u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39menizer.UnitsTokenizer object at \u001b[0m             \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[1;36m0x7ce03410ae60\u001b[0m\u001b[39m>\u001b[0m\u001b[1;39m]\u001b[0m\u001b[39m,\u001b[0m                            \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m                       \u001b[0m\u001b[32m'__init'\u001b[0m\u001b[39m: \u001b[0m            \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[32m'units.models.UnitsDecoder'\u001b[0m\u001b[39m,\u001b[0m                 \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m                       \u001b[0m\u001b[32m'coord_order'\u001b[0m\u001b[39m: \u001b[0m\u001b[32m'xy'\u001b[0m\u001b[39m,\u001b[0m  \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m                       \u001b[0m\u001b[32m'detect_type'\u001b[0m\u001b[39m: \u001b[0m       \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[32m'quad'\u001b[0m\u001b[39m,\u001b[0m                                      \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m                       \u001b[0m\u001b[32m'fixed_text_len'\u001b[0m\u001b[39m: \u001b[0m    \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[3;92mTrue\u001b[0m\u001b[39m,\u001b[0m                                        \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m                       \u001b[0m\u001b[32m'iterative_decoding'\u001b[0m\u001b[39m:\u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[3;92mTrue\u001b[0m\u001b[39m,\u001b[0m                                        \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m                       \u001b[0m\u001b[32m'prompt'\u001b[0m\u001b[39m: \u001b[0m\u001b[32m'point'\u001b[0m\u001b[1;39m}\u001b[0m\u001b[1;39m]\u001b[0m\u001b[39m,\u001b[0m  \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m           \u001b[0m\u001b[32m'__init'\u001b[0m\u001b[39m: \u001b[0m\u001b[32m'units.models.Units'\u001b[0m\u001b[39m,\u001b[0m   \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m           \u001b[0m\u001b[32m'wo_source_pos_encod'\u001b[0m\u001b[39m: \u001b[0m\u001b[3;92mTrue\u001b[0m\u001b[1;39m}\u001b[0m\u001b[39m,\u001b[0m     \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m \u001b[0m\u001b[32m'n_gpu'\u001b[0m\u001b[39m: \u001b[0m\u001b[1;36m2\u001b[0m\u001b[39m,\u001b[0m                                 \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m \u001b[0m\u001b[32m'n_machine'\u001b[0m\u001b[39m: \u001b[0m\u001b[1;36m1\u001b[0m\u001b[39m,\u001b[0m                             \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m \u001b[0m\u001b[32m'training'\u001b[0m\u001b[39m: \u001b[0m\u001b[1;39m{\u001b[0m\u001b[32m'clip_grad'\u001b[0m\u001b[39m: \u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[39m,\u001b[0m              \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m              \u001b[0m\u001b[32m'datasources'\u001b[0m\u001b[39m: \u001b[0m\u001b[1;39m{\u001b[0m\u001b[32m'datasource'\u001b[0m\u001b[39m: \u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[1;39m{\u001b[0m\u001b[32m'__fn'\u001b[0m\u001b[39m: \u001b[0m\u001b[32m'units.datasource.LMDBSource'\u001b[0m\u001b[1;39m}\u001b[0m\u001b[39m,\u001b[0m     \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m                              \u001b[0m\u001b[32m'path'\u001b[0m\u001b[39m: \u001b[0m       \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[32m'train_datasets'\u001b[0m\u001b[39m,\u001b[0m                            \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m                              \u001b[0m\u001b[32m'sources'\u001b[0m\u001b[39m: \u001b[0m    \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[1;39m[\u001b[0m\u001b[1;39m(\u001b[0m\u001b[32m'vintext_train.lmdb'\u001b[0m\u001b[39m, \u001b[0m\u001b[1;36m12.0\u001b[0m\u001b[1;39m)\u001b[0m\u001b[1;39m]\u001b[0m\u001b[1;39m}\u001b[0m\u001b[39m,\u001b[0m             \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m              \u001b[0m\u001b[32m'img_multiple'\u001b[0m\u001b[39m: \u001b[0m\u001b[1;36m32\u001b[0m\u001b[39m,\u001b[0m            \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m              \u001b[0m\u001b[32m'loader'\u001b[0m\u001b[39m: \u001b[0m\u001b[1;39m{\u001b[0m\u001b[32m'batch_size'\u001b[0m\u001b[39m: \u001b[0m\u001b[1;36m5\u001b[0m\u001b[39m,\u001b[0m    \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m                         \u001b[0m\u001b[32m'drop_last'\u001b[0m\u001b[39m: \u001b[0m\u001b[3;91mFalse\u001b[0m\u001b[39m,\u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m                         \u001b[0m\u001b[32m'num_workers'\u001b[0m\u001b[39m: \u001b[0m\u001b[1;36m2\u001b[0m\u001b[39m,\u001b[0m   \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m                         \u001b[0m\u001b[32m'pin_memory'\u001b[0m\u001b[39m: \u001b[0m      \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[3;91mFalse\u001b[0m\u001b[39m,\u001b[0m                                       \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m                         \u001b[0m\u001b[32m'shuffle'\u001b[0m\u001b[39m: \u001b[0m\u001b[3;92mTrue\u001b[0m\u001b[39m,\u001b[0m    \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m                         \u001b[0m\u001b[32m'timeout'\u001b[0m\u001b[39m: \u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;39m}\u001b[0m\u001b[39m,\u001b[0m      \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[39m              \u001b[0m\u001b[32m'mappers'\u001b[0m\u001b[39m: \u001b[0m\u001b[1;39m[\u001b[0m\u001b[1;39m{\u001b[0m\u001b[32m'__args'\u001b[0m\u001b[39m: \u001b[0m        \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[1;39m[\u001b[0m\u001b[39m<units.tokenizer.UnitsTokenizer object at \u001b[0m  \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[1;36m0x7ce03410ae60\u001b[0m\u001b[1m>\u001b[0m,                             \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                               \u001b[1;36m25\u001b[0m\u001b[1m]\u001b[0m,   \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                    \u001b[32m'__init'\u001b[0m:         \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[32m'units.models.UnitsMapper'\u001b[0m,                  \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                    \u001b[32m'all_unks_remove'\u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         : \u001b[3;91mFalse\u001b[0m,                                     \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                    \u001b[32m'coord_order'\u001b[0m:    \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[32m'xy'\u001b[0m,                                        \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                    \u001b[32m'dcs_inputs'\u001b[0m:     \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[3;92mTrue\u001b[0m,                                        \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                    \u001b[32m'decoder_length'\u001b[0m: \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[1;36m1024\u001b[0m,                                        \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                    \u001b[32m'fixed_text_len'\u001b[0m: \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[3;92mTrue\u001b[0m,                                        \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                    \u001b[32m'ignore_idx'\u001b[0m:     \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[1;36m-100\u001b[0m,                                        \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                    \u001b[32m'iou_filtering'\u001b[0m:  \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[3;91mFalse\u001b[0m,                                       \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                    \u001b[32m'n_object'\u001b[0m: \u001b[1;36m100\u001b[0m,  \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                    \u001b[32m'prompt'\u001b[0m:         \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[32m'point'\u001b[0m\u001b[1m}\u001b[0m\u001b[1m]\u001b[0m,                                   \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                       \u001b[32m'mixed_precision'\u001b[0m: \u001b[3;91mFalse\u001b[0m,      \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                       \u001b[32m'n_iter'\u001b[0m: \u001b[1;36m5001\u001b[0m,                \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                       \u001b[32m'optimizer'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'amsgrad'\u001b[0m:       \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[3;91mFalse\u001b[0m,                                       \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                     \u001b[32m'betas'\u001b[0m: \u001b[1m(\u001b[0m\u001b[1;36m0.9\u001b[0m,   \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[1;36m0.999\u001b[0m\u001b[1m)\u001b[0m,                                      \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                     \u001b[32m'eps'\u001b[0m: \u001b[1;36m1e-08\u001b[0m,    \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                     \u001b[32m'lr'\u001b[0m: \u001b[1;36m3e-05\u001b[0m,     \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                     \u001b[32m'type'\u001b[0m: \u001b[32m'adamw'\u001b[0m, \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                     \u001b[32m'weight_decay'\u001b[0m:  \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[1;36m0\u001b[0m\u001b[1m}\u001b[0m,                                          \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                       \u001b[32m'resume_ckpt_freq'\u001b[0m: \u001b[1;36m100\u001b[0m,       \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                       \u001b[32m'scheduler'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'type'\u001b[0m:          \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[32m'constant'\u001b[0m\u001b[1m}\u001b[0m,                                 \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                       \u001b[32m'transform'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1m{\u001b[0m\u001b[32m'__args'\u001b[0m:       \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1m{\u001b[0m\u001b[32m'__args'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1;36m-45\u001b[0m, \u001b[1;36m45\u001b[0m\u001b[1m]\u001b[0m,                     \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                                    \u001b[32m'\u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[32m__init'\u001b[0m: \u001b[32m'units.augment.RandomRotate'\u001b[0m\u001b[1m}\u001b[0m,      \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                                   \u001b[1;36m0.\u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[1;36m333\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m,                                      \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                      \u001b[32m'__init'\u001b[0m:       \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[32m'units.augment.RandomSelect'\u001b[0m\u001b[1m}\u001b[0m,               \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                     \u001b[1m{\u001b[0m\u001b[32m'__args'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1;36m1.0\u001b[0m, \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[1;36m1.0\u001b[0m, \u001b[1m[\u001b[0m\u001b[1;36m1920\u001b[0m, \u001b[1;36m1920\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m,                          \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                      \u001b[32m'__init'\u001b[0m:       \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[32m'units.augment.RandomResizeScale'\u001b[0m\u001b[1m}\u001b[0m,          \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                     \u001b[1m{\u001b[0m\u001b[32m'__args'\u001b[0m:       \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1920\u001b[0m, \u001b[1;36m1920\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m,                              \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                      \u001b[32m'__init'\u001b[0m:       \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[32m'units.augment.ExpandPAD'\u001b[0m\u001b[1m}\u001b[0m,                  \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                     \u001b[1m{\u001b[0m\u001b[32m'__args'\u001b[0m:       \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[1m[\u001b[0m\u001b[1m{\u001b[0m\u001b[32m'__args'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1;36m0.4\u001b[0m, \u001b[1;36m0.4\u001b[0m, \u001b[1;36m0.2\u001b[0m, \u001b[1;36m0.1\u001b[0m\u001b[1m]\u001b[0m,            \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                                  \u001b[32m'__\u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[32minit'\u001b[0m: \u001b[32m'units.augment.ColorJitter'\u001b[0m\u001b[1m}\u001b[0m,         \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                                 \u001b[1;36m0.8\u001b[0m\u001b[1m]\u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         ,                                            \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                      \u001b[32m'__init'\u001b[0m:       \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[32m'units.augment.RandomApply'\u001b[0m\u001b[1m}\u001b[0m,                \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                     \u001b[1m{\u001b[0m\u001b[32m'__args'\u001b[0m:       \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[1m[\u001b[0m\u001b[1m{\u001b[0m\u001b[32m'__init'\u001b[0m: \u001b[32m'units.transform.Grayscale'\u001b[0m\u001b[1m}\u001b[0m,    \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                                 \u001b[1;36m0.3\u001b[0m\u001b[1m]\u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         ,                                            \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                      \u001b[32m'__init'\u001b[0m:       \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[32m'units.augment.RandomApply'\u001b[0m\u001b[1m}\u001b[0m,                \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                     \u001b[1m{\u001b[0m\u001b[32m'__args'\u001b[0m:       \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1m{\u001b[0m\u001b[32m'__init'\u001b[0m:                                \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[32m'units.augment.RandomGaussianBlur'\u001b[0m\u001b[1m}\u001b[0m,         \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                                   \u001b[1;36m0.\u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[1;36m3\u001b[0m\u001b[1m]\u001b[0m,                                          \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                                  \u001b[1m[\u001b[0m\u001b[1m{\u001b[0m\u001b[32m'\u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[32m__init'\u001b[0m: \u001b[32m'units.augment.RandomUnsharpMask'\u001b[0m\u001b[1m}\u001b[0m, \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                                   \u001b[1;36m0.\u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[1;36m1\u001b[0m\u001b[1m]\u001b[0m,                                          \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                                  \u001b[1m[\u001b[0m\u001b[1m{\u001b[0m\u001b[32m'\u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[32m__init'\u001b[0m: \u001b[32m'units.transform.EdgeEnhance'\u001b[0m\u001b[1m}\u001b[0m,     \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                                   \u001b[1;36m0.\u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[1;36m1\u001b[0m\u001b[1m]\u001b[0m,                                          \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                                  \u001b[1m[\u001b[0m\u001b[1m{\u001b[0m\u001b[32m'\u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[32m__args'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1m{\u001b[0m\u001b[32m'__init'\u001b[0m:                        \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[32m'units.augment.RandomUnsharpMask'\u001b[0m\u001b[1m}\u001b[0m,          \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                                      \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                    \u001b[1m{\u001b[0m\u001b[32m'__init'\u001b[0m:                        \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[32m'units.transform.EdgeEnhance'\u001b[0m\u001b[1m}\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m,            \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                                    \u001b[32m'\u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[32m__init'\u001b[0m: \u001b[32m'units.transform.Compose'\u001b[0m\u001b[1m}\u001b[0m,         \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                                   \u001b[1;36m0.\u001b[0m \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[1;36m1\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m,                                        \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                      \u001b[32m'__init'\u001b[0m:       \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[32m'units.augment.RandomSelect'\u001b[0m\u001b[1m}\u001b[0m,               \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                     \u001b[1m{\u001b[0m\u001b[32m'__init'\u001b[0m:       \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[32m'units.transform.ToTensor'\u001b[0m\u001b[1m}\u001b[0m,                 \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                     \u001b[1m{\u001b[0m\u001b[32m'__init'\u001b[0m:       \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[32m'units.transform.Normalize'\u001b[0m\u001b[1m}\u001b[0m\u001b[1m]\u001b[0m,               \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                       \u001b[32m'val_loader'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'batch_size'\u001b[0m:   \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[1;36m12\u001b[0m,                                          \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                      \u001b[32m'drop_last'\u001b[0m:    \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[3;91mFalse\u001b[0m,                                       \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                      \u001b[32m'num_workers'\u001b[0m:  \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[1;36m6\u001b[0m,                                           \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                      \u001b[32m'pin_memory'\u001b[0m:   \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[3;91mFalse\u001b[0m,                                       \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                      \u001b[32m'shuffle'\u001b[0m:      \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m         \u001b[3;91mFalse\u001b[0m,                                       \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                                      \u001b[32m'timeout'\u001b[0m: \u001b[1;36m0\u001b[0m\u001b[1m}\u001b[0m,  \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                       \u001b[32m'wd_skip_fn'\u001b[0m: \u001b[32m'vit'\u001b[0m,           \u001b[2m           \u001b[0m\n\u001b[2;36m               \u001b[0m                       \u001b[32m'weight_decay'\u001b[0m: \u001b[1;36m0.0001\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m       \u001b[2m           \u001b[0m\nfrozen ne  -1\nDay la pretrained  False\nfrozen ne  -1\nDay la pretrained  False\nn_vocab ne  1117\nn_vocab ne  1117\n#0 vintext_test.lmdb total: 500 \n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcolabnguyen082\u001b[0m (\u001b[33mphuc-honor-hcmus\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\nfrozen ne  -1\n\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.17.4 is available!  To upgrade, please run:\n\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.17.0\n\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/units/wandb/run-20240715_111907-usxitgsi\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33munitsonvintextbynp\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/phuc-honor-hcmus/units\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/phuc-honor-hcmus/units/runs/usxitgsi\u001b[0m\n^C\n[2024-07-15 11:19:29,109] torch.distributed.elastic.agent.server.api: [WARNING] Received Signals.SIGINT death signal, shutting down workers\n[2024-07-15 11:19:29,110] torch.distributed.elastic.multiprocessing.api: [WARNING] Closing process 896 via signal SIGINT\n[2024-07-15 11:19:29,110] torch.distributed.elastic.multiprocessing.api: [WARNING] Closing process 897 via signal SIGINT\n","output_type":"stream"}]},{"cell_type":"code","source":"!tar -zcvf \"./res_output_ke4ne5.tar.gz\" \"./res_output\"\nFileLink(r'../units/res_output_ke4ne5.tar.gz')","metadata":{},"execution_count":null,"outputs":[]}]}